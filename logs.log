2025-02-05 22:04:58,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-05 22:04:58,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-05 22:04:58,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-05 22:04:58,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 09:32:17,796:INFO:PyCaret ClassificationExperiment
2025-02-06 09:32:17,796:INFO:Logging name: clf-default-name
2025-02-06 09:32:17,796:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 09:32:17,796:INFO:version 3.3.2
2025-02-06 09:32:17,796:INFO:Initializing setup()
2025-02-06 09:32:17,797:INFO:self.USI: a792
2025-02-06 09:32:17,797:INFO:self._variable_keys: {'seed', 'memory', 'y_train', 'log_plots_param', 'y_test', 'data', 'y', 'fold_generator', 'html_param', 'target_param', 'X_test', '_ml_usecase', 'idx', 'fold_shuffle_param', 'exp_id', 'logging_param', 'USI', 'fold_groups_param', 'n_jobs_param', 'X', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'exp_name_log', '_available_plots', 'gpu_param', 'fix_imbalance'}
2025-02-06 09:32:17,797:INFO:Checking environment
2025-02-06 09:32:17,797:INFO:python_version: 3.11.9
2025-02-06 09:32:17,797:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 09:32:17,797:INFO:machine: AMD64
2025-02-06 09:32:17,797:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 09:32:17,801:INFO:Memory: svmem(total=67771465728, available=50641584128, percent=25.3, used=17129881600, free=50641584128)
2025-02-06 09:32:17,801:INFO:Physical Core: 8
2025-02-06 09:32:17,801:INFO:Logical Core: 16
2025-02-06 09:32:17,801:INFO:Checking libraries
2025-02-06 09:32:17,801:INFO:System:
2025-02-06 09:32:17,801:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 09:32:17,801:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 09:32:17,801:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 09:32:17,801:INFO:PyCaret required dependencies:
2025-02-06 09:32:17,843:INFO:                 pip: 25.0
2025-02-06 09:32:17,843:INFO:          setuptools: 65.5.0
2025-02-06 09:32:17,843:INFO:             pycaret: 3.3.2
2025-02-06 09:32:17,843:INFO:             IPython: 8.32.0
2025-02-06 09:32:17,843:INFO:          ipywidgets: 8.1.5
2025-02-06 09:32:17,843:INFO:                tqdm: 4.67.1
2025-02-06 09:32:17,843:INFO:               numpy: 1.26.4
2025-02-06 09:32:17,843:INFO:              pandas: 2.1.4
2025-02-06 09:32:17,843:INFO:              jinja2: 3.1.5
2025-02-06 09:32:17,843:INFO:               scipy: 1.11.4
2025-02-06 09:32:17,843:INFO:              joblib: 1.3.2
2025-02-06 09:32:17,843:INFO:             sklearn: 1.4.2
2025-02-06 09:32:17,843:INFO:                pyod: 2.0.3
2025-02-06 09:32:17,843:INFO:            imblearn: 0.13.0
2025-02-06 09:32:17,843:INFO:   category_encoders: 2.7.0
2025-02-06 09:32:17,843:INFO:            lightgbm: 4.5.0
2025-02-06 09:32:17,843:INFO:               numba: 0.61.0
2025-02-06 09:32:17,843:INFO:            requests: 2.32.3
2025-02-06 09:32:17,843:INFO:          matplotlib: 3.7.5
2025-02-06 09:32:17,843:INFO:          scikitplot: 0.3.7
2025-02-06 09:32:17,843:INFO:         yellowbrick: 1.5
2025-02-06 09:32:17,843:INFO:              plotly: 5.24.1
2025-02-06 09:32:17,843:INFO:    plotly-resampler: Not installed
2025-02-06 09:32:17,843:INFO:             kaleido: 0.2.1
2025-02-06 09:32:17,843:INFO:           schemdraw: 0.15
2025-02-06 09:32:17,843:INFO:         statsmodels: 0.14.4
2025-02-06 09:32:17,843:INFO:              sktime: 0.26.0
2025-02-06 09:32:17,844:INFO:               tbats: 1.1.3
2025-02-06 09:32:17,844:INFO:            pmdarima: 2.0.4
2025-02-06 09:32:17,844:INFO:              psutil: 6.1.1
2025-02-06 09:32:17,844:INFO:          markupsafe: 3.0.2
2025-02-06 09:32:17,844:INFO:             pickle5: Not installed
2025-02-06 09:32:17,844:INFO:         cloudpickle: 3.1.1
2025-02-06 09:32:17,844:INFO:         deprecation: 2.1.0
2025-02-06 09:32:17,844:INFO:              xxhash: 3.5.0
2025-02-06 09:32:17,844:INFO:           wurlitzer: Not installed
2025-02-06 09:32:17,844:INFO:PyCaret optional dependencies:
2025-02-06 09:32:17,849:INFO:                shap: Not installed
2025-02-06 09:32:17,850:INFO:           interpret: Not installed
2025-02-06 09:32:17,850:INFO:                umap: Not installed
2025-02-06 09:32:17,850:INFO:     ydata_profiling: Not installed
2025-02-06 09:32:17,850:INFO:  explainerdashboard: Not installed
2025-02-06 09:32:17,850:INFO:             autoviz: Not installed
2025-02-06 09:32:17,850:INFO:           fairlearn: Not installed
2025-02-06 09:32:17,850:INFO:          deepchecks: Not installed
2025-02-06 09:32:17,850:INFO:             xgboost: Not installed
2025-02-06 09:32:17,850:INFO:            catboost: Not installed
2025-02-06 09:32:17,850:INFO:              kmodes: Not installed
2025-02-06 09:32:17,850:INFO:             mlxtend: Not installed
2025-02-06 09:32:17,850:INFO:       statsforecast: Not installed
2025-02-06 09:32:17,850:INFO:        tune_sklearn: Not installed
2025-02-06 09:32:17,850:INFO:                 ray: Not installed
2025-02-06 09:32:17,850:INFO:            hyperopt: Not installed
2025-02-06 09:32:17,850:INFO:              optuna: Not installed
2025-02-06 09:32:17,850:INFO:               skopt: Not installed
2025-02-06 09:32:17,850:INFO:              mlflow: Not installed
2025-02-06 09:32:17,850:INFO:              gradio: Not installed
2025-02-06 09:32:17,850:INFO:             fastapi: Not installed
2025-02-06 09:32:17,850:INFO:             uvicorn: Not installed
2025-02-06 09:32:17,850:INFO:              m2cgen: Not installed
2025-02-06 09:32:17,850:INFO:           evidently: Not installed
2025-02-06 09:32:17,850:INFO:               fugue: Not installed
2025-02-06 09:32:17,850:INFO:           streamlit: Not installed
2025-02-06 09:32:17,850:INFO:             prophet: Not installed
2025-02-06 09:32:17,850:INFO:None
2025-02-06 09:32:17,850:INFO:Set up data.
2025-02-06 09:32:17,864:INFO:Set up folding strategy.
2025-02-06 09:32:17,864:INFO:Set up train/test split.
2025-02-06 09:32:17,876:INFO:Set up index.
2025-02-06 09:32:17,876:INFO:Assigning column types.
2025-02-06 09:32:17,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 09:32:17,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 09:32:17,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:32:17,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:17,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:17,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 09:32:17,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:32:17,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:17,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:17,971:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 09:32:17,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:32:18,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:32:18,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 09:32:18,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,126:INFO:Preparing preprocessing pipeline...
2025-02-06 09:32:18,128:INFO:Set up simple imputation.
2025-02-06 09:32:18,168:INFO:Finished creating preprocessing pipeline.
2025-02-06 09:32:18,170:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'safra', 'VAR_1', 'VAR_2',
                                             'VAR_3', 'VAR_4', 'VAR_5', 'VAR_6',
                                             'VAR_7', 'VAR_8', 'VAR_9',
                                             'VAR_10', 'VAR_11', 'VAR_12',
                                             'VAR_13', 'VAR_14', 'VAR_15',
                                             'VAR_16', 'VAR_17', 'VAR_18',
                                             'VAR_19', 'VAR_20', 'VAR_21',
                                             'VAR_22...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 09:32:18,170:INFO:Creating final display dataframe.
2025-02-06 09:32:18,290:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 81)
4        Transformed data shape        (8211, 81)
5   Transformed train set shape        (5747, 81)
6    Transformed test set shape        (2464, 81)
7              Numeric features                80
8      Rows with missing values             99.7%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a792
2025-02-06 09:32:18,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:32:18,376:INFO:setup() successfully completed in 0.58s...............
2025-02-06 09:34:58,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 09:34:58,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 09:34:58,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 09:34:58,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 09:34:59,106:INFO:PyCaret ClassificationExperiment
2025-02-06 09:34:59,106:INFO:Logging name: clf-default-name
2025-02-06 09:34:59,106:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 09:34:59,106:INFO:version 3.3.2
2025-02-06 09:34:59,106:INFO:Initializing setup()
2025-02-06 09:34:59,106:INFO:self.USI: 286d
2025-02-06 09:34:59,106:INFO:self._variable_keys: {'is_multiclass', 'gpu_n_jobs_param', 'y_test', 'exp_name_log', 'fold_groups_param', 'target_param', 'logging_param', 'memory', 'y_train', 'y', 'html_param', '_ml_usecase', 'fix_imbalance', 'gpu_param', 'data', 'USI', 'X', 'pipeline', 'exp_id', 'n_jobs_param', 'idx', 'fold_shuffle_param', 'log_plots_param', 'fold_generator', '_available_plots', 'seed', 'X_test', 'X_train'}
2025-02-06 09:34:59,106:INFO:Checking environment
2025-02-06 09:34:59,106:INFO:python_version: 3.11.9
2025-02-06 09:34:59,106:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 09:34:59,106:INFO:machine: AMD64
2025-02-06 09:34:59,106:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 09:34:59,112:INFO:Memory: svmem(total=67771465728, available=50910990336, percent=24.9, used=16860475392, free=50910990336)
2025-02-06 09:34:59,112:INFO:Physical Core: 8
2025-02-06 09:34:59,112:INFO:Logical Core: 16
2025-02-06 09:34:59,112:INFO:Checking libraries
2025-02-06 09:34:59,112:INFO:System:
2025-02-06 09:34:59,112:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 09:34:59,113:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 09:34:59,113:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 09:34:59,113:INFO:PyCaret required dependencies:
2025-02-06 09:34:59,124:INFO:                 pip: 25.0
2025-02-06 09:34:59,124:INFO:          setuptools: 65.5.0
2025-02-06 09:34:59,124:INFO:             pycaret: 3.3.2
2025-02-06 09:34:59,124:INFO:             IPython: 8.32.0
2025-02-06 09:34:59,124:INFO:          ipywidgets: 8.1.5
2025-02-06 09:34:59,124:INFO:                tqdm: 4.67.1
2025-02-06 09:34:59,124:INFO:               numpy: 1.26.4
2025-02-06 09:34:59,124:INFO:              pandas: 2.1.4
2025-02-06 09:34:59,124:INFO:              jinja2: 3.1.5
2025-02-06 09:34:59,124:INFO:               scipy: 1.11.4
2025-02-06 09:34:59,124:INFO:              joblib: 1.3.2
2025-02-06 09:34:59,124:INFO:             sklearn: 1.4.2
2025-02-06 09:34:59,124:INFO:                pyod: 2.0.3
2025-02-06 09:34:59,124:INFO:            imblearn: 0.13.0
2025-02-06 09:34:59,124:INFO:   category_encoders: 2.7.0
2025-02-06 09:34:59,124:INFO:            lightgbm: 4.5.0
2025-02-06 09:34:59,124:INFO:               numba: 0.61.0
2025-02-06 09:34:59,124:INFO:            requests: 2.32.3
2025-02-06 09:34:59,124:INFO:          matplotlib: 3.7.5
2025-02-06 09:34:59,124:INFO:          scikitplot: 0.3.7
2025-02-06 09:34:59,124:INFO:         yellowbrick: 1.5
2025-02-06 09:34:59,124:INFO:              plotly: 5.24.1
2025-02-06 09:34:59,124:INFO:    plotly-resampler: Not installed
2025-02-06 09:34:59,124:INFO:             kaleido: 0.2.1
2025-02-06 09:34:59,124:INFO:           schemdraw: 0.15
2025-02-06 09:34:59,124:INFO:         statsmodels: 0.14.4
2025-02-06 09:34:59,124:INFO:              sktime: 0.26.0
2025-02-06 09:34:59,124:INFO:               tbats: 1.1.3
2025-02-06 09:34:59,124:INFO:            pmdarima: 2.0.4
2025-02-06 09:34:59,124:INFO:              psutil: 6.1.1
2025-02-06 09:34:59,124:INFO:          markupsafe: 3.0.2
2025-02-06 09:34:59,124:INFO:             pickle5: Not installed
2025-02-06 09:34:59,124:INFO:         cloudpickle: 3.1.1
2025-02-06 09:34:59,124:INFO:         deprecation: 2.1.0
2025-02-06 09:34:59,124:INFO:              xxhash: 3.5.0
2025-02-06 09:34:59,124:INFO:           wurlitzer: Not installed
2025-02-06 09:34:59,124:INFO:PyCaret optional dependencies:
2025-02-06 09:34:59,130:INFO:                shap: Not installed
2025-02-06 09:34:59,130:INFO:           interpret: Not installed
2025-02-06 09:34:59,130:INFO:                umap: Not installed
2025-02-06 09:34:59,130:INFO:     ydata_profiling: Not installed
2025-02-06 09:34:59,130:INFO:  explainerdashboard: Not installed
2025-02-06 09:34:59,130:INFO:             autoviz: Not installed
2025-02-06 09:34:59,130:INFO:           fairlearn: Not installed
2025-02-06 09:34:59,130:INFO:          deepchecks: Not installed
2025-02-06 09:34:59,130:INFO:             xgboost: Not installed
2025-02-06 09:34:59,130:INFO:            catboost: Not installed
2025-02-06 09:34:59,130:INFO:              kmodes: Not installed
2025-02-06 09:34:59,130:INFO:             mlxtend: Not installed
2025-02-06 09:34:59,130:INFO:       statsforecast: Not installed
2025-02-06 09:34:59,130:INFO:        tune_sklearn: Not installed
2025-02-06 09:34:59,130:INFO:                 ray: Not installed
2025-02-06 09:34:59,130:INFO:            hyperopt: Not installed
2025-02-06 09:34:59,130:INFO:              optuna: Not installed
2025-02-06 09:34:59,130:INFO:               skopt: Not installed
2025-02-06 09:34:59,130:INFO:              mlflow: Not installed
2025-02-06 09:34:59,130:INFO:              gradio: Not installed
2025-02-06 09:34:59,130:INFO:             fastapi: Not installed
2025-02-06 09:34:59,130:INFO:             uvicorn: Not installed
2025-02-06 09:34:59,130:INFO:              m2cgen: Not installed
2025-02-06 09:34:59,130:INFO:           evidently: Not installed
2025-02-06 09:34:59,130:INFO:               fugue: Not installed
2025-02-06 09:34:59,130:INFO:           streamlit: Not installed
2025-02-06 09:34:59,130:INFO:             prophet: Not installed
2025-02-06 09:34:59,130:INFO:None
2025-02-06 09:34:59,130:INFO:Set up data.
2025-02-06 09:34:59,145:INFO:Set up folding strategy.
2025-02-06 09:34:59,145:INFO:Set up train/test split.
2025-02-06 09:34:59,156:INFO:Set up index.
2025-02-06 09:34:59,156:INFO:Assigning column types.
2025-02-06 09:34:59,168:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 09:34:59,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,236:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,236:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,252:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 09:34:59,276:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 09:34:59,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,329:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 09:34:59,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 09:34:59,409:INFO:Preparing preprocessing pipeline...
2025-02-06 09:34:59,411:INFO:Set up simple imputation.
2025-02-06 10:20:07,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 10:20:07,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 10:20:07,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 10:20:07,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 10:20:08,010:INFO:PyCaret ClassificationExperiment
2025-02-06 10:20:08,010:INFO:Logging name: clf-default-name
2025-02-06 10:20:08,010:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 10:20:08,010:INFO:version 3.3.2
2025-02-06 10:20:08,010:INFO:Initializing setup()
2025-02-06 10:20:08,010:INFO:self.USI: 4aa0
2025-02-06 10:20:08,010:INFO:self._variable_keys: {'USI', 'X', 'data', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'n_jobs_param', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'seed', 'y', '_ml_usecase', 'idx', 'gpu_param', '_available_plots', 'y_test', 'log_plots_param', 'is_multiclass', 'target_param', 'X_test', 'logging_param', 'pipeline', 'y_train', 'fix_imbalance', 'exp_id', 'html_param', 'exp_name_log'}
2025-02-06 10:20:08,010:INFO:Checking environment
2025-02-06 10:20:08,010:INFO:python_version: 3.11.9
2025-02-06 10:20:08,010:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 10:20:08,010:INFO:machine: AMD64
2025-02-06 10:20:08,010:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 10:20:08,014:INFO:Memory: svmem(total=67771465728, available=51062734848, percent=24.7, used=16708730880, free=51062734848)
2025-02-06 10:20:08,014:INFO:Physical Core: 8
2025-02-06 10:20:08,014:INFO:Logical Core: 16
2025-02-06 10:20:08,014:INFO:Checking libraries
2025-02-06 10:20:08,014:INFO:System:
2025-02-06 10:20:08,014:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 10:20:08,014:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 10:20:08,015:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 10:20:08,015:INFO:PyCaret required dependencies:
2025-02-06 10:20:08,027:INFO:                 pip: 25.0
2025-02-06 10:20:08,027:INFO:          setuptools: 65.5.0
2025-02-06 10:20:08,027:INFO:             pycaret: 3.3.2
2025-02-06 10:20:08,027:INFO:             IPython: 8.32.0
2025-02-06 10:20:08,027:INFO:          ipywidgets: 8.1.5
2025-02-06 10:20:08,027:INFO:                tqdm: 4.67.1
2025-02-06 10:20:08,027:INFO:               numpy: 1.26.4
2025-02-06 10:20:08,027:INFO:              pandas: 2.1.4
2025-02-06 10:20:08,027:INFO:              jinja2: 3.1.5
2025-02-06 10:20:08,027:INFO:               scipy: 1.11.4
2025-02-06 10:20:08,027:INFO:              joblib: 1.3.2
2025-02-06 10:20:08,027:INFO:             sklearn: 1.4.2
2025-02-06 10:20:08,027:INFO:                pyod: 2.0.3
2025-02-06 10:20:08,027:INFO:            imblearn: 0.13.0
2025-02-06 10:20:08,027:INFO:   category_encoders: 2.7.0
2025-02-06 10:20:08,027:INFO:            lightgbm: 4.5.0
2025-02-06 10:20:08,027:INFO:               numba: 0.61.0
2025-02-06 10:20:08,027:INFO:            requests: 2.32.3
2025-02-06 10:20:08,027:INFO:          matplotlib: 3.7.5
2025-02-06 10:20:08,027:INFO:          scikitplot: 0.3.7
2025-02-06 10:20:08,027:INFO:         yellowbrick: 1.5
2025-02-06 10:20:08,027:INFO:              plotly: 5.24.1
2025-02-06 10:20:08,027:INFO:    plotly-resampler: Not installed
2025-02-06 10:20:08,027:INFO:             kaleido: 0.2.1
2025-02-06 10:20:08,027:INFO:           schemdraw: 0.15
2025-02-06 10:20:08,027:INFO:         statsmodels: 0.14.4
2025-02-06 10:20:08,027:INFO:              sktime: 0.26.0
2025-02-06 10:20:08,027:INFO:               tbats: 1.1.3
2025-02-06 10:20:08,027:INFO:            pmdarima: 2.0.4
2025-02-06 10:20:08,027:INFO:              psutil: 6.1.1
2025-02-06 10:20:08,027:INFO:          markupsafe: 3.0.2
2025-02-06 10:20:08,027:INFO:             pickle5: Not installed
2025-02-06 10:20:08,027:INFO:         cloudpickle: 3.1.1
2025-02-06 10:20:08,027:INFO:         deprecation: 2.1.0
2025-02-06 10:20:08,027:INFO:              xxhash: 3.5.0
2025-02-06 10:20:08,027:INFO:           wurlitzer: Not installed
2025-02-06 10:20:08,027:INFO:PyCaret optional dependencies:
2025-02-06 10:20:08,033:INFO:                shap: Not installed
2025-02-06 10:20:08,033:INFO:           interpret: Not installed
2025-02-06 10:20:08,033:INFO:                umap: Not installed
2025-02-06 10:20:08,033:INFO:     ydata_profiling: Not installed
2025-02-06 10:20:08,033:INFO:  explainerdashboard: Not installed
2025-02-06 10:20:08,033:INFO:             autoviz: Not installed
2025-02-06 10:20:08,033:INFO:           fairlearn: Not installed
2025-02-06 10:20:08,033:INFO:          deepchecks: Not installed
2025-02-06 10:20:08,033:INFO:             xgboost: Not installed
2025-02-06 10:20:08,033:INFO:            catboost: Not installed
2025-02-06 10:20:08,033:INFO:              kmodes: Not installed
2025-02-06 10:20:08,033:INFO:             mlxtend: Not installed
2025-02-06 10:20:08,033:INFO:       statsforecast: Not installed
2025-02-06 10:20:08,033:INFO:        tune_sklearn: Not installed
2025-02-06 10:20:08,033:INFO:                 ray: Not installed
2025-02-06 10:20:08,033:INFO:            hyperopt: Not installed
2025-02-06 10:20:08,033:INFO:              optuna: Not installed
2025-02-06 10:20:08,033:INFO:               skopt: Not installed
2025-02-06 10:20:08,033:INFO:              mlflow: Not installed
2025-02-06 10:20:08,033:INFO:              gradio: Not installed
2025-02-06 10:20:08,033:INFO:             fastapi: Not installed
2025-02-06 10:20:08,033:INFO:             uvicorn: Not installed
2025-02-06 10:20:08,033:INFO:              m2cgen: Not installed
2025-02-06 10:20:08,033:INFO:           evidently: Not installed
2025-02-06 10:20:08,033:INFO:               fugue: Not installed
2025-02-06 10:20:08,033:INFO:           streamlit: Not installed
2025-02-06 10:20:08,033:INFO:             prophet: Not installed
2025-02-06 10:20:08,033:INFO:None
2025-02-06 10:20:08,033:INFO:Set up data.
2025-02-06 10:20:08,042:INFO:Set up folding strategy.
2025-02-06 10:20:08,042:INFO:Set up train/test split.
2025-02-06 10:20:08,048:INFO:Set up index.
2025-02-06 10:20:08,049:INFO:Assigning column types.
2025-02-06 10:20:08,057:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 10:20:08,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,085:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,127:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 10:20:08,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,205:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 10:20:08,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 10:20:08,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,297:INFO:Preparing preprocessing pipeline...
2025-02-06 10:20:08,299:INFO:Set up simple imputation.
2025-02-06 10:20:08,328:INFO:Finished creating preprocessing pipeline.
2025-02-06 10:20:08,329:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 10:20:08,329:INFO:Creating final display dataframe.
2025-02-06 10:20:08,404:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              4aa0
2025-02-06 10:20:08,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 10:20:08,486:INFO:setup() successfully completed in 0.48s...............
2025-02-06 11:21:16,342:INFO:Initializing create_model()
2025-02-06 11:21:16,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A67FC574D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 11:21:16,342:INFO:Checking exceptions
2025-02-06 11:21:16,350:INFO:Importing libraries
2025-02-06 11:21:16,350:INFO:Copying training dataset
2025-02-06 11:21:16,357:INFO:Defining folds
2025-02-06 11:21:16,357:INFO:Declaring metric variables
2025-02-06 11:21:16,359:INFO:Importing untrained model
2025-02-06 11:21:16,361:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 11:21:16,364:INFO:Starting cross validation
2025-02-06 11:21:16,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 11:21:23,078:INFO:Calculating mean and std
2025-02-06 11:21:23,080:INFO:Creating metrics dataframe
2025-02-06 11:21:23,083:INFO:Finalizing model
2025-02-06 11:21:23,113:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 11:21:23,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001488 seconds.
2025-02-06 11:21:23,116:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 11:21:23,116:INFO:[LightGBM] [Info] Total Bins 6711
2025-02-06 11:21:23,116:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 11:21:23,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 11:21:23,117:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 11:21:23,227:INFO:Uploading results into container
2025-02-06 11:21:23,229:INFO:Uploading model into container now
2025-02-06 11:21:23,233:INFO:_master_model_container: 1
2025-02-06 11:21:23,233:INFO:_display_container: 2
2025-02-06 11:21:23,234:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 11:21:23,234:INFO:create_model() successfully completed......................................
2025-02-06 11:23:12,354:INFO:PyCaret ClassificationExperiment
2025-02-06 11:23:12,354:INFO:Logging name: clf-default-name
2025-02-06 11:23:12,354:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 11:23:12,354:INFO:version 3.3.2
2025-02-06 11:23:12,354:INFO:Initializing setup()
2025-02-06 11:23:12,354:INFO:self.USI: 85a8
2025-02-06 11:23:12,354:INFO:self._variable_keys: {'USI', 'X', 'data', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'n_jobs_param', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'seed', 'y', '_ml_usecase', 'idx', 'gpu_param', '_available_plots', 'y_test', 'log_plots_param', 'is_multiclass', 'target_param', 'X_test', 'logging_param', 'pipeline', 'y_train', 'fix_imbalance', 'exp_id', 'html_param', 'exp_name_log'}
2025-02-06 11:23:12,354:INFO:Checking environment
2025-02-06 11:23:12,354:INFO:python_version: 3.11.9
2025-02-06 11:23:12,354:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 11:23:12,354:INFO:machine: AMD64
2025-02-06 11:23:12,354:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 11:23:12,359:INFO:Memory: svmem(total=67771465728, available=49813794816, percent=26.5, used=17957670912, free=49813794816)
2025-02-06 11:23:12,359:INFO:Physical Core: 8
2025-02-06 11:23:12,359:INFO:Logical Core: 16
2025-02-06 11:23:12,359:INFO:Checking libraries
2025-02-06 11:23:12,359:INFO:System:
2025-02-06 11:23:12,359:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 11:23:12,359:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 11:23:12,359:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 11:23:12,359:INFO:PyCaret required dependencies:
2025-02-06 11:23:12,359:INFO:                 pip: 25.0
2025-02-06 11:23:12,359:INFO:          setuptools: 65.5.0
2025-02-06 11:23:12,359:INFO:             pycaret: 3.3.2
2025-02-06 11:23:12,360:INFO:             IPython: 8.32.0
2025-02-06 11:23:12,360:INFO:          ipywidgets: 8.1.5
2025-02-06 11:23:12,360:INFO:                tqdm: 4.67.1
2025-02-06 11:23:12,360:INFO:               numpy: 1.26.4
2025-02-06 11:23:12,360:INFO:              pandas: 2.1.4
2025-02-06 11:23:12,360:INFO:              jinja2: 3.1.5
2025-02-06 11:23:12,360:INFO:               scipy: 1.11.4
2025-02-06 11:23:12,360:INFO:              joblib: 1.3.2
2025-02-06 11:23:12,360:INFO:             sklearn: 1.4.2
2025-02-06 11:23:12,360:INFO:                pyod: 2.0.3
2025-02-06 11:23:12,360:INFO:            imblearn: 0.13.0
2025-02-06 11:23:12,360:INFO:   category_encoders: 2.7.0
2025-02-06 11:23:12,360:INFO:            lightgbm: 4.5.0
2025-02-06 11:23:12,360:INFO:               numba: 0.61.0
2025-02-06 11:23:12,360:INFO:            requests: 2.32.3
2025-02-06 11:23:12,360:INFO:          matplotlib: 3.7.5
2025-02-06 11:23:12,360:INFO:          scikitplot: 0.3.7
2025-02-06 11:23:12,360:INFO:         yellowbrick: 1.5
2025-02-06 11:23:12,360:INFO:              plotly: 5.24.1
2025-02-06 11:23:12,360:INFO:    plotly-resampler: Not installed
2025-02-06 11:23:12,360:INFO:             kaleido: 0.2.1
2025-02-06 11:23:12,360:INFO:           schemdraw: 0.15
2025-02-06 11:23:12,360:INFO:         statsmodels: 0.14.4
2025-02-06 11:23:12,360:INFO:              sktime: 0.26.0
2025-02-06 11:23:12,360:INFO:               tbats: 1.1.3
2025-02-06 11:23:12,360:INFO:            pmdarima: 2.0.4
2025-02-06 11:23:12,360:INFO:              psutil: 6.1.1
2025-02-06 11:23:12,360:INFO:          markupsafe: 3.0.2
2025-02-06 11:23:12,360:INFO:             pickle5: Not installed
2025-02-06 11:23:12,360:INFO:         cloudpickle: 3.1.1
2025-02-06 11:23:12,360:INFO:         deprecation: 2.1.0
2025-02-06 11:23:12,360:INFO:              xxhash: 3.5.0
2025-02-06 11:23:12,360:INFO:           wurlitzer: Not installed
2025-02-06 11:23:12,360:INFO:PyCaret optional dependencies:
2025-02-06 11:23:12,360:INFO:                shap: Not installed
2025-02-06 11:23:12,360:INFO:           interpret: Not installed
2025-02-06 11:23:12,360:INFO:                umap: Not installed
2025-02-06 11:23:12,360:INFO:     ydata_profiling: Not installed
2025-02-06 11:23:12,360:INFO:  explainerdashboard: Not installed
2025-02-06 11:23:12,360:INFO:             autoviz: Not installed
2025-02-06 11:23:12,360:INFO:           fairlearn: Not installed
2025-02-06 11:23:12,360:INFO:          deepchecks: Not installed
2025-02-06 11:23:12,360:INFO:             xgboost: Not installed
2025-02-06 11:23:12,360:INFO:            catboost: Not installed
2025-02-06 11:23:12,360:INFO:              kmodes: Not installed
2025-02-06 11:23:12,360:INFO:             mlxtend: Not installed
2025-02-06 11:23:12,360:INFO:       statsforecast: Not installed
2025-02-06 11:23:12,360:INFO:        tune_sklearn: Not installed
2025-02-06 11:23:12,360:INFO:                 ray: Not installed
2025-02-06 11:23:12,360:INFO:            hyperopt: Not installed
2025-02-06 11:23:12,360:INFO:              optuna: Not installed
2025-02-06 11:23:12,360:INFO:               skopt: Not installed
2025-02-06 11:23:12,360:INFO:              mlflow: Not installed
2025-02-06 11:23:12,360:INFO:              gradio: Not installed
2025-02-06 11:23:12,360:INFO:             fastapi: Not installed
2025-02-06 11:23:12,360:INFO:             uvicorn: Not installed
2025-02-06 11:23:12,360:INFO:              m2cgen: Not installed
2025-02-06 11:23:12,360:INFO:           evidently: Not installed
2025-02-06 11:23:12,360:INFO:               fugue: Not installed
2025-02-06 11:23:12,360:INFO:           streamlit: Not installed
2025-02-06 11:23:12,360:INFO:             prophet: Not installed
2025-02-06 11:23:12,360:INFO:None
2025-02-06 11:23:12,360:INFO:Set up data.
2025-02-06 11:23:12,369:INFO:Set up folding strategy.
2025-02-06 11:23:12,369:INFO:Set up train/test split.
2025-02-06 11:23:12,379:INFO:Set up index.
2025-02-06 11:23:12,381:INFO:Assigning column types.
2025-02-06 11:23:12,389:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 11:23:12,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,460:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,476:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 11:23:12,499:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 11:23:12,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,553:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 11:23:12,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,631:INFO:Preparing preprocessing pipeline...
2025-02-06 11:23:12,632:INFO:Set up simple imputation.
2025-02-06 11:23:12,667:INFO:Finished creating preprocessing pipeline.
2025-02-06 11:23:12,669:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 11:23:12,669:INFO:Creating final display dataframe.
2025-02-06 11:23:12,734:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              85a8
2025-02-06 11:23:12,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 11:23:12,812:INFO:setup() successfully completed in 0.46s...............
2025-02-06 11:23:15,069:INFO:Initializing create_model()
2025-02-06 11:23:15,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A6119F62D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 11:23:15,069:INFO:Checking exceptions
2025-02-06 11:23:15,070:INFO:Importing libraries
2025-02-06 11:23:15,070:INFO:Copying training dataset
2025-02-06 11:23:15,080:INFO:Defining folds
2025-02-06 11:23:15,080:INFO:Declaring metric variables
2025-02-06 11:23:15,080:INFO:Importing untrained model
2025-02-06 11:23:15,080:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 11:23:15,080:INFO:Starting cross validation
2025-02-06 11:23:15,081:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 11:23:16,899:INFO:Calculating mean and std
2025-02-06 11:23:16,899:INFO:Creating metrics dataframe
2025-02-06 11:23:16,901:INFO:Finalizing model
2025-02-06 11:23:16,921:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 11:23:16,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002512 seconds.
2025-02-06 11:23:16,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 11:23:16,926:INFO:[LightGBM] [Info] Total Bins 6711
2025-02-06 11:23:16,926:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 11:23:16,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 11:23:16,926:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 11:23:17,057:INFO:Uploading results into container
2025-02-06 11:23:17,057:INFO:Uploading model into container now
2025-02-06 11:23:17,058:INFO:_master_model_container: 1
2025-02-06 11:23:17,058:INFO:_display_container: 2
2025-02-06 11:23:17,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 11:23:17,058:INFO:create_model() successfully completed......................................
2025-02-06 12:35:06,985:INFO:PyCaret ClassificationExperiment
2025-02-06 12:35:06,985:INFO:Logging name: clf-default-name
2025-02-06 12:35:06,985:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 12:35:06,985:INFO:version 3.3.2
2025-02-06 12:35:06,985:INFO:Initializing setup()
2025-02-06 12:35:06,985:INFO:self.USI: 7e4b
2025-02-06 12:35:06,985:INFO:self._variable_keys: {'USI', 'X', 'data', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'n_jobs_param', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'seed', 'y', '_ml_usecase', 'idx', 'gpu_param', '_available_plots', 'y_test', 'log_plots_param', 'is_multiclass', 'target_param', 'X_test', 'logging_param', 'pipeline', 'y_train', 'fix_imbalance', 'exp_id', 'html_param', 'exp_name_log'}
2025-02-06 12:35:06,985:INFO:Checking environment
2025-02-06 12:35:06,985:INFO:python_version: 3.11.9
2025-02-06 12:35:06,985:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 12:35:06,985:INFO:machine: AMD64
2025-02-06 12:35:06,985:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 12:35:06,988:INFO:Memory: svmem(total=67771465728, available=50415935488, percent=25.6, used=17355530240, free=50415935488)
2025-02-06 12:35:06,988:INFO:Physical Core: 8
2025-02-06 12:35:06,988:INFO:Logical Core: 16
2025-02-06 12:35:06,988:INFO:Checking libraries
2025-02-06 12:35:06,988:INFO:System:
2025-02-06 12:35:06,988:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 12:35:06,988:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 12:35:06,988:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 12:35:06,988:INFO:PyCaret required dependencies:
2025-02-06 12:35:06,988:INFO:                 pip: 25.0
2025-02-06 12:35:06,989:INFO:          setuptools: 65.5.0
2025-02-06 12:35:06,989:INFO:             pycaret: 3.3.2
2025-02-06 12:35:06,989:INFO:             IPython: 8.32.0
2025-02-06 12:35:06,989:INFO:          ipywidgets: 8.1.5
2025-02-06 12:35:06,989:INFO:                tqdm: 4.67.1
2025-02-06 12:35:06,989:INFO:               numpy: 1.26.4
2025-02-06 12:35:06,989:INFO:              pandas: 2.1.4
2025-02-06 12:35:06,989:INFO:              jinja2: 3.1.5
2025-02-06 12:35:06,989:INFO:               scipy: 1.11.4
2025-02-06 12:35:06,989:INFO:              joblib: 1.3.2
2025-02-06 12:35:06,989:INFO:             sklearn: 1.4.2
2025-02-06 12:35:06,989:INFO:                pyod: 2.0.3
2025-02-06 12:35:06,989:INFO:            imblearn: 0.13.0
2025-02-06 12:35:06,989:INFO:   category_encoders: 2.7.0
2025-02-06 12:35:06,989:INFO:            lightgbm: 4.5.0
2025-02-06 12:35:06,989:INFO:               numba: 0.61.0
2025-02-06 12:35:06,989:INFO:            requests: 2.32.3
2025-02-06 12:35:06,989:INFO:          matplotlib: 3.7.5
2025-02-06 12:35:06,989:INFO:          scikitplot: 0.3.7
2025-02-06 12:35:06,989:INFO:         yellowbrick: 1.5
2025-02-06 12:35:06,989:INFO:              plotly: 5.24.1
2025-02-06 12:35:06,989:INFO:    plotly-resampler: Not installed
2025-02-06 12:35:06,989:INFO:             kaleido: 0.2.1
2025-02-06 12:35:06,989:INFO:           schemdraw: 0.15
2025-02-06 12:35:06,989:INFO:         statsmodels: 0.14.4
2025-02-06 12:35:06,989:INFO:              sktime: 0.26.0
2025-02-06 12:35:06,989:INFO:               tbats: 1.1.3
2025-02-06 12:35:06,989:INFO:            pmdarima: 2.0.4
2025-02-06 12:35:06,989:INFO:              psutil: 6.1.1
2025-02-06 12:35:06,990:INFO:          markupsafe: 3.0.2
2025-02-06 12:35:06,990:INFO:             pickle5: Not installed
2025-02-06 12:35:06,990:INFO:         cloudpickle: 3.1.1
2025-02-06 12:35:06,990:INFO:         deprecation: 2.1.0
2025-02-06 12:35:06,990:INFO:              xxhash: 3.5.0
2025-02-06 12:35:06,990:INFO:           wurlitzer: Not installed
2025-02-06 12:35:06,990:INFO:PyCaret optional dependencies:
2025-02-06 12:35:06,990:INFO:                shap: Not installed
2025-02-06 12:35:06,990:INFO:           interpret: Not installed
2025-02-06 12:35:06,990:INFO:                umap: Not installed
2025-02-06 12:35:06,990:INFO:     ydata_profiling: Not installed
2025-02-06 12:35:06,990:INFO:  explainerdashboard: Not installed
2025-02-06 12:35:06,990:INFO:             autoviz: Not installed
2025-02-06 12:35:06,990:INFO:           fairlearn: Not installed
2025-02-06 12:35:06,990:INFO:          deepchecks: Not installed
2025-02-06 12:35:06,990:INFO:             xgboost: Not installed
2025-02-06 12:35:06,990:INFO:            catboost: Not installed
2025-02-06 12:35:06,990:INFO:              kmodes: Not installed
2025-02-06 12:35:06,990:INFO:             mlxtend: Not installed
2025-02-06 12:35:06,990:INFO:       statsforecast: Not installed
2025-02-06 12:35:06,990:INFO:        tune_sklearn: Not installed
2025-02-06 12:35:06,990:INFO:                 ray: Not installed
2025-02-06 12:35:06,990:INFO:            hyperopt: Not installed
2025-02-06 12:35:06,990:INFO:              optuna: Not installed
2025-02-06 12:35:06,990:INFO:               skopt: Not installed
2025-02-06 12:35:06,990:INFO:              mlflow: Not installed
2025-02-06 12:35:06,990:INFO:              gradio: Not installed
2025-02-06 12:35:06,990:INFO:             fastapi: Not installed
2025-02-06 12:35:06,990:INFO:             uvicorn: Not installed
2025-02-06 12:35:06,990:INFO:              m2cgen: Not installed
2025-02-06 12:35:06,990:INFO:           evidently: Not installed
2025-02-06 12:35:06,990:INFO:               fugue: Not installed
2025-02-06 12:35:06,990:INFO:           streamlit: Not installed
2025-02-06 12:35:06,990:INFO:             prophet: Not installed
2025-02-06 12:35:06,990:INFO:None
2025-02-06 12:35:06,990:INFO:Set up data.
2025-02-06 12:35:06,998:INFO:Set up folding strategy.
2025-02-06 12:35:06,998:INFO:Set up train/test split.
2025-02-06 12:35:07,005:INFO:Set up index.
2025-02-06 12:35:07,006:INFO:Assigning column types.
2025-02-06 12:35:07,012:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 12:35:07,037:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,037:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,092:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 12:35:07,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,154:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:35:07,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,170:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 12:35:07,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,247:INFO:Preparing preprocessing pipeline...
2025-02-06 12:35:07,249:INFO:Set up simple imputation.
2025-02-06 12:35:07,268:INFO:Finished creating preprocessing pipeline.
2025-02-06 12:35:07,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 12:35:07,270:INFO:Creating final display dataframe.
2025-02-06 12:35:07,339:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              7e4b
2025-02-06 12:35:07,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:35:07,417:INFO:setup() successfully completed in 0.43s...............
2025-02-06 12:35:07,417:INFO:Initializing create_model()
2025-02-06 12:35:07,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A61931F610>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 12:35:07,417:INFO:Checking exceptions
2025-02-06 12:35:07,419:INFO:Importing libraries
2025-02-06 12:35:07,419:INFO:Copying training dataset
2025-02-06 12:35:07,425:INFO:Defining folds
2025-02-06 12:35:07,425:INFO:Declaring metric variables
2025-02-06 12:35:07,425:INFO:Importing untrained model
2025-02-06 12:35:07,426:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 12:35:07,426:INFO:Starting cross validation
2025-02-06 12:35:07,426:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 12:35:09,527:INFO:Calculating mean and std
2025-02-06 12:35:09,528:INFO:Creating metrics dataframe
2025-02-06 12:35:09,529:INFO:Finalizing model
2025-02-06 12:35:09,548:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 12:35:09,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.
2025-02-06 12:35:09,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 12:35:09,551:INFO:[LightGBM] [Info] Total Bins 6711
2025-02-06 12:35:09,553:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 12:35:09,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 12:35:09,553:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 12:35:09,667:INFO:Uploading results into container
2025-02-06 12:35:09,668:INFO:Uploading model into container now
2025-02-06 12:35:09,668:INFO:_master_model_container: 1
2025-02-06 12:35:09,668:INFO:_display_container: 2
2025-02-06 12:35:09,669:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 12:35:09,669:INFO:create_model() successfully completed......................................
2025-02-06 12:36:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 12:36:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 12:36:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 12:36:45,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 12:36:56,143:INFO:PyCaret ClassificationExperiment
2025-02-06 12:36:56,144:INFO:Logging name: clf-default-name
2025-02-06 12:36:56,144:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 12:36:56,144:INFO:version 3.3.2
2025-02-06 12:36:56,144:INFO:Initializing setup()
2025-02-06 12:36:56,144:INFO:self.USI: 2b07
2025-02-06 12:36:56,144:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 12:36:56,144:INFO:Checking environment
2025-02-06 12:36:56,144:INFO:python_version: 3.11.9
2025-02-06 12:36:56,144:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 12:36:56,144:INFO:machine: AMD64
2025-02-06 12:36:56,144:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 12:36:56,147:INFO:Memory: svmem(total=67771465728, available=50514644992, percent=25.5, used=17256820736, free=50514644992)
2025-02-06 12:36:56,147:INFO:Physical Core: 8
2025-02-06 12:36:56,147:INFO:Logical Core: 16
2025-02-06 12:36:56,147:INFO:Checking libraries
2025-02-06 12:36:56,147:INFO:System:
2025-02-06 12:36:56,147:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 12:36:56,147:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 12:36:56,147:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 12:36:56,147:INFO:PyCaret required dependencies:
2025-02-06 12:36:56,162:INFO:                 pip: 25.0
2025-02-06 12:36:56,162:INFO:          setuptools: 65.5.0
2025-02-06 12:36:56,162:INFO:             pycaret: 3.3.2
2025-02-06 12:36:56,162:INFO:             IPython: 8.32.0
2025-02-06 12:36:56,162:INFO:          ipywidgets: 8.1.5
2025-02-06 12:36:56,162:INFO:                tqdm: 4.67.1
2025-02-06 12:36:56,162:INFO:               numpy: 1.26.4
2025-02-06 12:36:56,162:INFO:              pandas: 2.1.4
2025-02-06 12:36:56,162:INFO:              jinja2: 3.1.5
2025-02-06 12:36:56,162:INFO:               scipy: 1.11.4
2025-02-06 12:36:56,162:INFO:              joblib: 1.3.2
2025-02-06 12:36:56,162:INFO:             sklearn: 1.4.2
2025-02-06 12:36:56,162:INFO:                pyod: 2.0.3
2025-02-06 12:36:56,162:INFO:            imblearn: 0.13.0
2025-02-06 12:36:56,162:INFO:   category_encoders: 2.7.0
2025-02-06 12:36:56,162:INFO:            lightgbm: 4.5.0
2025-02-06 12:36:56,162:INFO:               numba: 0.61.0
2025-02-06 12:36:56,162:INFO:            requests: 2.32.3
2025-02-06 12:36:56,162:INFO:          matplotlib: 3.7.5
2025-02-06 12:36:56,162:INFO:          scikitplot: 0.3.7
2025-02-06 12:36:56,162:INFO:         yellowbrick: 1.5
2025-02-06 12:36:56,162:INFO:              plotly: 5.24.1
2025-02-06 12:36:56,162:INFO:    plotly-resampler: Not installed
2025-02-06 12:36:56,162:INFO:             kaleido: 0.2.1
2025-02-06 12:36:56,162:INFO:           schemdraw: 0.15
2025-02-06 12:36:56,162:INFO:         statsmodels: 0.14.4
2025-02-06 12:36:56,162:INFO:              sktime: 0.26.0
2025-02-06 12:36:56,162:INFO:               tbats: 1.1.3
2025-02-06 12:36:56,162:INFO:            pmdarima: 2.0.4
2025-02-06 12:36:56,163:INFO:              psutil: 6.1.1
2025-02-06 12:36:56,163:INFO:          markupsafe: 3.0.2
2025-02-06 12:36:56,163:INFO:             pickle5: Not installed
2025-02-06 12:36:56,163:INFO:         cloudpickle: 3.1.1
2025-02-06 12:36:56,163:INFO:         deprecation: 2.1.0
2025-02-06 12:36:56,163:INFO:              xxhash: 3.5.0
2025-02-06 12:36:56,163:INFO:           wurlitzer: Not installed
2025-02-06 12:36:56,163:INFO:PyCaret optional dependencies:
2025-02-06 12:36:56,171:INFO:                shap: Not installed
2025-02-06 12:36:56,171:INFO:           interpret: Not installed
2025-02-06 12:36:56,171:INFO:                umap: Not installed
2025-02-06 12:36:56,171:INFO:     ydata_profiling: Not installed
2025-02-06 12:36:56,171:INFO:  explainerdashboard: Not installed
2025-02-06 12:36:56,171:INFO:             autoviz: Not installed
2025-02-06 12:36:56,171:INFO:           fairlearn: Not installed
2025-02-06 12:36:56,171:INFO:          deepchecks: Not installed
2025-02-06 12:36:56,171:INFO:             xgboost: Not installed
2025-02-06 12:36:56,171:INFO:            catboost: Not installed
2025-02-06 12:36:56,171:INFO:              kmodes: Not installed
2025-02-06 12:36:56,171:INFO:             mlxtend: Not installed
2025-02-06 12:36:56,171:INFO:       statsforecast: Not installed
2025-02-06 12:36:56,171:INFO:        tune_sklearn: Not installed
2025-02-06 12:36:56,171:INFO:                 ray: Not installed
2025-02-06 12:36:56,171:INFO:            hyperopt: Not installed
2025-02-06 12:36:56,171:INFO:              optuna: Not installed
2025-02-06 12:36:56,171:INFO:               skopt: Not installed
2025-02-06 12:36:56,171:INFO:              mlflow: Not installed
2025-02-06 12:36:56,171:INFO:              gradio: Not installed
2025-02-06 12:36:56,171:INFO:             fastapi: Not installed
2025-02-06 12:36:56,171:INFO:             uvicorn: Not installed
2025-02-06 12:36:56,171:INFO:              m2cgen: Not installed
2025-02-06 12:36:56,171:INFO:           evidently: Not installed
2025-02-06 12:36:56,171:INFO:               fugue: Not installed
2025-02-06 12:36:56,171:INFO:           streamlit: Not installed
2025-02-06 12:36:56,171:INFO:             prophet: Not installed
2025-02-06 12:36:56,171:INFO:None
2025-02-06 12:36:56,171:INFO:Set up data.
2025-02-06 12:36:56,184:INFO:Set up folding strategy.
2025-02-06 12:36:56,184:INFO:Set up train/test split.
2025-02-06 12:36:56,191:INFO:Set up index.
2025-02-06 12:36:56,194:INFO:Assigning column types.
2025-02-06 12:36:56,200:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 12:36:56,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,269:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,284:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 12:36:56,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 12:36:56,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,363:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 12:36:56,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,441:INFO:Preparing preprocessing pipeline...
2025-02-06 12:36:56,443:INFO:Set up simple imputation.
2025-02-06 12:36:56,464:INFO:Finished creating preprocessing pipeline.
2025-02-06 12:36:56,467:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 12:36:56,467:INFO:Creating final display dataframe.
2025-02-06 12:36:56,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              2b07
2025-02-06 12:36:56,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 12:36:56,616:INFO:setup() successfully completed in 0.47s...............
2025-02-06 12:36:56,616:INFO:Initializing create_model()
2025-02-06 12:36:56,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C75F26310>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 12:36:56,616:INFO:Checking exceptions
2025-02-06 12:36:56,617:INFO:Importing libraries
2025-02-06 12:36:56,617:INFO:Copying training dataset
2025-02-06 12:36:56,623:INFO:Defining folds
2025-02-06 12:36:56,623:INFO:Declaring metric variables
2025-02-06 12:36:56,623:INFO:Importing untrained model
2025-02-06 12:36:56,623:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 12:36:56,623:INFO:Starting cross validation
2025-02-06 12:36:56,623:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 12:36:58,891:INFO:Calculating mean and std
2025-02-06 12:36:58,891:INFO:Creating metrics dataframe
2025-02-06 12:36:58,893:INFO:Finalizing model
2025-02-06 12:36:58,910:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 12:36:58,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.
2025-02-06 12:36:58,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 12:36:58,912:INFO:[LightGBM] [Info] Total Bins 6711
2025-02-06 12:36:58,912:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 12:36:58,913:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 12:36:58,913:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 12:36:59,028:INFO:Uploading results into container
2025-02-06 12:36:59,028:INFO:Uploading model into container now
2025-02-06 12:36:59,029:INFO:_master_model_container: 1
2025-02-06 12:36:59,029:INFO:_display_container: 2
2025-02-06 12:36:59,029:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 12:36:59,029:INFO:create_model() successfully completed......................................
2025-02-06 13:34:11,831:INFO:PyCaret ClassificationExperiment
2025-02-06 13:34:11,831:INFO:Logging name: clf-default-name
2025-02-06 13:34:11,831:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:34:11,831:INFO:version 3.3.2
2025-02-06 13:34:11,831:INFO:Initializing setup()
2025-02-06 13:34:11,831:INFO:self.USI: b09f
2025-02-06 13:34:11,831:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:34:11,831:INFO:Checking environment
2025-02-06 13:34:11,831:INFO:python_version: 3.11.9
2025-02-06 13:34:11,831:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:34:11,831:INFO:machine: AMD64
2025-02-06 13:34:11,831:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:34:11,835:INFO:Memory: svmem(total=67771465728, available=50376769536, percent=25.7, used=17394696192, free=50376769536)
2025-02-06 13:34:11,835:INFO:Physical Core: 8
2025-02-06 13:34:11,835:INFO:Logical Core: 16
2025-02-06 13:34:11,835:INFO:Checking libraries
2025-02-06 13:34:11,835:INFO:System:
2025-02-06 13:34:11,835:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:34:11,835:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:34:11,835:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:34:11,835:INFO:PyCaret required dependencies:
2025-02-06 13:34:11,835:INFO:                 pip: 25.0
2025-02-06 13:34:11,835:INFO:          setuptools: 65.5.0
2025-02-06 13:34:11,835:INFO:             pycaret: 3.3.2
2025-02-06 13:34:11,835:INFO:             IPython: 8.32.0
2025-02-06 13:34:11,835:INFO:          ipywidgets: 8.1.5
2025-02-06 13:34:11,835:INFO:                tqdm: 4.67.1
2025-02-06 13:34:11,835:INFO:               numpy: 1.26.4
2025-02-06 13:34:11,835:INFO:              pandas: 2.1.4
2025-02-06 13:34:11,835:INFO:              jinja2: 3.1.5
2025-02-06 13:34:11,835:INFO:               scipy: 1.11.4
2025-02-06 13:34:11,835:INFO:              joblib: 1.3.2
2025-02-06 13:34:11,835:INFO:             sklearn: 1.4.2
2025-02-06 13:34:11,835:INFO:                pyod: 2.0.3
2025-02-06 13:34:11,835:INFO:            imblearn: 0.13.0
2025-02-06 13:34:11,835:INFO:   category_encoders: 2.7.0
2025-02-06 13:34:11,835:INFO:            lightgbm: 4.5.0
2025-02-06 13:34:11,835:INFO:               numba: 0.61.0
2025-02-06 13:34:11,835:INFO:            requests: 2.32.3
2025-02-06 13:34:11,835:INFO:          matplotlib: 3.7.5
2025-02-06 13:34:11,835:INFO:          scikitplot: 0.3.7
2025-02-06 13:34:11,835:INFO:         yellowbrick: 1.5
2025-02-06 13:34:11,835:INFO:              plotly: 5.24.1
2025-02-06 13:34:11,835:INFO:    plotly-resampler: Not installed
2025-02-06 13:34:11,835:INFO:             kaleido: 0.2.1
2025-02-06 13:34:11,836:INFO:           schemdraw: 0.15
2025-02-06 13:34:11,836:INFO:         statsmodels: 0.14.4
2025-02-06 13:34:11,836:INFO:              sktime: 0.26.0
2025-02-06 13:34:11,836:INFO:               tbats: 1.1.3
2025-02-06 13:34:11,836:INFO:            pmdarima: 2.0.4
2025-02-06 13:34:11,836:INFO:              psutil: 6.1.1
2025-02-06 13:34:11,836:INFO:          markupsafe: 3.0.2
2025-02-06 13:34:11,836:INFO:             pickle5: Not installed
2025-02-06 13:34:11,836:INFO:         cloudpickle: 3.1.1
2025-02-06 13:34:11,836:INFO:         deprecation: 2.1.0
2025-02-06 13:34:11,836:INFO:              xxhash: 3.5.0
2025-02-06 13:34:11,836:INFO:           wurlitzer: Not installed
2025-02-06 13:34:11,836:INFO:PyCaret optional dependencies:
2025-02-06 13:34:11,836:INFO:                shap: Not installed
2025-02-06 13:34:11,836:INFO:           interpret: Not installed
2025-02-06 13:34:11,836:INFO:                umap: Not installed
2025-02-06 13:34:11,836:INFO:     ydata_profiling: Not installed
2025-02-06 13:34:11,836:INFO:  explainerdashboard: Not installed
2025-02-06 13:34:11,836:INFO:             autoviz: Not installed
2025-02-06 13:34:11,836:INFO:           fairlearn: Not installed
2025-02-06 13:34:11,836:INFO:          deepchecks: Not installed
2025-02-06 13:34:11,836:INFO:             xgboost: Not installed
2025-02-06 13:34:11,836:INFO:            catboost: Not installed
2025-02-06 13:34:11,836:INFO:              kmodes: Not installed
2025-02-06 13:34:11,836:INFO:             mlxtend: Not installed
2025-02-06 13:34:11,836:INFO:       statsforecast: Not installed
2025-02-06 13:34:11,836:INFO:        tune_sklearn: Not installed
2025-02-06 13:34:11,836:INFO:                 ray: Not installed
2025-02-06 13:34:11,836:INFO:            hyperopt: Not installed
2025-02-06 13:34:11,836:INFO:              optuna: Not installed
2025-02-06 13:34:11,836:INFO:               skopt: Not installed
2025-02-06 13:34:11,836:INFO:              mlflow: Not installed
2025-02-06 13:34:11,836:INFO:              gradio: Not installed
2025-02-06 13:34:11,836:INFO:             fastapi: Not installed
2025-02-06 13:34:11,836:INFO:             uvicorn: Not installed
2025-02-06 13:34:11,836:INFO:              m2cgen: Not installed
2025-02-06 13:34:11,836:INFO:           evidently: Not installed
2025-02-06 13:34:11,836:INFO:               fugue: Not installed
2025-02-06 13:34:11,836:INFO:           streamlit: Not installed
2025-02-06 13:34:11,836:INFO:             prophet: Not installed
2025-02-06 13:34:11,836:INFO:None
2025-02-06 13:34:11,836:INFO:Set up data.
2025-02-06 13:34:11,844:INFO:Set up folding strategy.
2025-02-06 13:34:11,844:INFO:Set up train/test split.
2025-02-06 13:34:11,852:INFO:Set up index.
2025-02-06 13:34:11,853:INFO:Assigning column types.
2025-02-06 13:34:11,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:34:11,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:34:11,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:34:11,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:11,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:11,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:34:11,924:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:34:11,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:11,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:11,940:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:34:11,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:34:11,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:11,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:34:12,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,019:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:34:12,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,098:INFO:Preparing preprocessing pipeline...
2025-02-06 13:34:12,099:INFO:Set up simple imputation.
2025-02-06 13:34:12,120:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:34:12,122:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:34:12,122:INFO:Creating final display dataframe.
2025-02-06 13:34:12,194:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              b09f
2025-02-06 13:34:12,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:34:12,273:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:34:12,273:INFO:Initializing create_model()
2025-02-06 13:34:12,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A5ECA90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:34:12,273:INFO:Checking exceptions
2025-02-06 13:34:12,274:INFO:Importing libraries
2025-02-06 13:34:12,274:INFO:Copying training dataset
2025-02-06 13:34:12,281:INFO:Defining folds
2025-02-06 13:34:12,281:INFO:Declaring metric variables
2025-02-06 13:34:12,281:INFO:Importing untrained model
2025-02-06 13:34:12,282:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:34:12,282:INFO:Starting cross validation
2025-02-06 13:34:12,282:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:34:14,471:INFO:Calculating mean and std
2025-02-06 13:34:14,471:INFO:Creating metrics dataframe
2025-02-06 13:34:14,472:INFO:Finalizing model
2025-02-06 13:34:14,493:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:34:14,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.
2025-02-06 13:34:14,495:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:34:14,495:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:34:14,495:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:34:14,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:34:14,495:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:34:14,613:INFO:Uploading results into container
2025-02-06 13:34:14,614:INFO:Uploading model into container now
2025-02-06 13:34:14,614:INFO:_master_model_container: 1
2025-02-06 13:34:14,614:INFO:_display_container: 2
2025-02-06 13:34:14,614:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:34:14,614:INFO:create_model() successfully completed......................................
2025-02-06 13:38:29,692:INFO:PyCaret ClassificationExperiment
2025-02-06 13:38:29,692:INFO:Logging name: clf-default-name
2025-02-06 13:38:29,692:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:38:29,692:INFO:version 3.3.2
2025-02-06 13:38:29,692:INFO:Initializing setup()
2025-02-06 13:38:29,692:INFO:self.USI: 7336
2025-02-06 13:38:29,692:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:38:29,692:INFO:Checking environment
2025-02-06 13:38:29,692:INFO:python_version: 3.11.9
2025-02-06 13:38:29,692:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:38:29,692:INFO:machine: AMD64
2025-02-06 13:38:29,692:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:38:29,696:INFO:Memory: svmem(total=67771465728, available=49087197184, percent=27.6, used=18684268544, free=49087197184)
2025-02-06 13:38:29,696:INFO:Physical Core: 8
2025-02-06 13:38:29,696:INFO:Logical Core: 16
2025-02-06 13:38:29,696:INFO:Checking libraries
2025-02-06 13:38:29,696:INFO:System:
2025-02-06 13:38:29,696:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:38:29,696:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:38:29,696:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:38:29,696:INFO:PyCaret required dependencies:
2025-02-06 13:38:29,697:INFO:                 pip: 25.0
2025-02-06 13:38:29,697:INFO:          setuptools: 65.5.0
2025-02-06 13:38:29,697:INFO:             pycaret: 3.3.2
2025-02-06 13:38:29,697:INFO:             IPython: 8.32.0
2025-02-06 13:38:29,697:INFO:          ipywidgets: 8.1.5
2025-02-06 13:38:29,697:INFO:                tqdm: 4.67.1
2025-02-06 13:38:29,697:INFO:               numpy: 1.26.4
2025-02-06 13:38:29,697:INFO:              pandas: 2.1.4
2025-02-06 13:38:29,697:INFO:              jinja2: 3.1.5
2025-02-06 13:38:29,697:INFO:               scipy: 1.11.4
2025-02-06 13:38:29,697:INFO:              joblib: 1.3.2
2025-02-06 13:38:29,697:INFO:             sklearn: 1.4.2
2025-02-06 13:38:29,697:INFO:                pyod: 2.0.3
2025-02-06 13:38:29,697:INFO:            imblearn: 0.13.0
2025-02-06 13:38:29,697:INFO:   category_encoders: 2.7.0
2025-02-06 13:38:29,697:INFO:            lightgbm: 4.5.0
2025-02-06 13:38:29,697:INFO:               numba: 0.61.0
2025-02-06 13:38:29,697:INFO:            requests: 2.32.3
2025-02-06 13:38:29,697:INFO:          matplotlib: 3.7.5
2025-02-06 13:38:29,697:INFO:          scikitplot: 0.3.7
2025-02-06 13:38:29,697:INFO:         yellowbrick: 1.5
2025-02-06 13:38:29,697:INFO:              plotly: 5.24.1
2025-02-06 13:38:29,697:INFO:    plotly-resampler: Not installed
2025-02-06 13:38:29,697:INFO:             kaleido: 0.2.1
2025-02-06 13:38:29,697:INFO:           schemdraw: 0.15
2025-02-06 13:38:29,697:INFO:         statsmodels: 0.14.4
2025-02-06 13:38:29,697:INFO:              sktime: 0.26.0
2025-02-06 13:38:29,697:INFO:               tbats: 1.1.3
2025-02-06 13:38:29,697:INFO:            pmdarima: 2.0.4
2025-02-06 13:38:29,697:INFO:              psutil: 6.1.1
2025-02-06 13:38:29,697:INFO:          markupsafe: 3.0.2
2025-02-06 13:38:29,697:INFO:             pickle5: Not installed
2025-02-06 13:38:29,697:INFO:         cloudpickle: 3.1.1
2025-02-06 13:38:29,697:INFO:         deprecation: 2.1.0
2025-02-06 13:38:29,697:INFO:              xxhash: 3.5.0
2025-02-06 13:38:29,697:INFO:           wurlitzer: Not installed
2025-02-06 13:38:29,697:INFO:PyCaret optional dependencies:
2025-02-06 13:38:29,697:INFO:                shap: Not installed
2025-02-06 13:38:29,697:INFO:           interpret: Not installed
2025-02-06 13:38:29,697:INFO:                umap: Not installed
2025-02-06 13:38:29,697:INFO:     ydata_profiling: Not installed
2025-02-06 13:38:29,697:INFO:  explainerdashboard: Not installed
2025-02-06 13:38:29,698:INFO:             autoviz: Not installed
2025-02-06 13:38:29,698:INFO:           fairlearn: Not installed
2025-02-06 13:38:29,698:INFO:          deepchecks: Not installed
2025-02-06 13:38:29,698:INFO:             xgboost: Not installed
2025-02-06 13:38:29,698:INFO:            catboost: Not installed
2025-02-06 13:38:29,698:INFO:              kmodes: Not installed
2025-02-06 13:38:29,698:INFO:             mlxtend: Not installed
2025-02-06 13:38:29,698:INFO:       statsforecast: Not installed
2025-02-06 13:38:29,698:INFO:        tune_sklearn: Not installed
2025-02-06 13:38:29,698:INFO:                 ray: Not installed
2025-02-06 13:38:29,698:INFO:            hyperopt: Not installed
2025-02-06 13:38:29,698:INFO:              optuna: Not installed
2025-02-06 13:38:29,698:INFO:               skopt: Not installed
2025-02-06 13:38:29,698:INFO:              mlflow: Not installed
2025-02-06 13:38:29,698:INFO:              gradio: Not installed
2025-02-06 13:38:29,698:INFO:             fastapi: Not installed
2025-02-06 13:38:29,698:INFO:             uvicorn: Not installed
2025-02-06 13:38:29,698:INFO:              m2cgen: Not installed
2025-02-06 13:38:29,698:INFO:           evidently: Not installed
2025-02-06 13:38:29,698:INFO:               fugue: Not installed
2025-02-06 13:38:29,698:INFO:           streamlit: Not installed
2025-02-06 13:38:29,698:INFO:             prophet: Not installed
2025-02-06 13:38:29,698:INFO:None
2025-02-06 13:38:29,698:INFO:Set up data.
2025-02-06 13:38:29,706:INFO:Set up folding strategy.
2025-02-06 13:38:29,706:INFO:Set up train/test split.
2025-02-06 13:38:29,713:INFO:Set up index.
2025-02-06 13:38:29,716:INFO:Assigning column types.
2025-02-06 13:38:29,723:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:38:29,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,801:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:38:29,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:29,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,879:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:38:29,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:29,959:INFO:Preparing preprocessing pipeline...
2025-02-06 13:38:29,960:INFO:Set up simple imputation.
2025-02-06 13:38:29,981:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:38:29,982:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:38:29,983:INFO:Creating final display dataframe.
2025-02-06 13:38:30,054:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              7336
2025-02-06 13:38:30,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:30,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:30,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:30,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:30,132:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:38:30,132:INFO:Initializing create_model()
2025-02-06 13:38:30,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A603390>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:38:30,132:INFO:Checking exceptions
2025-02-06 13:38:30,134:INFO:Importing libraries
2025-02-06 13:38:30,134:INFO:Copying training dataset
2025-02-06 13:38:30,140:INFO:Defining folds
2025-02-06 13:38:30,141:INFO:Declaring metric variables
2025-02-06 13:38:30,141:INFO:Importing untrained model
2025-02-06 13:38:30,141:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:38:30,141:INFO:Starting cross validation
2025-02-06 13:38:30,141:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:38:32,025:INFO:Calculating mean and std
2025-02-06 13:38:32,025:INFO:Creating metrics dataframe
2025-02-06 13:38:32,027:INFO:Finalizing model
2025-02-06 13:38:32,040:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:38:32,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.
2025-02-06 13:38:32,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:38:32,043:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:38:32,043:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:38:32,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:38:32,043:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:38:32,157:INFO:Uploading results into container
2025-02-06 13:38:32,157:INFO:Uploading model into container now
2025-02-06 13:38:32,158:INFO:_master_model_container: 1
2025-02-06 13:38:32,158:INFO:_display_container: 2
2025-02-06 13:38:32,158:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:38:32,158:INFO:create_model() successfully completed......................................
2025-02-06 13:38:39,180:INFO:PyCaret ClassificationExperiment
2025-02-06 13:38:39,180:INFO:Logging name: clf-default-name
2025-02-06 13:38:39,180:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:38:39,180:INFO:version 3.3.2
2025-02-06 13:38:39,180:INFO:Initializing setup()
2025-02-06 13:38:39,180:INFO:self.USI: 69b7
2025-02-06 13:38:39,180:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:38:39,180:INFO:Checking environment
2025-02-06 13:38:39,180:INFO:python_version: 3.11.9
2025-02-06 13:38:39,180:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:38:39,180:INFO:machine: AMD64
2025-02-06 13:38:39,180:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:38:39,184:INFO:Memory: svmem(total=67771465728, available=48468848640, percent=28.5, used=19302617088, free=48468848640)
2025-02-06 13:38:39,184:INFO:Physical Core: 8
2025-02-06 13:38:39,184:INFO:Logical Core: 16
2025-02-06 13:38:39,184:INFO:Checking libraries
2025-02-06 13:38:39,184:INFO:System:
2025-02-06 13:38:39,184:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:38:39,184:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:38:39,184:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:38:39,184:INFO:PyCaret required dependencies:
2025-02-06 13:38:39,184:INFO:                 pip: 25.0
2025-02-06 13:38:39,184:INFO:          setuptools: 65.5.0
2025-02-06 13:38:39,184:INFO:             pycaret: 3.3.2
2025-02-06 13:38:39,184:INFO:             IPython: 8.32.0
2025-02-06 13:38:39,184:INFO:          ipywidgets: 8.1.5
2025-02-06 13:38:39,184:INFO:                tqdm: 4.67.1
2025-02-06 13:38:39,184:INFO:               numpy: 1.26.4
2025-02-06 13:38:39,184:INFO:              pandas: 2.1.4
2025-02-06 13:38:39,184:INFO:              jinja2: 3.1.5
2025-02-06 13:38:39,184:INFO:               scipy: 1.11.4
2025-02-06 13:38:39,184:INFO:              joblib: 1.3.2
2025-02-06 13:38:39,184:INFO:             sklearn: 1.4.2
2025-02-06 13:38:39,184:INFO:                pyod: 2.0.3
2025-02-06 13:38:39,184:INFO:            imblearn: 0.13.0
2025-02-06 13:38:39,184:INFO:   category_encoders: 2.7.0
2025-02-06 13:38:39,184:INFO:            lightgbm: 4.5.0
2025-02-06 13:38:39,184:INFO:               numba: 0.61.0
2025-02-06 13:38:39,184:INFO:            requests: 2.32.3
2025-02-06 13:38:39,184:INFO:          matplotlib: 3.7.5
2025-02-06 13:38:39,184:INFO:          scikitplot: 0.3.7
2025-02-06 13:38:39,184:INFO:         yellowbrick: 1.5
2025-02-06 13:38:39,184:INFO:              plotly: 5.24.1
2025-02-06 13:38:39,184:INFO:    plotly-resampler: Not installed
2025-02-06 13:38:39,184:INFO:             kaleido: 0.2.1
2025-02-06 13:38:39,184:INFO:           schemdraw: 0.15
2025-02-06 13:38:39,184:INFO:         statsmodels: 0.14.4
2025-02-06 13:38:39,184:INFO:              sktime: 0.26.0
2025-02-06 13:38:39,184:INFO:               tbats: 1.1.3
2025-02-06 13:38:39,184:INFO:            pmdarima: 2.0.4
2025-02-06 13:38:39,184:INFO:              psutil: 6.1.1
2025-02-06 13:38:39,184:INFO:          markupsafe: 3.0.2
2025-02-06 13:38:39,184:INFO:             pickle5: Not installed
2025-02-06 13:38:39,185:INFO:         cloudpickle: 3.1.1
2025-02-06 13:38:39,185:INFO:         deprecation: 2.1.0
2025-02-06 13:38:39,185:INFO:              xxhash: 3.5.0
2025-02-06 13:38:39,185:INFO:           wurlitzer: Not installed
2025-02-06 13:38:39,185:INFO:PyCaret optional dependencies:
2025-02-06 13:38:39,185:INFO:                shap: Not installed
2025-02-06 13:38:39,185:INFO:           interpret: Not installed
2025-02-06 13:38:39,185:INFO:                umap: Not installed
2025-02-06 13:38:39,185:INFO:     ydata_profiling: Not installed
2025-02-06 13:38:39,185:INFO:  explainerdashboard: Not installed
2025-02-06 13:38:39,185:INFO:             autoviz: Not installed
2025-02-06 13:38:39,185:INFO:           fairlearn: Not installed
2025-02-06 13:38:39,185:INFO:          deepchecks: Not installed
2025-02-06 13:38:39,185:INFO:             xgboost: Not installed
2025-02-06 13:38:39,185:INFO:            catboost: Not installed
2025-02-06 13:38:39,185:INFO:              kmodes: Not installed
2025-02-06 13:38:39,185:INFO:             mlxtend: Not installed
2025-02-06 13:38:39,185:INFO:       statsforecast: Not installed
2025-02-06 13:38:39,185:INFO:        tune_sklearn: Not installed
2025-02-06 13:38:39,185:INFO:                 ray: Not installed
2025-02-06 13:38:39,185:INFO:            hyperopt: Not installed
2025-02-06 13:38:39,185:INFO:              optuna: Not installed
2025-02-06 13:38:39,185:INFO:               skopt: Not installed
2025-02-06 13:38:39,185:INFO:              mlflow: Not installed
2025-02-06 13:38:39,185:INFO:              gradio: Not installed
2025-02-06 13:38:39,185:INFO:             fastapi: Not installed
2025-02-06 13:38:39,185:INFO:             uvicorn: Not installed
2025-02-06 13:38:39,185:INFO:              m2cgen: Not installed
2025-02-06 13:38:39,185:INFO:           evidently: Not installed
2025-02-06 13:38:39,185:INFO:               fugue: Not installed
2025-02-06 13:38:39,185:INFO:           streamlit: Not installed
2025-02-06 13:38:39,185:INFO:             prophet: Not installed
2025-02-06 13:38:39,185:INFO:None
2025-02-06 13:38:39,185:INFO:Set up data.
2025-02-06 13:38:39,194:INFO:Set up folding strategy.
2025-02-06 13:38:39,194:INFO:Set up train/test split.
2025-02-06 13:38:39,202:INFO:Set up index.
2025-02-06 13:38:39,203:INFO:Assigning column types.
2025-02-06 13:38:39,210:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:38:39,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,275:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,290:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:38:39,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:39,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,367:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:38:39,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,444:INFO:Preparing preprocessing pipeline...
2025-02-06 13:38:39,446:INFO:Set up simple imputation.
2025-02-06 13:38:39,467:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:38:39,469:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:38:39,469:INFO:Creating final display dataframe.
2025-02-06 13:38:39,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              69b7
2025-02-06 13:38:39,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:39,619:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:38:39,620:INFO:Initializing create_model()
2025-02-06 13:38:39,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A6048D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:38:39,620:INFO:Checking exceptions
2025-02-06 13:38:39,620:INFO:Importing libraries
2025-02-06 13:38:39,620:INFO:Copying training dataset
2025-02-06 13:38:39,628:INFO:Defining folds
2025-02-06 13:38:39,628:INFO:Declaring metric variables
2025-02-06 13:38:39,628:INFO:Importing untrained model
2025-02-06 13:38:39,628:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:38:39,628:INFO:Starting cross validation
2025-02-06 13:38:39,628:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:38:41,418:INFO:Calculating mean and std
2025-02-06 13:38:41,418:INFO:Creating metrics dataframe
2025-02-06 13:38:41,420:INFO:Finalizing model
2025-02-06 13:38:41,435:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:38:41,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.
2025-02-06 13:38:41,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:38:41,438:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:38:41,438:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:38:41,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:38:41,438:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:38:41,552:INFO:Uploading results into container
2025-02-06 13:38:41,553:INFO:Uploading model into container now
2025-02-06 13:38:41,553:INFO:_master_model_container: 1
2025-02-06 13:38:41,553:INFO:_display_container: 2
2025-02-06 13:38:41,554:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:38:41,554:INFO:create_model() successfully completed......................................
2025-02-06 13:38:55,893:INFO:PyCaret ClassificationExperiment
2025-02-06 13:38:55,893:INFO:Logging name: clf-default-name
2025-02-06 13:38:55,893:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:38:55,893:INFO:version 3.3.2
2025-02-06 13:38:55,893:INFO:Initializing setup()
2025-02-06 13:38:55,893:INFO:self.USI: 6899
2025-02-06 13:38:55,893:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:38:55,894:INFO:Checking environment
2025-02-06 13:38:55,894:INFO:python_version: 3.11.9
2025-02-06 13:38:55,894:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:38:55,894:INFO:machine: AMD64
2025-02-06 13:38:55,894:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:38:55,898:INFO:Memory: svmem(total=67771465728, available=47961849856, percent=29.2, used=19809615872, free=47961849856)
2025-02-06 13:38:55,898:INFO:Physical Core: 8
2025-02-06 13:38:55,898:INFO:Logical Core: 16
2025-02-06 13:38:55,898:INFO:Checking libraries
2025-02-06 13:38:55,898:INFO:System:
2025-02-06 13:38:55,898:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:38:55,898:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:38:55,898:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:38:55,898:INFO:PyCaret required dependencies:
2025-02-06 13:38:55,898:INFO:                 pip: 25.0
2025-02-06 13:38:55,898:INFO:          setuptools: 65.5.0
2025-02-06 13:38:55,898:INFO:             pycaret: 3.3.2
2025-02-06 13:38:55,898:INFO:             IPython: 8.32.0
2025-02-06 13:38:55,898:INFO:          ipywidgets: 8.1.5
2025-02-06 13:38:55,898:INFO:                tqdm: 4.67.1
2025-02-06 13:38:55,898:INFO:               numpy: 1.26.4
2025-02-06 13:38:55,898:INFO:              pandas: 2.1.4
2025-02-06 13:38:55,898:INFO:              jinja2: 3.1.5
2025-02-06 13:38:55,898:INFO:               scipy: 1.11.4
2025-02-06 13:38:55,898:INFO:              joblib: 1.3.2
2025-02-06 13:38:55,898:INFO:             sklearn: 1.4.2
2025-02-06 13:38:55,898:INFO:                pyod: 2.0.3
2025-02-06 13:38:55,898:INFO:            imblearn: 0.13.0
2025-02-06 13:38:55,898:INFO:   category_encoders: 2.7.0
2025-02-06 13:38:55,898:INFO:            lightgbm: 4.5.0
2025-02-06 13:38:55,898:INFO:               numba: 0.61.0
2025-02-06 13:38:55,898:INFO:            requests: 2.32.3
2025-02-06 13:38:55,898:INFO:          matplotlib: 3.7.5
2025-02-06 13:38:55,898:INFO:          scikitplot: 0.3.7
2025-02-06 13:38:55,898:INFO:         yellowbrick: 1.5
2025-02-06 13:38:55,898:INFO:              plotly: 5.24.1
2025-02-06 13:38:55,898:INFO:    plotly-resampler: Not installed
2025-02-06 13:38:55,898:INFO:             kaleido: 0.2.1
2025-02-06 13:38:55,898:INFO:           schemdraw: 0.15
2025-02-06 13:38:55,898:INFO:         statsmodels: 0.14.4
2025-02-06 13:38:55,898:INFO:              sktime: 0.26.0
2025-02-06 13:38:55,898:INFO:               tbats: 1.1.3
2025-02-06 13:38:55,898:INFO:            pmdarima: 2.0.4
2025-02-06 13:38:55,898:INFO:              psutil: 6.1.1
2025-02-06 13:38:55,899:INFO:          markupsafe: 3.0.2
2025-02-06 13:38:55,899:INFO:             pickle5: Not installed
2025-02-06 13:38:55,899:INFO:         cloudpickle: 3.1.1
2025-02-06 13:38:55,899:INFO:         deprecation: 2.1.0
2025-02-06 13:38:55,899:INFO:              xxhash: 3.5.0
2025-02-06 13:38:55,899:INFO:           wurlitzer: Not installed
2025-02-06 13:38:55,899:INFO:PyCaret optional dependencies:
2025-02-06 13:38:55,899:INFO:                shap: Not installed
2025-02-06 13:38:55,899:INFO:           interpret: Not installed
2025-02-06 13:38:55,899:INFO:                umap: Not installed
2025-02-06 13:38:55,899:INFO:     ydata_profiling: Not installed
2025-02-06 13:38:55,899:INFO:  explainerdashboard: Not installed
2025-02-06 13:38:55,899:INFO:             autoviz: Not installed
2025-02-06 13:38:55,899:INFO:           fairlearn: Not installed
2025-02-06 13:38:55,899:INFO:          deepchecks: Not installed
2025-02-06 13:38:55,899:INFO:             xgboost: Not installed
2025-02-06 13:38:55,899:INFO:            catboost: Not installed
2025-02-06 13:38:55,899:INFO:              kmodes: Not installed
2025-02-06 13:38:55,899:INFO:             mlxtend: Not installed
2025-02-06 13:38:55,899:INFO:       statsforecast: Not installed
2025-02-06 13:38:55,899:INFO:        tune_sklearn: Not installed
2025-02-06 13:38:55,899:INFO:                 ray: Not installed
2025-02-06 13:38:55,899:INFO:            hyperopt: Not installed
2025-02-06 13:38:55,899:INFO:              optuna: Not installed
2025-02-06 13:38:55,899:INFO:               skopt: Not installed
2025-02-06 13:38:55,899:INFO:              mlflow: Not installed
2025-02-06 13:38:55,899:INFO:              gradio: Not installed
2025-02-06 13:38:55,899:INFO:             fastapi: Not installed
2025-02-06 13:38:55,899:INFO:             uvicorn: Not installed
2025-02-06 13:38:55,899:INFO:              m2cgen: Not installed
2025-02-06 13:38:55,899:INFO:           evidently: Not installed
2025-02-06 13:38:55,899:INFO:               fugue: Not installed
2025-02-06 13:38:55,899:INFO:           streamlit: Not installed
2025-02-06 13:38:55,899:INFO:             prophet: Not installed
2025-02-06 13:38:55,899:INFO:None
2025-02-06 13:38:55,899:INFO:Set up data.
2025-02-06 13:38:55,907:INFO:Set up folding strategy.
2025-02-06 13:38:55,907:INFO:Set up train/test split.
2025-02-06 13:38:55,914:INFO:Set up index.
2025-02-06 13:38:55,915:INFO:Assigning column types.
2025-02-06 13:38:55,922:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:38:55,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:55,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:55,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:55,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:55,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:38:55,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:56,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,002:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:38:56,027:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:56,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:38:56,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:38:56,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,160:INFO:Preparing preprocessing pipeline...
2025-02-06 13:38:56,161:INFO:Set up simple imputation.
2025-02-06 13:38:56,183:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:38:56,184:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:38:56,184:INFO:Creating final display dataframe.
2025-02-06 13:38:56,257:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              6899
2025-02-06 13:38:56,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:38:56,335:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:38:56,336:INFO:Initializing create_model()
2025-02-06 13:38:56,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C767E4A10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:38:56,336:INFO:Checking exceptions
2025-02-06 13:38:56,337:INFO:Importing libraries
2025-02-06 13:38:56,337:INFO:Copying training dataset
2025-02-06 13:38:56,344:INFO:Defining folds
2025-02-06 13:38:56,344:INFO:Declaring metric variables
2025-02-06 13:38:56,344:INFO:Importing untrained model
2025-02-06 13:38:56,344:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:38:56,344:INFO:Starting cross validation
2025-02-06 13:38:56,344:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:38:57,842:INFO:Calculating mean and std
2025-02-06 13:38:57,842:INFO:Creating metrics dataframe
2025-02-06 13:38:57,844:INFO:Finalizing model
2025-02-06 13:38:57,857:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:38:57,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.
2025-02-06 13:38:57,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:38:57,859:INFO:[LightGBM] [Info] Total Bins 6970
2025-02-06 13:38:57,859:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:38:57,859:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:38:57,859:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:38:57,990:INFO:Uploading results into container
2025-02-06 13:38:57,990:INFO:Uploading model into container now
2025-02-06 13:38:57,991:INFO:_master_model_container: 1
2025-02-06 13:38:57,991:INFO:_display_container: 2
2025-02-06 13:38:57,991:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1234, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:38:57,991:INFO:create_model() successfully completed......................................
2025-02-06 13:39:07,787:INFO:PyCaret ClassificationExperiment
2025-02-06 13:39:07,787:INFO:Logging name: clf-default-name
2025-02-06 13:39:07,787:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:39:07,787:INFO:version 3.3.2
2025-02-06 13:39:07,787:INFO:Initializing setup()
2025-02-06 13:39:07,787:INFO:self.USI: fb7f
2025-02-06 13:39:07,787:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:39:07,787:INFO:Checking environment
2025-02-06 13:39:07,787:INFO:python_version: 3.11.9
2025-02-06 13:39:07,787:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:39:07,787:INFO:machine: AMD64
2025-02-06 13:39:07,787:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:39:07,791:INFO:Memory: svmem(total=67771465728, available=47852466176, percent=29.4, used=19918999552, free=47852466176)
2025-02-06 13:39:07,791:INFO:Physical Core: 8
2025-02-06 13:39:07,791:INFO:Logical Core: 16
2025-02-06 13:39:07,791:INFO:Checking libraries
2025-02-06 13:39:07,791:INFO:System:
2025-02-06 13:39:07,791:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:39:07,791:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:39:07,791:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:39:07,791:INFO:PyCaret required dependencies:
2025-02-06 13:39:07,791:INFO:                 pip: 25.0
2025-02-06 13:39:07,792:INFO:          setuptools: 65.5.0
2025-02-06 13:39:07,792:INFO:             pycaret: 3.3.2
2025-02-06 13:39:07,792:INFO:             IPython: 8.32.0
2025-02-06 13:39:07,792:INFO:          ipywidgets: 8.1.5
2025-02-06 13:39:07,792:INFO:                tqdm: 4.67.1
2025-02-06 13:39:07,792:INFO:               numpy: 1.26.4
2025-02-06 13:39:07,792:INFO:              pandas: 2.1.4
2025-02-06 13:39:07,792:INFO:              jinja2: 3.1.5
2025-02-06 13:39:07,792:INFO:               scipy: 1.11.4
2025-02-06 13:39:07,792:INFO:              joblib: 1.3.2
2025-02-06 13:39:07,792:INFO:             sklearn: 1.4.2
2025-02-06 13:39:07,792:INFO:                pyod: 2.0.3
2025-02-06 13:39:07,792:INFO:            imblearn: 0.13.0
2025-02-06 13:39:07,792:INFO:   category_encoders: 2.7.0
2025-02-06 13:39:07,792:INFO:            lightgbm: 4.5.0
2025-02-06 13:39:07,792:INFO:               numba: 0.61.0
2025-02-06 13:39:07,792:INFO:            requests: 2.32.3
2025-02-06 13:39:07,792:INFO:          matplotlib: 3.7.5
2025-02-06 13:39:07,792:INFO:          scikitplot: 0.3.7
2025-02-06 13:39:07,792:INFO:         yellowbrick: 1.5
2025-02-06 13:39:07,792:INFO:              plotly: 5.24.1
2025-02-06 13:39:07,792:INFO:    plotly-resampler: Not installed
2025-02-06 13:39:07,792:INFO:             kaleido: 0.2.1
2025-02-06 13:39:07,792:INFO:           schemdraw: 0.15
2025-02-06 13:39:07,792:INFO:         statsmodels: 0.14.4
2025-02-06 13:39:07,792:INFO:              sktime: 0.26.0
2025-02-06 13:39:07,792:INFO:               tbats: 1.1.3
2025-02-06 13:39:07,792:INFO:            pmdarima: 2.0.4
2025-02-06 13:39:07,792:INFO:              psutil: 6.1.1
2025-02-06 13:39:07,792:INFO:          markupsafe: 3.0.2
2025-02-06 13:39:07,792:INFO:             pickle5: Not installed
2025-02-06 13:39:07,792:INFO:         cloudpickle: 3.1.1
2025-02-06 13:39:07,792:INFO:         deprecation: 2.1.0
2025-02-06 13:39:07,792:INFO:              xxhash: 3.5.0
2025-02-06 13:39:07,792:INFO:           wurlitzer: Not installed
2025-02-06 13:39:07,792:INFO:PyCaret optional dependencies:
2025-02-06 13:39:07,792:INFO:                shap: Not installed
2025-02-06 13:39:07,792:INFO:           interpret: Not installed
2025-02-06 13:39:07,792:INFO:                umap: Not installed
2025-02-06 13:39:07,792:INFO:     ydata_profiling: Not installed
2025-02-06 13:39:07,792:INFO:  explainerdashboard: Not installed
2025-02-06 13:39:07,792:INFO:             autoviz: Not installed
2025-02-06 13:39:07,792:INFO:           fairlearn: Not installed
2025-02-06 13:39:07,792:INFO:          deepchecks: Not installed
2025-02-06 13:39:07,792:INFO:             xgboost: Not installed
2025-02-06 13:39:07,792:INFO:            catboost: Not installed
2025-02-06 13:39:07,792:INFO:              kmodes: Not installed
2025-02-06 13:39:07,792:INFO:             mlxtend: Not installed
2025-02-06 13:39:07,792:INFO:       statsforecast: Not installed
2025-02-06 13:39:07,792:INFO:        tune_sklearn: Not installed
2025-02-06 13:39:07,792:INFO:                 ray: Not installed
2025-02-06 13:39:07,792:INFO:            hyperopt: Not installed
2025-02-06 13:39:07,792:INFO:              optuna: Not installed
2025-02-06 13:39:07,792:INFO:               skopt: Not installed
2025-02-06 13:39:07,792:INFO:              mlflow: Not installed
2025-02-06 13:39:07,792:INFO:              gradio: Not installed
2025-02-06 13:39:07,792:INFO:             fastapi: Not installed
2025-02-06 13:39:07,792:INFO:             uvicorn: Not installed
2025-02-06 13:39:07,792:INFO:              m2cgen: Not installed
2025-02-06 13:39:07,792:INFO:           evidently: Not installed
2025-02-06 13:39:07,792:INFO:               fugue: Not installed
2025-02-06 13:39:07,792:INFO:           streamlit: Not installed
2025-02-06 13:39:07,792:INFO:             prophet: Not installed
2025-02-06 13:39:07,792:INFO:None
2025-02-06 13:39:07,792:INFO:Set up data.
2025-02-06 13:39:07,801:INFO:Set up folding strategy.
2025-02-06 13:39:07,801:INFO:Set up train/test split.
2025-02-06 13:39:07,808:INFO:Set up index.
2025-02-06 13:39:07,809:INFO:Assigning column types.
2025-02-06 13:39:07,815:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:39:07,840:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,894:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:39:07,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:07,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:07,971:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:39:08,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,050:INFO:Preparing preprocessing pipeline...
2025-02-06 13:39:08,051:INFO:Set up simple imputation.
2025-02-06 13:39:08,071:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:39:08,075:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:39:08,075:INFO:Creating final display dataframe.
2025-02-06 13:39:08,147:INFO:Setup _display_container:                     Description             Value
0                    Session id             22222
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              fb7f
2025-02-06 13:39:08,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:08,234:INFO:setup() successfully completed in 0.45s...............
2025-02-06 13:39:08,235:INFO:Initializing create_model()
2025-02-06 13:39:08,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A61CA10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:39:08,235:INFO:Checking exceptions
2025-02-06 13:39:08,236:INFO:Importing libraries
2025-02-06 13:39:08,236:INFO:Copying training dataset
2025-02-06 13:39:08,245:INFO:Defining folds
2025-02-06 13:39:08,246:INFO:Declaring metric variables
2025-02-06 13:39:08,246:INFO:Importing untrained model
2025-02-06 13:39:08,246:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:39:08,246:INFO:Starting cross validation
2025-02-06 13:39:08,246:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:39:08,646:INFO:Calculating mean and std
2025-02-06 13:39:08,647:INFO:Creating metrics dataframe
2025-02-06 13:39:08,647:INFO:Finalizing model
2025-02-06 13:39:08,661:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:39:08,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.
2025-02-06 13:39:08,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:39:08,664:INFO:[LightGBM] [Info] Total Bins 6965
2025-02-06 13:39:08,664:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:39:08,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:39:08,664:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:39:08,797:INFO:Uploading results into container
2025-02-06 13:39:08,797:INFO:Uploading model into container now
2025-02-06 13:39:08,797:INFO:_master_model_container: 1
2025-02-06 13:39:08,797:INFO:_display_container: 2
2025-02-06 13:39:08,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=22222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:39:08,799:INFO:create_model() successfully completed......................................
2025-02-06 13:39:16,670:INFO:PyCaret ClassificationExperiment
2025-02-06 13:39:16,671:INFO:Logging name: clf-default-name
2025-02-06 13:39:16,671:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:39:16,671:INFO:version 3.3.2
2025-02-06 13:39:16,671:INFO:Initializing setup()
2025-02-06 13:39:16,671:INFO:self.USI: df22
2025-02-06 13:39:16,671:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:39:16,671:INFO:Checking environment
2025-02-06 13:39:16,671:INFO:python_version: 3.11.9
2025-02-06 13:39:16,671:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:39:16,671:INFO:machine: AMD64
2025-02-06 13:39:16,671:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:39:16,676:INFO:Memory: svmem(total=67771465728, available=47858675712, percent=29.4, used=19912790016, free=47858675712)
2025-02-06 13:39:16,676:INFO:Physical Core: 8
2025-02-06 13:39:16,676:INFO:Logical Core: 16
2025-02-06 13:39:16,676:INFO:Checking libraries
2025-02-06 13:39:16,676:INFO:System:
2025-02-06 13:39:16,676:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:39:16,676:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:39:16,676:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:39:16,676:INFO:PyCaret required dependencies:
2025-02-06 13:39:16,676:INFO:                 pip: 25.0
2025-02-06 13:39:16,676:INFO:          setuptools: 65.5.0
2025-02-06 13:39:16,676:INFO:             pycaret: 3.3.2
2025-02-06 13:39:16,676:INFO:             IPython: 8.32.0
2025-02-06 13:39:16,676:INFO:          ipywidgets: 8.1.5
2025-02-06 13:39:16,676:INFO:                tqdm: 4.67.1
2025-02-06 13:39:16,676:INFO:               numpy: 1.26.4
2025-02-06 13:39:16,676:INFO:              pandas: 2.1.4
2025-02-06 13:39:16,676:INFO:              jinja2: 3.1.5
2025-02-06 13:39:16,676:INFO:               scipy: 1.11.4
2025-02-06 13:39:16,676:INFO:              joblib: 1.3.2
2025-02-06 13:39:16,676:INFO:             sklearn: 1.4.2
2025-02-06 13:39:16,677:INFO:                pyod: 2.0.3
2025-02-06 13:39:16,677:INFO:            imblearn: 0.13.0
2025-02-06 13:39:16,677:INFO:   category_encoders: 2.7.0
2025-02-06 13:39:16,677:INFO:            lightgbm: 4.5.0
2025-02-06 13:39:16,677:INFO:               numba: 0.61.0
2025-02-06 13:39:16,677:INFO:            requests: 2.32.3
2025-02-06 13:39:16,677:INFO:          matplotlib: 3.7.5
2025-02-06 13:39:16,677:INFO:          scikitplot: 0.3.7
2025-02-06 13:39:16,677:INFO:         yellowbrick: 1.5
2025-02-06 13:39:16,677:INFO:              plotly: 5.24.1
2025-02-06 13:39:16,677:INFO:    plotly-resampler: Not installed
2025-02-06 13:39:16,677:INFO:             kaleido: 0.2.1
2025-02-06 13:39:16,677:INFO:           schemdraw: 0.15
2025-02-06 13:39:16,677:INFO:         statsmodels: 0.14.4
2025-02-06 13:39:16,677:INFO:              sktime: 0.26.0
2025-02-06 13:39:16,677:INFO:               tbats: 1.1.3
2025-02-06 13:39:16,677:INFO:            pmdarima: 2.0.4
2025-02-06 13:39:16,677:INFO:              psutil: 6.1.1
2025-02-06 13:39:16,677:INFO:          markupsafe: 3.0.2
2025-02-06 13:39:16,677:INFO:             pickle5: Not installed
2025-02-06 13:39:16,677:INFO:         cloudpickle: 3.1.1
2025-02-06 13:39:16,677:INFO:         deprecation: 2.1.0
2025-02-06 13:39:16,677:INFO:              xxhash: 3.5.0
2025-02-06 13:39:16,677:INFO:           wurlitzer: Not installed
2025-02-06 13:39:16,677:INFO:PyCaret optional dependencies:
2025-02-06 13:39:16,677:INFO:                shap: Not installed
2025-02-06 13:39:16,677:INFO:           interpret: Not installed
2025-02-06 13:39:16,677:INFO:                umap: Not installed
2025-02-06 13:39:16,677:INFO:     ydata_profiling: Not installed
2025-02-06 13:39:16,677:INFO:  explainerdashboard: Not installed
2025-02-06 13:39:16,677:INFO:             autoviz: Not installed
2025-02-06 13:39:16,677:INFO:           fairlearn: Not installed
2025-02-06 13:39:16,677:INFO:          deepchecks: Not installed
2025-02-06 13:39:16,677:INFO:             xgboost: Not installed
2025-02-06 13:39:16,677:INFO:            catboost: Not installed
2025-02-06 13:39:16,677:INFO:              kmodes: Not installed
2025-02-06 13:39:16,677:INFO:             mlxtend: Not installed
2025-02-06 13:39:16,677:INFO:       statsforecast: Not installed
2025-02-06 13:39:16,677:INFO:        tune_sklearn: Not installed
2025-02-06 13:39:16,677:INFO:                 ray: Not installed
2025-02-06 13:39:16,677:INFO:            hyperopt: Not installed
2025-02-06 13:39:16,677:INFO:              optuna: Not installed
2025-02-06 13:39:16,677:INFO:               skopt: Not installed
2025-02-06 13:39:16,677:INFO:              mlflow: Not installed
2025-02-06 13:39:16,677:INFO:              gradio: Not installed
2025-02-06 13:39:16,677:INFO:             fastapi: Not installed
2025-02-06 13:39:16,677:INFO:             uvicorn: Not installed
2025-02-06 13:39:16,677:INFO:              m2cgen: Not installed
2025-02-06 13:39:16,677:INFO:           evidently: Not installed
2025-02-06 13:39:16,677:INFO:               fugue: Not installed
2025-02-06 13:39:16,677:INFO:           streamlit: Not installed
2025-02-06 13:39:16,677:INFO:             prophet: Not installed
2025-02-06 13:39:16,677:INFO:None
2025-02-06 13:39:16,677:INFO:Set up data.
2025-02-06 13:39:16,685:INFO:Set up folding strategy.
2025-02-06 13:39:16,685:INFO:Set up train/test split.
2025-02-06 13:39:16,691:INFO:Set up index.
2025-02-06 13:39:16,693:INFO:Assigning column types.
2025-02-06 13:39:16,700:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:39:16,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,779:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:39:16,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:39:16,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,857:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:39:16,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:16,934:INFO:Preparing preprocessing pipeline...
2025-02-06 13:39:16,935:INFO:Set up simple imputation.
2025-02-06 13:39:16,957:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:39:16,958:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:39:16,958:INFO:Creating final display dataframe.
2025-02-06 13:39:17,030:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              df22
2025-02-06 13:39:17,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:17,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:17,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:17,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:39:17,109:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:39:17,109:INFO:Initializing create_model()
2025-02-06 13:39:17,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A80E210>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:39:17,109:INFO:Checking exceptions
2025-02-06 13:39:17,110:INFO:Importing libraries
2025-02-06 13:39:17,110:INFO:Copying training dataset
2025-02-06 13:39:17,116:INFO:Defining folds
2025-02-06 13:39:17,116:INFO:Declaring metric variables
2025-02-06 13:39:17,116:INFO:Importing untrained model
2025-02-06 13:39:17,117:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:39:17,117:INFO:Starting cross validation
2025-02-06 13:39:17,117:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:39:17,532:INFO:Calculating mean and std
2025-02-06 13:39:17,532:INFO:Creating metrics dataframe
2025-02-06 13:39:17,533:INFO:Finalizing model
2025-02-06 13:39:17,551:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:39:17,552:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001028 seconds.
2025-02-06 13:39:17,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:39:17,552:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:39:17,553:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:39:17,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:39:17,553:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:39:17,674:INFO:Uploading results into container
2025-02-06 13:39:17,675:INFO:Uploading model into container now
2025-02-06 13:39:17,675:INFO:_master_model_container: 1
2025-02-06 13:39:17,675:INFO:_display_container: 2
2025-02-06 13:39:17,675:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:39:17,675:INFO:create_model() successfully completed......................................
2025-02-06 13:54:48,262:INFO:PyCaret ClassificationExperiment
2025-02-06 13:54:48,263:INFO:Logging name: clf-default-name
2025-02-06 13:54:48,263:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:54:48,263:INFO:version 3.3.2
2025-02-06 13:54:48,263:INFO:Initializing setup()
2025-02-06 13:54:48,263:INFO:self.USI: 69cd
2025-02-06 13:54:48,263:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:54:48,263:INFO:Checking environment
2025-02-06 13:54:48,263:INFO:python_version: 3.11.9
2025-02-06 13:54:48,263:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:54:48,263:INFO:machine: AMD64
2025-02-06 13:54:48,263:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:54:48,267:INFO:Memory: svmem(total=67771465728, available=50458144768, percent=25.5, used=17313320960, free=50458144768)
2025-02-06 13:54:48,267:INFO:Physical Core: 8
2025-02-06 13:54:48,267:INFO:Logical Core: 16
2025-02-06 13:54:48,267:INFO:Checking libraries
2025-02-06 13:54:48,267:INFO:System:
2025-02-06 13:54:48,267:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:54:48,267:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:54:48,267:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:54:48,267:INFO:PyCaret required dependencies:
2025-02-06 13:54:48,267:INFO:                 pip: 25.0
2025-02-06 13:54:48,267:INFO:          setuptools: 65.5.0
2025-02-06 13:54:48,267:INFO:             pycaret: 3.3.2
2025-02-06 13:54:48,267:INFO:             IPython: 8.32.0
2025-02-06 13:54:48,267:INFO:          ipywidgets: 8.1.5
2025-02-06 13:54:48,267:INFO:                tqdm: 4.67.1
2025-02-06 13:54:48,267:INFO:               numpy: 1.26.4
2025-02-06 13:54:48,267:INFO:              pandas: 2.1.4
2025-02-06 13:54:48,267:INFO:              jinja2: 3.1.5
2025-02-06 13:54:48,267:INFO:               scipy: 1.11.4
2025-02-06 13:54:48,267:INFO:              joblib: 1.3.2
2025-02-06 13:54:48,267:INFO:             sklearn: 1.4.2
2025-02-06 13:54:48,267:INFO:                pyod: 2.0.3
2025-02-06 13:54:48,267:INFO:            imblearn: 0.13.0
2025-02-06 13:54:48,268:INFO:   category_encoders: 2.7.0
2025-02-06 13:54:48,268:INFO:            lightgbm: 4.5.0
2025-02-06 13:54:48,268:INFO:               numba: 0.61.0
2025-02-06 13:54:48,268:INFO:            requests: 2.32.3
2025-02-06 13:54:48,268:INFO:          matplotlib: 3.7.5
2025-02-06 13:54:48,268:INFO:          scikitplot: 0.3.7
2025-02-06 13:54:48,268:INFO:         yellowbrick: 1.5
2025-02-06 13:54:48,268:INFO:              plotly: 5.24.1
2025-02-06 13:54:48,268:INFO:    plotly-resampler: Not installed
2025-02-06 13:54:48,268:INFO:             kaleido: 0.2.1
2025-02-06 13:54:48,268:INFO:           schemdraw: 0.15
2025-02-06 13:54:48,268:INFO:         statsmodels: 0.14.4
2025-02-06 13:54:48,268:INFO:              sktime: 0.26.0
2025-02-06 13:54:48,268:INFO:               tbats: 1.1.3
2025-02-06 13:54:48,268:INFO:            pmdarima: 2.0.4
2025-02-06 13:54:48,268:INFO:              psutil: 6.1.1
2025-02-06 13:54:48,268:INFO:          markupsafe: 3.0.2
2025-02-06 13:54:48,268:INFO:             pickle5: Not installed
2025-02-06 13:54:48,268:INFO:         cloudpickle: 3.1.1
2025-02-06 13:54:48,268:INFO:         deprecation: 2.1.0
2025-02-06 13:54:48,268:INFO:              xxhash: 3.5.0
2025-02-06 13:54:48,268:INFO:           wurlitzer: Not installed
2025-02-06 13:54:48,268:INFO:PyCaret optional dependencies:
2025-02-06 13:54:48,268:INFO:                shap: Not installed
2025-02-06 13:54:48,268:INFO:           interpret: Not installed
2025-02-06 13:54:48,268:INFO:                umap: Not installed
2025-02-06 13:54:48,268:INFO:     ydata_profiling: Not installed
2025-02-06 13:54:48,268:INFO:  explainerdashboard: Not installed
2025-02-06 13:54:48,268:INFO:             autoviz: Not installed
2025-02-06 13:54:48,268:INFO:           fairlearn: Not installed
2025-02-06 13:54:48,268:INFO:          deepchecks: Not installed
2025-02-06 13:54:48,268:INFO:             xgboost: Not installed
2025-02-06 13:54:48,268:INFO:            catboost: Not installed
2025-02-06 13:54:48,268:INFO:              kmodes: Not installed
2025-02-06 13:54:48,268:INFO:             mlxtend: Not installed
2025-02-06 13:54:48,268:INFO:       statsforecast: Not installed
2025-02-06 13:54:48,268:INFO:        tune_sklearn: Not installed
2025-02-06 13:54:48,268:INFO:                 ray: Not installed
2025-02-06 13:54:48,268:INFO:            hyperopt: Not installed
2025-02-06 13:54:48,268:INFO:              optuna: Not installed
2025-02-06 13:54:48,268:INFO:               skopt: Not installed
2025-02-06 13:54:48,268:INFO:              mlflow: Not installed
2025-02-06 13:54:48,268:INFO:              gradio: Not installed
2025-02-06 13:54:48,268:INFO:             fastapi: Not installed
2025-02-06 13:54:48,268:INFO:             uvicorn: Not installed
2025-02-06 13:54:48,268:INFO:              m2cgen: Not installed
2025-02-06 13:54:48,268:INFO:           evidently: Not installed
2025-02-06 13:54:48,268:INFO:               fugue: Not installed
2025-02-06 13:54:48,268:INFO:           streamlit: Not installed
2025-02-06 13:54:48,268:INFO:             prophet: Not installed
2025-02-06 13:54:48,268:INFO:None
2025-02-06 13:54:48,268:INFO:Set up data.
2025-02-06 13:54:48,277:INFO:Set up folding strategy.
2025-02-06 13:54:48,277:INFO:Set up train/test split.
2025-02-06 13:54:48,284:INFO:Set up index.
2025-02-06 13:54:48,285:INFO:Assigning column types.
2025-02-06 13:54:48,292:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:54:48,315:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,355:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,370:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:54:48,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:54:48,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,449:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:54:48,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,528:INFO:Preparing preprocessing pipeline...
2025-02-06 13:54:48,529:INFO:Set up simple imputation.
2025-02-06 13:54:48,565:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:54:48,566:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:54:48,566:INFO:Creating final display dataframe.
2025-02-06 13:54:48,640:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              69cd
2025-02-06 13:54:48,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:54:48,718:INFO:setup() successfully completed in 0.46s...............
2025-02-06 13:54:48,718:INFO:Initializing create_model()
2025-02-06 13:54:48,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7BC6E0D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:54:48,718:INFO:Checking exceptions
2025-02-06 13:54:48,720:INFO:Importing libraries
2025-02-06 13:54:48,720:INFO:Copying training dataset
2025-02-06 13:54:48,727:INFO:Defining folds
2025-02-06 13:54:48,727:INFO:Declaring metric variables
2025-02-06 13:54:48,727:INFO:Importing untrained model
2025-02-06 13:54:48,727:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:54:48,727:INFO:Starting cross validation
2025-02-06 13:54:48,728:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:54:55,690:INFO:Calculating mean and std
2025-02-06 13:54:55,690:INFO:Creating metrics dataframe
2025-02-06 13:54:55,693:INFO:Finalizing model
2025-02-06 13:54:55,722:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:54:55,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002515 seconds.
2025-02-06 13:54:55,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:54:55,726:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:54:55,727:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:54:55,727:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:54:55,727:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:54:55,862:INFO:Uploading results into container
2025-02-06 13:54:55,863:INFO:Uploading model into container now
2025-02-06 13:54:55,863:INFO:_master_model_container: 1
2025-02-06 13:54:55,863:INFO:_display_container: 2
2025-02-06 13:54:55,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:54:55,863:INFO:create_model() successfully completed......................................
2025-02-06 13:55:45,591:INFO:PyCaret ClassificationExperiment
2025-02-06 13:55:45,591:INFO:Logging name: clf-default-name
2025-02-06 13:55:45,591:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:55:45,591:INFO:version 3.3.2
2025-02-06 13:55:45,591:INFO:Initializing setup()
2025-02-06 13:55:45,591:INFO:self.USI: e1c1
2025-02-06 13:55:45,591:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:55:45,591:INFO:Checking environment
2025-02-06 13:55:45,591:INFO:python_version: 3.11.9
2025-02-06 13:55:45,591:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:55:45,591:INFO:machine: AMD64
2025-02-06 13:55:45,591:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:55:45,595:INFO:Memory: svmem(total=67771465728, available=49278377984, percent=27.3, used=18493087744, free=49278377984)
2025-02-06 13:55:45,595:INFO:Physical Core: 8
2025-02-06 13:55:45,595:INFO:Logical Core: 16
2025-02-06 13:55:45,595:INFO:Checking libraries
2025-02-06 13:55:45,595:INFO:System:
2025-02-06 13:55:45,595:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:55:45,595:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:55:45,595:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:55:45,595:INFO:PyCaret required dependencies:
2025-02-06 13:55:45,596:INFO:                 pip: 25.0
2025-02-06 13:55:45,596:INFO:          setuptools: 65.5.0
2025-02-06 13:55:45,596:INFO:             pycaret: 3.3.2
2025-02-06 13:55:45,596:INFO:             IPython: 8.32.0
2025-02-06 13:55:45,596:INFO:          ipywidgets: 8.1.5
2025-02-06 13:55:45,596:INFO:                tqdm: 4.67.1
2025-02-06 13:55:45,596:INFO:               numpy: 1.26.4
2025-02-06 13:55:45,596:INFO:              pandas: 2.1.4
2025-02-06 13:55:45,596:INFO:              jinja2: 3.1.5
2025-02-06 13:55:45,596:INFO:               scipy: 1.11.4
2025-02-06 13:55:45,596:INFO:              joblib: 1.3.2
2025-02-06 13:55:45,596:INFO:             sklearn: 1.4.2
2025-02-06 13:55:45,596:INFO:                pyod: 2.0.3
2025-02-06 13:55:45,596:INFO:            imblearn: 0.13.0
2025-02-06 13:55:45,596:INFO:   category_encoders: 2.7.0
2025-02-06 13:55:45,596:INFO:            lightgbm: 4.5.0
2025-02-06 13:55:45,596:INFO:               numba: 0.61.0
2025-02-06 13:55:45,596:INFO:            requests: 2.32.3
2025-02-06 13:55:45,596:INFO:          matplotlib: 3.7.5
2025-02-06 13:55:45,596:INFO:          scikitplot: 0.3.7
2025-02-06 13:55:45,596:INFO:         yellowbrick: 1.5
2025-02-06 13:55:45,596:INFO:              plotly: 5.24.1
2025-02-06 13:55:45,596:INFO:    plotly-resampler: Not installed
2025-02-06 13:55:45,596:INFO:             kaleido: 0.2.1
2025-02-06 13:55:45,596:INFO:           schemdraw: 0.15
2025-02-06 13:55:45,596:INFO:         statsmodels: 0.14.4
2025-02-06 13:55:45,596:INFO:              sktime: 0.26.0
2025-02-06 13:55:45,596:INFO:               tbats: 1.1.3
2025-02-06 13:55:45,596:INFO:            pmdarima: 2.0.4
2025-02-06 13:55:45,596:INFO:              psutil: 6.1.1
2025-02-06 13:55:45,596:INFO:          markupsafe: 3.0.2
2025-02-06 13:55:45,596:INFO:             pickle5: Not installed
2025-02-06 13:55:45,596:INFO:         cloudpickle: 3.1.1
2025-02-06 13:55:45,597:INFO:         deprecation: 2.1.0
2025-02-06 13:55:45,597:INFO:              xxhash: 3.5.0
2025-02-06 13:55:45,597:INFO:           wurlitzer: Not installed
2025-02-06 13:55:45,597:INFO:PyCaret optional dependencies:
2025-02-06 13:55:45,597:INFO:                shap: Not installed
2025-02-06 13:55:45,597:INFO:           interpret: Not installed
2025-02-06 13:55:45,597:INFO:                umap: Not installed
2025-02-06 13:55:45,597:INFO:     ydata_profiling: Not installed
2025-02-06 13:55:45,597:INFO:  explainerdashboard: Not installed
2025-02-06 13:55:45,597:INFO:             autoviz: Not installed
2025-02-06 13:55:45,597:INFO:           fairlearn: Not installed
2025-02-06 13:55:45,597:INFO:          deepchecks: Not installed
2025-02-06 13:55:45,597:INFO:             xgboost: Not installed
2025-02-06 13:55:45,597:INFO:            catboost: Not installed
2025-02-06 13:55:45,597:INFO:              kmodes: Not installed
2025-02-06 13:55:45,597:INFO:             mlxtend: Not installed
2025-02-06 13:55:45,597:INFO:       statsforecast: Not installed
2025-02-06 13:55:45,597:INFO:        tune_sklearn: Not installed
2025-02-06 13:55:45,597:INFO:                 ray: Not installed
2025-02-06 13:55:45,597:INFO:            hyperopt: Not installed
2025-02-06 13:55:45,597:INFO:              optuna: Not installed
2025-02-06 13:55:45,597:INFO:               skopt: Not installed
2025-02-06 13:55:45,597:INFO:              mlflow: Not installed
2025-02-06 13:55:45,597:INFO:              gradio: Not installed
2025-02-06 13:55:45,597:INFO:             fastapi: Not installed
2025-02-06 13:55:45,597:INFO:             uvicorn: Not installed
2025-02-06 13:55:45,597:INFO:              m2cgen: Not installed
2025-02-06 13:55:45,597:INFO:           evidently: Not installed
2025-02-06 13:55:45,597:INFO:               fugue: Not installed
2025-02-06 13:55:45,597:INFO:           streamlit: Not installed
2025-02-06 13:55:45,597:INFO:             prophet: Not installed
2025-02-06 13:55:45,597:INFO:None
2025-02-06 13:55:45,597:INFO:Set up data.
2025-02-06 13:55:45,605:INFO:Set up folding strategy.
2025-02-06 13:55:45,605:INFO:Set up train/test split.
2025-02-06 13:55:45,611:INFO:Set up index.
2025-02-06 13:55:45,612:INFO:Assigning column types.
2025-02-06 13:55:45,619:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:55:45,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,698:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:55:45,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:55:45,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,779:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:55:45,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,859:INFO:Preparing preprocessing pipeline...
2025-02-06 13:55:45,860:INFO:Set up simple imputation.
2025-02-06 13:55:45,881:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:55:45,883:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:55:45,883:INFO:Creating final display dataframe.
2025-02-06 13:55:45,954:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              e1c1
2025-02-06 13:55:45,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:45,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:46,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:46,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:55:46,033:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:55:46,033:INFO:Initializing create_model()
2025-02-06 13:55:46,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7BDB43D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:55:46,033:INFO:Checking exceptions
2025-02-06 13:55:46,034:INFO:Importing libraries
2025-02-06 13:55:46,034:INFO:Copying training dataset
2025-02-06 13:55:46,040:INFO:Defining folds
2025-02-06 13:55:46,041:INFO:Declaring metric variables
2025-02-06 13:55:46,041:INFO:Importing untrained model
2025-02-06 13:55:46,041:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:55:46,041:INFO:Starting cross validation
2025-02-06 13:55:46,041:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:55:47,892:INFO:Calculating mean and std
2025-02-06 13:55:47,893:INFO:Creating metrics dataframe
2025-02-06 13:55:47,894:INFO:Finalizing model
2025-02-06 13:55:47,916:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:55:47,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001580 seconds.
2025-02-06 13:55:47,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:55:47,919:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:55:47,921:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:55:47,921:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:55:47,921:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:55:48,072:INFO:Uploading results into container
2025-02-06 13:55:48,073:INFO:Uploading model into container now
2025-02-06 13:55:48,074:INFO:_master_model_container: 1
2025-02-06 13:55:48,074:INFO:_display_container: 2
2025-02-06 13:55:48,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:55:48,074:INFO:create_model() successfully completed......................................
2025-02-06 13:57:33,152:INFO:PyCaret ClassificationExperiment
2025-02-06 13:57:33,152:INFO:Logging name: clf-default-name
2025-02-06 13:57:33,152:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:57:33,152:INFO:version 3.3.2
2025-02-06 13:57:33,152:INFO:Initializing setup()
2025-02-06 13:57:33,152:INFO:self.USI: 5490
2025-02-06 13:57:33,152:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:57:33,152:INFO:Checking environment
2025-02-06 13:57:33,152:INFO:python_version: 3.11.9
2025-02-06 13:57:33,152:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:57:33,152:INFO:machine: AMD64
2025-02-06 13:57:33,152:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:57:33,158:INFO:Memory: svmem(total=67771465728, available=48689721344, percent=28.2, used=19081744384, free=48689721344)
2025-02-06 13:57:33,158:INFO:Physical Core: 8
2025-02-06 13:57:33,159:INFO:Logical Core: 16
2025-02-06 13:57:33,159:INFO:Checking libraries
2025-02-06 13:57:33,159:INFO:System:
2025-02-06 13:57:33,159:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:57:33,159:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:57:33,159:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:57:33,159:INFO:PyCaret required dependencies:
2025-02-06 13:57:33,159:INFO:                 pip: 25.0
2025-02-06 13:57:33,159:INFO:          setuptools: 65.5.0
2025-02-06 13:57:33,159:INFO:             pycaret: 3.3.2
2025-02-06 13:57:33,159:INFO:             IPython: 8.32.0
2025-02-06 13:57:33,159:INFO:          ipywidgets: 8.1.5
2025-02-06 13:57:33,159:INFO:                tqdm: 4.67.1
2025-02-06 13:57:33,159:INFO:               numpy: 1.26.4
2025-02-06 13:57:33,159:INFO:              pandas: 2.1.4
2025-02-06 13:57:33,159:INFO:              jinja2: 3.1.5
2025-02-06 13:57:33,159:INFO:               scipy: 1.11.4
2025-02-06 13:57:33,159:INFO:              joblib: 1.3.2
2025-02-06 13:57:33,159:INFO:             sklearn: 1.4.2
2025-02-06 13:57:33,159:INFO:                pyod: 2.0.3
2025-02-06 13:57:33,159:INFO:            imblearn: 0.13.0
2025-02-06 13:57:33,159:INFO:   category_encoders: 2.7.0
2025-02-06 13:57:33,159:INFO:            lightgbm: 4.5.0
2025-02-06 13:57:33,159:INFO:               numba: 0.61.0
2025-02-06 13:57:33,159:INFO:            requests: 2.32.3
2025-02-06 13:57:33,159:INFO:          matplotlib: 3.7.5
2025-02-06 13:57:33,159:INFO:          scikitplot: 0.3.7
2025-02-06 13:57:33,159:INFO:         yellowbrick: 1.5
2025-02-06 13:57:33,159:INFO:              plotly: 5.24.1
2025-02-06 13:57:33,159:INFO:    plotly-resampler: Not installed
2025-02-06 13:57:33,159:INFO:             kaleido: 0.2.1
2025-02-06 13:57:33,159:INFO:           schemdraw: 0.15
2025-02-06 13:57:33,159:INFO:         statsmodels: 0.14.4
2025-02-06 13:57:33,159:INFO:              sktime: 0.26.0
2025-02-06 13:57:33,159:INFO:               tbats: 1.1.3
2025-02-06 13:57:33,159:INFO:            pmdarima: 2.0.4
2025-02-06 13:57:33,159:INFO:              psutil: 6.1.1
2025-02-06 13:57:33,159:INFO:          markupsafe: 3.0.2
2025-02-06 13:57:33,159:INFO:             pickle5: Not installed
2025-02-06 13:57:33,159:INFO:         cloudpickle: 3.1.1
2025-02-06 13:57:33,159:INFO:         deprecation: 2.1.0
2025-02-06 13:57:33,159:INFO:              xxhash: 3.5.0
2025-02-06 13:57:33,160:INFO:           wurlitzer: Not installed
2025-02-06 13:57:33,160:INFO:PyCaret optional dependencies:
2025-02-06 13:57:33,160:INFO:                shap: Not installed
2025-02-06 13:57:33,160:INFO:           interpret: Not installed
2025-02-06 13:57:33,160:INFO:                umap: Not installed
2025-02-06 13:57:33,160:INFO:     ydata_profiling: Not installed
2025-02-06 13:57:33,160:INFO:  explainerdashboard: Not installed
2025-02-06 13:57:33,160:INFO:             autoviz: Not installed
2025-02-06 13:57:33,160:INFO:           fairlearn: Not installed
2025-02-06 13:57:33,160:INFO:          deepchecks: Not installed
2025-02-06 13:57:33,160:INFO:             xgboost: Not installed
2025-02-06 13:57:33,160:INFO:            catboost: Not installed
2025-02-06 13:57:33,160:INFO:              kmodes: Not installed
2025-02-06 13:57:33,160:INFO:             mlxtend: Not installed
2025-02-06 13:57:33,160:INFO:       statsforecast: Not installed
2025-02-06 13:57:33,160:INFO:        tune_sklearn: Not installed
2025-02-06 13:57:33,160:INFO:                 ray: Not installed
2025-02-06 13:57:33,160:INFO:            hyperopt: Not installed
2025-02-06 13:57:33,160:INFO:              optuna: Not installed
2025-02-06 13:57:33,160:INFO:               skopt: Not installed
2025-02-06 13:57:33,160:INFO:              mlflow: Not installed
2025-02-06 13:57:33,160:INFO:              gradio: Not installed
2025-02-06 13:57:33,160:INFO:             fastapi: Not installed
2025-02-06 13:57:33,160:INFO:             uvicorn: Not installed
2025-02-06 13:57:33,160:INFO:              m2cgen: Not installed
2025-02-06 13:57:33,160:INFO:           evidently: Not installed
2025-02-06 13:57:33,160:INFO:               fugue: Not installed
2025-02-06 13:57:33,160:INFO:           streamlit: Not installed
2025-02-06 13:57:33,160:INFO:             prophet: Not installed
2025-02-06 13:57:33,160:INFO:None
2025-02-06 13:57:33,160:INFO:Set up data.
2025-02-06 13:57:33,173:INFO:Set up folding strategy.
2025-02-06 13:57:33,173:INFO:Set up train/test split.
2025-02-06 13:57:33,182:INFO:Set up index.
2025-02-06 13:57:33,183:INFO:Assigning column types.
2025-02-06 13:57:33,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:57:33,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,265:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,282:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:57:33,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:57:33,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,367:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:57:33,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,456:INFO:Preparing preprocessing pipeline...
2025-02-06 13:57:33,457:INFO:Set up simple imputation.
2025-02-06 13:57:33,484:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:57:33,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:57:33,485:INFO:Creating final display dataframe.
2025-02-06 13:57:33,564:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              5490
2025-02-06 13:57:33,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:57:33,653:INFO:setup() successfully completed in 0.5s...............
2025-02-06 13:57:33,653:INFO:Initializing create_model()
2025-02-06 13:57:33,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A845650>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:57:33,653:INFO:Checking exceptions
2025-02-06 13:57:33,654:INFO:Importing libraries
2025-02-06 13:57:33,654:INFO:Copying training dataset
2025-02-06 13:57:33,662:INFO:Defining folds
2025-02-06 13:57:33,662:INFO:Declaring metric variables
2025-02-06 13:57:33,662:INFO:Importing untrained model
2025-02-06 13:57:33,662:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:57:33,662:INFO:Starting cross validation
2025-02-06 13:57:33,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:57:35,645:INFO:Calculating mean and std
2025-02-06 13:57:35,645:INFO:Creating metrics dataframe
2025-02-06 13:57:35,646:INFO:Finalizing model
2025-02-06 13:57:35,662:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:57:35,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.
2025-02-06 13:57:35,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:57:35,663:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:57:35,663:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:57:35,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:57:35,663:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:57:35,780:INFO:Uploading results into container
2025-02-06 13:57:35,780:INFO:Uploading model into container now
2025-02-06 13:57:35,781:INFO:_master_model_container: 1
2025-02-06 13:57:35,781:INFO:_display_container: 2
2025-02-06 13:57:35,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:57:35,781:INFO:create_model() successfully completed......................................
2025-02-06 13:59:33,026:INFO:PyCaret ClassificationExperiment
2025-02-06 13:59:33,026:INFO:Logging name: clf-default-name
2025-02-06 13:59:33,026:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 13:59:33,026:INFO:version 3.3.2
2025-02-06 13:59:33,026:INFO:Initializing setup()
2025-02-06 13:59:33,026:INFO:self.USI: 18dc
2025-02-06 13:59:33,026:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 13:59:33,026:INFO:Checking environment
2025-02-06 13:59:33,026:INFO:python_version: 3.11.9
2025-02-06 13:59:33,026:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 13:59:33,026:INFO:machine: AMD64
2025-02-06 13:59:33,026:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 13:59:33,031:INFO:Memory: svmem(total=67771465728, available=48082509824, percent=29.1, used=19688955904, free=48082509824)
2025-02-06 13:59:33,031:INFO:Physical Core: 8
2025-02-06 13:59:33,031:INFO:Logical Core: 16
2025-02-06 13:59:33,031:INFO:Checking libraries
2025-02-06 13:59:33,031:INFO:System:
2025-02-06 13:59:33,031:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 13:59:33,031:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 13:59:33,031:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 13:59:33,031:INFO:PyCaret required dependencies:
2025-02-06 13:59:33,031:INFO:                 pip: 25.0
2025-02-06 13:59:33,031:INFO:          setuptools: 65.5.0
2025-02-06 13:59:33,031:INFO:             pycaret: 3.3.2
2025-02-06 13:59:33,031:INFO:             IPython: 8.32.0
2025-02-06 13:59:33,031:INFO:          ipywidgets: 8.1.5
2025-02-06 13:59:33,031:INFO:                tqdm: 4.67.1
2025-02-06 13:59:33,031:INFO:               numpy: 1.26.4
2025-02-06 13:59:33,031:INFO:              pandas: 2.1.4
2025-02-06 13:59:33,031:INFO:              jinja2: 3.1.5
2025-02-06 13:59:33,031:INFO:               scipy: 1.11.4
2025-02-06 13:59:33,031:INFO:              joblib: 1.3.2
2025-02-06 13:59:33,031:INFO:             sklearn: 1.4.2
2025-02-06 13:59:33,031:INFO:                pyod: 2.0.3
2025-02-06 13:59:33,031:INFO:            imblearn: 0.13.0
2025-02-06 13:59:33,031:INFO:   category_encoders: 2.7.0
2025-02-06 13:59:33,031:INFO:            lightgbm: 4.5.0
2025-02-06 13:59:33,031:INFO:               numba: 0.61.0
2025-02-06 13:59:33,031:INFO:            requests: 2.32.3
2025-02-06 13:59:33,031:INFO:          matplotlib: 3.7.5
2025-02-06 13:59:33,031:INFO:          scikitplot: 0.3.7
2025-02-06 13:59:33,031:INFO:         yellowbrick: 1.5
2025-02-06 13:59:33,031:INFO:              plotly: 5.24.1
2025-02-06 13:59:33,031:INFO:    plotly-resampler: Not installed
2025-02-06 13:59:33,031:INFO:             kaleido: 0.2.1
2025-02-06 13:59:33,031:INFO:           schemdraw: 0.15
2025-02-06 13:59:33,031:INFO:         statsmodels: 0.14.4
2025-02-06 13:59:33,031:INFO:              sktime: 0.26.0
2025-02-06 13:59:33,031:INFO:               tbats: 1.1.3
2025-02-06 13:59:33,031:INFO:            pmdarima: 2.0.4
2025-02-06 13:59:33,031:INFO:              psutil: 6.1.1
2025-02-06 13:59:33,031:INFO:          markupsafe: 3.0.2
2025-02-06 13:59:33,031:INFO:             pickle5: Not installed
2025-02-06 13:59:33,031:INFO:         cloudpickle: 3.1.1
2025-02-06 13:59:33,031:INFO:         deprecation: 2.1.0
2025-02-06 13:59:33,031:INFO:              xxhash: 3.5.0
2025-02-06 13:59:33,031:INFO:           wurlitzer: Not installed
2025-02-06 13:59:33,031:INFO:PyCaret optional dependencies:
2025-02-06 13:59:33,031:INFO:                shap: Not installed
2025-02-06 13:59:33,031:INFO:           interpret: Not installed
2025-02-06 13:59:33,031:INFO:                umap: Not installed
2025-02-06 13:59:33,031:INFO:     ydata_profiling: Not installed
2025-02-06 13:59:33,032:INFO:  explainerdashboard: Not installed
2025-02-06 13:59:33,032:INFO:             autoviz: Not installed
2025-02-06 13:59:33,032:INFO:           fairlearn: Not installed
2025-02-06 13:59:33,032:INFO:          deepchecks: Not installed
2025-02-06 13:59:33,032:INFO:             xgboost: Not installed
2025-02-06 13:59:33,032:INFO:            catboost: Not installed
2025-02-06 13:59:33,032:INFO:              kmodes: Not installed
2025-02-06 13:59:33,032:INFO:             mlxtend: Not installed
2025-02-06 13:59:33,032:INFO:       statsforecast: Not installed
2025-02-06 13:59:33,032:INFO:        tune_sklearn: Not installed
2025-02-06 13:59:33,032:INFO:                 ray: Not installed
2025-02-06 13:59:33,032:INFO:            hyperopt: Not installed
2025-02-06 13:59:33,032:INFO:              optuna: Not installed
2025-02-06 13:59:33,032:INFO:               skopt: Not installed
2025-02-06 13:59:33,032:INFO:              mlflow: Not installed
2025-02-06 13:59:33,032:INFO:              gradio: Not installed
2025-02-06 13:59:33,032:INFO:             fastapi: Not installed
2025-02-06 13:59:33,032:INFO:             uvicorn: Not installed
2025-02-06 13:59:33,032:INFO:              m2cgen: Not installed
2025-02-06 13:59:33,032:INFO:           evidently: Not installed
2025-02-06 13:59:33,032:INFO:               fugue: Not installed
2025-02-06 13:59:33,032:INFO:           streamlit: Not installed
2025-02-06 13:59:33,032:INFO:             prophet: Not installed
2025-02-06 13:59:33,032:INFO:None
2025-02-06 13:59:33,032:INFO:Set up data.
2025-02-06 13:59:33,040:INFO:Set up folding strategy.
2025-02-06 13:59:33,040:INFO:Set up train/test split.
2025-02-06 13:59:33,046:INFO:Set up index.
2025-02-06 13:59:33,047:INFO:Assigning column types.
2025-02-06 13:59:33,055:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 13:59:33,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,119:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,134:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 13:59:33,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,197:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 13:59:33,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,212:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 13:59:33,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,291:INFO:Preparing preprocessing pipeline...
2025-02-06 13:59:33,292:INFO:Set up simple imputation.
2025-02-06 13:59:33,314:INFO:Finished creating preprocessing pipeline.
2025-02-06 13:59:33,315:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 13:59:33,315:INFO:Creating final display dataframe.
2025-02-06 13:59:33,387:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              18dc
2025-02-06 13:59:33,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 13:59:33,466:INFO:setup() successfully completed in 0.44s...............
2025-02-06 13:59:33,466:INFO:Initializing create_model()
2025-02-06 13:59:33,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C76805F50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 13:59:33,466:INFO:Checking exceptions
2025-02-06 13:59:33,466:INFO:Importing libraries
2025-02-06 13:59:33,467:INFO:Copying training dataset
2025-02-06 13:59:33,474:INFO:Defining folds
2025-02-06 13:59:33,474:INFO:Declaring metric variables
2025-02-06 13:59:33,474:INFO:Importing untrained model
2025-02-06 13:59:33,474:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 13:59:33,474:INFO:Starting cross validation
2025-02-06 13:59:33,475:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 13:59:35,017:INFO:Calculating mean and std
2025-02-06 13:59:35,017:INFO:Creating metrics dataframe
2025-02-06 13:59:35,018:INFO:Finalizing model
2025-02-06 13:59:35,032:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 13:59:35,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000972 seconds.
2025-02-06 13:59:35,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 13:59:35,034:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 13:59:35,034:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 13:59:35,034:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 13:59:35,034:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 13:59:35,147:INFO:Uploading results into container
2025-02-06 13:59:35,148:INFO:Uploading model into container now
2025-02-06 13:59:35,148:INFO:_master_model_container: 1
2025-02-06 13:59:35,148:INFO:_display_container: 2
2025-02-06 13:59:35,148:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 13:59:35,148:INFO:create_model() successfully completed......................................
2025-02-06 14:00:09,137:INFO:PyCaret ClassificationExperiment
2025-02-06 14:00:09,137:INFO:Logging name: clf-default-name
2025-02-06 14:00:09,137:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:00:09,137:INFO:version 3.3.2
2025-02-06 14:00:09,137:INFO:Initializing setup()
2025-02-06 14:00:09,137:INFO:self.USI: bdc3
2025-02-06 14:00:09,137:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 14:00:09,138:INFO:Checking environment
2025-02-06 14:00:09,138:INFO:python_version: 3.11.9
2025-02-06 14:00:09,138:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:00:09,138:INFO:machine: AMD64
2025-02-06 14:00:09,138:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:00:09,143:INFO:Memory: svmem(total=67771465728, available=48090697728, percent=29.0, used=19680768000, free=48090697728)
2025-02-06 14:00:09,143:INFO:Physical Core: 8
2025-02-06 14:00:09,143:INFO:Logical Core: 16
2025-02-06 14:00:09,143:INFO:Checking libraries
2025-02-06 14:00:09,143:INFO:System:
2025-02-06 14:00:09,143:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:00:09,143:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:00:09,143:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:00:09,143:INFO:PyCaret required dependencies:
2025-02-06 14:00:09,143:INFO:                 pip: 25.0
2025-02-06 14:00:09,143:INFO:          setuptools: 65.5.0
2025-02-06 14:00:09,143:INFO:             pycaret: 3.3.2
2025-02-06 14:00:09,143:INFO:             IPython: 8.32.0
2025-02-06 14:00:09,143:INFO:          ipywidgets: 8.1.5
2025-02-06 14:00:09,143:INFO:                tqdm: 4.67.1
2025-02-06 14:00:09,143:INFO:               numpy: 1.26.4
2025-02-06 14:00:09,143:INFO:              pandas: 2.1.4
2025-02-06 14:00:09,143:INFO:              jinja2: 3.1.5
2025-02-06 14:00:09,143:INFO:               scipy: 1.11.4
2025-02-06 14:00:09,143:INFO:              joblib: 1.3.2
2025-02-06 14:00:09,143:INFO:             sklearn: 1.4.2
2025-02-06 14:00:09,143:INFO:                pyod: 2.0.3
2025-02-06 14:00:09,143:INFO:            imblearn: 0.13.0
2025-02-06 14:00:09,143:INFO:   category_encoders: 2.7.0
2025-02-06 14:00:09,143:INFO:            lightgbm: 4.5.0
2025-02-06 14:00:09,143:INFO:               numba: 0.61.0
2025-02-06 14:00:09,143:INFO:            requests: 2.32.3
2025-02-06 14:00:09,143:INFO:          matplotlib: 3.7.5
2025-02-06 14:00:09,143:INFO:          scikitplot: 0.3.7
2025-02-06 14:00:09,143:INFO:         yellowbrick: 1.5
2025-02-06 14:00:09,143:INFO:              plotly: 5.24.1
2025-02-06 14:00:09,143:INFO:    plotly-resampler: Not installed
2025-02-06 14:00:09,143:INFO:             kaleido: 0.2.1
2025-02-06 14:00:09,143:INFO:           schemdraw: 0.15
2025-02-06 14:00:09,143:INFO:         statsmodels: 0.14.4
2025-02-06 14:00:09,143:INFO:              sktime: 0.26.0
2025-02-06 14:00:09,143:INFO:               tbats: 1.1.3
2025-02-06 14:00:09,143:INFO:            pmdarima: 2.0.4
2025-02-06 14:00:09,143:INFO:              psutil: 6.1.1
2025-02-06 14:00:09,143:INFO:          markupsafe: 3.0.2
2025-02-06 14:00:09,143:INFO:             pickle5: Not installed
2025-02-06 14:00:09,143:INFO:         cloudpickle: 3.1.1
2025-02-06 14:00:09,143:INFO:         deprecation: 2.1.0
2025-02-06 14:00:09,143:INFO:              xxhash: 3.5.0
2025-02-06 14:00:09,143:INFO:           wurlitzer: Not installed
2025-02-06 14:00:09,143:INFO:PyCaret optional dependencies:
2025-02-06 14:00:09,143:INFO:                shap: Not installed
2025-02-06 14:00:09,143:INFO:           interpret: Not installed
2025-02-06 14:00:09,143:INFO:                umap: Not installed
2025-02-06 14:00:09,143:INFO:     ydata_profiling: Not installed
2025-02-06 14:00:09,143:INFO:  explainerdashboard: Not installed
2025-02-06 14:00:09,143:INFO:             autoviz: Not installed
2025-02-06 14:00:09,144:INFO:           fairlearn: Not installed
2025-02-06 14:00:09,144:INFO:          deepchecks: Not installed
2025-02-06 14:00:09,144:INFO:             xgboost: Not installed
2025-02-06 14:00:09,144:INFO:            catboost: Not installed
2025-02-06 14:00:09,144:INFO:              kmodes: Not installed
2025-02-06 14:00:09,144:INFO:             mlxtend: Not installed
2025-02-06 14:00:09,144:INFO:       statsforecast: Not installed
2025-02-06 14:00:09,144:INFO:        tune_sklearn: Not installed
2025-02-06 14:00:09,144:INFO:                 ray: Not installed
2025-02-06 14:00:09,144:INFO:            hyperopt: Not installed
2025-02-06 14:00:09,144:INFO:              optuna: Not installed
2025-02-06 14:00:09,144:INFO:               skopt: Not installed
2025-02-06 14:00:09,144:INFO:              mlflow: Not installed
2025-02-06 14:00:09,144:INFO:              gradio: Not installed
2025-02-06 14:00:09,144:INFO:             fastapi: Not installed
2025-02-06 14:00:09,144:INFO:             uvicorn: Not installed
2025-02-06 14:00:09,144:INFO:              m2cgen: Not installed
2025-02-06 14:00:09,144:INFO:           evidently: Not installed
2025-02-06 14:00:09,144:INFO:               fugue: Not installed
2025-02-06 14:00:09,144:INFO:           streamlit: Not installed
2025-02-06 14:00:09,144:INFO:             prophet: Not installed
2025-02-06 14:00:09,144:INFO:None
2025-02-06 14:00:09,144:INFO:Set up data.
2025-02-06 14:00:09,151:INFO:Set up folding strategy.
2025-02-06 14:00:09,151:INFO:Set up train/test split.
2025-02-06 14:00:09,158:INFO:Set up index.
2025-02-06 14:00:09,160:INFO:Assigning column types.
2025-02-06 14:00:09,166:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:00:09,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,191:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,245:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:00:09,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:09,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,323:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:00:09,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,402:INFO:Preparing preprocessing pipeline...
2025-02-06 14:00:09,403:INFO:Set up simple imputation.
2025-02-06 14:00:09,424:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:00:09,425:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:00:09,425:INFO:Creating final display dataframe.
2025-02-06 14:00:09,498:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              bdc3
2025-02-06 14:00:09,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:09,577:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:00:09,577:INFO:Initializing create_model()
2025-02-06 14:00:09,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A629BD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:00:09,577:INFO:Checking exceptions
2025-02-06 14:00:09,577:INFO:Importing libraries
2025-02-06 14:00:09,577:INFO:Copying training dataset
2025-02-06 14:00:09,585:INFO:Defining folds
2025-02-06 14:00:09,585:INFO:Declaring metric variables
2025-02-06 14:00:09,585:INFO:Importing untrained model
2025-02-06 14:00:09,585:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:00:09,585:INFO:Starting cross validation
2025-02-06 14:00:09,585:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:00:10,108:INFO:Calculating mean and std
2025-02-06 14:00:10,109:INFO:Creating metrics dataframe
2025-02-06 14:00:10,110:INFO:Finalizing model
2025-02-06 14:00:10,124:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:00:10,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.
2025-02-06 14:00:10,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:00:10,127:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:00:10,127:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:00:10,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:00:10,127:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:00:10,263:INFO:Uploading results into container
2025-02-06 14:00:10,264:INFO:Uploading model into container now
2025-02-06 14:00:10,264:INFO:_master_model_container: 1
2025-02-06 14:00:10,264:INFO:_display_container: 2
2025-02-06 14:00:10,264:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:00:10,264:INFO:create_model() successfully completed......................................
2025-02-06 14:00:37,053:INFO:PyCaret ClassificationExperiment
2025-02-06 14:00:37,053:INFO:Logging name: clf-default-name
2025-02-06 14:00:37,053:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:00:37,053:INFO:version 3.3.2
2025-02-06 14:00:37,053:INFO:Initializing setup()
2025-02-06 14:00:37,054:INFO:self.USI: 34f4
2025-02-06 14:00:37,054:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 14:00:37,054:INFO:Checking environment
2025-02-06 14:00:37,054:INFO:python_version: 3.11.9
2025-02-06 14:00:37,054:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:00:37,054:INFO:machine: AMD64
2025-02-06 14:00:37,054:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:00:37,058:INFO:Memory: svmem(total=67771465728, available=47997345792, percent=29.2, used=19774119936, free=47997345792)
2025-02-06 14:00:37,058:INFO:Physical Core: 8
2025-02-06 14:00:37,058:INFO:Logical Core: 16
2025-02-06 14:00:37,058:INFO:Checking libraries
2025-02-06 14:00:37,058:INFO:System:
2025-02-06 14:00:37,058:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:00:37,058:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:00:37,058:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:00:37,058:INFO:PyCaret required dependencies:
2025-02-06 14:00:37,058:INFO:                 pip: 25.0
2025-02-06 14:00:37,058:INFO:          setuptools: 65.5.0
2025-02-06 14:00:37,058:INFO:             pycaret: 3.3.2
2025-02-06 14:00:37,058:INFO:             IPython: 8.32.0
2025-02-06 14:00:37,058:INFO:          ipywidgets: 8.1.5
2025-02-06 14:00:37,058:INFO:                tqdm: 4.67.1
2025-02-06 14:00:37,059:INFO:               numpy: 1.26.4
2025-02-06 14:00:37,059:INFO:              pandas: 2.1.4
2025-02-06 14:00:37,059:INFO:              jinja2: 3.1.5
2025-02-06 14:00:37,059:INFO:               scipy: 1.11.4
2025-02-06 14:00:37,059:INFO:              joblib: 1.3.2
2025-02-06 14:00:37,059:INFO:             sklearn: 1.4.2
2025-02-06 14:00:37,059:INFO:                pyod: 2.0.3
2025-02-06 14:00:37,059:INFO:            imblearn: 0.13.0
2025-02-06 14:00:37,059:INFO:   category_encoders: 2.7.0
2025-02-06 14:00:37,059:INFO:            lightgbm: 4.5.0
2025-02-06 14:00:37,059:INFO:               numba: 0.61.0
2025-02-06 14:00:37,059:INFO:            requests: 2.32.3
2025-02-06 14:00:37,059:INFO:          matplotlib: 3.7.5
2025-02-06 14:00:37,059:INFO:          scikitplot: 0.3.7
2025-02-06 14:00:37,059:INFO:         yellowbrick: 1.5
2025-02-06 14:00:37,059:INFO:              plotly: 5.24.1
2025-02-06 14:00:37,059:INFO:    plotly-resampler: Not installed
2025-02-06 14:00:37,059:INFO:             kaleido: 0.2.1
2025-02-06 14:00:37,059:INFO:           schemdraw: 0.15
2025-02-06 14:00:37,059:INFO:         statsmodels: 0.14.4
2025-02-06 14:00:37,059:INFO:              sktime: 0.26.0
2025-02-06 14:00:37,059:INFO:               tbats: 1.1.3
2025-02-06 14:00:37,059:INFO:            pmdarima: 2.0.4
2025-02-06 14:00:37,059:INFO:              psutil: 6.1.1
2025-02-06 14:00:37,059:INFO:          markupsafe: 3.0.2
2025-02-06 14:00:37,059:INFO:             pickle5: Not installed
2025-02-06 14:00:37,059:INFO:         cloudpickle: 3.1.1
2025-02-06 14:00:37,059:INFO:         deprecation: 2.1.0
2025-02-06 14:00:37,059:INFO:              xxhash: 3.5.0
2025-02-06 14:00:37,059:INFO:           wurlitzer: Not installed
2025-02-06 14:00:37,059:INFO:PyCaret optional dependencies:
2025-02-06 14:00:37,059:INFO:                shap: Not installed
2025-02-06 14:00:37,059:INFO:           interpret: Not installed
2025-02-06 14:00:37,059:INFO:                umap: Not installed
2025-02-06 14:00:37,059:INFO:     ydata_profiling: Not installed
2025-02-06 14:00:37,059:INFO:  explainerdashboard: Not installed
2025-02-06 14:00:37,059:INFO:             autoviz: Not installed
2025-02-06 14:00:37,059:INFO:           fairlearn: Not installed
2025-02-06 14:00:37,059:INFO:          deepchecks: Not installed
2025-02-06 14:00:37,059:INFO:             xgboost: Not installed
2025-02-06 14:00:37,059:INFO:            catboost: Not installed
2025-02-06 14:00:37,059:INFO:              kmodes: Not installed
2025-02-06 14:00:37,059:INFO:             mlxtend: Not installed
2025-02-06 14:00:37,059:INFO:       statsforecast: Not installed
2025-02-06 14:00:37,059:INFO:        tune_sklearn: Not installed
2025-02-06 14:00:37,059:INFO:                 ray: Not installed
2025-02-06 14:00:37,059:INFO:            hyperopt: Not installed
2025-02-06 14:00:37,059:INFO:              optuna: Not installed
2025-02-06 14:00:37,059:INFO:               skopt: Not installed
2025-02-06 14:00:37,059:INFO:              mlflow: Not installed
2025-02-06 14:00:37,059:INFO:              gradio: Not installed
2025-02-06 14:00:37,059:INFO:             fastapi: Not installed
2025-02-06 14:00:37,059:INFO:             uvicorn: Not installed
2025-02-06 14:00:37,059:INFO:              m2cgen: Not installed
2025-02-06 14:00:37,059:INFO:           evidently: Not installed
2025-02-06 14:00:37,060:INFO:               fugue: Not installed
2025-02-06 14:00:37,060:INFO:           streamlit: Not installed
2025-02-06 14:00:37,060:INFO:             prophet: Not installed
2025-02-06 14:00:37,060:INFO:None
2025-02-06 14:00:37,060:INFO:Set up data.
2025-02-06 14:00:37,068:INFO:Set up folding strategy.
2025-02-06 14:00:37,068:INFO:Set up train/test split.
2025-02-06 14:00:37,074:INFO:Set up index.
2025-02-06 14:00:37,076:INFO:Assigning column types.
2025-02-06 14:00:37,082:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:00:37,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,162:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:00:37,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:00:37,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,247:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:00:37,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,325:INFO:Preparing preprocessing pipeline...
2025-02-06 14:00:37,326:INFO:Set up simple imputation.
2025-02-06 14:00:37,347:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:00:37,349:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:00:37,349:INFO:Creating final display dataframe.
2025-02-06 14:00:37,422:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              34f4
2025-02-06 14:00:37,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:00:37,499:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:00:37,499:INFO:Initializing create_model()
2025-02-06 14:00:37,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C75F25C50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:00:37,499:INFO:Checking exceptions
2025-02-06 14:00:37,500:INFO:Importing libraries
2025-02-06 14:00:37,500:INFO:Copying training dataset
2025-02-06 14:00:37,508:INFO:Defining folds
2025-02-06 14:00:37,509:INFO:Declaring metric variables
2025-02-06 14:00:37,509:INFO:Importing untrained model
2025-02-06 14:00:37,509:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:00:37,509:INFO:Starting cross validation
2025-02-06 14:00:37,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:00:37,946:INFO:Calculating mean and std
2025-02-06 14:00:37,946:INFO:Creating metrics dataframe
2025-02-06 14:00:37,947:INFO:Finalizing model
2025-02-06 14:00:37,964:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:00:37,965:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000998 seconds.
2025-02-06 14:00:37,965:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:00:37,966:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:00:37,966:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:00:37,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:00:37,966:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:00:38,097:INFO:Uploading results into container
2025-02-06 14:00:38,097:INFO:Uploading model into container now
2025-02-06 14:00:38,098:INFO:_master_model_container: 1
2025-02-06 14:00:38,098:INFO:_display_container: 2
2025-02-06 14:00:38,098:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:00:38,098:INFO:create_model() successfully completed......................................
2025-02-06 14:01:27,902:INFO:PyCaret ClassificationExperiment
2025-02-06 14:01:27,902:INFO:Logging name: clf-default-name
2025-02-06 14:01:27,902:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:01:27,902:INFO:version 3.3.2
2025-02-06 14:01:27,902:INFO:Initializing setup()
2025-02-06 14:01:27,902:INFO:self.USI: 7464
2025-02-06 14:01:27,902:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 14:01:27,902:INFO:Checking environment
2025-02-06 14:01:27,902:INFO:python_version: 3.11.9
2025-02-06 14:01:27,903:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:01:27,903:INFO:machine: AMD64
2025-02-06 14:01:27,903:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:01:27,906:INFO:Memory: svmem(total=67771465728, available=47988166656, percent=29.2, used=19783299072, free=47988166656)
2025-02-06 14:01:27,906:INFO:Physical Core: 8
2025-02-06 14:01:27,906:INFO:Logical Core: 16
2025-02-06 14:01:27,906:INFO:Checking libraries
2025-02-06 14:01:27,906:INFO:System:
2025-02-06 14:01:27,906:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:01:27,906:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:01:27,906:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:01:27,906:INFO:PyCaret required dependencies:
2025-02-06 14:01:27,906:INFO:                 pip: 25.0
2025-02-06 14:01:27,906:INFO:          setuptools: 65.5.0
2025-02-06 14:01:27,906:INFO:             pycaret: 3.3.2
2025-02-06 14:01:27,906:INFO:             IPython: 8.32.0
2025-02-06 14:01:27,906:INFO:          ipywidgets: 8.1.5
2025-02-06 14:01:27,908:INFO:                tqdm: 4.67.1
2025-02-06 14:01:27,908:INFO:               numpy: 1.26.4
2025-02-06 14:01:27,908:INFO:              pandas: 2.1.4
2025-02-06 14:01:27,908:INFO:              jinja2: 3.1.5
2025-02-06 14:01:27,908:INFO:               scipy: 1.11.4
2025-02-06 14:01:27,908:INFO:              joblib: 1.3.2
2025-02-06 14:01:27,908:INFO:             sklearn: 1.4.2
2025-02-06 14:01:27,908:INFO:                pyod: 2.0.3
2025-02-06 14:01:27,908:INFO:            imblearn: 0.13.0
2025-02-06 14:01:27,908:INFO:   category_encoders: 2.7.0
2025-02-06 14:01:27,908:INFO:            lightgbm: 4.5.0
2025-02-06 14:01:27,908:INFO:               numba: 0.61.0
2025-02-06 14:01:27,908:INFO:            requests: 2.32.3
2025-02-06 14:01:27,908:INFO:          matplotlib: 3.7.5
2025-02-06 14:01:27,908:INFO:          scikitplot: 0.3.7
2025-02-06 14:01:27,908:INFO:         yellowbrick: 1.5
2025-02-06 14:01:27,908:INFO:              plotly: 5.24.1
2025-02-06 14:01:27,908:INFO:    plotly-resampler: Not installed
2025-02-06 14:01:27,908:INFO:             kaleido: 0.2.1
2025-02-06 14:01:27,908:INFO:           schemdraw: 0.15
2025-02-06 14:01:27,908:INFO:         statsmodels: 0.14.4
2025-02-06 14:01:27,908:INFO:              sktime: 0.26.0
2025-02-06 14:01:27,908:INFO:               tbats: 1.1.3
2025-02-06 14:01:27,908:INFO:            pmdarima: 2.0.4
2025-02-06 14:01:27,908:INFO:              psutil: 6.1.1
2025-02-06 14:01:27,908:INFO:          markupsafe: 3.0.2
2025-02-06 14:01:27,908:INFO:             pickle5: Not installed
2025-02-06 14:01:27,908:INFO:         cloudpickle: 3.1.1
2025-02-06 14:01:27,908:INFO:         deprecation: 2.1.0
2025-02-06 14:01:27,908:INFO:              xxhash: 3.5.0
2025-02-06 14:01:27,908:INFO:           wurlitzer: Not installed
2025-02-06 14:01:27,908:INFO:PyCaret optional dependencies:
2025-02-06 14:01:27,908:INFO:                shap: Not installed
2025-02-06 14:01:27,908:INFO:           interpret: Not installed
2025-02-06 14:01:27,908:INFO:                umap: Not installed
2025-02-06 14:01:27,908:INFO:     ydata_profiling: Not installed
2025-02-06 14:01:27,908:INFO:  explainerdashboard: Not installed
2025-02-06 14:01:27,908:INFO:             autoviz: Not installed
2025-02-06 14:01:27,908:INFO:           fairlearn: Not installed
2025-02-06 14:01:27,908:INFO:          deepchecks: Not installed
2025-02-06 14:01:27,908:INFO:             xgboost: Not installed
2025-02-06 14:01:27,908:INFO:            catboost: Not installed
2025-02-06 14:01:27,908:INFO:              kmodes: Not installed
2025-02-06 14:01:27,908:INFO:             mlxtend: Not installed
2025-02-06 14:01:27,908:INFO:       statsforecast: Not installed
2025-02-06 14:01:27,908:INFO:        tune_sklearn: Not installed
2025-02-06 14:01:27,908:INFO:                 ray: Not installed
2025-02-06 14:01:27,908:INFO:            hyperopt: Not installed
2025-02-06 14:01:27,908:INFO:              optuna: Not installed
2025-02-06 14:01:27,908:INFO:               skopt: Not installed
2025-02-06 14:01:27,908:INFO:              mlflow: Not installed
2025-02-06 14:01:27,908:INFO:              gradio: Not installed
2025-02-06 14:01:27,908:INFO:             fastapi: Not installed
2025-02-06 14:01:27,908:INFO:             uvicorn: Not installed
2025-02-06 14:01:27,908:INFO:              m2cgen: Not installed
2025-02-06 14:01:27,908:INFO:           evidently: Not installed
2025-02-06 14:01:27,908:INFO:               fugue: Not installed
2025-02-06 14:01:27,908:INFO:           streamlit: Not installed
2025-02-06 14:01:27,908:INFO:             prophet: Not installed
2025-02-06 14:01:27,908:INFO:None
2025-02-06 14:01:27,908:INFO:Set up data.
2025-02-06 14:01:27,917:INFO:Set up folding strategy.
2025-02-06 14:01:27,917:INFO:Set up train/test split.
2025-02-06 14:01:27,923:INFO:Set up index.
2025-02-06 14:01:27,925:INFO:Assigning column types.
2025-02-06 14:01:27,932:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:01:27,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:01:27,955:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:01:27,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:27,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:27,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:01:27,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:01:28,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,010:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:01:28,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:01:28,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:01:28,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,093:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:01:28,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,171:INFO:Preparing preprocessing pipeline...
2025-02-06 14:01:28,172:INFO:Set up simple imputation.
2025-02-06 14:01:28,193:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:01:28,194:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:01:28,195:INFO:Creating final display dataframe.
2025-02-06 14:01:28,267:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              7464
2025-02-06 14:01:28,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:01:28,345:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:01:28,345:INFO:Initializing create_model()
2025-02-06 14:01:28,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A6048D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:01:28,345:INFO:Checking exceptions
2025-02-06 14:01:28,346:INFO:Importing libraries
2025-02-06 14:01:28,346:INFO:Copying training dataset
2025-02-06 14:01:28,353:INFO:Defining folds
2025-02-06 14:01:28,353:INFO:Declaring metric variables
2025-02-06 14:01:28,353:INFO:Importing untrained model
2025-02-06 14:01:28,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:01:28,353:INFO:Starting cross validation
2025-02-06 14:01:28,354:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:01:28,819:INFO:Calculating mean and std
2025-02-06 14:01:28,819:INFO:Creating metrics dataframe
2025-02-06 14:01:28,820:INFO:Finalizing model
2025-02-06 14:01:28,835:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:01:28,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
2025-02-06 14:01:28,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:01:28,837:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:01:28,837:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:01:28,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:01:28,837:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:01:28,979:INFO:Uploading results into container
2025-02-06 14:01:28,980:INFO:Uploading model into container now
2025-02-06 14:01:28,980:INFO:_master_model_container: 1
2025-02-06 14:01:28,980:INFO:_display_container: 2
2025-02-06 14:01:28,981:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:01:28,981:INFO:create_model() successfully completed......................................
2025-02-06 14:02:20,931:INFO:PyCaret ClassificationExperiment
2025-02-06 14:02:20,931:INFO:Logging name: clf-default-name
2025-02-06 14:02:20,932:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:02:20,932:INFO:version 3.3.2
2025-02-06 14:02:20,932:INFO:Initializing setup()
2025-02-06 14:02:20,932:INFO:self.USI: 01c0
2025-02-06 14:02:20,932:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 14:02:20,932:INFO:Checking environment
2025-02-06 14:02:20,932:INFO:python_version: 3.11.9
2025-02-06 14:02:20,932:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:02:20,932:INFO:machine: AMD64
2025-02-06 14:02:20,932:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:02:20,936:INFO:Memory: svmem(total=67771465728, available=48042754048, percent=29.1, used=19728711680, free=48042754048)
2025-02-06 14:02:20,936:INFO:Physical Core: 8
2025-02-06 14:02:20,936:INFO:Logical Core: 16
2025-02-06 14:02:20,936:INFO:Checking libraries
2025-02-06 14:02:20,936:INFO:System:
2025-02-06 14:02:20,936:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:02:20,936:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:02:20,936:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:02:20,936:INFO:PyCaret required dependencies:
2025-02-06 14:02:20,936:INFO:                 pip: 25.0
2025-02-06 14:02:20,936:INFO:          setuptools: 65.5.0
2025-02-06 14:02:20,936:INFO:             pycaret: 3.3.2
2025-02-06 14:02:20,937:INFO:             IPython: 8.32.0
2025-02-06 14:02:20,937:INFO:          ipywidgets: 8.1.5
2025-02-06 14:02:20,937:INFO:                tqdm: 4.67.1
2025-02-06 14:02:20,937:INFO:               numpy: 1.26.4
2025-02-06 14:02:20,937:INFO:              pandas: 2.1.4
2025-02-06 14:02:20,937:INFO:              jinja2: 3.1.5
2025-02-06 14:02:20,937:INFO:               scipy: 1.11.4
2025-02-06 14:02:20,937:INFO:              joblib: 1.3.2
2025-02-06 14:02:20,937:INFO:             sklearn: 1.4.2
2025-02-06 14:02:20,937:INFO:                pyod: 2.0.3
2025-02-06 14:02:20,937:INFO:            imblearn: 0.13.0
2025-02-06 14:02:20,937:INFO:   category_encoders: 2.7.0
2025-02-06 14:02:20,937:INFO:            lightgbm: 4.5.0
2025-02-06 14:02:20,937:INFO:               numba: 0.61.0
2025-02-06 14:02:20,937:INFO:            requests: 2.32.3
2025-02-06 14:02:20,937:INFO:          matplotlib: 3.7.5
2025-02-06 14:02:20,937:INFO:          scikitplot: 0.3.7
2025-02-06 14:02:20,937:INFO:         yellowbrick: 1.5
2025-02-06 14:02:20,937:INFO:              plotly: 5.24.1
2025-02-06 14:02:20,937:INFO:    plotly-resampler: Not installed
2025-02-06 14:02:20,937:INFO:             kaleido: 0.2.1
2025-02-06 14:02:20,937:INFO:           schemdraw: 0.15
2025-02-06 14:02:20,937:INFO:         statsmodels: 0.14.4
2025-02-06 14:02:20,937:INFO:              sktime: 0.26.0
2025-02-06 14:02:20,937:INFO:               tbats: 1.1.3
2025-02-06 14:02:20,937:INFO:            pmdarima: 2.0.4
2025-02-06 14:02:20,937:INFO:              psutil: 6.1.1
2025-02-06 14:02:20,937:INFO:          markupsafe: 3.0.2
2025-02-06 14:02:20,937:INFO:             pickle5: Not installed
2025-02-06 14:02:20,937:INFO:         cloudpickle: 3.1.1
2025-02-06 14:02:20,937:INFO:         deprecation: 2.1.0
2025-02-06 14:02:20,937:INFO:              xxhash: 3.5.0
2025-02-06 14:02:20,937:INFO:           wurlitzer: Not installed
2025-02-06 14:02:20,937:INFO:PyCaret optional dependencies:
2025-02-06 14:02:20,938:INFO:                shap: Not installed
2025-02-06 14:02:20,938:INFO:           interpret: Not installed
2025-02-06 14:02:20,938:INFO:                umap: Not installed
2025-02-06 14:02:20,938:INFO:     ydata_profiling: Not installed
2025-02-06 14:02:20,938:INFO:  explainerdashboard: Not installed
2025-02-06 14:02:20,938:INFO:             autoviz: Not installed
2025-02-06 14:02:20,938:INFO:           fairlearn: Not installed
2025-02-06 14:02:20,938:INFO:          deepchecks: Not installed
2025-02-06 14:02:20,938:INFO:             xgboost: Not installed
2025-02-06 14:02:20,938:INFO:            catboost: Not installed
2025-02-06 14:02:20,938:INFO:              kmodes: Not installed
2025-02-06 14:02:20,938:INFO:             mlxtend: Not installed
2025-02-06 14:02:20,938:INFO:       statsforecast: Not installed
2025-02-06 14:02:20,938:INFO:        tune_sklearn: Not installed
2025-02-06 14:02:20,938:INFO:                 ray: Not installed
2025-02-06 14:02:20,938:INFO:            hyperopt: Not installed
2025-02-06 14:02:20,938:INFO:              optuna: Not installed
2025-02-06 14:02:20,938:INFO:               skopt: Not installed
2025-02-06 14:02:20,938:INFO:              mlflow: Not installed
2025-02-06 14:02:20,938:INFO:              gradio: Not installed
2025-02-06 14:02:20,938:INFO:             fastapi: Not installed
2025-02-06 14:02:20,938:INFO:             uvicorn: Not installed
2025-02-06 14:02:20,938:INFO:              m2cgen: Not installed
2025-02-06 14:02:20,938:INFO:           evidently: Not installed
2025-02-06 14:02:20,938:INFO:               fugue: Not installed
2025-02-06 14:02:20,938:INFO:           streamlit: Not installed
2025-02-06 14:02:20,938:INFO:             prophet: Not installed
2025-02-06 14:02:20,938:INFO:None
2025-02-06 14:02:20,938:INFO:Set up data.
2025-02-06 14:02:20,949:INFO:Set up folding strategy.
2025-02-06 14:02:20,949:INFO:Set up train/test split.
2025-02-06 14:02:20,957:INFO:Set up index.
2025-02-06 14:02:20,958:INFO:Assigning column types.
2025-02-06 14:02:20,967:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:02:20,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:02:20,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:21,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:02:21,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:21,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:02:21,072:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:21,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:21,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,126:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:02:21,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,204:INFO:Preparing preprocessing pipeline...
2025-02-06 14:02:21,206:INFO:Set up simple imputation.
2025-02-06 14:02:21,227:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:02:21,229:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:02:21,229:INFO:Creating final display dataframe.
2025-02-06 14:02:21,302:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              01c0
2025-02-06 14:02:21,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:21,382:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:02:21,382:INFO:Initializing create_model()
2025-02-06 14:02:21,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C7A5D1350>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:02:21,382:INFO:Checking exceptions
2025-02-06 14:02:21,383:INFO:Importing libraries
2025-02-06 14:02:21,383:INFO:Copying training dataset
2025-02-06 14:02:21,390:INFO:Defining folds
2025-02-06 14:02:21,390:INFO:Declaring metric variables
2025-02-06 14:02:21,390:INFO:Importing untrained model
2025-02-06 14:02:21,390:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:02:21,390:INFO:Starting cross validation
2025-02-06 14:02:21,390:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:02:22,966:INFO:Calculating mean and std
2025-02-06 14:02:22,966:INFO:Creating metrics dataframe
2025-02-06 14:02:22,967:INFO:Finalizing model
2025-02-06 14:02:22,982:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:02:22,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.
2025-02-06 14:02:22,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:02:22,984:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:02:22,984:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:02:22,984:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:02:22,984:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:02:23,102:INFO:Uploading results into container
2025-02-06 14:02:23,103:INFO:Uploading model into container now
2025-02-06 14:02:23,103:INFO:_master_model_container: 1
2025-02-06 14:02:23,103:INFO:_display_container: 2
2025-02-06 14:02:23,103:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:02:23,103:INFO:create_model() successfully completed......................................
2025-02-06 14:02:42,429:INFO:PyCaret ClassificationExperiment
2025-02-06 14:02:42,429:INFO:Logging name: clf-default-name
2025-02-06 14:02:42,429:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:02:42,429:INFO:version 3.3.2
2025-02-06 14:02:42,429:INFO:Initializing setup()
2025-02-06 14:02:42,429:INFO:self.USI: 333c
2025-02-06 14:02:42,429:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'logging_param', 'X', 'fold_groups_param', 'seed', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'log_plots_param', 'exp_id', 'USI', 'X_test', 'idx', 'is_multiclass', 'y', 'gpu_param', 'data', 'memory', 'X_train', 'y_test', 'gpu_n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'exp_name_log', 'fold_shuffle_param'}
2025-02-06 14:02:42,429:INFO:Checking environment
2025-02-06 14:02:42,429:INFO:python_version: 3.11.9
2025-02-06 14:02:42,429:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:02:42,429:INFO:machine: AMD64
2025-02-06 14:02:42,429:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:02:42,434:INFO:Memory: svmem(total=67771465728, available=47908900864, percent=29.3, used=19862564864, free=47908900864)
2025-02-06 14:02:42,434:INFO:Physical Core: 8
2025-02-06 14:02:42,434:INFO:Logical Core: 16
2025-02-06 14:02:42,434:INFO:Checking libraries
2025-02-06 14:02:42,434:INFO:System:
2025-02-06 14:02:42,434:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:02:42,434:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:02:42,434:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:02:42,434:INFO:PyCaret required dependencies:
2025-02-06 14:02:42,434:INFO:                 pip: 25.0
2025-02-06 14:02:42,434:INFO:          setuptools: 65.5.0
2025-02-06 14:02:42,434:INFO:             pycaret: 3.3.2
2025-02-06 14:02:42,434:INFO:             IPython: 8.32.0
2025-02-06 14:02:42,434:INFO:          ipywidgets: 8.1.5
2025-02-06 14:02:42,434:INFO:                tqdm: 4.67.1
2025-02-06 14:02:42,434:INFO:               numpy: 1.26.4
2025-02-06 14:02:42,434:INFO:              pandas: 2.1.4
2025-02-06 14:02:42,434:INFO:              jinja2: 3.1.5
2025-02-06 14:02:42,434:INFO:               scipy: 1.11.4
2025-02-06 14:02:42,434:INFO:              joblib: 1.3.2
2025-02-06 14:02:42,434:INFO:             sklearn: 1.4.2
2025-02-06 14:02:42,434:INFO:                pyod: 2.0.3
2025-02-06 14:02:42,434:INFO:            imblearn: 0.13.0
2025-02-06 14:02:42,434:INFO:   category_encoders: 2.7.0
2025-02-06 14:02:42,434:INFO:            lightgbm: 4.5.0
2025-02-06 14:02:42,434:INFO:               numba: 0.61.0
2025-02-06 14:02:42,434:INFO:            requests: 2.32.3
2025-02-06 14:02:42,434:INFO:          matplotlib: 3.7.5
2025-02-06 14:02:42,434:INFO:          scikitplot: 0.3.7
2025-02-06 14:02:42,434:INFO:         yellowbrick: 1.5
2025-02-06 14:02:42,434:INFO:              plotly: 5.24.1
2025-02-06 14:02:42,434:INFO:    plotly-resampler: Not installed
2025-02-06 14:02:42,434:INFO:             kaleido: 0.2.1
2025-02-06 14:02:42,434:INFO:           schemdraw: 0.15
2025-02-06 14:02:42,434:INFO:         statsmodels: 0.14.4
2025-02-06 14:02:42,434:INFO:              sktime: 0.26.0
2025-02-06 14:02:42,434:INFO:               tbats: 1.1.3
2025-02-06 14:02:42,434:INFO:            pmdarima: 2.0.4
2025-02-06 14:02:42,434:INFO:              psutil: 6.1.1
2025-02-06 14:02:42,434:INFO:          markupsafe: 3.0.2
2025-02-06 14:02:42,434:INFO:             pickle5: Not installed
2025-02-06 14:02:42,434:INFO:         cloudpickle: 3.1.1
2025-02-06 14:02:42,435:INFO:         deprecation: 2.1.0
2025-02-06 14:02:42,435:INFO:              xxhash: 3.5.0
2025-02-06 14:02:42,435:INFO:           wurlitzer: Not installed
2025-02-06 14:02:42,435:INFO:PyCaret optional dependencies:
2025-02-06 14:02:42,435:INFO:                shap: Not installed
2025-02-06 14:02:42,435:INFO:           interpret: Not installed
2025-02-06 14:02:42,435:INFO:                umap: Not installed
2025-02-06 14:02:42,435:INFO:     ydata_profiling: Not installed
2025-02-06 14:02:42,435:INFO:  explainerdashboard: Not installed
2025-02-06 14:02:42,435:INFO:             autoviz: Not installed
2025-02-06 14:02:42,435:INFO:           fairlearn: Not installed
2025-02-06 14:02:42,435:INFO:          deepchecks: Not installed
2025-02-06 14:02:42,435:INFO:             xgboost: Not installed
2025-02-06 14:02:42,435:INFO:            catboost: Not installed
2025-02-06 14:02:42,435:INFO:              kmodes: Not installed
2025-02-06 14:02:42,435:INFO:             mlxtend: Not installed
2025-02-06 14:02:42,435:INFO:       statsforecast: Not installed
2025-02-06 14:02:42,435:INFO:        tune_sklearn: Not installed
2025-02-06 14:02:42,435:INFO:                 ray: Not installed
2025-02-06 14:02:42,435:INFO:            hyperopt: Not installed
2025-02-06 14:02:42,435:INFO:              optuna: Not installed
2025-02-06 14:02:42,435:INFO:               skopt: Not installed
2025-02-06 14:02:42,435:INFO:              mlflow: Not installed
2025-02-06 14:02:42,435:INFO:              gradio: Not installed
2025-02-06 14:02:42,435:INFO:             fastapi: Not installed
2025-02-06 14:02:42,435:INFO:             uvicorn: Not installed
2025-02-06 14:02:42,435:INFO:              m2cgen: Not installed
2025-02-06 14:02:42,435:INFO:           evidently: Not installed
2025-02-06 14:02:42,435:INFO:               fugue: Not installed
2025-02-06 14:02:42,435:INFO:           streamlit: Not installed
2025-02-06 14:02:42,435:INFO:             prophet: Not installed
2025-02-06 14:02:42,435:INFO:None
2025-02-06 14:02:42,435:INFO:Set up data.
2025-02-06 14:02:42,443:INFO:Set up folding strategy.
2025-02-06 14:02:42,443:INFO:Set up train/test split.
2025-02-06 14:02:42,450:INFO:Set up index.
2025-02-06 14:02:42,451:INFO:Assigning column types.
2025-02-06 14:02:42,458:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:02:42,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,482:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,522:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,537:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:02:42,561:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:02:42,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,616:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:02:42,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,694:INFO:Preparing preprocessing pipeline...
2025-02-06 14:02:42,696:INFO:Set up simple imputation.
2025-02-06 14:02:42,718:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:02:42,720:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:02:42,720:INFO:Creating final display dataframe.
2025-02-06 14:02:42,794:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              333c
2025-02-06 14:02:42,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:02:42,874:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:02:42,874:INFO:Initializing create_model()
2025-02-06 14:02:42,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C75726390>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:02:42,874:INFO:Checking exceptions
2025-02-06 14:02:42,876:INFO:Importing libraries
2025-02-06 14:02:42,876:INFO:Copying training dataset
2025-02-06 14:02:42,882:INFO:Defining folds
2025-02-06 14:02:42,882:INFO:Declaring metric variables
2025-02-06 14:02:42,882:INFO:Importing untrained model
2025-02-06 14:02:42,882:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:02:42,882:INFO:Starting cross validation
2025-02-06 14:02:42,883:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:02:43,295:INFO:Calculating mean and std
2025-02-06 14:02:43,295:INFO:Creating metrics dataframe
2025-02-06 14:02:43,296:INFO:Finalizing model
2025-02-06 14:02:43,311:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:02:43,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.
2025-02-06 14:02:43,312:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:02:43,313:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:02:43,313:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:02:43,313:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:02:43,313:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:02:43,444:INFO:Uploading results into container
2025-02-06 14:02:43,445:INFO:Uploading model into container now
2025-02-06 14:02:43,445:INFO:_master_model_container: 1
2025-02-06 14:02:43,445:INFO:_display_container: 2
2025-02-06 14:02:43,445:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:02:43,445:INFO:create_model() successfully completed......................................
2025-02-06 14:07:13,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:07:13,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:07:13,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:07:13,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:08:55,593:INFO:PyCaret ClassificationExperiment
2025-02-06 14:08:55,594:INFO:Logging name: clf-default-name
2025-02-06 14:08:55,594:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:08:55,594:INFO:version 3.3.2
2025-02-06 14:08:55,594:INFO:Initializing setup()
2025-02-06 14:08:55,594:INFO:self.USI: 131f
2025-02-06 14:08:55,594:INFO:self._variable_keys: {'target_param', 'exp_name_log', 'idx', '_ml_usecase', 'X_train', 'USI', 'fold_generator', 'pipeline', 'y', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'memory', 'log_plots_param', 'fix_imbalance', 'gpu_n_jobs_param', 'logging_param', 'n_jobs_param', 'exp_id', 'seed', 'y_train', 'gpu_param', 'html_param', 'is_multiclass', '_available_plots', 'data', 'X', 'X_test'}
2025-02-06 14:08:55,594:INFO:Checking environment
2025-02-06 14:08:55,594:INFO:python_version: 3.11.9
2025-02-06 14:08:55,594:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:08:55,594:INFO:machine: AMD64
2025-02-06 14:08:55,594:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:08:55,598:INFO:Memory: svmem(total=67771465728, available=50392915968, percent=25.6, used=17378549760, free=50392915968)
2025-02-06 14:08:55,598:INFO:Physical Core: 8
2025-02-06 14:08:55,598:INFO:Logical Core: 16
2025-02-06 14:08:55,598:INFO:Checking libraries
2025-02-06 14:08:55,598:INFO:System:
2025-02-06 14:08:55,598:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:08:55,598:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:08:55,598:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:08:55,598:INFO:PyCaret required dependencies:
2025-02-06 14:08:55,611:INFO:                 pip: 25.0
2025-02-06 14:08:55,611:INFO:          setuptools: 65.5.0
2025-02-06 14:08:55,611:INFO:             pycaret: 3.3.2
2025-02-06 14:08:55,611:INFO:             IPython: 8.32.0
2025-02-06 14:08:55,611:INFO:          ipywidgets: 8.1.5
2025-02-06 14:08:55,611:INFO:                tqdm: 4.67.1
2025-02-06 14:08:55,611:INFO:               numpy: 1.26.4
2025-02-06 14:08:55,611:INFO:              pandas: 2.1.4
2025-02-06 14:08:55,611:INFO:              jinja2: 3.1.5
2025-02-06 14:08:55,611:INFO:               scipy: 1.11.4
2025-02-06 14:08:55,611:INFO:              joblib: 1.3.2
2025-02-06 14:08:55,611:INFO:             sklearn: 1.4.2
2025-02-06 14:08:55,611:INFO:                pyod: 2.0.3
2025-02-06 14:08:55,611:INFO:            imblearn: 0.13.0
2025-02-06 14:08:55,611:INFO:   category_encoders: 2.7.0
2025-02-06 14:08:55,611:INFO:            lightgbm: 4.5.0
2025-02-06 14:08:55,611:INFO:               numba: 0.61.0
2025-02-06 14:08:55,611:INFO:            requests: 2.32.3
2025-02-06 14:08:55,611:INFO:          matplotlib: 3.7.5
2025-02-06 14:08:55,611:INFO:          scikitplot: 0.3.7
2025-02-06 14:08:55,611:INFO:         yellowbrick: 1.5
2025-02-06 14:08:55,611:INFO:              plotly: 5.24.1
2025-02-06 14:08:55,611:INFO:    plotly-resampler: Not installed
2025-02-06 14:08:55,612:INFO:             kaleido: 0.2.1
2025-02-06 14:08:55,612:INFO:           schemdraw: 0.15
2025-02-06 14:08:55,612:INFO:         statsmodels: 0.14.4
2025-02-06 14:08:55,612:INFO:              sktime: 0.26.0
2025-02-06 14:08:55,612:INFO:               tbats: 1.1.3
2025-02-06 14:08:55,612:INFO:            pmdarima: 2.0.4
2025-02-06 14:08:55,612:INFO:              psutil: 6.1.1
2025-02-06 14:08:55,612:INFO:          markupsafe: 3.0.2
2025-02-06 14:08:55,612:INFO:             pickle5: Not installed
2025-02-06 14:08:55,612:INFO:         cloudpickle: 3.1.1
2025-02-06 14:08:55,612:INFO:         deprecation: 2.1.0
2025-02-06 14:08:55,612:INFO:              xxhash: 3.5.0
2025-02-06 14:08:55,612:INFO:           wurlitzer: Not installed
2025-02-06 14:08:55,612:INFO:PyCaret optional dependencies:
2025-02-06 14:08:55,617:INFO:                shap: Not installed
2025-02-06 14:08:55,617:INFO:           interpret: Not installed
2025-02-06 14:08:55,617:INFO:                umap: Not installed
2025-02-06 14:08:55,617:INFO:     ydata_profiling: Not installed
2025-02-06 14:08:55,617:INFO:  explainerdashboard: Not installed
2025-02-06 14:08:55,617:INFO:             autoviz: Not installed
2025-02-06 14:08:55,617:INFO:           fairlearn: Not installed
2025-02-06 14:08:55,617:INFO:          deepchecks: Not installed
2025-02-06 14:08:55,617:INFO:             xgboost: Not installed
2025-02-06 14:08:55,617:INFO:            catboost: Not installed
2025-02-06 14:08:55,617:INFO:              kmodes: Not installed
2025-02-06 14:08:55,617:INFO:             mlxtend: Not installed
2025-02-06 14:08:55,617:INFO:       statsforecast: Not installed
2025-02-06 14:08:55,617:INFO:        tune_sklearn: Not installed
2025-02-06 14:08:55,617:INFO:                 ray: Not installed
2025-02-06 14:08:55,617:INFO:            hyperopt: Not installed
2025-02-06 14:08:55,617:INFO:              optuna: Not installed
2025-02-06 14:08:55,617:INFO:               skopt: Not installed
2025-02-06 14:08:55,617:INFO:              mlflow: Not installed
2025-02-06 14:08:55,617:INFO:              gradio: Not installed
2025-02-06 14:08:55,617:INFO:             fastapi: Not installed
2025-02-06 14:08:55,617:INFO:             uvicorn: Not installed
2025-02-06 14:08:55,617:INFO:              m2cgen: Not installed
2025-02-06 14:08:55,617:INFO:           evidently: Not installed
2025-02-06 14:08:55,617:INFO:               fugue: Not installed
2025-02-06 14:08:55,617:INFO:           streamlit: Not installed
2025-02-06 14:08:55,617:INFO:             prophet: Not installed
2025-02-06 14:08:55,618:INFO:None
2025-02-06 14:08:55,618:INFO:Set up data.
2025-02-06 14:08:55,626:INFO:Set up folding strategy.
2025-02-06 14:08:55,626:INFO:Set up train/test split.
2025-02-06 14:08:55,633:INFO:Set up index.
2025-02-06 14:08:55,635:INFO:Assigning column types.
2025-02-06 14:08:55,641:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:08:55,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,711:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,725:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:08:55,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:08:55,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,803:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:08:55,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:55,883:INFO:Preparing preprocessing pipeline...
2025-02-06 14:08:55,884:INFO:Set up simple imputation.
2025-02-06 14:08:55,904:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:08:55,906:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:08:55,906:INFO:Creating final display dataframe.
2025-02-06 14:08:55,981:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              131f
2025-02-06 14:08:56,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:56,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:56,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:56,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:08:56,058:INFO:setup() successfully completed in 0.47s...............
2025-02-06 14:08:56,058:INFO:Initializing create_model()
2025-02-06 14:08:56,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000241539DDD90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:08:56,058:INFO:Checking exceptions
2025-02-06 14:08:56,059:INFO:Importing libraries
2025-02-06 14:08:56,059:INFO:Copying training dataset
2025-02-06 14:08:56,066:INFO:Defining folds
2025-02-06 14:08:56,066:INFO:Declaring metric variables
2025-02-06 14:08:56,066:INFO:Importing untrained model
2025-02-06 14:08:56,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:08:56,066:INFO:Starting cross validation
2025-02-06 14:08:56,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:08:58,258:INFO:Calculating mean and std
2025-02-06 14:08:58,258:INFO:Creating metrics dataframe
2025-02-06 14:08:58,260:INFO:Finalizing model
2025-02-06 14:08:58,282:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:08:58,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001202 seconds.
2025-02-06 14:08:58,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:08:58,284:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:08:58,284:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:08:58,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:08:58,285:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:08:58,394:INFO:Uploading results into container
2025-02-06 14:08:58,395:INFO:Uploading model into container now
2025-02-06 14:08:58,395:INFO:_master_model_container: 1
2025-02-06 14:08:58,395:INFO:_display_container: 2
2025-02-06 14:08:58,395:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:08:58,396:INFO:create_model() successfully completed......................................
2025-02-06 14:09:10,783:INFO:PyCaret ClassificationExperiment
2025-02-06 14:09:10,783:INFO:Logging name: clf-default-name
2025-02-06 14:09:10,783:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:09:10,783:INFO:version 3.3.2
2025-02-06 14:09:10,784:INFO:Initializing setup()
2025-02-06 14:09:10,784:INFO:self.USI: 4da9
2025-02-06 14:09:10,784:INFO:self._variable_keys: {'target_param', 'exp_name_log', 'idx', '_ml_usecase', 'X_train', 'USI', 'fold_generator', 'pipeline', 'y', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'memory', 'log_plots_param', 'fix_imbalance', 'gpu_n_jobs_param', 'logging_param', 'n_jobs_param', 'exp_id', 'seed', 'y_train', 'gpu_param', 'html_param', 'is_multiclass', '_available_plots', 'data', 'X', 'X_test'}
2025-02-06 14:09:10,784:INFO:Checking environment
2025-02-06 14:09:10,784:INFO:python_version: 3.11.9
2025-02-06 14:09:10,784:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:09:10,784:INFO:machine: AMD64
2025-02-06 14:09:10,784:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:09:10,787:INFO:Memory: svmem(total=67771465728, available=49326698496, percent=27.2, used=18444767232, free=49326698496)
2025-02-06 14:09:10,788:INFO:Physical Core: 8
2025-02-06 14:09:10,788:INFO:Logical Core: 16
2025-02-06 14:09:10,788:INFO:Checking libraries
2025-02-06 14:09:10,788:INFO:System:
2025-02-06 14:09:10,788:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:09:10,788:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:09:10,788:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:09:10,788:INFO:PyCaret required dependencies:
2025-02-06 14:09:10,788:INFO:                 pip: 25.0
2025-02-06 14:09:10,788:INFO:          setuptools: 65.5.0
2025-02-06 14:09:10,788:INFO:             pycaret: 3.3.2
2025-02-06 14:09:10,788:INFO:             IPython: 8.32.0
2025-02-06 14:09:10,788:INFO:          ipywidgets: 8.1.5
2025-02-06 14:09:10,788:INFO:                tqdm: 4.67.1
2025-02-06 14:09:10,788:INFO:               numpy: 1.26.4
2025-02-06 14:09:10,788:INFO:              pandas: 2.1.4
2025-02-06 14:09:10,788:INFO:              jinja2: 3.1.5
2025-02-06 14:09:10,788:INFO:               scipy: 1.11.4
2025-02-06 14:09:10,788:INFO:              joblib: 1.3.2
2025-02-06 14:09:10,788:INFO:             sklearn: 1.4.2
2025-02-06 14:09:10,788:INFO:                pyod: 2.0.3
2025-02-06 14:09:10,788:INFO:            imblearn: 0.13.0
2025-02-06 14:09:10,788:INFO:   category_encoders: 2.7.0
2025-02-06 14:09:10,788:INFO:            lightgbm: 4.5.0
2025-02-06 14:09:10,788:INFO:               numba: 0.61.0
2025-02-06 14:09:10,788:INFO:            requests: 2.32.3
2025-02-06 14:09:10,788:INFO:          matplotlib: 3.7.5
2025-02-06 14:09:10,788:INFO:          scikitplot: 0.3.7
2025-02-06 14:09:10,788:INFO:         yellowbrick: 1.5
2025-02-06 14:09:10,788:INFO:              plotly: 5.24.1
2025-02-06 14:09:10,788:INFO:    plotly-resampler: Not installed
2025-02-06 14:09:10,788:INFO:             kaleido: 0.2.1
2025-02-06 14:09:10,788:INFO:           schemdraw: 0.15
2025-02-06 14:09:10,788:INFO:         statsmodels: 0.14.4
2025-02-06 14:09:10,788:INFO:              sktime: 0.26.0
2025-02-06 14:09:10,788:INFO:               tbats: 1.1.3
2025-02-06 14:09:10,788:INFO:            pmdarima: 2.0.4
2025-02-06 14:09:10,788:INFO:              psutil: 6.1.1
2025-02-06 14:09:10,788:INFO:          markupsafe: 3.0.2
2025-02-06 14:09:10,788:INFO:             pickle5: Not installed
2025-02-06 14:09:10,788:INFO:         cloudpickle: 3.1.1
2025-02-06 14:09:10,788:INFO:         deprecation: 2.1.0
2025-02-06 14:09:10,788:INFO:              xxhash: 3.5.0
2025-02-06 14:09:10,788:INFO:           wurlitzer: Not installed
2025-02-06 14:09:10,788:INFO:PyCaret optional dependencies:
2025-02-06 14:09:10,788:INFO:                shap: Not installed
2025-02-06 14:09:10,788:INFO:           interpret: Not installed
2025-02-06 14:09:10,788:INFO:                umap: Not installed
2025-02-06 14:09:10,788:INFO:     ydata_profiling: Not installed
2025-02-06 14:09:10,788:INFO:  explainerdashboard: Not installed
2025-02-06 14:09:10,788:INFO:             autoviz: Not installed
2025-02-06 14:09:10,788:INFO:           fairlearn: Not installed
2025-02-06 14:09:10,788:INFO:          deepchecks: Not installed
2025-02-06 14:09:10,788:INFO:             xgboost: Not installed
2025-02-06 14:09:10,788:INFO:            catboost: Not installed
2025-02-06 14:09:10,788:INFO:              kmodes: Not installed
2025-02-06 14:09:10,788:INFO:             mlxtend: Not installed
2025-02-06 14:09:10,788:INFO:       statsforecast: Not installed
2025-02-06 14:09:10,788:INFO:        tune_sklearn: Not installed
2025-02-06 14:09:10,788:INFO:                 ray: Not installed
2025-02-06 14:09:10,788:INFO:            hyperopt: Not installed
2025-02-06 14:09:10,788:INFO:              optuna: Not installed
2025-02-06 14:09:10,788:INFO:               skopt: Not installed
2025-02-06 14:09:10,788:INFO:              mlflow: Not installed
2025-02-06 14:09:10,788:INFO:              gradio: Not installed
2025-02-06 14:09:10,788:INFO:             fastapi: Not installed
2025-02-06 14:09:10,788:INFO:             uvicorn: Not installed
2025-02-06 14:09:10,788:INFO:              m2cgen: Not installed
2025-02-06 14:09:10,788:INFO:           evidently: Not installed
2025-02-06 14:09:10,788:INFO:               fugue: Not installed
2025-02-06 14:09:10,788:INFO:           streamlit: Not installed
2025-02-06 14:09:10,788:INFO:             prophet: Not installed
2025-02-06 14:09:10,789:INFO:None
2025-02-06 14:09:10,789:INFO:Set up data.
2025-02-06 14:09:10,797:INFO:Set up folding strategy.
2025-02-06 14:09:10,797:INFO:Set up train/test split.
2025-02-06 14:09:10,803:INFO:Set up index.
2025-02-06 14:09:10,805:INFO:Assigning column types.
2025-02-06 14:09:10,812:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:09:10,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,883:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,899:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:09:10,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:09:10,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:10,977:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:09:11,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,056:INFO:Preparing preprocessing pipeline...
2025-02-06 14:09:11,058:INFO:Set up simple imputation.
2025-02-06 14:09:11,080:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:09:11,081:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:09:11,081:INFO:Creating final display dataframe.
2025-02-06 14:09:11,153:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              4da9
2025-02-06 14:09:11,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:09:11,231:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:09:11,231:INFO:Initializing create_model()
2025-02-06 14:09:11,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024154C3D490>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:09:11,231:INFO:Checking exceptions
2025-02-06 14:09:11,232:INFO:Importing libraries
2025-02-06 14:09:11,232:INFO:Copying training dataset
2025-02-06 14:09:11,239:INFO:Defining folds
2025-02-06 14:09:11,239:INFO:Declaring metric variables
2025-02-06 14:09:11,239:INFO:Importing untrained model
2025-02-06 14:09:11,239:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:09:11,239:INFO:Starting cross validation
2025-02-06 14:09:11,240:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:09:13,105:INFO:Calculating mean and std
2025-02-06 14:09:13,105:INFO:Creating metrics dataframe
2025-02-06 14:09:13,106:INFO:Finalizing model
2025-02-06 14:09:13,122:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:09:13,123:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001098 seconds.
2025-02-06 14:09:13,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:09:13,123:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:09:13,123:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:09:13,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:09:13,123:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:09:13,231:INFO:Uploading results into container
2025-02-06 14:09:13,231:INFO:Uploading model into container now
2025-02-06 14:09:13,232:INFO:_master_model_container: 1
2025-02-06 14:09:13,232:INFO:_display_container: 2
2025-02-06 14:09:13,232:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:09:13,232:INFO:create_model() successfully completed......................................
2025-02-06 14:22:14,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:22:14,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:22:14,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:22:14,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:22:15,323:INFO:PyCaret ClassificationExperiment
2025-02-06 14:22:15,323:INFO:Logging name: clf-default-name
2025-02-06 14:22:15,323:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:22:15,323:INFO:version 3.3.2
2025-02-06 14:22:15,323:INFO:Initializing setup()
2025-02-06 14:22:15,323:INFO:self.USI: a64d
2025-02-06 14:22:15,323:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:22:15,323:INFO:Checking environment
2025-02-06 14:22:15,323:INFO:python_version: 3.11.9
2025-02-06 14:22:15,323:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:22:15,323:INFO:machine: AMD64
2025-02-06 14:22:15,323:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:22:15,329:INFO:Memory: svmem(total=67771465728, available=50590928896, percent=25.4, used=17180536832, free=50590928896)
2025-02-06 14:22:15,329:INFO:Physical Core: 8
2025-02-06 14:22:15,329:INFO:Logical Core: 16
2025-02-06 14:22:15,329:INFO:Checking libraries
2025-02-06 14:22:15,329:INFO:System:
2025-02-06 14:22:15,329:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:22:15,329:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:22:15,329:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:22:15,329:INFO:PyCaret required dependencies:
2025-02-06 14:22:15,342:INFO:                 pip: 25.0
2025-02-06 14:22:15,343:INFO:          setuptools: 65.5.0
2025-02-06 14:22:15,343:INFO:             pycaret: 3.3.2
2025-02-06 14:22:15,343:INFO:             IPython: 8.32.0
2025-02-06 14:22:15,343:INFO:          ipywidgets: 8.1.5
2025-02-06 14:22:15,343:INFO:                tqdm: 4.67.1
2025-02-06 14:22:15,343:INFO:               numpy: 1.26.4
2025-02-06 14:22:15,343:INFO:              pandas: 2.1.4
2025-02-06 14:22:15,343:INFO:              jinja2: 3.1.5
2025-02-06 14:22:15,343:INFO:               scipy: 1.11.4
2025-02-06 14:22:15,343:INFO:              joblib: 1.3.2
2025-02-06 14:22:15,343:INFO:             sklearn: 1.4.2
2025-02-06 14:22:15,343:INFO:                pyod: 2.0.3
2025-02-06 14:22:15,343:INFO:            imblearn: 0.13.0
2025-02-06 14:22:15,343:INFO:   category_encoders: 2.7.0
2025-02-06 14:22:15,343:INFO:            lightgbm: 4.5.0
2025-02-06 14:22:15,343:INFO:               numba: 0.61.0
2025-02-06 14:22:15,343:INFO:            requests: 2.32.3
2025-02-06 14:22:15,343:INFO:          matplotlib: 3.7.5
2025-02-06 14:22:15,343:INFO:          scikitplot: 0.3.7
2025-02-06 14:22:15,343:INFO:         yellowbrick: 1.5
2025-02-06 14:22:15,343:INFO:              plotly: 5.24.1
2025-02-06 14:22:15,343:INFO:    plotly-resampler: Not installed
2025-02-06 14:22:15,343:INFO:             kaleido: 0.2.1
2025-02-06 14:22:15,343:INFO:           schemdraw: 0.15
2025-02-06 14:22:15,343:INFO:         statsmodels: 0.14.4
2025-02-06 14:22:15,343:INFO:              sktime: 0.26.0
2025-02-06 14:22:15,343:INFO:               tbats: 1.1.3
2025-02-06 14:22:15,343:INFO:            pmdarima: 2.0.4
2025-02-06 14:22:15,343:INFO:              psutil: 6.1.1
2025-02-06 14:22:15,343:INFO:          markupsafe: 3.0.2
2025-02-06 14:22:15,343:INFO:             pickle5: Not installed
2025-02-06 14:22:15,343:INFO:         cloudpickle: 3.1.1
2025-02-06 14:22:15,343:INFO:         deprecation: 2.1.0
2025-02-06 14:22:15,343:INFO:              xxhash: 3.5.0
2025-02-06 14:22:15,343:INFO:           wurlitzer: Not installed
2025-02-06 14:22:15,343:INFO:PyCaret optional dependencies:
2025-02-06 14:22:15,350:INFO:                shap: Not installed
2025-02-06 14:22:15,350:INFO:           interpret: Not installed
2025-02-06 14:22:15,350:INFO:                umap: Not installed
2025-02-06 14:22:15,350:INFO:     ydata_profiling: Not installed
2025-02-06 14:22:15,350:INFO:  explainerdashboard: Not installed
2025-02-06 14:22:15,351:INFO:             autoviz: Not installed
2025-02-06 14:22:15,351:INFO:           fairlearn: Not installed
2025-02-06 14:22:15,351:INFO:          deepchecks: Not installed
2025-02-06 14:22:15,351:INFO:             xgboost: Not installed
2025-02-06 14:22:15,351:INFO:            catboost: Not installed
2025-02-06 14:22:15,351:INFO:              kmodes: Not installed
2025-02-06 14:22:15,351:INFO:             mlxtend: Not installed
2025-02-06 14:22:15,351:INFO:       statsforecast: Not installed
2025-02-06 14:22:15,351:INFO:        tune_sklearn: Not installed
2025-02-06 14:22:15,351:INFO:                 ray: Not installed
2025-02-06 14:22:15,351:INFO:            hyperopt: Not installed
2025-02-06 14:22:15,351:INFO:              optuna: Not installed
2025-02-06 14:22:15,351:INFO:               skopt: Not installed
2025-02-06 14:22:15,351:INFO:              mlflow: Not installed
2025-02-06 14:22:15,351:INFO:              gradio: Not installed
2025-02-06 14:22:15,351:INFO:             fastapi: Not installed
2025-02-06 14:22:15,351:INFO:             uvicorn: Not installed
2025-02-06 14:22:15,351:INFO:              m2cgen: Not installed
2025-02-06 14:22:15,351:INFO:           evidently: Not installed
2025-02-06 14:22:15,351:INFO:               fugue: Not installed
2025-02-06 14:22:15,351:INFO:           streamlit: Not installed
2025-02-06 14:22:15,351:INFO:             prophet: Not installed
2025-02-06 14:22:15,351:INFO:None
2025-02-06 14:22:15,351:INFO:Set up data.
2025-02-06 14:22:15,360:INFO:Set up folding strategy.
2025-02-06 14:22:15,360:INFO:Set up train/test split.
2025-02-06 14:22:15,367:INFO:Set up index.
2025-02-06 14:22:15,368:INFO:Assigning column types.
2025-02-06 14:22:15,375:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:22:15,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,461:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:22:15,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:15,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,545:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:22:15,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,624:INFO:Preparing preprocessing pipeline...
2025-02-06 14:22:15,626:INFO:Set up simple imputation.
2025-02-06 14:22:15,648:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:22:15,650:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:22:15,650:INFO:Creating final display dataframe.
2025-02-06 14:22:15,720:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a64d
2025-02-06 14:22:15,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:15,798:INFO:setup() successfully completed in 0.48s...............
2025-02-06 14:22:15,798:INFO:Initializing create_model()
2025-02-06 14:22:15,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F35FB610>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:22:15,798:INFO:Checking exceptions
2025-02-06 14:22:15,799:INFO:Importing libraries
2025-02-06 14:22:15,799:INFO:Copying training dataset
2025-02-06 14:22:15,806:INFO:Defining folds
2025-02-06 14:22:15,806:INFO:Declaring metric variables
2025-02-06 14:22:15,806:INFO:Importing untrained model
2025-02-06 14:22:15,806:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:22:15,806:INFO:Starting cross validation
2025-02-06 14:22:15,807:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:22:19,035:INFO:Calculating mean and std
2025-02-06 14:22:19,035:INFO:Creating metrics dataframe
2025-02-06 14:22:19,037:INFO:Finalizing model
2025-02-06 14:22:19,057:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:22:19,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.
2025-02-06 14:22:19,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:22:19,059:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:22:19,059:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:22:19,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:22:19,059:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:22:19,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:19,423:INFO:Uploading results into container
2025-02-06 14:22:19,424:INFO:Uploading model into container now
2025-02-06 14:22:19,424:INFO:_master_model_container: 1
2025-02-06 14:22:19,424:INFO:_display_container: 2
2025-02-06 14:22:19,424:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:22:19,424:INFO:create_model() successfully completed......................................
2025-02-06 14:22:33,988:INFO:PyCaret ClassificationExperiment
2025-02-06 14:22:33,988:INFO:Logging name: clf-default-name
2025-02-06 14:22:33,988:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:22:33,990:INFO:version 3.3.2
2025-02-06 14:22:33,990:INFO:Initializing setup()
2025-02-06 14:22:33,990:INFO:self.USI: fb2f
2025-02-06 14:22:33,990:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:22:33,990:INFO:Checking environment
2025-02-06 14:22:33,990:INFO:python_version: 3.11.9
2025-02-06 14:22:33,990:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:22:33,990:INFO:machine: AMD64
2025-02-06 14:22:33,990:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:22:33,994:INFO:Memory: svmem(total=67771465728, available=49529962496, percent=26.9, used=18241503232, free=49529962496)
2025-02-06 14:22:33,994:INFO:Physical Core: 8
2025-02-06 14:22:33,994:INFO:Logical Core: 16
2025-02-06 14:22:33,994:INFO:Checking libraries
2025-02-06 14:22:33,994:INFO:System:
2025-02-06 14:22:33,994:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:22:33,994:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:22:33,994:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:22:33,994:INFO:PyCaret required dependencies:
2025-02-06 14:22:33,994:INFO:                 pip: 25.0
2025-02-06 14:22:33,994:INFO:          setuptools: 65.5.0
2025-02-06 14:22:33,994:INFO:             pycaret: 3.3.2
2025-02-06 14:22:33,994:INFO:             IPython: 8.32.0
2025-02-06 14:22:33,995:INFO:          ipywidgets: 8.1.5
2025-02-06 14:22:33,995:INFO:                tqdm: 4.67.1
2025-02-06 14:22:33,995:INFO:               numpy: 1.26.4
2025-02-06 14:22:33,995:INFO:              pandas: 2.1.4
2025-02-06 14:22:33,995:INFO:              jinja2: 3.1.5
2025-02-06 14:22:33,995:INFO:               scipy: 1.11.4
2025-02-06 14:22:33,995:INFO:              joblib: 1.3.2
2025-02-06 14:22:33,995:INFO:             sklearn: 1.4.2
2025-02-06 14:22:33,995:INFO:                pyod: 2.0.3
2025-02-06 14:22:33,995:INFO:            imblearn: 0.13.0
2025-02-06 14:22:33,995:INFO:   category_encoders: 2.7.0
2025-02-06 14:22:33,995:INFO:            lightgbm: 4.5.0
2025-02-06 14:22:33,995:INFO:               numba: 0.61.0
2025-02-06 14:22:33,995:INFO:            requests: 2.32.3
2025-02-06 14:22:33,995:INFO:          matplotlib: 3.7.5
2025-02-06 14:22:33,995:INFO:          scikitplot: 0.3.7
2025-02-06 14:22:33,995:INFO:         yellowbrick: 1.5
2025-02-06 14:22:33,995:INFO:              plotly: 5.24.1
2025-02-06 14:22:33,995:INFO:    plotly-resampler: Not installed
2025-02-06 14:22:33,995:INFO:             kaleido: 0.2.1
2025-02-06 14:22:33,995:INFO:           schemdraw: 0.15
2025-02-06 14:22:33,995:INFO:         statsmodels: 0.14.4
2025-02-06 14:22:33,995:INFO:              sktime: 0.26.0
2025-02-06 14:22:33,995:INFO:               tbats: 1.1.3
2025-02-06 14:22:33,995:INFO:            pmdarima: 2.0.4
2025-02-06 14:22:33,995:INFO:              psutil: 6.1.1
2025-02-06 14:22:33,995:INFO:          markupsafe: 3.0.2
2025-02-06 14:22:33,995:INFO:             pickle5: Not installed
2025-02-06 14:22:33,995:INFO:         cloudpickle: 3.1.1
2025-02-06 14:22:33,995:INFO:         deprecation: 2.1.0
2025-02-06 14:22:33,995:INFO:              xxhash: 3.5.0
2025-02-06 14:22:33,995:INFO:           wurlitzer: Not installed
2025-02-06 14:22:33,995:INFO:PyCaret optional dependencies:
2025-02-06 14:22:33,995:INFO:                shap: Not installed
2025-02-06 14:22:33,995:INFO:           interpret: Not installed
2025-02-06 14:22:33,995:INFO:                umap: Not installed
2025-02-06 14:22:33,995:INFO:     ydata_profiling: Not installed
2025-02-06 14:22:33,995:INFO:  explainerdashboard: Not installed
2025-02-06 14:22:33,995:INFO:             autoviz: Not installed
2025-02-06 14:22:33,995:INFO:           fairlearn: Not installed
2025-02-06 14:22:33,995:INFO:          deepchecks: Not installed
2025-02-06 14:22:33,995:INFO:             xgboost: Not installed
2025-02-06 14:22:33,995:INFO:            catboost: Not installed
2025-02-06 14:22:33,995:INFO:              kmodes: Not installed
2025-02-06 14:22:33,995:INFO:             mlxtend: Not installed
2025-02-06 14:22:33,995:INFO:       statsforecast: Not installed
2025-02-06 14:22:33,995:INFO:        tune_sklearn: Not installed
2025-02-06 14:22:33,995:INFO:                 ray: Not installed
2025-02-06 14:22:33,995:INFO:            hyperopt: Not installed
2025-02-06 14:22:33,995:INFO:              optuna: Not installed
2025-02-06 14:22:33,995:INFO:               skopt: Not installed
2025-02-06 14:22:33,995:INFO:              mlflow: Not installed
2025-02-06 14:22:33,995:INFO:              gradio: Not installed
2025-02-06 14:22:33,995:INFO:             fastapi: Not installed
2025-02-06 14:22:33,995:INFO:             uvicorn: Not installed
2025-02-06 14:22:33,995:INFO:              m2cgen: Not installed
2025-02-06 14:22:33,995:INFO:           evidently: Not installed
2025-02-06 14:22:33,995:INFO:               fugue: Not installed
2025-02-06 14:22:33,995:INFO:           streamlit: Not installed
2025-02-06 14:22:33,995:INFO:             prophet: Not installed
2025-02-06 14:22:33,995:INFO:None
2025-02-06 14:22:33,995:INFO:Set up data.
2025-02-06 14:22:34,004:INFO:Set up folding strategy.
2025-02-06 14:22:34,004:INFO:Set up train/test split.
2025-02-06 14:22:34,011:INFO:Set up index.
2025-02-06 14:22:34,012:INFO:Assigning column types.
2025-02-06 14:22:34,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:22:34,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,098:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:22:34,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:34,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,176:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:22:34,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,254:INFO:Preparing preprocessing pipeline...
2025-02-06 14:22:34,256:INFO:Set up simple imputation.
2025-02-06 14:22:34,277:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:22:34,279:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:22:34,279:INFO:Creating final display dataframe.
2025-02-06 14:22:34,349:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              fb2f
2025-02-06 14:22:34,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:34,440:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:22:34,440:INFO:Initializing create_model()
2025-02-06 14:22:34,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F437B390>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:22:34,440:INFO:Checking exceptions
2025-02-06 14:22:34,441:INFO:Importing libraries
2025-02-06 14:22:34,441:INFO:Copying training dataset
2025-02-06 14:22:34,448:INFO:Defining folds
2025-02-06 14:22:34,448:INFO:Declaring metric variables
2025-02-06 14:22:34,448:INFO:Importing untrained model
2025-02-06 14:22:34,448:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:22:34,449:INFO:Starting cross validation
2025-02-06 14:22:34,449:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:22:37,418:INFO:Calculating mean and std
2025-02-06 14:22:37,419:INFO:Creating metrics dataframe
2025-02-06 14:22:37,420:INFO:Finalizing model
2025-02-06 14:22:37,434:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:22:37,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.
2025-02-06 14:22:37,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:22:37,436:INFO:[LightGBM] [Info] Total Bins 6966
2025-02-06 14:22:37,436:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:22:37,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:22:37,436:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:22:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:37,822:INFO:Uploading results into container
2025-02-06 14:22:37,822:INFO:Uploading model into container now
2025-02-06 14:22:37,823:INFO:_master_model_container: 1
2025-02-06 14:22:37,823:INFO:_display_container: 2
2025-02-06 14:22:37,823:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:22:37,823:INFO:create_model() successfully completed......................................
2025-02-06 14:22:44,000:INFO:PyCaret ClassificationExperiment
2025-02-06 14:22:44,000:INFO:Logging name: clf-default-name
2025-02-06 14:22:44,000:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:22:44,000:INFO:version 3.3.2
2025-02-06 14:22:44,000:INFO:Initializing setup()
2025-02-06 14:22:44,000:INFO:self.USI: 982b
2025-02-06 14:22:44,000:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:22:44,000:INFO:Checking environment
2025-02-06 14:22:44,000:INFO:python_version: 3.11.9
2025-02-06 14:22:44,000:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:22:44,000:INFO:machine: AMD64
2025-02-06 14:22:44,000:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:22:44,004:INFO:Memory: svmem(total=67771465728, available=48892497920, percent=27.9, used=18878967808, free=48892497920)
2025-02-06 14:22:44,004:INFO:Physical Core: 8
2025-02-06 14:22:44,004:INFO:Logical Core: 16
2025-02-06 14:22:44,004:INFO:Checking libraries
2025-02-06 14:22:44,004:INFO:System:
2025-02-06 14:22:44,004:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:22:44,004:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:22:44,004:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:22:44,004:INFO:PyCaret required dependencies:
2025-02-06 14:22:44,004:INFO:                 pip: 25.0
2025-02-06 14:22:44,004:INFO:          setuptools: 65.5.0
2025-02-06 14:22:44,004:INFO:             pycaret: 3.3.2
2025-02-06 14:22:44,004:INFO:             IPython: 8.32.0
2025-02-06 14:22:44,004:INFO:          ipywidgets: 8.1.5
2025-02-06 14:22:44,004:INFO:                tqdm: 4.67.1
2025-02-06 14:22:44,004:INFO:               numpy: 1.26.4
2025-02-06 14:22:44,004:INFO:              pandas: 2.1.4
2025-02-06 14:22:44,004:INFO:              jinja2: 3.1.5
2025-02-06 14:22:44,004:INFO:               scipy: 1.11.4
2025-02-06 14:22:44,005:INFO:              joblib: 1.3.2
2025-02-06 14:22:44,005:INFO:             sklearn: 1.4.2
2025-02-06 14:22:44,005:INFO:                pyod: 2.0.3
2025-02-06 14:22:44,005:INFO:            imblearn: 0.13.0
2025-02-06 14:22:44,005:INFO:   category_encoders: 2.7.0
2025-02-06 14:22:44,005:INFO:            lightgbm: 4.5.0
2025-02-06 14:22:44,005:INFO:               numba: 0.61.0
2025-02-06 14:22:44,005:INFO:            requests: 2.32.3
2025-02-06 14:22:44,005:INFO:          matplotlib: 3.7.5
2025-02-06 14:22:44,005:INFO:          scikitplot: 0.3.7
2025-02-06 14:22:44,005:INFO:         yellowbrick: 1.5
2025-02-06 14:22:44,005:INFO:              plotly: 5.24.1
2025-02-06 14:22:44,005:INFO:    plotly-resampler: Not installed
2025-02-06 14:22:44,005:INFO:             kaleido: 0.2.1
2025-02-06 14:22:44,005:INFO:           schemdraw: 0.15
2025-02-06 14:22:44,005:INFO:         statsmodels: 0.14.4
2025-02-06 14:22:44,005:INFO:              sktime: 0.26.0
2025-02-06 14:22:44,005:INFO:               tbats: 1.1.3
2025-02-06 14:22:44,005:INFO:            pmdarima: 2.0.4
2025-02-06 14:22:44,005:INFO:              psutil: 6.1.1
2025-02-06 14:22:44,005:INFO:          markupsafe: 3.0.2
2025-02-06 14:22:44,005:INFO:             pickle5: Not installed
2025-02-06 14:22:44,005:INFO:         cloudpickle: 3.1.1
2025-02-06 14:22:44,005:INFO:         deprecation: 2.1.0
2025-02-06 14:22:44,005:INFO:              xxhash: 3.5.0
2025-02-06 14:22:44,005:INFO:           wurlitzer: Not installed
2025-02-06 14:22:44,005:INFO:PyCaret optional dependencies:
2025-02-06 14:22:44,005:INFO:                shap: Not installed
2025-02-06 14:22:44,005:INFO:           interpret: Not installed
2025-02-06 14:22:44,005:INFO:                umap: Not installed
2025-02-06 14:22:44,005:INFO:     ydata_profiling: Not installed
2025-02-06 14:22:44,005:INFO:  explainerdashboard: Not installed
2025-02-06 14:22:44,005:INFO:             autoviz: Not installed
2025-02-06 14:22:44,005:INFO:           fairlearn: Not installed
2025-02-06 14:22:44,005:INFO:          deepchecks: Not installed
2025-02-06 14:22:44,005:INFO:             xgboost: Not installed
2025-02-06 14:22:44,005:INFO:            catboost: Not installed
2025-02-06 14:22:44,005:INFO:              kmodes: Not installed
2025-02-06 14:22:44,005:INFO:             mlxtend: Not installed
2025-02-06 14:22:44,005:INFO:       statsforecast: Not installed
2025-02-06 14:22:44,005:INFO:        tune_sklearn: Not installed
2025-02-06 14:22:44,005:INFO:                 ray: Not installed
2025-02-06 14:22:44,005:INFO:            hyperopt: Not installed
2025-02-06 14:22:44,005:INFO:              optuna: Not installed
2025-02-06 14:22:44,005:INFO:               skopt: Not installed
2025-02-06 14:22:44,005:INFO:              mlflow: Not installed
2025-02-06 14:22:44,005:INFO:              gradio: Not installed
2025-02-06 14:22:44,005:INFO:             fastapi: Not installed
2025-02-06 14:22:44,005:INFO:             uvicorn: Not installed
2025-02-06 14:22:44,005:INFO:              m2cgen: Not installed
2025-02-06 14:22:44,005:INFO:           evidently: Not installed
2025-02-06 14:22:44,005:INFO:               fugue: Not installed
2025-02-06 14:22:44,005:INFO:           streamlit: Not installed
2025-02-06 14:22:44,005:INFO:             prophet: Not installed
2025-02-06 14:22:44,005:INFO:None
2025-02-06 14:22:44,005:INFO:Set up data.
2025-02-06 14:22:44,013:INFO:Set up folding strategy.
2025-02-06 14:22:44,013:INFO:Set up train/test split.
2025-02-06 14:22:44,020:INFO:Set up index.
2025-02-06 14:22:44,021:INFO:Assigning column types.
2025-02-06 14:22:44,029:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:22:44,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,053:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,108:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:22:44,133:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:22:44,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,190:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:22:44,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,269:INFO:Preparing preprocessing pipeline...
2025-02-06 14:22:44,271:INFO:Set up simple imputation.
2025-02-06 14:22:44,292:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:22:44,293:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:22:44,293:INFO:Creating final display dataframe.
2025-02-06 14:22:44,363:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              982b
2025-02-06 14:22:44,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:22:44,442:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:22:44,442:INFO:Initializing create_model()
2025-02-06 14:22:44,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F3F81090>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:22:44,442:INFO:Checking exceptions
2025-02-06 14:22:44,443:INFO:Importing libraries
2025-02-06 14:22:44,443:INFO:Copying training dataset
2025-02-06 14:22:44,450:INFO:Defining folds
2025-02-06 14:22:44,450:INFO:Declaring metric variables
2025-02-06 14:22:44,450:INFO:Importing untrained model
2025-02-06 14:22:44,450:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:22:44,450:INFO:Starting cross validation
2025-02-06 14:22:44,450:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:22:47,234:INFO:Calculating mean and std
2025-02-06 14:22:47,235:INFO:Creating metrics dataframe
2025-02-06 14:22:47,236:INFO:Finalizing model
2025-02-06 14:22:47,252:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:22:47,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001729 seconds.
2025-02-06 14:22:47,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:22:47,255:INFO:[LightGBM] [Info] Total Bins 6970
2025-02-06 14:22:47,255:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:22:47,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:22:47,255:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:22:47,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:22:47,638:INFO:Uploading results into container
2025-02-06 14:22:47,640:INFO:Uploading model into container now
2025-02-06 14:22:47,640:INFO:_master_model_container: 1
2025-02-06 14:22:47,640:INFO:_display_container: 2
2025-02-06 14:22:47,640:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1234, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:22:47,640:INFO:create_model() successfully completed......................................
2025-02-06 14:24:55,950:INFO:PyCaret ClassificationExperiment
2025-02-06 14:24:55,950:INFO:Logging name: clf-default-name
2025-02-06 14:24:55,951:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:24:55,951:INFO:version 3.3.2
2025-02-06 14:24:55,951:INFO:Initializing setup()
2025-02-06 14:24:55,951:INFO:self.USI: 14de
2025-02-06 14:24:55,951:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:24:55,951:INFO:Checking environment
2025-02-06 14:24:55,951:INFO:python_version: 3.11.9
2025-02-06 14:24:55,951:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:24:55,951:INFO:machine: AMD64
2025-02-06 14:24:55,951:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:24:55,955:INFO:Memory: svmem(total=67771465728, available=48277102592, percent=28.8, used=19494363136, free=48277102592)
2025-02-06 14:24:55,955:INFO:Physical Core: 8
2025-02-06 14:24:55,955:INFO:Logical Core: 16
2025-02-06 14:24:55,955:INFO:Checking libraries
2025-02-06 14:24:55,955:INFO:System:
2025-02-06 14:24:55,955:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:24:55,955:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:24:55,955:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:24:55,955:INFO:PyCaret required dependencies:
2025-02-06 14:24:55,955:INFO:                 pip: 25.0
2025-02-06 14:24:55,955:INFO:          setuptools: 65.5.0
2025-02-06 14:24:55,955:INFO:             pycaret: 3.3.2
2025-02-06 14:24:55,955:INFO:             IPython: 8.32.0
2025-02-06 14:24:55,955:INFO:          ipywidgets: 8.1.5
2025-02-06 14:24:55,955:INFO:                tqdm: 4.67.1
2025-02-06 14:24:55,955:INFO:               numpy: 1.26.4
2025-02-06 14:24:55,956:INFO:              pandas: 2.1.4
2025-02-06 14:24:55,956:INFO:              jinja2: 3.1.5
2025-02-06 14:24:55,956:INFO:               scipy: 1.11.4
2025-02-06 14:24:55,956:INFO:              joblib: 1.3.2
2025-02-06 14:24:55,956:INFO:             sklearn: 1.4.2
2025-02-06 14:24:55,956:INFO:                pyod: 2.0.3
2025-02-06 14:24:55,956:INFO:            imblearn: 0.13.0
2025-02-06 14:24:55,956:INFO:   category_encoders: 2.7.0
2025-02-06 14:24:55,956:INFO:            lightgbm: 4.5.0
2025-02-06 14:24:55,956:INFO:               numba: 0.61.0
2025-02-06 14:24:55,956:INFO:            requests: 2.32.3
2025-02-06 14:24:55,956:INFO:          matplotlib: 3.7.5
2025-02-06 14:24:55,956:INFO:          scikitplot: 0.3.7
2025-02-06 14:24:55,956:INFO:         yellowbrick: 1.5
2025-02-06 14:24:55,956:INFO:              plotly: 5.24.1
2025-02-06 14:24:55,956:INFO:    plotly-resampler: Not installed
2025-02-06 14:24:55,956:INFO:             kaleido: 0.2.1
2025-02-06 14:24:55,956:INFO:           schemdraw: 0.15
2025-02-06 14:24:55,956:INFO:         statsmodels: 0.14.4
2025-02-06 14:24:55,956:INFO:              sktime: 0.26.0
2025-02-06 14:24:55,956:INFO:               tbats: 1.1.3
2025-02-06 14:24:55,956:INFO:            pmdarima: 2.0.4
2025-02-06 14:24:55,956:INFO:              psutil: 6.1.1
2025-02-06 14:24:55,956:INFO:          markupsafe: 3.0.2
2025-02-06 14:24:55,956:INFO:             pickle5: Not installed
2025-02-06 14:24:55,956:INFO:         cloudpickle: 3.1.1
2025-02-06 14:24:55,956:INFO:         deprecation: 2.1.0
2025-02-06 14:24:55,956:INFO:              xxhash: 3.5.0
2025-02-06 14:24:55,956:INFO:           wurlitzer: Not installed
2025-02-06 14:24:55,956:INFO:PyCaret optional dependencies:
2025-02-06 14:24:55,956:INFO:                shap: Not installed
2025-02-06 14:24:55,956:INFO:           interpret: Not installed
2025-02-06 14:24:55,956:INFO:                umap: Not installed
2025-02-06 14:24:55,956:INFO:     ydata_profiling: Not installed
2025-02-06 14:24:55,957:INFO:  explainerdashboard: Not installed
2025-02-06 14:24:55,957:INFO:             autoviz: Not installed
2025-02-06 14:24:55,957:INFO:           fairlearn: Not installed
2025-02-06 14:24:55,957:INFO:          deepchecks: Not installed
2025-02-06 14:24:55,957:INFO:             xgboost: Not installed
2025-02-06 14:24:55,957:INFO:            catboost: Not installed
2025-02-06 14:24:55,957:INFO:              kmodes: Not installed
2025-02-06 14:24:55,957:INFO:             mlxtend: Not installed
2025-02-06 14:24:55,957:INFO:       statsforecast: Not installed
2025-02-06 14:24:55,957:INFO:        tune_sklearn: Not installed
2025-02-06 14:24:55,957:INFO:                 ray: Not installed
2025-02-06 14:24:55,957:INFO:            hyperopt: Not installed
2025-02-06 14:24:55,957:INFO:              optuna: Not installed
2025-02-06 14:24:55,957:INFO:               skopt: Not installed
2025-02-06 14:24:55,957:INFO:              mlflow: Not installed
2025-02-06 14:24:55,957:INFO:              gradio: Not installed
2025-02-06 14:24:55,957:INFO:             fastapi: Not installed
2025-02-06 14:24:55,957:INFO:             uvicorn: Not installed
2025-02-06 14:24:55,957:INFO:              m2cgen: Not installed
2025-02-06 14:24:55,957:INFO:           evidently: Not installed
2025-02-06 14:24:55,957:INFO:               fugue: Not installed
2025-02-06 14:24:55,957:INFO:           streamlit: Not installed
2025-02-06 14:24:55,957:INFO:             prophet: Not installed
2025-02-06 14:24:55,957:INFO:None
2025-02-06 14:24:55,957:INFO:Set up data.
2025-02-06 14:24:55,967:INFO:Set up folding strategy.
2025-02-06 14:24:55,967:INFO:Set up train/test split.
2025-02-06 14:24:55,975:INFO:Set up index.
2025-02-06 14:24:55,975:INFO:Assigning column types.
2025-02-06 14:24:55,982:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:24:56,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,007:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,061:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:24:56,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,125:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:24:56,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,140:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:24:56,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,220:INFO:Preparing preprocessing pipeline...
2025-02-06 14:24:56,221:INFO:Set up simple imputation.
2025-02-06 14:24:56,242:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:24:56,243:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:24:56,243:INFO:Creating final display dataframe.
2025-02-06 14:24:56,314:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              14de
2025-02-06 14:24:56,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:24:56,392:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:24:56,392:INFO:Initializing create_model()
2025-02-06 14:24:56,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F437C710>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:24:56,392:INFO:Checking exceptions
2025-02-06 14:24:56,393:INFO:Importing libraries
2025-02-06 14:24:56,393:INFO:Copying training dataset
2025-02-06 14:24:56,401:INFO:Defining folds
2025-02-06 14:24:56,401:INFO:Declaring metric variables
2025-02-06 14:24:56,401:INFO:Importing untrained model
2025-02-06 14:24:56,401:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:24:56,401:INFO:Starting cross validation
2025-02-06 14:24:56,401:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:24:58,614:INFO:Calculating mean and std
2025-02-06 14:24:58,614:INFO:Creating metrics dataframe
2025-02-06 14:24:58,616:INFO:Finalizing model
2025-02-06 14:24:58,637:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:24:58,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001088 seconds.
2025-02-06 14:24:58,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:24:58,639:INFO:[LightGBM] [Info] Total Bins 6964
2025-02-06 14:24:58,639:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:24:58,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:24:58,639:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:24:58,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:58,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:24:59,017:INFO:Uploading results into container
2025-02-06 14:24:59,018:INFO:Uploading model into container now
2025-02-06 14:24:59,018:INFO:_master_model_container: 1
2025-02-06 14:24:59,018:INFO:_display_container: 2
2025-02-06 14:24:59,018:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:24:59,018:INFO:create_model() successfully completed......................................
2025-02-06 14:25:09,384:INFO:PyCaret ClassificationExperiment
2025-02-06 14:25:09,384:INFO:Logging name: clf-default-name
2025-02-06 14:25:09,384:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:25:09,384:INFO:version 3.3.2
2025-02-06 14:25:09,384:INFO:Initializing setup()
2025-02-06 14:25:09,384:INFO:self.USI: b7a9
2025-02-06 14:25:09,384:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:25:09,384:INFO:Checking environment
2025-02-06 14:25:09,384:INFO:python_version: 3.11.9
2025-02-06 14:25:09,384:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:25:09,384:INFO:machine: AMD64
2025-02-06 14:25:09,384:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:25:09,388:INFO:Memory: svmem(total=67771465728, available=48159367168, percent=28.9, used=19612098560, free=48159367168)
2025-02-06 14:25:09,388:INFO:Physical Core: 8
2025-02-06 14:25:09,388:INFO:Logical Core: 16
2025-02-06 14:25:09,388:INFO:Checking libraries
2025-02-06 14:25:09,388:INFO:System:
2025-02-06 14:25:09,388:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:25:09,388:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:25:09,388:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:25:09,388:INFO:PyCaret required dependencies:
2025-02-06 14:25:09,388:INFO:                 pip: 25.0
2025-02-06 14:25:09,388:INFO:          setuptools: 65.5.0
2025-02-06 14:25:09,388:INFO:             pycaret: 3.3.2
2025-02-06 14:25:09,388:INFO:             IPython: 8.32.0
2025-02-06 14:25:09,388:INFO:          ipywidgets: 8.1.5
2025-02-06 14:25:09,388:INFO:                tqdm: 4.67.1
2025-02-06 14:25:09,388:INFO:               numpy: 1.26.4
2025-02-06 14:25:09,388:INFO:              pandas: 2.1.4
2025-02-06 14:25:09,388:INFO:              jinja2: 3.1.5
2025-02-06 14:25:09,388:INFO:               scipy: 1.11.4
2025-02-06 14:25:09,388:INFO:              joblib: 1.3.2
2025-02-06 14:25:09,388:INFO:             sklearn: 1.4.2
2025-02-06 14:25:09,388:INFO:                pyod: 2.0.3
2025-02-06 14:25:09,388:INFO:            imblearn: 0.13.0
2025-02-06 14:25:09,388:INFO:   category_encoders: 2.7.0
2025-02-06 14:25:09,388:INFO:            lightgbm: 4.5.0
2025-02-06 14:25:09,388:INFO:               numba: 0.61.0
2025-02-06 14:25:09,388:INFO:            requests: 2.32.3
2025-02-06 14:25:09,388:INFO:          matplotlib: 3.7.5
2025-02-06 14:25:09,388:INFO:          scikitplot: 0.3.7
2025-02-06 14:25:09,388:INFO:         yellowbrick: 1.5
2025-02-06 14:25:09,388:INFO:              plotly: 5.24.1
2025-02-06 14:25:09,388:INFO:    plotly-resampler: Not installed
2025-02-06 14:25:09,388:INFO:             kaleido: 0.2.1
2025-02-06 14:25:09,388:INFO:           schemdraw: 0.15
2025-02-06 14:25:09,388:INFO:         statsmodels: 0.14.4
2025-02-06 14:25:09,388:INFO:              sktime: 0.26.0
2025-02-06 14:25:09,388:INFO:               tbats: 1.1.3
2025-02-06 14:25:09,388:INFO:            pmdarima: 2.0.4
2025-02-06 14:25:09,388:INFO:              psutil: 6.1.1
2025-02-06 14:25:09,388:INFO:          markupsafe: 3.0.2
2025-02-06 14:25:09,388:INFO:             pickle5: Not installed
2025-02-06 14:25:09,388:INFO:         cloudpickle: 3.1.1
2025-02-06 14:25:09,388:INFO:         deprecation: 2.1.0
2025-02-06 14:25:09,388:INFO:              xxhash: 3.5.0
2025-02-06 14:25:09,388:INFO:           wurlitzer: Not installed
2025-02-06 14:25:09,388:INFO:PyCaret optional dependencies:
2025-02-06 14:25:09,388:INFO:                shap: Not installed
2025-02-06 14:25:09,388:INFO:           interpret: Not installed
2025-02-06 14:25:09,388:INFO:                umap: Not installed
2025-02-06 14:25:09,388:INFO:     ydata_profiling: Not installed
2025-02-06 14:25:09,388:INFO:  explainerdashboard: Not installed
2025-02-06 14:25:09,388:INFO:             autoviz: Not installed
2025-02-06 14:25:09,388:INFO:           fairlearn: Not installed
2025-02-06 14:25:09,388:INFO:          deepchecks: Not installed
2025-02-06 14:25:09,388:INFO:             xgboost: Not installed
2025-02-06 14:25:09,388:INFO:            catboost: Not installed
2025-02-06 14:25:09,388:INFO:              kmodes: Not installed
2025-02-06 14:25:09,388:INFO:             mlxtend: Not installed
2025-02-06 14:25:09,388:INFO:       statsforecast: Not installed
2025-02-06 14:25:09,388:INFO:        tune_sklearn: Not installed
2025-02-06 14:25:09,388:INFO:                 ray: Not installed
2025-02-06 14:25:09,388:INFO:            hyperopt: Not installed
2025-02-06 14:25:09,388:INFO:              optuna: Not installed
2025-02-06 14:25:09,388:INFO:               skopt: Not installed
2025-02-06 14:25:09,388:INFO:              mlflow: Not installed
2025-02-06 14:25:09,388:INFO:              gradio: Not installed
2025-02-06 14:25:09,388:INFO:             fastapi: Not installed
2025-02-06 14:25:09,388:INFO:             uvicorn: Not installed
2025-02-06 14:25:09,388:INFO:              m2cgen: Not installed
2025-02-06 14:25:09,388:INFO:           evidently: Not installed
2025-02-06 14:25:09,388:INFO:               fugue: Not installed
2025-02-06 14:25:09,388:INFO:           streamlit: Not installed
2025-02-06 14:25:09,388:INFO:             prophet: Not installed
2025-02-06 14:25:09,388:INFO:None
2025-02-06 14:25:09,388:INFO:Set up data.
2025-02-06 14:25:09,398:INFO:Set up folding strategy.
2025-02-06 14:25:09,398:INFO:Set up train/test split.
2025-02-06 14:25:09,405:INFO:Set up index.
2025-02-06 14:25:09,405:INFO:Assigning column types.
2025-02-06 14:25:09,412:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:25:09,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,437:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,476:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,491:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:25:09,515:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,553:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:09,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,568:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:25:09,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,646:INFO:Preparing preprocessing pipeline...
2025-02-06 14:25:09,648:INFO:Set up simple imputation.
2025-02-06 14:25:09,669:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:25:09,671:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:25:09,671:INFO:Creating final display dataframe.
2025-02-06 14:25:09,741:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              b7a9
2025-02-06 14:25:09,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:09,820:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:25:09,820:INFO:Initializing create_model()
2025-02-06 14:25:09,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F42C9B90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:25:09,820:INFO:Checking exceptions
2025-02-06 14:25:09,821:INFO:Importing libraries
2025-02-06 14:25:09,821:INFO:Copying training dataset
2025-02-06 14:25:09,828:INFO:Defining folds
2025-02-06 14:25:09,828:INFO:Declaring metric variables
2025-02-06 14:25:09,828:INFO:Importing untrained model
2025-02-06 14:25:09,828:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:25:09,828:INFO:Starting cross validation
2025-02-06 14:25:09,829:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:25:11,254:INFO:Calculating mean and std
2025-02-06 14:25:11,254:INFO:Creating metrics dataframe
2025-02-06 14:25:11,255:INFO:Finalizing model
2025-02-06 14:25:11,272:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:25:11,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001013 seconds.
2025-02-06 14:25:11,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:25:11,273:INFO:[LightGBM] [Info] Total Bins 6964
2025-02-06 14:25:11,273:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:25:11,273:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:25:11,274:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:25:11,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:11,669:INFO:Uploading results into container
2025-02-06 14:25:11,670:INFO:Uploading model into container now
2025-02-06 14:25:11,670:INFO:_master_model_container: 1
2025-02-06 14:25:11,670:INFO:_display_container: 2
2025-02-06 14:25:11,670:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:25:11,670:INFO:create_model() successfully completed......................................
2025-02-06 14:25:27,493:INFO:PyCaret ClassificationExperiment
2025-02-06 14:25:27,493:INFO:Logging name: clf-default-name
2025-02-06 14:25:27,493:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:25:27,493:INFO:version 3.3.2
2025-02-06 14:25:27,493:INFO:Initializing setup()
2025-02-06 14:25:27,493:INFO:self.USI: 8dba
2025-02-06 14:25:27,493:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:25:27,493:INFO:Checking environment
2025-02-06 14:25:27,493:INFO:python_version: 3.11.9
2025-02-06 14:25:27,493:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:25:27,493:INFO:machine: AMD64
2025-02-06 14:25:27,494:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:25:27,499:INFO:Memory: svmem(total=67771465728, available=48106844160, percent=29.0, used=19664621568, free=48106844160)
2025-02-06 14:25:27,499:INFO:Physical Core: 8
2025-02-06 14:25:27,499:INFO:Logical Core: 16
2025-02-06 14:25:27,499:INFO:Checking libraries
2025-02-06 14:25:27,499:INFO:System:
2025-02-06 14:25:27,500:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:25:27,500:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:25:27,500:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:25:27,500:INFO:PyCaret required dependencies:
2025-02-06 14:25:27,500:INFO:                 pip: 25.0
2025-02-06 14:25:27,500:INFO:          setuptools: 65.5.0
2025-02-06 14:25:27,500:INFO:             pycaret: 3.3.2
2025-02-06 14:25:27,500:INFO:             IPython: 8.32.0
2025-02-06 14:25:27,500:INFO:          ipywidgets: 8.1.5
2025-02-06 14:25:27,500:INFO:                tqdm: 4.67.1
2025-02-06 14:25:27,500:INFO:               numpy: 1.26.4
2025-02-06 14:25:27,500:INFO:              pandas: 2.1.4
2025-02-06 14:25:27,500:INFO:              jinja2: 3.1.5
2025-02-06 14:25:27,500:INFO:               scipy: 1.11.4
2025-02-06 14:25:27,500:INFO:              joblib: 1.3.2
2025-02-06 14:25:27,500:INFO:             sklearn: 1.4.2
2025-02-06 14:25:27,500:INFO:                pyod: 2.0.3
2025-02-06 14:25:27,500:INFO:            imblearn: 0.13.0
2025-02-06 14:25:27,500:INFO:   category_encoders: 2.7.0
2025-02-06 14:25:27,500:INFO:            lightgbm: 4.5.0
2025-02-06 14:25:27,500:INFO:               numba: 0.61.0
2025-02-06 14:25:27,500:INFO:            requests: 2.32.3
2025-02-06 14:25:27,500:INFO:          matplotlib: 3.7.5
2025-02-06 14:25:27,500:INFO:          scikitplot: 0.3.7
2025-02-06 14:25:27,500:INFO:         yellowbrick: 1.5
2025-02-06 14:25:27,500:INFO:              plotly: 5.24.1
2025-02-06 14:25:27,500:INFO:    plotly-resampler: Not installed
2025-02-06 14:25:27,500:INFO:             kaleido: 0.2.1
2025-02-06 14:25:27,500:INFO:           schemdraw: 0.15
2025-02-06 14:25:27,500:INFO:         statsmodels: 0.14.4
2025-02-06 14:25:27,500:INFO:              sktime: 0.26.0
2025-02-06 14:25:27,500:INFO:               tbats: 1.1.3
2025-02-06 14:25:27,500:INFO:            pmdarima: 2.0.4
2025-02-06 14:25:27,500:INFO:              psutil: 6.1.1
2025-02-06 14:25:27,500:INFO:          markupsafe: 3.0.2
2025-02-06 14:25:27,500:INFO:             pickle5: Not installed
2025-02-06 14:25:27,500:INFO:         cloudpickle: 3.1.1
2025-02-06 14:25:27,500:INFO:         deprecation: 2.1.0
2025-02-06 14:25:27,500:INFO:              xxhash: 3.5.0
2025-02-06 14:25:27,500:INFO:           wurlitzer: Not installed
2025-02-06 14:25:27,500:INFO:PyCaret optional dependencies:
2025-02-06 14:25:27,500:INFO:                shap: Not installed
2025-02-06 14:25:27,500:INFO:           interpret: Not installed
2025-02-06 14:25:27,500:INFO:                umap: Not installed
2025-02-06 14:25:27,500:INFO:     ydata_profiling: Not installed
2025-02-06 14:25:27,500:INFO:  explainerdashboard: Not installed
2025-02-06 14:25:27,500:INFO:             autoviz: Not installed
2025-02-06 14:25:27,500:INFO:           fairlearn: Not installed
2025-02-06 14:25:27,500:INFO:          deepchecks: Not installed
2025-02-06 14:25:27,500:INFO:             xgboost: Not installed
2025-02-06 14:25:27,500:INFO:            catboost: Not installed
2025-02-06 14:25:27,500:INFO:              kmodes: Not installed
2025-02-06 14:25:27,500:INFO:             mlxtend: Not installed
2025-02-06 14:25:27,500:INFO:       statsforecast: Not installed
2025-02-06 14:25:27,500:INFO:        tune_sklearn: Not installed
2025-02-06 14:25:27,500:INFO:                 ray: Not installed
2025-02-06 14:25:27,500:INFO:            hyperopt: Not installed
2025-02-06 14:25:27,500:INFO:              optuna: Not installed
2025-02-06 14:25:27,500:INFO:               skopt: Not installed
2025-02-06 14:25:27,500:INFO:              mlflow: Not installed
2025-02-06 14:25:27,500:INFO:              gradio: Not installed
2025-02-06 14:25:27,500:INFO:             fastapi: Not installed
2025-02-06 14:25:27,500:INFO:             uvicorn: Not installed
2025-02-06 14:25:27,500:INFO:              m2cgen: Not installed
2025-02-06 14:25:27,500:INFO:           evidently: Not installed
2025-02-06 14:25:27,500:INFO:               fugue: Not installed
2025-02-06 14:25:27,500:INFO:           streamlit: Not installed
2025-02-06 14:25:27,500:INFO:             prophet: Not installed
2025-02-06 14:25:27,500:INFO:None
2025-02-06 14:25:27,500:INFO:Set up data.
2025-02-06 14:25:27,512:INFO:Set up folding strategy.
2025-02-06 14:25:27,513:INFO:Set up train/test split.
2025-02-06 14:25:27,522:INFO:Set up index.
2025-02-06 14:25:27,526:INFO:Assigning column types.
2025-02-06 14:25:27,534:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:25:27,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:25:27,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,679:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:27,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,695:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:25:27,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,774:INFO:Preparing preprocessing pipeline...
2025-02-06 14:25:27,776:INFO:Set up simple imputation.
2025-02-06 14:25:27,798:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:25:27,800:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:25:27,800:INFO:Creating final display dataframe.
2025-02-06 14:25:27,871:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              8dba
2025-02-06 14:25:27,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:27,950:INFO:setup() successfully completed in 0.46s...............
2025-02-06 14:25:27,950:INFO:Initializing create_model()
2025-02-06 14:25:27,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F479B090>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:25:27,950:INFO:Checking exceptions
2025-02-06 14:25:27,951:INFO:Importing libraries
2025-02-06 14:25:27,951:INFO:Copying training dataset
2025-02-06 14:25:27,959:INFO:Defining folds
2025-02-06 14:25:27,959:INFO:Declaring metric variables
2025-02-06 14:25:27,959:INFO:Importing untrained model
2025-02-06 14:25:27,959:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:25:27,960:INFO:Starting cross validation
2025-02-06 14:25:27,960:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:25:29,328:INFO:Calculating mean and std
2025-02-06 14:25:29,329:INFO:Creating metrics dataframe
2025-02-06 14:25:29,330:INFO:Finalizing model
2025-02-06 14:25:29,349:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:25:29,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.
2025-02-06 14:25:29,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:25:29,351:INFO:[LightGBM] [Info] Total Bins 6964
2025-02-06 14:25:29,351:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:25:29,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:25:29,351:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:25:29,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:29,688:INFO:Uploading results into container
2025-02-06 14:25:29,689:INFO:Uploading model into container now
2025-02-06 14:25:29,689:INFO:_master_model_container: 1
2025-02-06 14:25:29,689:INFO:_display_container: 2
2025-02-06 14:25:29,689:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:25:29,690:INFO:create_model() successfully completed......................................
2025-02-06 14:25:41,190:INFO:PyCaret ClassificationExperiment
2025-02-06 14:25:41,190:INFO:Logging name: clf-default-name
2025-02-06 14:25:41,191:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:25:41,191:INFO:version 3.3.2
2025-02-06 14:25:41,191:INFO:Initializing setup()
2025-02-06 14:25:41,191:INFO:self.USI: ade8
2025-02-06 14:25:41,191:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:25:41,191:INFO:Checking environment
2025-02-06 14:25:41,191:INFO:python_version: 3.11.9
2025-02-06 14:25:41,191:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:25:41,191:INFO:machine: AMD64
2025-02-06 14:25:41,191:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:25:41,199:INFO:Memory: svmem(total=67771465728, available=48085438464, percent=29.0, used=19686027264, free=48085438464)
2025-02-06 14:25:41,199:INFO:Physical Core: 8
2025-02-06 14:25:41,199:INFO:Logical Core: 16
2025-02-06 14:25:41,199:INFO:Checking libraries
2025-02-06 14:25:41,199:INFO:System:
2025-02-06 14:25:41,199:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:25:41,199:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:25:41,199:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:25:41,199:INFO:PyCaret required dependencies:
2025-02-06 14:25:41,199:INFO:                 pip: 25.0
2025-02-06 14:25:41,199:INFO:          setuptools: 65.5.0
2025-02-06 14:25:41,199:INFO:             pycaret: 3.3.2
2025-02-06 14:25:41,199:INFO:             IPython: 8.32.0
2025-02-06 14:25:41,199:INFO:          ipywidgets: 8.1.5
2025-02-06 14:25:41,199:INFO:                tqdm: 4.67.1
2025-02-06 14:25:41,199:INFO:               numpy: 1.26.4
2025-02-06 14:25:41,199:INFO:              pandas: 2.1.4
2025-02-06 14:25:41,199:INFO:              jinja2: 3.1.5
2025-02-06 14:25:41,199:INFO:               scipy: 1.11.4
2025-02-06 14:25:41,199:INFO:              joblib: 1.3.2
2025-02-06 14:25:41,199:INFO:             sklearn: 1.4.2
2025-02-06 14:25:41,199:INFO:                pyod: 2.0.3
2025-02-06 14:25:41,199:INFO:            imblearn: 0.13.0
2025-02-06 14:25:41,199:INFO:   category_encoders: 2.7.0
2025-02-06 14:25:41,199:INFO:            lightgbm: 4.5.0
2025-02-06 14:25:41,199:INFO:               numba: 0.61.0
2025-02-06 14:25:41,199:INFO:            requests: 2.32.3
2025-02-06 14:25:41,199:INFO:          matplotlib: 3.7.5
2025-02-06 14:25:41,199:INFO:          scikitplot: 0.3.7
2025-02-06 14:25:41,199:INFO:         yellowbrick: 1.5
2025-02-06 14:25:41,199:INFO:              plotly: 5.24.1
2025-02-06 14:25:41,199:INFO:    plotly-resampler: Not installed
2025-02-06 14:25:41,199:INFO:             kaleido: 0.2.1
2025-02-06 14:25:41,199:INFO:           schemdraw: 0.15
2025-02-06 14:25:41,200:INFO:         statsmodels: 0.14.4
2025-02-06 14:25:41,200:INFO:              sktime: 0.26.0
2025-02-06 14:25:41,200:INFO:               tbats: 1.1.3
2025-02-06 14:25:41,200:INFO:            pmdarima: 2.0.4
2025-02-06 14:25:41,200:INFO:              psutil: 6.1.1
2025-02-06 14:25:41,200:INFO:          markupsafe: 3.0.2
2025-02-06 14:25:41,200:INFO:             pickle5: Not installed
2025-02-06 14:25:41,200:INFO:         cloudpickle: 3.1.1
2025-02-06 14:25:41,200:INFO:         deprecation: 2.1.0
2025-02-06 14:25:41,200:INFO:              xxhash: 3.5.0
2025-02-06 14:25:41,200:INFO:           wurlitzer: Not installed
2025-02-06 14:25:41,200:INFO:PyCaret optional dependencies:
2025-02-06 14:25:41,200:INFO:                shap: Not installed
2025-02-06 14:25:41,200:INFO:           interpret: Not installed
2025-02-06 14:25:41,200:INFO:                umap: Not installed
2025-02-06 14:25:41,200:INFO:     ydata_profiling: Not installed
2025-02-06 14:25:41,200:INFO:  explainerdashboard: Not installed
2025-02-06 14:25:41,200:INFO:             autoviz: Not installed
2025-02-06 14:25:41,200:INFO:           fairlearn: Not installed
2025-02-06 14:25:41,200:INFO:          deepchecks: Not installed
2025-02-06 14:25:41,200:INFO:             xgboost: Not installed
2025-02-06 14:25:41,200:INFO:            catboost: Not installed
2025-02-06 14:25:41,200:INFO:              kmodes: Not installed
2025-02-06 14:25:41,200:INFO:             mlxtend: Not installed
2025-02-06 14:25:41,200:INFO:       statsforecast: Not installed
2025-02-06 14:25:41,200:INFO:        tune_sklearn: Not installed
2025-02-06 14:25:41,200:INFO:                 ray: Not installed
2025-02-06 14:25:41,200:INFO:            hyperopt: Not installed
2025-02-06 14:25:41,200:INFO:              optuna: Not installed
2025-02-06 14:25:41,200:INFO:               skopt: Not installed
2025-02-06 14:25:41,200:INFO:              mlflow: Not installed
2025-02-06 14:25:41,200:INFO:              gradio: Not installed
2025-02-06 14:25:41,200:INFO:             fastapi: Not installed
2025-02-06 14:25:41,200:INFO:             uvicorn: Not installed
2025-02-06 14:25:41,200:INFO:              m2cgen: Not installed
2025-02-06 14:25:41,200:INFO:           evidently: Not installed
2025-02-06 14:25:41,200:INFO:               fugue: Not installed
2025-02-06 14:25:41,200:INFO:           streamlit: Not installed
2025-02-06 14:25:41,200:INFO:             prophet: Not installed
2025-02-06 14:25:41,200:INFO:None
2025-02-06 14:25:41,200:INFO:Set up data.
2025-02-06 14:25:41,211:INFO:Set up folding strategy.
2025-02-06 14:25:41,211:INFO:Set up train/test split.
2025-02-06 14:25:41,220:INFO:Set up index.
2025-02-06 14:25:41,221:INFO:Assigning column types.
2025-02-06 14:25:41,229:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:25:41,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,292:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,307:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:25:41,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,370:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:25:41,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,384:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:25:41,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,463:INFO:Preparing preprocessing pipeline...
2025-02-06 14:25:41,465:INFO:Set up simple imputation.
2025-02-06 14:25:41,486:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:25:41,487:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:25:41,487:INFO:Creating final display dataframe.
2025-02-06 14:25:41,558:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              ade8
2025-02-06 14:25:41,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:25:41,638:INFO:setup() successfully completed in 0.45s...............
2025-02-06 14:25:41,639:INFO:Initializing create_model()
2025-02-06 14:25:41,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F3C83D10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:25:41,639:INFO:Checking exceptions
2025-02-06 14:25:41,640:INFO:Importing libraries
2025-02-06 14:25:41,640:INFO:Copying training dataset
2025-02-06 14:25:41,648:INFO:Defining folds
2025-02-06 14:25:41,648:INFO:Declaring metric variables
2025-02-06 14:25:41,648:INFO:Importing untrained model
2025-02-06 14:25:41,648:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:25:41,648:INFO:Starting cross validation
2025-02-06 14:25:41,648:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:25:43,292:INFO:Calculating mean and std
2025-02-06 14:25:43,292:INFO:Creating metrics dataframe
2025-02-06 14:25:43,293:INFO:Finalizing model
2025-02-06 14:25:43,309:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:25:43,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.
2025-02-06 14:25:43,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:25:43,310:INFO:[LightGBM] [Info] Total Bins 6964
2025-02-06 14:25:43,310:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 41
2025-02-06 14:25:43,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:25:43,310:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:25:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:25:43,688:INFO:Uploading results into container
2025-02-06 14:25:43,688:INFO:Uploading model into container now
2025-02-06 14:25:43,689:INFO:_master_model_container: 1
2025-02-06 14:25:43,689:INFO:_display_container: 2
2025-02-06 14:25:43,689:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:25:43,689:INFO:create_model() successfully completed......................................
2025-02-06 14:26:11,339:INFO:PyCaret ClassificationExperiment
2025-02-06 14:26:11,339:INFO:Logging name: clf-default-name
2025-02-06 14:26:11,339:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:26:11,339:INFO:version 3.3.2
2025-02-06 14:26:11,339:INFO:Initializing setup()
2025-02-06 14:26:11,339:INFO:self.USI: 1601
2025-02-06 14:26:11,339:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'target_param', '_available_plots', 'fold_generator', 'gpu_n_jobs_param', 'exp_name_log', 'y_train', 'n_jobs_param', 'is_multiclass', '_ml_usecase', 'memory', 'logging_param', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'seed', 'X', 'USI', 'exp_id', 'html_param', 'data', 'y', 'idx', 'X_test', 'X_train'}
2025-02-06 14:26:11,339:INFO:Checking environment
2025-02-06 14:26:11,339:INFO:python_version: 3.11.9
2025-02-06 14:26:11,339:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:26:11,339:INFO:machine: AMD64
2025-02-06 14:26:11,339:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:26:11,344:INFO:Memory: svmem(total=67771465728, available=48076857344, percent=29.1, used=19694608384, free=48076857344)
2025-02-06 14:26:11,344:INFO:Physical Core: 8
2025-02-06 14:26:11,344:INFO:Logical Core: 16
2025-02-06 14:26:11,344:INFO:Checking libraries
2025-02-06 14:26:11,344:INFO:System:
2025-02-06 14:26:11,344:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:26:11,344:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:26:11,344:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:26:11,344:INFO:PyCaret required dependencies:
2025-02-06 14:26:11,344:INFO:                 pip: 25.0
2025-02-06 14:26:11,344:INFO:          setuptools: 65.5.0
2025-02-06 14:26:11,344:INFO:             pycaret: 3.3.2
2025-02-06 14:26:11,344:INFO:             IPython: 8.32.0
2025-02-06 14:26:11,344:INFO:          ipywidgets: 8.1.5
2025-02-06 14:26:11,344:INFO:                tqdm: 4.67.1
2025-02-06 14:26:11,344:INFO:               numpy: 1.26.4
2025-02-06 14:26:11,344:INFO:              pandas: 2.1.4
2025-02-06 14:26:11,344:INFO:              jinja2: 3.1.5
2025-02-06 14:26:11,344:INFO:               scipy: 1.11.4
2025-02-06 14:26:11,344:INFO:              joblib: 1.3.2
2025-02-06 14:26:11,344:INFO:             sklearn: 1.4.2
2025-02-06 14:26:11,344:INFO:                pyod: 2.0.3
2025-02-06 14:26:11,344:INFO:            imblearn: 0.13.0
2025-02-06 14:26:11,344:INFO:   category_encoders: 2.7.0
2025-02-06 14:26:11,344:INFO:            lightgbm: 4.5.0
2025-02-06 14:26:11,344:INFO:               numba: 0.61.0
2025-02-06 14:26:11,344:INFO:            requests: 2.32.3
2025-02-06 14:26:11,344:INFO:          matplotlib: 3.7.5
2025-02-06 14:26:11,344:INFO:          scikitplot: 0.3.7
2025-02-06 14:26:11,344:INFO:         yellowbrick: 1.5
2025-02-06 14:26:11,344:INFO:              plotly: 5.24.1
2025-02-06 14:26:11,344:INFO:    plotly-resampler: Not installed
2025-02-06 14:26:11,344:INFO:             kaleido: 0.2.1
2025-02-06 14:26:11,344:INFO:           schemdraw: 0.15
2025-02-06 14:26:11,344:INFO:         statsmodels: 0.14.4
2025-02-06 14:26:11,344:INFO:              sktime: 0.26.0
2025-02-06 14:26:11,344:INFO:               tbats: 1.1.3
2025-02-06 14:26:11,344:INFO:            pmdarima: 2.0.4
2025-02-06 14:26:11,344:INFO:              psutil: 6.1.1
2025-02-06 14:26:11,344:INFO:          markupsafe: 3.0.2
2025-02-06 14:26:11,344:INFO:             pickle5: Not installed
2025-02-06 14:26:11,344:INFO:         cloudpickle: 3.1.1
2025-02-06 14:26:11,344:INFO:         deprecation: 2.1.0
2025-02-06 14:26:11,344:INFO:              xxhash: 3.5.0
2025-02-06 14:26:11,344:INFO:           wurlitzer: Not installed
2025-02-06 14:26:11,344:INFO:PyCaret optional dependencies:
2025-02-06 14:26:11,344:INFO:                shap: Not installed
2025-02-06 14:26:11,344:INFO:           interpret: Not installed
2025-02-06 14:26:11,344:INFO:                umap: Not installed
2025-02-06 14:26:11,344:INFO:     ydata_profiling: Not installed
2025-02-06 14:26:11,344:INFO:  explainerdashboard: Not installed
2025-02-06 14:26:11,345:INFO:             autoviz: Not installed
2025-02-06 14:26:11,345:INFO:           fairlearn: Not installed
2025-02-06 14:26:11,345:INFO:          deepchecks: Not installed
2025-02-06 14:26:11,345:INFO:             xgboost: Not installed
2025-02-06 14:26:11,345:INFO:            catboost: Not installed
2025-02-06 14:26:11,345:INFO:              kmodes: Not installed
2025-02-06 14:26:11,345:INFO:             mlxtend: Not installed
2025-02-06 14:26:11,345:INFO:       statsforecast: Not installed
2025-02-06 14:26:11,345:INFO:        tune_sklearn: Not installed
2025-02-06 14:26:11,345:INFO:                 ray: Not installed
2025-02-06 14:26:11,345:INFO:            hyperopt: Not installed
2025-02-06 14:26:11,345:INFO:              optuna: Not installed
2025-02-06 14:26:11,345:INFO:               skopt: Not installed
2025-02-06 14:26:11,345:INFO:              mlflow: Not installed
2025-02-06 14:26:11,345:INFO:              gradio: Not installed
2025-02-06 14:26:11,345:INFO:             fastapi: Not installed
2025-02-06 14:26:11,345:INFO:             uvicorn: Not installed
2025-02-06 14:26:11,345:INFO:              m2cgen: Not installed
2025-02-06 14:26:11,345:INFO:           evidently: Not installed
2025-02-06 14:26:11,345:INFO:               fugue: Not installed
2025-02-06 14:26:11,345:INFO:           streamlit: Not installed
2025-02-06 14:26:11,345:INFO:             prophet: Not installed
2025-02-06 14:26:11,345:INFO:None
2025-02-06 14:26:11,345:INFO:Set up data.
2025-02-06 14:26:11,354:INFO:Set up folding strategy.
2025-02-06 14:26:11,354:INFO:Set up train/test split.
2025-02-06 14:26:11,361:INFO:Set up index.
2025-02-06 14:26:11,362:INFO:Assigning column types.
2025-02-06 14:26:11,369:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:26:11,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,393:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,432:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,446:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:26:11,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:26:11,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,525:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:26:11,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,603:INFO:Preparing preprocessing pipeline...
2025-02-06 14:26:11,604:INFO:Set up simple imputation.
2025-02-06 14:26:11,625:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:26:11,627:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:26:11,627:INFO:Creating final display dataframe.
2025-02-06 14:26:11,695:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              1601
2025-02-06 14:26:11,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:26:11,773:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:26:11,773:INFO:Initializing create_model()
2025-02-06 14:26:11,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217F44BB610>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:26:11,773:INFO:Checking exceptions
2025-02-06 14:26:11,774:INFO:Importing libraries
2025-02-06 14:26:11,774:INFO:Copying training dataset
2025-02-06 14:26:11,782:INFO:Defining folds
2025-02-06 14:26:11,782:INFO:Declaring metric variables
2025-02-06 14:26:11,782:INFO:Importing untrained model
2025-02-06 14:26:11,782:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:26:11,782:INFO:Starting cross validation
2025-02-06 14:26:11,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:26:13,217:INFO:Calculating mean and std
2025-02-06 14:26:13,218:INFO:Creating metrics dataframe
2025-02-06 14:26:13,219:INFO:Finalizing model
2025-02-06 14:26:13,234:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:26:13,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
2025-02-06 14:26:13,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:26:13,235:INFO:[LightGBM] [Info] Total Bins 6709
2025-02-06 14:26:13,235:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 14:26:13,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:26:13,236:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:26:13,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:26:13,627:INFO:Uploading results into container
2025-02-06 14:26:13,628:INFO:Uploading model into container now
2025-02-06 14:26:13,628:INFO:_master_model_container: 1
2025-02-06 14:26:13,628:INFO:_display_container: 2
2025-02-06 14:26:13,628:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:26:13,628:INFO:create_model() successfully completed......................................
2025-02-06 14:27:07,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:27:07,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:27:07,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:27:07,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:27:09,206:INFO:PyCaret ClassificationExperiment
2025-02-06 14:27:09,206:INFO:Logging name: clf-default-name
2025-02-06 14:27:09,206:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:27:09,206:INFO:version 3.3.2
2025-02-06 14:27:09,206:INFO:Initializing setup()
2025-02-06 14:27:09,206:INFO:self.USI: 5760
2025-02-06 14:27:09,207:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'data', 'X_test', 'fix_imbalance', 'fold_generator', 'X_train', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'seed', 'gpu_param', 'idx', 'n_jobs_param', 'y_test', 'fold_groups_param', 'X', 'y', 'memory', 'is_multiclass', 'exp_name_log', '_ml_usecase', '_available_plots', 'y_train', 'logging_param', 'exp_id', 'target_param', 'USI'}
2025-02-06 14:27:09,207:INFO:Checking environment
2025-02-06 14:27:09,207:INFO:python_version: 3.11.9
2025-02-06 14:27:09,207:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:27:09,207:INFO:machine: AMD64
2025-02-06 14:27:09,207:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:27:09,212:INFO:Memory: svmem(total=67771465728, available=50516549632, percent=25.5, used=17254916096, free=50516549632)
2025-02-06 14:27:09,212:INFO:Physical Core: 8
2025-02-06 14:27:09,212:INFO:Logical Core: 16
2025-02-06 14:27:09,212:INFO:Checking libraries
2025-02-06 14:27:09,212:INFO:System:
2025-02-06 14:27:09,212:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:27:09,212:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:27:09,212:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:27:09,212:INFO:PyCaret required dependencies:
2025-02-06 14:27:09,230:INFO:                 pip: 25.0
2025-02-06 14:27:09,230:INFO:          setuptools: 65.5.0
2025-02-06 14:27:09,230:INFO:             pycaret: 3.3.2
2025-02-06 14:27:09,230:INFO:             IPython: 8.32.0
2025-02-06 14:27:09,230:INFO:          ipywidgets: 8.1.5
2025-02-06 14:27:09,230:INFO:                tqdm: 4.67.1
2025-02-06 14:27:09,230:INFO:               numpy: 1.26.4
2025-02-06 14:27:09,230:INFO:              pandas: 2.1.4
2025-02-06 14:27:09,230:INFO:              jinja2: 3.1.5
2025-02-06 14:27:09,230:INFO:               scipy: 1.11.4
2025-02-06 14:27:09,230:INFO:              joblib: 1.3.2
2025-02-06 14:27:09,230:INFO:             sklearn: 1.4.2
2025-02-06 14:27:09,230:INFO:                pyod: 2.0.3
2025-02-06 14:27:09,230:INFO:            imblearn: 0.13.0
2025-02-06 14:27:09,230:INFO:   category_encoders: 2.7.0
2025-02-06 14:27:09,230:INFO:            lightgbm: 4.5.0
2025-02-06 14:27:09,230:INFO:               numba: 0.61.0
2025-02-06 14:27:09,230:INFO:            requests: 2.32.3
2025-02-06 14:27:09,230:INFO:          matplotlib: 3.7.5
2025-02-06 14:27:09,230:INFO:          scikitplot: 0.3.7
2025-02-06 14:27:09,230:INFO:         yellowbrick: 1.5
2025-02-06 14:27:09,230:INFO:              plotly: 5.24.1
2025-02-06 14:27:09,230:INFO:    plotly-resampler: Not installed
2025-02-06 14:27:09,230:INFO:             kaleido: 0.2.1
2025-02-06 14:27:09,230:INFO:           schemdraw: 0.15
2025-02-06 14:27:09,230:INFO:         statsmodels: 0.14.4
2025-02-06 14:27:09,230:INFO:              sktime: 0.26.0
2025-02-06 14:27:09,230:INFO:               tbats: 1.1.3
2025-02-06 14:27:09,230:INFO:            pmdarima: 2.0.4
2025-02-06 14:27:09,230:INFO:              psutil: 6.1.1
2025-02-06 14:27:09,230:INFO:          markupsafe: 3.0.2
2025-02-06 14:27:09,230:INFO:             pickle5: Not installed
2025-02-06 14:27:09,230:INFO:         cloudpickle: 3.1.1
2025-02-06 14:27:09,230:INFO:         deprecation: 2.1.0
2025-02-06 14:27:09,230:INFO:              xxhash: 3.5.0
2025-02-06 14:27:09,230:INFO:           wurlitzer: Not installed
2025-02-06 14:27:09,230:INFO:PyCaret optional dependencies:
2025-02-06 14:27:09,237:INFO:                shap: Not installed
2025-02-06 14:27:09,237:INFO:           interpret: Not installed
2025-02-06 14:27:09,237:INFO:                umap: Not installed
2025-02-06 14:27:09,237:INFO:     ydata_profiling: Not installed
2025-02-06 14:27:09,237:INFO:  explainerdashboard: Not installed
2025-02-06 14:27:09,238:INFO:             autoviz: Not installed
2025-02-06 14:27:09,238:INFO:           fairlearn: Not installed
2025-02-06 14:27:09,238:INFO:          deepchecks: Not installed
2025-02-06 14:27:09,238:INFO:             xgboost: Not installed
2025-02-06 14:27:09,238:INFO:            catboost: Not installed
2025-02-06 14:27:09,238:INFO:              kmodes: Not installed
2025-02-06 14:27:09,238:INFO:             mlxtend: Not installed
2025-02-06 14:27:09,238:INFO:       statsforecast: Not installed
2025-02-06 14:27:09,238:INFO:        tune_sklearn: Not installed
2025-02-06 14:27:09,238:INFO:                 ray: Not installed
2025-02-06 14:27:09,238:INFO:            hyperopt: Not installed
2025-02-06 14:27:09,238:INFO:              optuna: Not installed
2025-02-06 14:27:09,238:INFO:               skopt: Not installed
2025-02-06 14:27:09,238:INFO:              mlflow: Not installed
2025-02-06 14:27:09,238:INFO:              gradio: Not installed
2025-02-06 14:27:09,238:INFO:             fastapi: Not installed
2025-02-06 14:27:09,238:INFO:             uvicorn: Not installed
2025-02-06 14:27:09,238:INFO:              m2cgen: Not installed
2025-02-06 14:27:09,238:INFO:           evidently: Not installed
2025-02-06 14:27:09,238:INFO:               fugue: Not installed
2025-02-06 14:27:09,238:INFO:           streamlit: Not installed
2025-02-06 14:27:09,238:INFO:             prophet: Not installed
2025-02-06 14:27:09,238:INFO:None
2025-02-06 14:27:09,238:INFO:Set up data.
2025-02-06 14:27:09,247:INFO:Set up folding strategy.
2025-02-06 14:27:09,247:INFO:Set up train/test split.
2025-02-06 14:27:09,255:INFO:Set up index.
2025-02-06 14:27:09,256:INFO:Assigning column types.
2025-02-06 14:27:09,262:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:27:09,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,335:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,350:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:27:09,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:27:09,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,429:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:27:09,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,508:INFO:Preparing preprocessing pipeline...
2025-02-06 14:27:09,509:INFO:Set up simple imputation.
2025-02-06 14:27:09,530:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:27:09,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:27:09,532:INFO:Creating final display dataframe.
2025-02-06 14:27:09,603:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              5760
2025-02-06 14:27:09,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:27:09,680:INFO:setup() successfully completed in 0.48s...............
2025-02-06 14:27:09,680:INFO:Initializing create_model()
2025-02-06 14:27:09,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9C3535210>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:27:09,680:INFO:Checking exceptions
2025-02-06 14:27:09,681:INFO:Importing libraries
2025-02-06 14:27:09,681:INFO:Copying training dataset
2025-02-06 14:27:09,688:INFO:Defining folds
2025-02-06 14:27:09,688:INFO:Declaring metric variables
2025-02-06 14:27:09,688:INFO:Importing untrained model
2025-02-06 14:27:09,688:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:27:09,688:INFO:Starting cross validation
2025-02-06 14:27:09,688:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:27:13,145:INFO:Calculating mean and std
2025-02-06 14:27:13,146:INFO:Creating metrics dataframe
2025-02-06 14:27:13,147:INFO:Finalizing model
2025-02-06 14:27:13,167:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:27:13,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.
2025-02-06 14:27:13,168:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:27:13,169:INFO:[LightGBM] [Info] Total Bins 6709
2025-02-06 14:27:13,170:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 14:27:13,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:27:13,170:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:27:13,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:27:13,588:INFO:Uploading results into container
2025-02-06 14:27:13,589:INFO:Uploading model into container now
2025-02-06 14:27:13,589:INFO:_master_model_container: 1
2025-02-06 14:27:13,589:INFO:_display_container: 2
2025-02-06 14:27:13,590:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=12346, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:27:13,590:INFO:create_model() successfully completed......................................
2025-02-06 14:30:11,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:30:11,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:30:11,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:30:11,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:30:12,832:INFO:PyCaret ClassificationExperiment
2025-02-06 14:30:12,832:INFO:Logging name: clf-default-name
2025-02-06 14:30:12,833:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:30:12,833:INFO:version 3.3.2
2025-02-06 14:30:12,833:INFO:Initializing setup()
2025-02-06 14:30:12,833:INFO:self.USI: fbfd
2025-02-06 14:30:12,833:INFO:self._variable_keys: {'fold_groups_param', 'seed', 'gpu_n_jobs_param', 'data', 'fix_imbalance', 'pipeline', 'fold_shuffle_param', 'USI', 'X_train', 'exp_name_log', 'logging_param', 'exp_id', '_ml_usecase', 'y_test', 'X_test', 'idx', 'is_multiclass', 'X', '_available_plots', 'target_param', 'memory', 'y_train', 'fold_generator', 'gpu_param', 'log_plots_param', 'y', 'html_param', 'n_jobs_param'}
2025-02-06 14:30:12,833:INFO:Checking environment
2025-02-06 14:30:12,833:INFO:python_version: 3.11.9
2025-02-06 14:30:12,833:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:30:12,833:INFO:machine: AMD64
2025-02-06 14:30:12,833:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:30:12,838:INFO:Memory: svmem(total=67771465728, available=50494865408, percent=25.5, used=17276600320, free=50494865408)
2025-02-06 14:30:12,838:INFO:Physical Core: 8
2025-02-06 14:30:12,838:INFO:Logical Core: 16
2025-02-06 14:30:12,838:INFO:Checking libraries
2025-02-06 14:30:12,838:INFO:System:
2025-02-06 14:30:12,838:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:30:12,838:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:30:12,838:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:30:12,838:INFO:PyCaret required dependencies:
2025-02-06 14:30:12,855:INFO:                 pip: 25.0
2025-02-06 14:30:12,855:INFO:          setuptools: 65.5.0
2025-02-06 14:30:12,855:INFO:             pycaret: 3.3.2
2025-02-06 14:30:12,855:INFO:             IPython: 8.32.0
2025-02-06 14:30:12,855:INFO:          ipywidgets: 8.1.5
2025-02-06 14:30:12,855:INFO:                tqdm: 4.67.1
2025-02-06 14:30:12,855:INFO:               numpy: 1.26.4
2025-02-06 14:30:12,855:INFO:              pandas: 2.1.4
2025-02-06 14:30:12,855:INFO:              jinja2: 3.1.5
2025-02-06 14:30:12,855:INFO:               scipy: 1.11.4
2025-02-06 14:30:12,855:INFO:              joblib: 1.3.2
2025-02-06 14:30:12,855:INFO:             sklearn: 1.4.2
2025-02-06 14:30:12,855:INFO:                pyod: 2.0.3
2025-02-06 14:30:12,855:INFO:            imblearn: 0.13.0
2025-02-06 14:30:12,855:INFO:   category_encoders: 2.7.0
2025-02-06 14:30:12,855:INFO:            lightgbm: 4.5.0
2025-02-06 14:30:12,855:INFO:               numba: 0.61.0
2025-02-06 14:30:12,855:INFO:            requests: 2.32.3
2025-02-06 14:30:12,855:INFO:          matplotlib: 3.7.5
2025-02-06 14:30:12,855:INFO:          scikitplot: 0.3.7
2025-02-06 14:30:12,855:INFO:         yellowbrick: 1.5
2025-02-06 14:30:12,855:INFO:              plotly: 5.24.1
2025-02-06 14:30:12,855:INFO:    plotly-resampler: Not installed
2025-02-06 14:30:12,855:INFO:             kaleido: 0.2.1
2025-02-06 14:30:12,855:INFO:           schemdraw: 0.15
2025-02-06 14:30:12,855:INFO:         statsmodels: 0.14.4
2025-02-06 14:30:12,855:INFO:              sktime: 0.26.0
2025-02-06 14:30:12,856:INFO:               tbats: 1.1.3
2025-02-06 14:30:12,856:INFO:            pmdarima: 2.0.4
2025-02-06 14:30:12,856:INFO:              psutil: 6.1.1
2025-02-06 14:30:12,856:INFO:          markupsafe: 3.0.2
2025-02-06 14:30:12,856:INFO:             pickle5: Not installed
2025-02-06 14:30:12,856:INFO:         cloudpickle: 3.1.1
2025-02-06 14:30:12,856:INFO:         deprecation: 2.1.0
2025-02-06 14:30:12,856:INFO:              xxhash: 3.5.0
2025-02-06 14:30:12,856:INFO:           wurlitzer: Not installed
2025-02-06 14:30:12,856:INFO:PyCaret optional dependencies:
2025-02-06 14:30:12,862:INFO:                shap: Not installed
2025-02-06 14:30:12,862:INFO:           interpret: Not installed
2025-02-06 14:30:12,862:INFO:                umap: Not installed
2025-02-06 14:30:12,862:INFO:     ydata_profiling: Not installed
2025-02-06 14:30:12,862:INFO:  explainerdashboard: Not installed
2025-02-06 14:30:12,862:INFO:             autoviz: Not installed
2025-02-06 14:30:12,862:INFO:           fairlearn: Not installed
2025-02-06 14:30:12,862:INFO:          deepchecks: Not installed
2025-02-06 14:30:12,862:INFO:             xgboost: Not installed
2025-02-06 14:30:12,862:INFO:            catboost: Not installed
2025-02-06 14:30:12,862:INFO:              kmodes: Not installed
2025-02-06 14:30:12,862:INFO:             mlxtend: Not installed
2025-02-06 14:30:12,862:INFO:       statsforecast: Not installed
2025-02-06 14:30:12,862:INFO:        tune_sklearn: Not installed
2025-02-06 14:30:12,862:INFO:                 ray: Not installed
2025-02-06 14:30:12,862:INFO:            hyperopt: Not installed
2025-02-06 14:30:12,862:INFO:              optuna: Not installed
2025-02-06 14:30:12,862:INFO:               skopt: Not installed
2025-02-06 14:30:12,862:INFO:              mlflow: Not installed
2025-02-06 14:30:12,862:INFO:              gradio: Not installed
2025-02-06 14:30:12,862:INFO:             fastapi: Not installed
2025-02-06 14:30:12,862:INFO:             uvicorn: Not installed
2025-02-06 14:30:12,862:INFO:              m2cgen: Not installed
2025-02-06 14:30:12,862:INFO:           evidently: Not installed
2025-02-06 14:30:12,862:INFO:               fugue: Not installed
2025-02-06 14:30:12,862:INFO:           streamlit: Not installed
2025-02-06 14:30:12,862:INFO:             prophet: Not installed
2025-02-06 14:30:12,862:INFO:None
2025-02-06 14:30:12,862:INFO:Set up data.
2025-02-06 14:30:12,873:INFO:Set up folding strategy.
2025-02-06 14:30:12,873:INFO:Set up train/test split.
2025-02-06 14:30:12,880:INFO:Set up index.
2025-02-06 14:30:12,882:INFO:Assigning column types.
2025-02-06 14:30:12,888:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:30:12,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:30:12,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:30:12,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:12,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:12,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:30:12,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:30:12,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:12,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:12,973:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:30:12,998:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:30:13,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:30:13,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,052:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:30:13,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,131:INFO:Preparing preprocessing pipeline...
2025-02-06 14:30:13,132:INFO:Set up simple imputation.
2025-02-06 14:30:13,153:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:30:13,157:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:30:13,157:INFO:Creating final display dataframe.
2025-02-06 14:30:13,227:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              fbfd
2025-02-06 14:30:13,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:30:13,309:INFO:setup() successfully completed in 0.48s...............
2025-02-06 14:30:13,309:INFO:Initializing create_model()
2025-02-06 14:30:13,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BB3107A10>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 100, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:30:13,309:INFO:Checking exceptions
2025-02-06 14:30:13,310:INFO:Importing libraries
2025-02-06 14:30:13,310:INFO:Copying training dataset
2025-02-06 14:30:13,316:INFO:Defining folds
2025-02-06 14:30:13,316:INFO:Declaring metric variables
2025-02-06 14:30:13,316:INFO:Importing untrained model
2025-02-06 14:31:42,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:31:42,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:31:42,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:31:42,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:31:44,593:INFO:PyCaret ClassificationExperiment
2025-02-06 14:31:44,593:INFO:Logging name: clf-default-name
2025-02-06 14:31:44,593:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:31:44,593:INFO:version 3.3.2
2025-02-06 14:31:44,593:INFO:Initializing setup()
2025-02-06 14:31:44,593:INFO:self.USI: eeb5
2025-02-06 14:31:44,593:INFO:self._variable_keys: {'X_test', 'data', 'y_test', 'logging_param', 'target_param', 'fold_shuffle_param', 'y', 'gpu_param', 'fold_groups_param', 'fold_generator', 'exp_id', 'gpu_n_jobs_param', 'html_param', 'idx', 'seed', 'X', 'X_train', 'fix_imbalance', 'y_train', '_available_plots', 'n_jobs_param', 'is_multiclass', 'USI', 'exp_name_log', 'memory', '_ml_usecase', 'pipeline', 'log_plots_param'}
2025-02-06 14:31:44,593:INFO:Checking environment
2025-02-06 14:31:44,593:INFO:python_version: 3.11.9
2025-02-06 14:31:44,593:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:31:44,593:INFO:machine: AMD64
2025-02-06 14:31:44,593:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:31:44,596:INFO:Memory: svmem(total=67771465728, available=50476863488, percent=25.5, used=17294602240, free=50476863488)
2025-02-06 14:31:44,596:INFO:Physical Core: 8
2025-02-06 14:31:44,596:INFO:Logical Core: 16
2025-02-06 14:31:44,597:INFO:Checking libraries
2025-02-06 14:31:44,597:INFO:System:
2025-02-06 14:31:44,597:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:31:44,597:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:31:44,597:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:31:44,597:INFO:PyCaret required dependencies:
2025-02-06 14:31:44,610:INFO:                 pip: 25.0
2025-02-06 14:31:44,610:INFO:          setuptools: 65.5.0
2025-02-06 14:31:44,610:INFO:             pycaret: 3.3.2
2025-02-06 14:31:44,610:INFO:             IPython: 8.32.0
2025-02-06 14:31:44,610:INFO:          ipywidgets: 8.1.5
2025-02-06 14:31:44,610:INFO:                tqdm: 4.67.1
2025-02-06 14:31:44,610:INFO:               numpy: 1.26.4
2025-02-06 14:31:44,610:INFO:              pandas: 2.1.4
2025-02-06 14:31:44,610:INFO:              jinja2: 3.1.5
2025-02-06 14:31:44,610:INFO:               scipy: 1.11.4
2025-02-06 14:31:44,610:INFO:              joblib: 1.3.2
2025-02-06 14:31:44,610:INFO:             sklearn: 1.4.2
2025-02-06 14:31:44,610:INFO:                pyod: 2.0.3
2025-02-06 14:31:44,610:INFO:            imblearn: 0.13.0
2025-02-06 14:31:44,610:INFO:   category_encoders: 2.7.0
2025-02-06 14:31:44,610:INFO:            lightgbm: 4.5.0
2025-02-06 14:31:44,610:INFO:               numba: 0.61.0
2025-02-06 14:31:44,610:INFO:            requests: 2.32.3
2025-02-06 14:31:44,610:INFO:          matplotlib: 3.7.5
2025-02-06 14:31:44,610:INFO:          scikitplot: 0.3.7
2025-02-06 14:31:44,610:INFO:         yellowbrick: 1.5
2025-02-06 14:31:44,610:INFO:              plotly: 5.24.1
2025-02-06 14:31:44,610:INFO:    plotly-resampler: Not installed
2025-02-06 14:31:44,610:INFO:             kaleido: 0.2.1
2025-02-06 14:31:44,610:INFO:           schemdraw: 0.15
2025-02-06 14:31:44,610:INFO:         statsmodels: 0.14.4
2025-02-06 14:31:44,610:INFO:              sktime: 0.26.0
2025-02-06 14:31:44,610:INFO:               tbats: 1.1.3
2025-02-06 14:31:44,610:INFO:            pmdarima: 2.0.4
2025-02-06 14:31:44,610:INFO:              psutil: 6.1.1
2025-02-06 14:31:44,610:INFO:          markupsafe: 3.0.2
2025-02-06 14:31:44,610:INFO:             pickle5: Not installed
2025-02-06 14:31:44,610:INFO:         cloudpickle: 3.1.1
2025-02-06 14:31:44,610:INFO:         deprecation: 2.1.0
2025-02-06 14:31:44,610:INFO:              xxhash: 3.5.0
2025-02-06 14:31:44,610:INFO:           wurlitzer: Not installed
2025-02-06 14:31:44,610:INFO:PyCaret optional dependencies:
2025-02-06 14:31:44,615:INFO:                shap: Not installed
2025-02-06 14:31:44,615:INFO:           interpret: Not installed
2025-02-06 14:31:44,615:INFO:                umap: Not installed
2025-02-06 14:31:44,615:INFO:     ydata_profiling: Not installed
2025-02-06 14:31:44,615:INFO:  explainerdashboard: Not installed
2025-02-06 14:31:44,615:INFO:             autoviz: Not installed
2025-02-06 14:31:44,615:INFO:           fairlearn: Not installed
2025-02-06 14:31:44,615:INFO:          deepchecks: Not installed
2025-02-06 14:31:44,615:INFO:             xgboost: Not installed
2025-02-06 14:31:44,615:INFO:            catboost: Not installed
2025-02-06 14:31:44,615:INFO:              kmodes: Not installed
2025-02-06 14:31:44,615:INFO:             mlxtend: Not installed
2025-02-06 14:31:44,615:INFO:       statsforecast: Not installed
2025-02-06 14:31:44,615:INFO:        tune_sklearn: Not installed
2025-02-06 14:31:44,615:INFO:                 ray: Not installed
2025-02-06 14:31:44,615:INFO:            hyperopt: Not installed
2025-02-06 14:31:44,615:INFO:              optuna: Not installed
2025-02-06 14:31:44,615:INFO:               skopt: Not installed
2025-02-06 14:31:44,615:INFO:              mlflow: Not installed
2025-02-06 14:31:44,615:INFO:              gradio: Not installed
2025-02-06 14:31:44,616:INFO:             fastapi: Not installed
2025-02-06 14:31:44,616:INFO:             uvicorn: Not installed
2025-02-06 14:31:44,616:INFO:              m2cgen: Not installed
2025-02-06 14:31:44,616:INFO:           evidently: Not installed
2025-02-06 14:31:44,616:INFO:               fugue: Not installed
2025-02-06 14:31:44,616:INFO:           streamlit: Not installed
2025-02-06 14:31:44,616:INFO:             prophet: Not installed
2025-02-06 14:31:44,616:INFO:None
2025-02-06 14:31:44,616:INFO:Set up data.
2025-02-06 14:31:44,625:INFO:Set up folding strategy.
2025-02-06 14:31:44,625:INFO:Set up train/test split.
2025-02-06 14:31:44,632:INFO:Set up index.
2025-02-06 14:31:44,633:INFO:Assigning column types.
2025-02-06 14:31:44,640:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:31:44,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,729:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:31:44,753:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:31:44,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:31:44,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:44,887:INFO:Preparing preprocessing pipeline...
2025-02-06 14:31:44,888:INFO:Set up simple imputation.
2025-02-06 14:31:44,910:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:31:44,912:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:31:44,912:INFO:Creating final display dataframe.
2025-02-06 14:31:44,984:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              eeb5
2025-02-06 14:31:45,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:45,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:45,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:45,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:31:45,064:INFO:setup() successfully completed in 0.47s...............
2025-02-06 14:31:45,064:INFO:Initializing create_model()
2025-02-06 14:31:45,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000211254226D0>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:31:45,064:INFO:Checking exceptions
2025-02-06 14:31:45,072:INFO:Importing libraries
2025-02-06 14:31:45,072:INFO:Copying training dataset
2025-02-06 14:31:45,078:INFO:Defining folds
2025-02-06 14:31:45,079:INFO:Declaring metric variables
2025-02-06 14:31:45,080:INFO:Importing untrained model
2025-02-06 14:31:45,082:INFO:Decision Tree Classifier Imported successfully
2025-02-06 14:31:45,086:INFO:Starting cross validation
2025-02-06 14:31:45,087:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:31:46,822:INFO:Calculating mean and std
2025-02-06 14:31:46,823:INFO:Creating metrics dataframe
2025-02-06 14:31:46,827:INFO:Finalizing model
2025-02-06 14:31:46,938:INFO:Uploading results into container
2025-02-06 14:31:46,938:INFO:Uploading model into container now
2025-02-06 14:31:46,942:INFO:_master_model_container: 1
2025-02-06 14:31:46,943:INFO:_display_container: 2
2025-02-06 14:31:46,943:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=12346, splitter='best')
2025-02-06 14:31:46,943:INFO:create_model() successfully completed......................................
2025-02-06 14:32:07,743:INFO:PyCaret ClassificationExperiment
2025-02-06 14:32:07,743:INFO:Logging name: clf-default-name
2025-02-06 14:32:07,743:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:32:07,743:INFO:version 3.3.2
2025-02-06 14:32:07,743:INFO:Initializing setup()
2025-02-06 14:32:07,743:INFO:self.USI: c34c
2025-02-06 14:32:07,743:INFO:self._variable_keys: {'X_test', 'data', 'y_test', 'logging_param', 'target_param', 'fold_shuffle_param', 'y', 'gpu_param', 'fold_groups_param', 'fold_generator', 'exp_id', 'gpu_n_jobs_param', 'html_param', 'idx', 'seed', 'X', 'X_train', 'fix_imbalance', 'y_train', '_available_plots', 'n_jobs_param', 'is_multiclass', 'USI', 'exp_name_log', 'memory', '_ml_usecase', 'pipeline', 'log_plots_param'}
2025-02-06 14:32:07,743:INFO:Checking environment
2025-02-06 14:32:07,743:INFO:python_version: 3.11.9
2025-02-06 14:32:07,743:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:32:07,743:INFO:machine: AMD64
2025-02-06 14:32:07,743:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:32:07,747:INFO:Memory: svmem(total=67771465728, available=49535176704, percent=26.9, used=18236289024, free=49535176704)
2025-02-06 14:32:07,747:INFO:Physical Core: 8
2025-02-06 14:32:07,747:INFO:Logical Core: 16
2025-02-06 14:32:07,747:INFO:Checking libraries
2025-02-06 14:32:07,747:INFO:System:
2025-02-06 14:32:07,747:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:32:07,747:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:32:07,747:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:32:07,747:INFO:PyCaret required dependencies:
2025-02-06 14:32:07,747:INFO:                 pip: 25.0
2025-02-06 14:32:07,747:INFO:          setuptools: 65.5.0
2025-02-06 14:32:07,747:INFO:             pycaret: 3.3.2
2025-02-06 14:32:07,747:INFO:             IPython: 8.32.0
2025-02-06 14:32:07,747:INFO:          ipywidgets: 8.1.5
2025-02-06 14:32:07,748:INFO:                tqdm: 4.67.1
2025-02-06 14:32:07,748:INFO:               numpy: 1.26.4
2025-02-06 14:32:07,748:INFO:              pandas: 2.1.4
2025-02-06 14:32:07,748:INFO:              jinja2: 3.1.5
2025-02-06 14:32:07,748:INFO:               scipy: 1.11.4
2025-02-06 14:32:07,748:INFO:              joblib: 1.3.2
2025-02-06 14:32:07,748:INFO:             sklearn: 1.4.2
2025-02-06 14:32:07,748:INFO:                pyod: 2.0.3
2025-02-06 14:32:07,748:INFO:            imblearn: 0.13.0
2025-02-06 14:32:07,748:INFO:   category_encoders: 2.7.0
2025-02-06 14:32:07,748:INFO:            lightgbm: 4.5.0
2025-02-06 14:32:07,748:INFO:               numba: 0.61.0
2025-02-06 14:32:07,748:INFO:            requests: 2.32.3
2025-02-06 14:32:07,748:INFO:          matplotlib: 3.7.5
2025-02-06 14:32:07,748:INFO:          scikitplot: 0.3.7
2025-02-06 14:32:07,748:INFO:         yellowbrick: 1.5
2025-02-06 14:32:07,749:INFO:              plotly: 5.24.1
2025-02-06 14:32:07,749:INFO:    plotly-resampler: Not installed
2025-02-06 14:32:07,749:INFO:             kaleido: 0.2.1
2025-02-06 14:32:07,749:INFO:           schemdraw: 0.15
2025-02-06 14:32:07,749:INFO:         statsmodels: 0.14.4
2025-02-06 14:32:07,749:INFO:              sktime: 0.26.0
2025-02-06 14:32:07,749:INFO:               tbats: 1.1.3
2025-02-06 14:32:07,749:INFO:            pmdarima: 2.0.4
2025-02-06 14:32:07,749:INFO:              psutil: 6.1.1
2025-02-06 14:32:07,749:INFO:          markupsafe: 3.0.2
2025-02-06 14:32:07,749:INFO:             pickle5: Not installed
2025-02-06 14:32:07,749:INFO:         cloudpickle: 3.1.1
2025-02-06 14:32:07,749:INFO:         deprecation: 2.1.0
2025-02-06 14:32:07,749:INFO:              xxhash: 3.5.0
2025-02-06 14:32:07,749:INFO:           wurlitzer: Not installed
2025-02-06 14:32:07,749:INFO:PyCaret optional dependencies:
2025-02-06 14:32:07,749:INFO:                shap: Not installed
2025-02-06 14:32:07,749:INFO:           interpret: Not installed
2025-02-06 14:32:07,749:INFO:                umap: Not installed
2025-02-06 14:32:07,749:INFO:     ydata_profiling: Not installed
2025-02-06 14:32:07,749:INFO:  explainerdashboard: Not installed
2025-02-06 14:32:07,749:INFO:             autoviz: Not installed
2025-02-06 14:32:07,749:INFO:           fairlearn: Not installed
2025-02-06 14:32:07,749:INFO:          deepchecks: Not installed
2025-02-06 14:32:07,749:INFO:             xgboost: Not installed
2025-02-06 14:32:07,749:INFO:            catboost: Not installed
2025-02-06 14:32:07,749:INFO:              kmodes: Not installed
2025-02-06 14:32:07,749:INFO:             mlxtend: Not installed
2025-02-06 14:32:07,749:INFO:       statsforecast: Not installed
2025-02-06 14:32:07,749:INFO:        tune_sklearn: Not installed
2025-02-06 14:32:07,749:INFO:                 ray: Not installed
2025-02-06 14:32:07,749:INFO:            hyperopt: Not installed
2025-02-06 14:32:07,749:INFO:              optuna: Not installed
2025-02-06 14:32:07,749:INFO:               skopt: Not installed
2025-02-06 14:32:07,749:INFO:              mlflow: Not installed
2025-02-06 14:32:07,749:INFO:              gradio: Not installed
2025-02-06 14:32:07,749:INFO:             fastapi: Not installed
2025-02-06 14:32:07,749:INFO:             uvicorn: Not installed
2025-02-06 14:32:07,749:INFO:              m2cgen: Not installed
2025-02-06 14:32:07,749:INFO:           evidently: Not installed
2025-02-06 14:32:07,749:INFO:               fugue: Not installed
2025-02-06 14:32:07,749:INFO:           streamlit: Not installed
2025-02-06 14:32:07,749:INFO:             prophet: Not installed
2025-02-06 14:32:07,749:INFO:None
2025-02-06 14:32:07,749:INFO:Set up data.
2025-02-06 14:32:07,757:INFO:Set up folding strategy.
2025-02-06 14:32:07,757:INFO:Set up train/test split.
2025-02-06 14:32:07,766:INFO:Set up index.
2025-02-06 14:32:07,767:INFO:Assigning column types.
2025-02-06 14:32:07,775:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:32:07,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,799:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,854:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:32:07,877:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,916:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:32:07,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,931:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:32:07,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:07,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,010:INFO:Preparing preprocessing pipeline...
2025-02-06 14:32:08,011:INFO:Set up simple imputation.
2025-02-06 14:32:08,032:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:32:08,033:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:32:08,033:INFO:Creating final display dataframe.
2025-02-06 14:32:08,105:INFO:Setup _display_container:                     Description             Value
0                    Session id             12346
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              c34c
2025-02-06 14:32:08,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:32:08,183:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:32:08,183:INFO:Initializing create_model()
2025-02-06 14:32:08,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021124DB6A90>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:32:08,183:INFO:Checking exceptions
2025-02-06 14:32:08,190:INFO:Importing libraries
2025-02-06 14:32:08,190:INFO:Copying training dataset
2025-02-06 14:32:08,200:INFO:Defining folds
2025-02-06 14:32:08,200:INFO:Declaring metric variables
2025-02-06 14:32:08,203:INFO:Importing untrained model
2025-02-06 14:32:08,204:INFO:Decision Tree Classifier Imported successfully
2025-02-06 14:32:08,207:INFO:Starting cross validation
2025-02-06 14:32:08,208:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:32:09,630:INFO:Calculating mean and std
2025-02-06 14:32:09,631:INFO:Creating metrics dataframe
2025-02-06 14:32:09,634:INFO:Finalizing model
2025-02-06 14:32:09,751:INFO:Uploading results into container
2025-02-06 14:32:09,751:INFO:Uploading model into container now
2025-02-06 14:32:09,755:INFO:_master_model_container: 1
2025-02-06 14:32:09,755:INFO:_display_container: 2
2025-02-06 14:32:09,756:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=12346, splitter='best')
2025-02-06 14:32:09,756:INFO:create_model() successfully completed......................................
2025-02-06 14:33:10,437:INFO:PyCaret ClassificationExperiment
2025-02-06 14:33:10,437:INFO:Logging name: clf-default-name
2025-02-06 14:33:10,437:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:33:10,437:INFO:version 3.3.2
2025-02-06 14:33:10,437:INFO:Initializing setup()
2025-02-06 14:33:10,437:INFO:self.USI: a118
2025-02-06 14:33:10,437:INFO:self._variable_keys: {'X_test', 'data', 'y_test', 'logging_param', 'target_param', 'fold_shuffle_param', 'y', 'gpu_param', 'fold_groups_param', 'fold_generator', 'exp_id', 'gpu_n_jobs_param', 'html_param', 'idx', 'seed', 'X', 'X_train', 'fix_imbalance', 'y_train', '_available_plots', 'n_jobs_param', 'is_multiclass', 'USI', 'exp_name_log', 'memory', '_ml_usecase', 'pipeline', 'log_plots_param'}
2025-02-06 14:33:10,438:INFO:Checking environment
2025-02-06 14:33:10,438:INFO:python_version: 3.11.9
2025-02-06 14:33:10,438:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:33:10,438:INFO:machine: AMD64
2025-02-06 14:33:10,438:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:33:10,443:INFO:Memory: svmem(total=67771465728, available=48787288064, percent=28.0, used=18984177664, free=48787288064)
2025-02-06 14:33:10,443:INFO:Physical Core: 8
2025-02-06 14:33:10,443:INFO:Logical Core: 16
2025-02-06 14:33:10,443:INFO:Checking libraries
2025-02-06 14:33:10,443:INFO:System:
2025-02-06 14:33:10,443:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:33:10,443:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:33:10,443:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:33:10,443:INFO:PyCaret required dependencies:
2025-02-06 14:33:10,443:INFO:                 pip: 25.0
2025-02-06 14:33:10,443:INFO:          setuptools: 65.5.0
2025-02-06 14:33:10,443:INFO:             pycaret: 3.3.2
2025-02-06 14:33:10,443:INFO:             IPython: 8.32.0
2025-02-06 14:33:10,443:INFO:          ipywidgets: 8.1.5
2025-02-06 14:33:10,443:INFO:                tqdm: 4.67.1
2025-02-06 14:33:10,443:INFO:               numpy: 1.26.4
2025-02-06 14:33:10,443:INFO:              pandas: 2.1.4
2025-02-06 14:33:10,443:INFO:              jinja2: 3.1.5
2025-02-06 14:33:10,443:INFO:               scipy: 1.11.4
2025-02-06 14:33:10,443:INFO:              joblib: 1.3.2
2025-02-06 14:33:10,443:INFO:             sklearn: 1.4.2
2025-02-06 14:33:10,443:INFO:                pyod: 2.0.3
2025-02-06 14:33:10,443:INFO:            imblearn: 0.13.0
2025-02-06 14:33:10,443:INFO:   category_encoders: 2.7.0
2025-02-06 14:33:10,443:INFO:            lightgbm: 4.5.0
2025-02-06 14:33:10,443:INFO:               numba: 0.61.0
2025-02-06 14:33:10,443:INFO:            requests: 2.32.3
2025-02-06 14:33:10,443:INFO:          matplotlib: 3.7.5
2025-02-06 14:33:10,443:INFO:          scikitplot: 0.3.7
2025-02-06 14:33:10,443:INFO:         yellowbrick: 1.5
2025-02-06 14:33:10,443:INFO:              plotly: 5.24.1
2025-02-06 14:33:10,443:INFO:    plotly-resampler: Not installed
2025-02-06 14:33:10,443:INFO:             kaleido: 0.2.1
2025-02-06 14:33:10,443:INFO:           schemdraw: 0.15
2025-02-06 14:33:10,443:INFO:         statsmodels: 0.14.4
2025-02-06 14:33:10,443:INFO:              sktime: 0.26.0
2025-02-06 14:33:10,443:INFO:               tbats: 1.1.3
2025-02-06 14:33:10,443:INFO:            pmdarima: 2.0.4
2025-02-06 14:33:10,444:INFO:              psutil: 6.1.1
2025-02-06 14:33:10,444:INFO:          markupsafe: 3.0.2
2025-02-06 14:33:10,444:INFO:             pickle5: Not installed
2025-02-06 14:33:10,444:INFO:         cloudpickle: 3.1.1
2025-02-06 14:33:10,444:INFO:         deprecation: 2.1.0
2025-02-06 14:33:10,444:INFO:              xxhash: 3.5.0
2025-02-06 14:33:10,444:INFO:           wurlitzer: Not installed
2025-02-06 14:33:10,444:INFO:PyCaret optional dependencies:
2025-02-06 14:33:10,444:INFO:                shap: Not installed
2025-02-06 14:33:10,444:INFO:           interpret: Not installed
2025-02-06 14:33:10,444:INFO:                umap: Not installed
2025-02-06 14:33:10,444:INFO:     ydata_profiling: Not installed
2025-02-06 14:33:10,444:INFO:  explainerdashboard: Not installed
2025-02-06 14:33:10,444:INFO:             autoviz: Not installed
2025-02-06 14:33:10,444:INFO:           fairlearn: Not installed
2025-02-06 14:33:10,444:INFO:          deepchecks: Not installed
2025-02-06 14:33:10,444:INFO:             xgboost: Not installed
2025-02-06 14:33:10,444:INFO:            catboost: Not installed
2025-02-06 14:33:10,444:INFO:              kmodes: Not installed
2025-02-06 14:33:10,444:INFO:             mlxtend: Not installed
2025-02-06 14:33:10,444:INFO:       statsforecast: Not installed
2025-02-06 14:33:10,444:INFO:        tune_sklearn: Not installed
2025-02-06 14:33:10,444:INFO:                 ray: Not installed
2025-02-06 14:33:10,444:INFO:            hyperopt: Not installed
2025-02-06 14:33:10,444:INFO:              optuna: Not installed
2025-02-06 14:33:10,444:INFO:               skopt: Not installed
2025-02-06 14:33:10,444:INFO:              mlflow: Not installed
2025-02-06 14:33:10,444:INFO:              gradio: Not installed
2025-02-06 14:33:10,444:INFO:             fastapi: Not installed
2025-02-06 14:33:10,444:INFO:             uvicorn: Not installed
2025-02-06 14:33:10,444:INFO:              m2cgen: Not installed
2025-02-06 14:33:10,444:INFO:           evidently: Not installed
2025-02-06 14:33:10,444:INFO:               fugue: Not installed
2025-02-06 14:33:10,444:INFO:           streamlit: Not installed
2025-02-06 14:33:10,444:INFO:             prophet: Not installed
2025-02-06 14:33:10,444:INFO:None
2025-02-06 14:33:10,444:INFO:Set up data.
2025-02-06 14:33:10,452:INFO:Set up folding strategy.
2025-02-06 14:33:10,452:INFO:Set up train/test split.
2025-02-06 14:33:10,459:INFO:Set up index.
2025-02-06 14:33:10,460:INFO:Assigning column types.
2025-02-06 14:33:10,468:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:33:10,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,530:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,546:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:33:10,570:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:33:10,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,625:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:33:10,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,703:INFO:Preparing preprocessing pipeline...
2025-02-06 14:33:10,704:INFO:Set up simple imputation.
2025-02-06 14:33:10,726:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:33:10,727:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:33:10,727:INFO:Creating final display dataframe.
2025-02-06 14:33:10,800:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape        (8211, 42)
5   Transformed train set shape        (5747, 42)
6    Transformed test set shape        (2464, 42)
7               Ignore features                 1
8              Numeric features                41
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a118
2025-02-06 14:33:10,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:33:10,879:INFO:setup() successfully completed in 0.44s...............
2025-02-06 14:33:10,879:INFO:Initializing create_model()
2025-02-06 14:33:10,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021125B72610>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:33:10,879:INFO:Checking exceptions
2025-02-06 14:33:10,886:INFO:Importing libraries
2025-02-06 14:33:10,886:INFO:Copying training dataset
2025-02-06 14:33:10,895:INFO:Defining folds
2025-02-06 14:33:10,895:INFO:Declaring metric variables
2025-02-06 14:33:10,896:INFO:Importing untrained model
2025-02-06 14:33:10,898:INFO:Decision Tree Classifier Imported successfully
2025-02-06 14:33:10,901:INFO:Starting cross validation
2025-02-06 14:33:10,901:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:33:12,356:INFO:Calculating mean and std
2025-02-06 14:33:12,358:INFO:Creating metrics dataframe
2025-02-06 14:33:12,360:INFO:Finalizing model
2025-02-06 14:33:12,481:INFO:Uploading results into container
2025-02-06 14:33:12,482:INFO:Uploading model into container now
2025-02-06 14:33:12,486:INFO:_master_model_container: 1
2025-02-06 14:33:12,486:INFO:_display_container: 2
2025-02-06 14:33:12,486:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1234, splitter='best')
2025-02-06 14:33:12,486:INFO:create_model() successfully completed......................................
2025-02-06 14:42:21,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:42:21,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:42:21,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:42:21,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:42:23,509:INFO:PyCaret ClassificationExperiment
2025-02-06 14:42:23,509:INFO:Logging name: clf-default-name
2025-02-06 14:42:23,509:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:42:23,509:INFO:version 3.3.2
2025-02-06 14:42:23,509:INFO:Initializing setup()
2025-02-06 14:42:23,509:INFO:self.USI: e5db
2025-02-06 14:42:23,509:INFO:self._variable_keys: {'is_multiclass', 'seed', 'fold_shuffle_param', 'X_train', 'gpu_param', 'n_jobs_param', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'log_plots_param', 'target_param', 'X_test', '_ml_usecase', 'X', 'memory', 'fold_generator', 'data', 'exp_name_log', 'y_train', 'html_param', 'y', 'USI', 'y_test', 'idx', 'fix_imbalance', 'fold_groups_param', '_available_plots', 'exp_id'}
2025-02-06 14:42:23,509:INFO:Checking environment
2025-02-06 14:42:23,509:INFO:python_version: 3.11.9
2025-02-06 14:42:23,509:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:42:23,509:INFO:machine: AMD64
2025-02-06 14:42:23,509:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:42:23,513:INFO:Memory: svmem(total=67771465728, available=50459979776, percent=25.5, used=17311485952, free=50459979776)
2025-02-06 14:42:23,513:INFO:Physical Core: 8
2025-02-06 14:42:23,513:INFO:Logical Core: 16
2025-02-06 14:42:23,513:INFO:Checking libraries
2025-02-06 14:42:23,513:INFO:System:
2025-02-06 14:42:23,513:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:42:23,513:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:42:23,513:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:42:23,513:INFO:PyCaret required dependencies:
2025-02-06 14:42:23,525:INFO:                 pip: 25.0
2025-02-06 14:42:23,525:INFO:          setuptools: 65.5.0
2025-02-06 14:42:23,525:INFO:             pycaret: 3.3.2
2025-02-06 14:42:23,525:INFO:             IPython: 8.32.0
2025-02-06 14:42:23,525:INFO:          ipywidgets: 8.1.5
2025-02-06 14:42:23,525:INFO:                tqdm: 4.67.1
2025-02-06 14:42:23,525:INFO:               numpy: 1.26.4
2025-02-06 14:42:23,525:INFO:              pandas: 2.1.4
2025-02-06 14:42:23,525:INFO:              jinja2: 3.1.5
2025-02-06 14:42:23,525:INFO:               scipy: 1.11.4
2025-02-06 14:42:23,525:INFO:              joblib: 1.3.2
2025-02-06 14:42:23,525:INFO:             sklearn: 1.4.2
2025-02-06 14:42:23,525:INFO:                pyod: 2.0.3
2025-02-06 14:42:23,526:INFO:            imblearn: 0.13.0
2025-02-06 14:42:23,526:INFO:   category_encoders: 2.7.0
2025-02-06 14:42:23,526:INFO:            lightgbm: 4.5.0
2025-02-06 14:42:23,526:INFO:               numba: 0.61.0
2025-02-06 14:42:23,526:INFO:            requests: 2.32.3
2025-02-06 14:42:23,526:INFO:          matplotlib: 3.7.5
2025-02-06 14:42:23,526:INFO:          scikitplot: 0.3.7
2025-02-06 14:42:23,526:INFO:         yellowbrick: 1.5
2025-02-06 14:42:23,526:INFO:              plotly: 5.24.1
2025-02-06 14:42:23,526:INFO:    plotly-resampler: Not installed
2025-02-06 14:42:23,526:INFO:             kaleido: 0.2.1
2025-02-06 14:42:23,526:INFO:           schemdraw: 0.15
2025-02-06 14:42:23,526:INFO:         statsmodels: 0.14.4
2025-02-06 14:42:23,526:INFO:              sktime: 0.26.0
2025-02-06 14:42:23,526:INFO:               tbats: 1.1.3
2025-02-06 14:42:23,526:INFO:            pmdarima: 2.0.4
2025-02-06 14:42:23,526:INFO:              psutil: 6.1.1
2025-02-06 14:42:23,526:INFO:          markupsafe: 3.0.2
2025-02-06 14:42:23,526:INFO:             pickle5: Not installed
2025-02-06 14:42:23,526:INFO:         cloudpickle: 3.1.1
2025-02-06 14:42:23,526:INFO:         deprecation: 2.1.0
2025-02-06 14:42:23,526:INFO:              xxhash: 3.5.0
2025-02-06 14:42:23,526:INFO:           wurlitzer: Not installed
2025-02-06 14:42:23,526:INFO:PyCaret optional dependencies:
2025-02-06 14:42:23,531:INFO:                shap: Not installed
2025-02-06 14:42:23,531:INFO:           interpret: Not installed
2025-02-06 14:42:23,531:INFO:                umap: Not installed
2025-02-06 14:42:23,531:INFO:     ydata_profiling: Not installed
2025-02-06 14:42:23,531:INFO:  explainerdashboard: Not installed
2025-02-06 14:42:23,531:INFO:             autoviz: Not installed
2025-02-06 14:42:23,531:INFO:           fairlearn: Not installed
2025-02-06 14:42:23,531:INFO:          deepchecks: Not installed
2025-02-06 14:42:23,531:INFO:             xgboost: Not installed
2025-02-06 14:42:23,531:INFO:            catboost: Not installed
2025-02-06 14:42:23,531:INFO:              kmodes: Not installed
2025-02-06 14:42:23,531:INFO:             mlxtend: Not installed
2025-02-06 14:42:23,531:INFO:       statsforecast: Not installed
2025-02-06 14:42:23,531:INFO:        tune_sklearn: Not installed
2025-02-06 14:42:23,531:INFO:                 ray: Not installed
2025-02-06 14:42:23,531:INFO:            hyperopt: Not installed
2025-02-06 14:42:23,531:INFO:              optuna: Not installed
2025-02-06 14:42:23,531:INFO:               skopt: Not installed
2025-02-06 14:42:23,531:INFO:              mlflow: Not installed
2025-02-06 14:42:23,531:INFO:              gradio: Not installed
2025-02-06 14:42:23,531:INFO:             fastapi: Not installed
2025-02-06 14:42:23,531:INFO:             uvicorn: Not installed
2025-02-06 14:42:23,531:INFO:              m2cgen: Not installed
2025-02-06 14:42:23,531:INFO:           evidently: Not installed
2025-02-06 14:42:23,531:INFO:               fugue: Not installed
2025-02-06 14:42:23,531:INFO:           streamlit: Not installed
2025-02-06 14:42:23,531:INFO:             prophet: Not installed
2025-02-06 14:42:23,531:INFO:None
2025-02-06 14:42:23,531:INFO:Set up data.
2025-02-06 14:42:23,540:INFO:Set up folding strategy.
2025-02-06 14:42:23,540:INFO:Set up train/test split.
2025-02-06 14:42:23,547:INFO:Set up index.
2025-02-06 14:42:23,548:INFO:Assigning column types.
2025-02-06 14:42:23,555:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:42:23,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,637:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:42:23,665:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,710:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:42:23,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,726:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:42:23,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,806:INFO:Preparing preprocessing pipeline...
2025-02-06 14:42:23,807:INFO:Set up simple imputation.
2025-02-06 14:42:23,828:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:42:23,830:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:42:23,830:INFO:Creating final display dataframe.
2025-02-06 14:42:23,901:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              e5db
2025-02-06 14:42:23,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:42:23,980:INFO:setup() successfully completed in 0.47s...............
2025-02-06 14:42:23,980:INFO:Initializing create_model()
2025-02-06 14:42:23,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DB71A418D0>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 14:42:23,980:INFO:Checking exceptions
2025-02-06 14:42:23,988:INFO:Importing libraries
2025-02-06 14:42:23,988:INFO:Copying training dataset
2025-02-06 14:42:23,996:INFO:Defining folds
2025-02-06 14:42:23,996:INFO:Declaring metric variables
2025-02-06 14:42:23,998:INFO:Importing untrained model
2025-02-06 14:42:23,999:INFO:Logistic Regression Imported successfully
2025-02-06 14:42:24,002:INFO:Starting cross validation
2025-02-06 14:42:24,003:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:42:25,747:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 14:42:25,747:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 14:42:25,747:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 14:42:25,747:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 14:42:25,761:INFO:Calculating mean and std
2025-02-06 14:42:25,762:INFO:Creating metrics dataframe
2025-02-06 14:42:25,765:INFO:Finalizing model
2025-02-06 14:42:26,202:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 14:42:26,205:INFO:Uploading results into container
2025-02-06 14:42:26,206:INFO:Uploading model into container now
2025-02-06 14:42:26,210:INFO:_master_model_container: 1
2025-02-06 14:42:26,210:INFO:_display_container: 2
2025-02-06 14:42:26,210:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1234, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 14:42:26,210:INFO:create_model() successfully completed......................................
2025-02-06 14:43:12,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:43:12,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:43:12,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:43:12,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 14:43:16,142:INFO:PyCaret ClassificationExperiment
2025-02-06 14:43:16,142:INFO:Logging name: clf-default-name
2025-02-06 14:43:16,142:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 14:43:16,142:INFO:version 3.3.2
2025-02-06 14:43:16,142:INFO:Initializing setup()
2025-02-06 14:43:16,142:INFO:self.USI: b937
2025-02-06 14:43:16,143:INFO:self._variable_keys: {'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_test', 'y_train', 'target_param', '_ml_usecase', 'n_jobs_param', 'idx', '_available_plots', 'fold_groups_param', 'log_plots_param', 'X', 'X_train', 'is_multiclass', 'fix_imbalance', 'gpu_param', 'data', 'exp_name_log', 'pipeline', 'fold_generator', 'y_test', 'y', 'memory', 'html_param', 'seed', 'exp_id', 'logging_param'}
2025-02-06 14:43:16,143:INFO:Checking environment
2025-02-06 14:43:16,143:INFO:python_version: 3.11.9
2025-02-06 14:43:16,143:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 14:43:16,143:INFO:machine: AMD64
2025-02-06 14:43:16,143:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 14:43:16,147:INFO:Memory: svmem(total=67771465728, available=50533830656, percent=25.4, used=17237635072, free=50533830656)
2025-02-06 14:43:16,147:INFO:Physical Core: 8
2025-02-06 14:43:16,147:INFO:Logical Core: 16
2025-02-06 14:43:16,147:INFO:Checking libraries
2025-02-06 14:43:16,147:INFO:System:
2025-02-06 14:43:16,147:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 14:43:16,147:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 14:43:16,147:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 14:43:16,147:INFO:PyCaret required dependencies:
2025-02-06 14:43:16,161:INFO:                 pip: 25.0
2025-02-06 14:43:16,161:INFO:          setuptools: 65.5.0
2025-02-06 14:43:16,161:INFO:             pycaret: 3.3.2
2025-02-06 14:43:16,161:INFO:             IPython: 8.32.0
2025-02-06 14:43:16,161:INFO:          ipywidgets: 8.1.5
2025-02-06 14:43:16,161:INFO:                tqdm: 4.67.1
2025-02-06 14:43:16,161:INFO:               numpy: 1.26.4
2025-02-06 14:43:16,161:INFO:              pandas: 2.1.4
2025-02-06 14:43:16,161:INFO:              jinja2: 3.1.5
2025-02-06 14:43:16,161:INFO:               scipy: 1.11.4
2025-02-06 14:43:16,161:INFO:              joblib: 1.3.2
2025-02-06 14:43:16,161:INFO:             sklearn: 1.4.2
2025-02-06 14:43:16,161:INFO:                pyod: 2.0.3
2025-02-06 14:43:16,161:INFO:            imblearn: 0.13.0
2025-02-06 14:43:16,161:INFO:   category_encoders: 2.7.0
2025-02-06 14:43:16,161:INFO:            lightgbm: 4.5.0
2025-02-06 14:43:16,161:INFO:               numba: 0.61.0
2025-02-06 14:43:16,161:INFO:            requests: 2.32.3
2025-02-06 14:43:16,161:INFO:          matplotlib: 3.7.5
2025-02-06 14:43:16,161:INFO:          scikitplot: 0.3.7
2025-02-06 14:43:16,161:INFO:         yellowbrick: 1.5
2025-02-06 14:43:16,161:INFO:              plotly: 5.24.1
2025-02-06 14:43:16,161:INFO:    plotly-resampler: Not installed
2025-02-06 14:43:16,161:INFO:             kaleido: 0.2.1
2025-02-06 14:43:16,161:INFO:           schemdraw: 0.15
2025-02-06 14:43:16,161:INFO:         statsmodels: 0.14.4
2025-02-06 14:43:16,162:INFO:              sktime: 0.26.0
2025-02-06 14:43:16,162:INFO:               tbats: 1.1.3
2025-02-06 14:43:16,162:INFO:            pmdarima: 2.0.4
2025-02-06 14:43:16,162:INFO:              psutil: 6.1.1
2025-02-06 14:43:16,162:INFO:          markupsafe: 3.0.2
2025-02-06 14:43:16,162:INFO:             pickle5: Not installed
2025-02-06 14:43:16,162:INFO:         cloudpickle: 3.1.1
2025-02-06 14:43:16,162:INFO:         deprecation: 2.1.0
2025-02-06 14:43:16,162:INFO:              xxhash: 3.5.0
2025-02-06 14:43:16,162:INFO:           wurlitzer: Not installed
2025-02-06 14:43:16,162:INFO:PyCaret optional dependencies:
2025-02-06 14:43:16,167:INFO:                shap: Not installed
2025-02-06 14:43:16,167:INFO:           interpret: Not installed
2025-02-06 14:43:16,167:INFO:                umap: Not installed
2025-02-06 14:43:16,167:INFO:     ydata_profiling: Not installed
2025-02-06 14:43:16,167:INFO:  explainerdashboard: Not installed
2025-02-06 14:43:16,167:INFO:             autoviz: Not installed
2025-02-06 14:43:16,167:INFO:           fairlearn: Not installed
2025-02-06 14:43:16,167:INFO:          deepchecks: Not installed
2025-02-06 14:43:16,167:INFO:             xgboost: Not installed
2025-02-06 14:43:16,167:INFO:            catboost: Not installed
2025-02-06 14:43:16,167:INFO:              kmodes: Not installed
2025-02-06 14:43:16,167:INFO:             mlxtend: Not installed
2025-02-06 14:43:16,167:INFO:       statsforecast: Not installed
2025-02-06 14:43:16,167:INFO:        tune_sklearn: Not installed
2025-02-06 14:43:16,167:INFO:                 ray: Not installed
2025-02-06 14:43:16,167:INFO:            hyperopt: Not installed
2025-02-06 14:43:16,167:INFO:              optuna: Not installed
2025-02-06 14:43:16,167:INFO:               skopt: Not installed
2025-02-06 14:43:16,167:INFO:              mlflow: Not installed
2025-02-06 14:43:16,167:INFO:              gradio: Not installed
2025-02-06 14:43:16,167:INFO:             fastapi: Not installed
2025-02-06 14:43:16,167:INFO:             uvicorn: Not installed
2025-02-06 14:43:16,167:INFO:              m2cgen: Not installed
2025-02-06 14:43:16,167:INFO:           evidently: Not installed
2025-02-06 14:43:16,167:INFO:               fugue: Not installed
2025-02-06 14:43:16,167:INFO:           streamlit: Not installed
2025-02-06 14:43:16,167:INFO:             prophet: Not installed
2025-02-06 14:43:16,167:INFO:None
2025-02-06 14:43:16,167:INFO:Set up data.
2025-02-06 14:43:16,176:INFO:Set up folding strategy.
2025-02-06 14:43:16,176:INFO:Set up train/test split.
2025-02-06 14:43:16,183:INFO:Set up index.
2025-02-06 14:43:16,184:INFO:Assigning column types.
2025-02-06 14:43:16,191:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 14:43:16,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,259:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,273:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 14:43:16,297:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,336:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 14:43:16,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,351:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 14:43:16,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,430:INFO:Preparing preprocessing pipeline...
2025-02-06 14:43:16,431:INFO:Set up simple imputation.
2025-02-06 14:43:16,451:INFO:Finished creating preprocessing pipeline.
2025-02-06 14:43:16,454:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 14:43:16,454:INFO:Creating final display dataframe.
2025-02-06 14:43:16,524:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              b937
2025-02-06 14:43:16,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 14:43:16,603:INFO:setup() successfully completed in 0.46s...............
2025-02-06 14:43:16,603:INFO:Initializing create_model()
2025-02-06 14:43:16,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000184B82CD490>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 14:43:16,603:INFO:Checking exceptions
2025-02-06 14:43:16,604:INFO:Importing libraries
2025-02-06 14:43:16,604:INFO:Copying training dataset
2025-02-06 14:43:16,611:INFO:Defining folds
2025-02-06 14:43:16,611:INFO:Declaring metric variables
2025-02-06 14:43:16,611:INFO:Importing untrained model
2025-02-06 14:43:16,611:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 14:43:16,611:INFO:Starting cross validation
2025-02-06 14:43:16,612:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 14:43:19,647:INFO:Calculating mean and std
2025-02-06 14:43:19,648:INFO:Creating metrics dataframe
2025-02-06 14:43:19,649:INFO:Finalizing model
2025-02-06 14:43:19,665:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 14:43:19,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.
2025-02-06 14:43:19,667:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 14:43:19,667:INFO:[LightGBM] [Info] Total Bins 6715
2025-02-06 14:43:19,667:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 14:43:19,667:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 14:43:19,667:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 14:43:19,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 14:43:20,061:INFO:Uploading results into container
2025-02-06 14:43:20,061:INFO:Uploading model into container now
2025-02-06 14:43:20,062:INFO:_master_model_container: 1
2025-02-06 14:43:20,062:INFO:_display_container: 2
2025-02-06 14:43:20,062:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1234, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 14:43:20,062:INFO:create_model() successfully completed......................................
2025-02-06 15:51:16,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 15:51:16,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 15:51:16,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 15:51:16,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 15:52:03,360:WARNING:c:\MachineLearning\code_challenge_pic_pay\funcoes.py:451: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=percentual_missing.index,

2025-02-06 16:38:20,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:20,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:20,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:20,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:21,110:WARNING:c:\MachineLearning\code_challenge_pic_pay\funcoes.py:451: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=percentual_missing.index,

2025-02-06 16:38:47,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:47,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:47,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:47,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:38:48,437:WARNING:c:\MachineLearning\code_challenge_pic_pay\funcoes.py:451: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=percentual_missing.index,

2025-02-06 16:41:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:41:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:41:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:41:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 16:41:06,019:WARNING:c:\MachineLearning\code_challenge_pic_pay\funcoes.py:452: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=percentual_missing.index,

2025-02-06 17:41:29,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 17:41:29,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 17:41:29,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 17:41:29,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 17:45:32,864:INFO:PyCaret ClassificationExperiment
2025-02-06 17:45:32,864:INFO:Logging name: clf-default-name
2025-02-06 17:45:32,864:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 17:45:32,864:INFO:version 3.3.2
2025-02-06 17:45:32,864:INFO:Initializing setup()
2025-02-06 17:45:32,864:INFO:self.USI: 081d
2025-02-06 17:45:32,864:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 17:45:32,864:INFO:Checking environment
2025-02-06 17:45:32,864:INFO:python_version: 3.11.9
2025-02-06 17:45:32,864:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 17:45:32,864:INFO:machine: AMD64
2025-02-06 17:45:32,864:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 17:45:32,869:INFO:Memory: svmem(total=67771465728, available=48996335616, percent=27.7, used=18775130112, free=48996335616)
2025-02-06 17:45:32,869:INFO:Physical Core: 8
2025-02-06 17:45:32,869:INFO:Logical Core: 16
2025-02-06 17:45:32,869:INFO:Checking libraries
2025-02-06 17:45:32,869:INFO:System:
2025-02-06 17:45:32,869:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 17:45:32,869:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 17:45:32,869:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 17:45:32,869:INFO:PyCaret required dependencies:
2025-02-06 17:45:32,913:INFO:                 pip: 25.0
2025-02-06 17:45:32,914:INFO:          setuptools: 65.5.0
2025-02-06 17:45:32,914:INFO:             pycaret: 3.3.2
2025-02-06 17:45:32,914:INFO:             IPython: 8.32.0
2025-02-06 17:45:32,914:INFO:          ipywidgets: 8.1.5
2025-02-06 17:45:32,914:INFO:                tqdm: 4.67.1
2025-02-06 17:45:32,914:INFO:               numpy: 1.26.4
2025-02-06 17:45:32,914:INFO:              pandas: 2.1.4
2025-02-06 17:45:32,914:INFO:              jinja2: 3.1.5
2025-02-06 17:45:32,914:INFO:               scipy: 1.11.4
2025-02-06 17:45:32,914:INFO:              joblib: 1.3.2
2025-02-06 17:45:32,914:INFO:             sklearn: 1.4.2
2025-02-06 17:45:32,914:INFO:                pyod: 2.0.3
2025-02-06 17:45:32,914:INFO:            imblearn: 0.13.0
2025-02-06 17:45:32,914:INFO:   category_encoders: 2.7.0
2025-02-06 17:45:32,914:INFO:            lightgbm: 4.5.0
2025-02-06 17:45:32,914:INFO:               numba: 0.61.0
2025-02-06 17:45:32,914:INFO:            requests: 2.32.3
2025-02-06 17:45:32,914:INFO:          matplotlib: 3.7.5
2025-02-06 17:45:32,914:INFO:          scikitplot: 0.3.7
2025-02-06 17:45:32,914:INFO:         yellowbrick: 1.5
2025-02-06 17:45:32,914:INFO:              plotly: 5.24.1
2025-02-06 17:45:32,914:INFO:    plotly-resampler: Not installed
2025-02-06 17:45:32,914:INFO:             kaleido: 0.2.1
2025-02-06 17:45:32,914:INFO:           schemdraw: 0.15
2025-02-06 17:45:32,914:INFO:         statsmodels: 0.14.4
2025-02-06 17:45:32,914:INFO:              sktime: 0.26.0
2025-02-06 17:45:32,914:INFO:               tbats: 1.1.3
2025-02-06 17:45:32,914:INFO:            pmdarima: 2.0.4
2025-02-06 17:45:32,914:INFO:              psutil: 6.1.1
2025-02-06 17:45:32,914:INFO:          markupsafe: 3.0.2
2025-02-06 17:45:32,914:INFO:             pickle5: Not installed
2025-02-06 17:45:32,914:INFO:         cloudpickle: 3.1.1
2025-02-06 17:45:32,914:INFO:         deprecation: 2.1.0
2025-02-06 17:45:32,914:INFO:              xxhash: 3.5.0
2025-02-06 17:45:32,914:INFO:           wurlitzer: Not installed
2025-02-06 17:45:32,914:INFO:PyCaret optional dependencies:
2025-02-06 17:45:32,923:INFO:                shap: Not installed
2025-02-06 17:45:32,923:INFO:           interpret: Not installed
2025-02-06 17:45:32,923:INFO:                umap: Not installed
2025-02-06 17:45:32,923:INFO:     ydata_profiling: Not installed
2025-02-06 17:45:32,923:INFO:  explainerdashboard: Not installed
2025-02-06 17:45:32,923:INFO:             autoviz: Not installed
2025-02-06 17:45:32,923:INFO:           fairlearn: Not installed
2025-02-06 17:45:32,923:INFO:          deepchecks: Not installed
2025-02-06 17:45:32,923:INFO:             xgboost: Not installed
2025-02-06 17:45:32,923:INFO:            catboost: Not installed
2025-02-06 17:45:32,923:INFO:              kmodes: Not installed
2025-02-06 17:45:32,923:INFO:             mlxtend: Not installed
2025-02-06 17:45:32,923:INFO:       statsforecast: Not installed
2025-02-06 17:45:32,923:INFO:        tune_sklearn: Not installed
2025-02-06 17:45:32,923:INFO:                 ray: Not installed
2025-02-06 17:45:32,923:INFO:            hyperopt: Not installed
2025-02-06 17:45:32,923:INFO:              optuna: Not installed
2025-02-06 17:45:32,923:INFO:               skopt: Not installed
2025-02-06 17:45:32,923:INFO:              mlflow: Not installed
2025-02-06 17:45:32,923:INFO:              gradio: Not installed
2025-02-06 17:45:32,923:INFO:             fastapi: Not installed
2025-02-06 17:45:32,924:INFO:             uvicorn: Not installed
2025-02-06 17:45:32,924:INFO:              m2cgen: Not installed
2025-02-06 17:45:32,924:INFO:           evidently: Not installed
2025-02-06 17:45:32,924:INFO:               fugue: Not installed
2025-02-06 17:45:32,924:INFO:           streamlit: Not installed
2025-02-06 17:45:32,924:INFO:             prophet: Not installed
2025-02-06 17:45:32,924:INFO:None
2025-02-06 17:45:32,924:INFO:Set up data.
2025-02-06 17:45:32,930:INFO:Set up folding strategy.
2025-02-06 17:45:32,930:INFO:Set up train/test split.
2025-02-06 17:45:32,935:INFO:Set up index.
2025-02-06 17:45:32,935:INFO:Assigning column types.
2025-02-06 17:45:32,940:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 17:45:32,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 17:45:32,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 17:45:32,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:32,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 17:45:33,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 17:45:33,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,025:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 17:45:33,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 17:45:33,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,087:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 17:45:33,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,103:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 17:45:33,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,180:INFO:Preparing preprocessing pipeline...
2025-02-06 17:45:33,181:INFO:Set up simple imputation.
2025-02-06 17:45:33,211:INFO:Finished creating preprocessing pipeline.
2025-02-06 17:45:33,213:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 17:45:33,213:INFO:Creating final display dataframe.
2025-02-06 17:45:33,278:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              081d
2025-02-06 17:45:33,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 17:45:33,376:INFO:setup() successfully completed in 0.51s...............
2025-02-06 17:45:33,376:INFO:Initializing compare_models()
2025-02-06 17:45:33,376:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 17:45:33,376:INFO:Checking exceptions
2025-02-06 17:45:33,379:INFO:Preparing display monitor
2025-02-06 17:45:33,394:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 17:45:33,394:INFO:Total runtime is 0.0 minutes
2025-02-06 17:45:33,396:INFO:SubProcess create_model() called ==================================
2025-02-06 17:45:33,396:INFO:Initializing create_model()
2025-02-06 17:45:33,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935C38710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:45:33,396:INFO:Checking exceptions
2025-02-06 17:45:33,396:INFO:Importing libraries
2025-02-06 17:45:33,396:INFO:Copying training dataset
2025-02-06 17:45:33,403:INFO:Defining folds
2025-02-06 17:45:33,403:INFO:Declaring metric variables
2025-02-06 17:45:33,405:INFO:Importing untrained model
2025-02-06 17:45:33,407:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:45:33,410:INFO:Starting cross validation
2025-02-06 17:45:33,411:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:45:35,459:INFO:Calculating mean and std
2025-02-06 17:45:35,460:INFO:Creating metrics dataframe
2025-02-06 17:45:35,462:INFO:Uploading results into container
2025-02-06 17:45:35,463:INFO:Uploading model into container now
2025-02-06 17:45:35,463:INFO:_master_model_container: 1
2025-02-06 17:45:35,463:INFO:_display_container: 2
2025-02-06 17:45:35,463:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:45:35,463:INFO:create_model() successfully completed......................................
2025-02-06 17:45:35,570:INFO:SubProcess create_model() end ==================================
2025-02-06 17:45:35,571:INFO:Creating metrics dataframe
2025-02-06 17:45:35,575:INFO:Initializing Logistic Regression
2025-02-06 17:45:35,575:INFO:Total runtime is 0.03635406494140625 minutes
2025-02-06 17:45:35,577:INFO:SubProcess create_model() called ==================================
2025-02-06 17:45:35,577:INFO:Initializing create_model()
2025-02-06 17:45:35,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935C38710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:45:35,577:INFO:Checking exceptions
2025-02-06 17:45:35,577:INFO:Importing libraries
2025-02-06 17:45:35,577:INFO:Copying training dataset
2025-02-06 17:45:35,583:INFO:Defining folds
2025-02-06 17:45:35,583:INFO:Declaring metric variables
2025-02-06 17:45:35,586:INFO:Importing untrained model
2025-02-06 17:45:35,588:INFO:Logistic Regression Imported successfully
2025-02-06 17:45:35,591:INFO:Starting cross validation
2025-02-06 17:45:35,592:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:45:37,109:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:45:37,109:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:45:37,109:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:45:37,111:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:45:37,113:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:45:37,134:INFO:Calculating mean and std
2025-02-06 17:45:37,135:INFO:Creating metrics dataframe
2025-02-06 17:45:37,136:INFO:Uploading results into container
2025-02-06 17:45:37,136:INFO:Uploading model into container now
2025-02-06 17:45:37,137:INFO:_master_model_container: 2
2025-02-06 17:45:37,137:INFO:_display_container: 2
2025-02-06 17:45:37,137:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:45:37,137:INFO:create_model() successfully completed......................................
2025-02-06 17:45:37,206:INFO:SubProcess create_model() end ==================================
2025-02-06 17:45:37,206:INFO:Creating metrics dataframe
2025-02-06 17:45:37,211:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 17:45:37,215:INFO:Initializing create_model()
2025-02-06 17:45:37,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:45:37,215:INFO:Checking exceptions
2025-02-06 17:45:37,216:INFO:Importing libraries
2025-02-06 17:45:37,216:INFO:Copying training dataset
2025-02-06 17:45:37,222:INFO:Defining folds
2025-02-06 17:45:37,222:INFO:Declaring metric variables
2025-02-06 17:45:37,222:INFO:Importing untrained model
2025-02-06 17:45:37,222:INFO:Declaring custom model
2025-02-06 17:45:37,222:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:45:37,222:INFO:Cross validation set to False
2025-02-06 17:45:37,222:INFO:Fitting Model
2025-02-06 17:45:37,235:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 17:45:37,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.
2025-02-06 17:45:37,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 17:45:37,237:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 17:45:37,237:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 17:45:37,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 17:45:37,237:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 17:45:37,317:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:45:37,317:INFO:create_model() successfully completed......................................
2025-02-06 17:45:37,389:INFO:_master_model_container: 2
2025-02-06 17:45:37,389:INFO:_display_container: 2
2025-02-06 17:45:37,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:45:37,389:INFO:compare_models() successfully completed......................................
2025-02-06 17:45:37,390:INFO:Initializing create_model()
2025-02-06 17:45:37,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:45:37,390:INFO:Checking exceptions
2025-02-06 17:45:37,400:INFO:Importing libraries
2025-02-06 17:45:37,400:INFO:Copying training dataset
2025-02-06 17:45:37,409:INFO:Defining folds
2025-02-06 17:45:37,409:INFO:Declaring metric variables
2025-02-06 17:45:37,413:INFO:Importing untrained model
2025-02-06 17:45:37,415:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:45:37,418:INFO:Starting cross validation
2025-02-06 17:45:37,419:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:45:39,272:INFO:Calculating mean and std
2025-02-06 17:45:39,273:INFO:Creating metrics dataframe
2025-02-06 17:45:39,277:INFO:Finalizing model
2025-02-06 17:45:39,290:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 17:45:39,293:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.
2025-02-06 17:45:39,293:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 17:45:39,293:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 17:45:39,293:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 17:45:39,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 17:45:39,293:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 17:45:39,406:INFO:Uploading results into container
2025-02-06 17:45:39,407:INFO:Uploading model into container now
2025-02-06 17:45:39,413:INFO:_master_model_container: 3
2025-02-06 17:45:39,413:INFO:_display_container: 3
2025-02-06 17:45:39,414:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:45:39,414:INFO:create_model() successfully completed......................................
2025-02-06 17:45:39,487:INFO:Initializing tune_model()
2025-02-06 17:45:39,487:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 17:45:39,487:INFO:Checking exceptions
2025-02-06 17:45:39,498:INFO:Copying training dataset
2025-02-06 17:45:39,505:INFO:Checking base model
2025-02-06 17:45:39,505:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 17:45:39,507:INFO:Declaring metric variables
2025-02-06 17:45:39,509:INFO:Defining Hyperparameters
2025-02-06 17:45:39,586:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 17:45:39,587:INFO:Tuning with n_jobs=-1
2025-02-06 17:45:39,587:INFO:Initializing RandomizedSearchCV
2025-02-06 17:45:55,832:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 17:45:55,833:INFO:Hyperparameter search completed
2025-02-06 17:45:55,833:INFO:SubProcess create_model() called ==================================
2025-02-06 17:45:55,833:INFO:Initializing create_model()
2025-02-06 17:45:55,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937815750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 17:45:55,834:INFO:Checking exceptions
2025-02-06 17:45:55,834:INFO:Importing libraries
2025-02-06 17:45:55,834:INFO:Copying training dataset
2025-02-06 17:45:55,843:INFO:Defining folds
2025-02-06 17:45:55,843:INFO:Declaring metric variables
2025-02-06 17:45:55,845:INFO:Importing untrained model
2025-02-06 17:45:55,845:INFO:Declaring custom model
2025-02-06 17:45:55,848:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:45:55,852:INFO:Starting cross validation
2025-02-06 17:45:55,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:45:59,035:INFO:Calculating mean and std
2025-02-06 17:45:59,037:INFO:Creating metrics dataframe
2025-02-06 17:45:59,041:INFO:Finalizing model
2025-02-06 17:45:59,054:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 17:45:59,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.
2025-02-06 17:45:59,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 17:45:59,055:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 17:45:59,056:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 17:45:59,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 17:45:59,056:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 17:45:59,734:INFO:Uploading results into container
2025-02-06 17:45:59,734:INFO:Uploading model into container now
2025-02-06 17:45:59,735:INFO:_master_model_container: 4
2025-02-06 17:45:59,735:INFO:_display_container: 4
2025-02-06 17:45:59,735:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:45:59,735:INFO:create_model() successfully completed......................................
2025-02-06 17:45:59,806:INFO:SubProcess create_model() end ==================================
2025-02-06 17:45:59,806:INFO:choose_better activated
2025-02-06 17:45:59,808:INFO:SubProcess create_model() called ==================================
2025-02-06 17:45:59,808:INFO:Initializing create_model()
2025-02-06 17:45:59,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:45:59,809:INFO:Checking exceptions
2025-02-06 17:45:59,809:INFO:Importing libraries
2025-02-06 17:45:59,809:INFO:Copying training dataset
2025-02-06 17:45:59,819:INFO:Defining folds
2025-02-06 17:45:59,819:INFO:Declaring metric variables
2025-02-06 17:45:59,819:INFO:Importing untrained model
2025-02-06 17:45:59,819:INFO:Declaring custom model
2025-02-06 17:45:59,819:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:45:59,821:INFO:Starting cross validation
2025-02-06 17:45:59,821:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:00,269:INFO:Calculating mean and std
2025-02-06 17:46:00,269:INFO:Creating metrics dataframe
2025-02-06 17:46:00,271:INFO:Finalizing model
2025-02-06 17:46:00,284:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 17:46:00,285:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.
2025-02-06 17:46:00,285:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 17:46:00,285:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 17:46:00,285:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 17:46:00,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 17:46:00,285:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 17:46:00,402:INFO:Uploading results into container
2025-02-06 17:46:00,402:INFO:Uploading model into container now
2025-02-06 17:46:00,402:INFO:_master_model_container: 5
2025-02-06 17:46:00,402:INFO:_display_container: 5
2025-02-06 17:46:00,403:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:46:00,403:INFO:create_model() successfully completed......................................
2025-02-06 17:46:00,470:INFO:SubProcess create_model() end ==================================
2025-02-06 17:46:00,470:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 17:46:00,470:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 17:46:00,471:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 17:46:00,471:INFO:choose_better completed
2025-02-06 17:46:00,476:INFO:_master_model_container: 5
2025-02-06 17:46:00,476:INFO:_display_container: 4
2025-02-06 17:46:00,476:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:46:00,476:INFO:tune_model() successfully completed......................................
2025-02-06 17:46:00,529:INFO:Initializing create_model()
2025-02-06 17:46:00,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:46:00,529:INFO:Checking exceptions
2025-02-06 17:46:00,535:INFO:Importing libraries
2025-02-06 17:46:00,535:INFO:Copying training dataset
2025-02-06 17:46:00,542:INFO:Defining folds
2025-02-06 17:46:00,542:INFO:Declaring metric variables
2025-02-06 17:46:00,544:INFO:Importing untrained model
2025-02-06 17:46:00,545:INFO:Logistic Regression Imported successfully
2025-02-06 17:46:00,548:INFO:Starting cross validation
2025-02-06 17:46:00,549:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:00,729:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:00,739:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:00,744:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:00,746:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:00,747:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:00,759:INFO:Calculating mean and std
2025-02-06 17:46:00,759:INFO:Creating metrics dataframe
2025-02-06 17:46:00,762:INFO:Finalizing model
2025-02-06 17:46:01,161:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,163:INFO:Uploading results into container
2025-02-06 17:46:01,163:INFO:Uploading model into container now
2025-02-06 17:46:01,167:INFO:_master_model_container: 6
2025-02-06 17:46:01,167:INFO:_display_container: 5
2025-02-06 17:46:01,167:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:46:01,167:INFO:create_model() successfully completed......................................
2025-02-06 17:46:01,224:INFO:Initializing tune_model()
2025-02-06 17:46:01,224:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 17:46:01,224:INFO:Checking exceptions
2025-02-06 17:46:01,232:INFO:Copying training dataset
2025-02-06 17:46:01,236:INFO:Checking base model
2025-02-06 17:46:01,236:INFO:Base model : Logistic Regression
2025-02-06 17:46:01,237:INFO:Declaring metric variables
2025-02-06 17:46:01,239:INFO:Defining Hyperparameters
2025-02-06 17:46:01,314:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 17:46:01,314:INFO:Tuning with n_jobs=-1
2025-02-06 17:46:01,314:INFO:Initializing RandomizedSearchCV
2025-02-06 17:46:01,382:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,385:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,387:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,388:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,392:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,394:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,395:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,397:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,411:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,413:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,854:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,859:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,863:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,878:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:01,902:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,152:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,193:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,305:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,334:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,335:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:02,465:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 17:46:02,466:INFO:Hyperparameter search completed
2025-02-06 17:46:02,466:INFO:SubProcess create_model() called ==================================
2025-02-06 17:46:02,467:INFO:Initializing create_model()
2025-02-06 17:46:02,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219378149D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 17:46:02,467:INFO:Checking exceptions
2025-02-06 17:46:02,467:INFO:Importing libraries
2025-02-06 17:46:02,467:INFO:Copying training dataset
2025-02-06 17:46:02,473:INFO:Defining folds
2025-02-06 17:46:02,473:INFO:Declaring metric variables
2025-02-06 17:46:02,475:INFO:Importing untrained model
2025-02-06 17:46:02,475:INFO:Declaring custom model
2025-02-06 17:46:02,477:INFO:Logistic Regression Imported successfully
2025-02-06 17:46:02,480:INFO:Starting cross validation
2025-02-06 17:46:02,480:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:02,820:INFO:Calculating mean and std
2025-02-06 17:46:02,820:INFO:Creating metrics dataframe
2025-02-06 17:46:02,823:INFO:Finalizing model
2025-02-06 17:46:03,078:INFO:Uploading results into container
2025-02-06 17:46:03,078:INFO:Uploading model into container now
2025-02-06 17:46:03,079:INFO:_master_model_container: 7
2025-02-06 17:46:03,079:INFO:_display_container: 6
2025-02-06 17:46:03,079:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:46:03,079:INFO:create_model() successfully completed......................................
2025-02-06 17:46:03,126:INFO:SubProcess create_model() end ==================================
2025-02-06 17:46:03,126:INFO:choose_better activated
2025-02-06 17:46:03,128:INFO:SubProcess create_model() called ==================================
2025-02-06 17:46:03,128:INFO:Initializing create_model()
2025-02-06 17:46:03,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:46:03,128:INFO:Checking exceptions
2025-02-06 17:46:03,130:INFO:Importing libraries
2025-02-06 17:46:03,130:INFO:Copying training dataset
2025-02-06 17:46:03,135:INFO:Defining folds
2025-02-06 17:46:03,135:INFO:Declaring metric variables
2025-02-06 17:46:03,135:INFO:Importing untrained model
2025-02-06 17:46:03,135:INFO:Declaring custom model
2025-02-06 17:46:03,135:INFO:Logistic Regression Imported successfully
2025-02-06 17:46:03,135:INFO:Starting cross validation
2025-02-06 17:46:03,136:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:03,308:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,311:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,315:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,316:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,325:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,334:INFO:Calculating mean and std
2025-02-06 17:46:03,334:INFO:Creating metrics dataframe
2025-02-06 17:46:03,335:INFO:Finalizing model
2025-02-06 17:46:03,721:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 17:46:03,721:INFO:Uploading results into container
2025-02-06 17:46:03,721:INFO:Uploading model into container now
2025-02-06 17:46:03,721:INFO:_master_model_container: 8
2025-02-06 17:46:03,721:INFO:_display_container: 7
2025-02-06 17:46:03,721:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:46:03,722:INFO:create_model() successfully completed......................................
2025-02-06 17:46:03,768:INFO:SubProcess create_model() end ==================================
2025-02-06 17:46:03,768:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 17:46:03,769:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 17:46:03,769:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 17:46:03,769:INFO:choose_better completed
2025-02-06 17:46:03,773:INFO:_master_model_container: 8
2025-02-06 17:46:03,773:INFO:_display_container: 6
2025-02-06 17:46:03,773:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:46:03,773:INFO:tune_model() successfully completed......................................
2025-02-06 17:46:03,812:INFO:Initializing compare_models()
2025-02-06 17:46:03,812:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 17:46:03,812:INFO:Checking exceptions
2025-02-06 17:46:03,814:INFO:Preparing display monitor
2025-02-06 17:46:03,824:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 17:46:03,824:INFO:Total runtime is 0.0 minutes
2025-02-06 17:46:03,825:INFO:SubProcess create_model() called ==================================
2025-02-06 17:46:03,825:INFO:Initializing create_model()
2025-02-06 17:46:03,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937871B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:46:03,825:INFO:Checking exceptions
2025-02-06 17:46:03,825:INFO:Importing libraries
2025-02-06 17:46:03,825:INFO:Copying training dataset
2025-02-06 17:46:03,832:INFO:Defining folds
2025-02-06 17:46:03,832:INFO:Declaring metric variables
2025-02-06 17:46:03,833:INFO:Importing untrained model
2025-02-06 17:46:03,833:INFO:Declaring custom model
2025-02-06 17:46:03,835:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:46:03,839:INFO:Starting cross validation
2025-02-06 17:46:03,839:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:06,812:INFO:Calculating mean and std
2025-02-06 17:46:06,813:INFO:Creating metrics dataframe
2025-02-06 17:46:06,815:INFO:Uploading results into container
2025-02-06 17:46:06,815:INFO:Uploading model into container now
2025-02-06 17:46:06,815:INFO:_master_model_container: 9
2025-02-06 17:46:06,815:INFO:_display_container: 7
2025-02-06 17:46:06,816:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:46:06,816:INFO:create_model() successfully completed......................................
2025-02-06 17:46:06,875:INFO:SubProcess create_model() end ==================================
2025-02-06 17:46:06,875:INFO:Creating metrics dataframe
2025-02-06 17:46:06,880:INFO:Initializing custom model Logistic Regression
2025-02-06 17:46:06,880:INFO:Total runtime is 0.05092529058456421 minutes
2025-02-06 17:46:06,882:INFO:SubProcess create_model() called ==================================
2025-02-06 17:46:06,882:INFO:Initializing create_model()
2025-02-06 17:46:06,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937871B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:46:06,882:INFO:Checking exceptions
2025-02-06 17:46:06,882:INFO:Importing libraries
2025-02-06 17:46:06,882:INFO:Copying training dataset
2025-02-06 17:46:06,891:INFO:Defining folds
2025-02-06 17:46:06,891:INFO:Declaring metric variables
2025-02-06 17:46:06,893:INFO:Importing untrained model
2025-02-06 17:46:06,893:INFO:Declaring custom model
2025-02-06 17:46:06,895:INFO:Logistic Regression Imported successfully
2025-02-06 17:46:06,899:INFO:Starting cross validation
2025-02-06 17:46:06,900:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 17:46:07,253:INFO:Calculating mean and std
2025-02-06 17:46:07,253:INFO:Creating metrics dataframe
2025-02-06 17:46:07,254:INFO:Uploading results into container
2025-02-06 17:46:07,255:INFO:Uploading model into container now
2025-02-06 17:46:07,255:INFO:_master_model_container: 10
2025-02-06 17:46:07,255:INFO:_display_container: 7
2025-02-06 17:46:07,255:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 17:46:07,255:INFO:create_model() successfully completed......................................
2025-02-06 17:46:07,306:INFO:SubProcess create_model() end ==================================
2025-02-06 17:46:07,306:INFO:Creating metrics dataframe
2025-02-06 17:46:07,309:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 17:46:07,312:INFO:Initializing create_model()
2025-02-06 17:46:07,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935359B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 17:46:07,313:INFO:Checking exceptions
2025-02-06 17:46:07,313:INFO:Importing libraries
2025-02-06 17:46:07,313:INFO:Copying training dataset
2025-02-06 17:46:07,319:INFO:Defining folds
2025-02-06 17:46:07,319:INFO:Declaring metric variables
2025-02-06 17:46:07,319:INFO:Importing untrained model
2025-02-06 17:46:07,319:INFO:Declaring custom model
2025-02-06 17:46:07,319:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 17:46:07,320:INFO:Cross validation set to False
2025-02-06 17:46:07,320:INFO:Fitting Model
2025-02-06 17:46:07,331:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 17:46:07,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
2025-02-06 17:46:07,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 17:46:07,332:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 17:46:07,333:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 17:46:07,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 17:46:07,333:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 17:46:07,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:46:07,847:INFO:create_model() successfully completed......................................
2025-02-06 17:46:07,914:INFO:_master_model_container: 10
2025-02-06 17:46:07,914:INFO:_display_container: 7
2025-02-06 17:46:07,914:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 17:46:07,914:INFO:compare_models() successfully completed......................................
2025-02-06 18:07:32,348:INFO:PyCaret ClassificationExperiment
2025-02-06 18:07:32,348:INFO:Logging name: clf-default-name
2025-02-06 18:07:32,348:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:07:32,348:INFO:version 3.3.2
2025-02-06 18:07:32,348:INFO:Initializing setup()
2025-02-06 18:07:32,348:INFO:self.USI: 10c9
2025-02-06 18:07:32,348:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:07:32,348:INFO:Checking environment
2025-02-06 18:07:32,348:INFO:python_version: 3.11.9
2025-02-06 18:07:32,350:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:07:32,350:INFO:machine: AMD64
2025-02-06 18:07:32,350:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:07:32,354:INFO:Memory: svmem(total=67771465728, available=48919687168, percent=27.8, used=18851778560, free=48919687168)
2025-02-06 18:07:32,354:INFO:Physical Core: 8
2025-02-06 18:07:32,354:INFO:Logical Core: 16
2025-02-06 18:07:32,354:INFO:Checking libraries
2025-02-06 18:07:32,354:INFO:System:
2025-02-06 18:07:32,354:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:07:32,354:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:07:32,354:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:07:32,354:INFO:PyCaret required dependencies:
2025-02-06 18:07:32,354:INFO:                 pip: 25.0
2025-02-06 18:07:32,354:INFO:          setuptools: 65.5.0
2025-02-06 18:07:32,354:INFO:             pycaret: 3.3.2
2025-02-06 18:07:32,354:INFO:             IPython: 8.32.0
2025-02-06 18:07:32,354:INFO:          ipywidgets: 8.1.5
2025-02-06 18:07:32,354:INFO:                tqdm: 4.67.1
2025-02-06 18:07:32,354:INFO:               numpy: 1.26.4
2025-02-06 18:07:32,354:INFO:              pandas: 2.1.4
2025-02-06 18:07:32,354:INFO:              jinja2: 3.1.5
2025-02-06 18:07:32,354:INFO:               scipy: 1.11.4
2025-02-06 18:07:32,354:INFO:              joblib: 1.3.2
2025-02-06 18:07:32,354:INFO:             sklearn: 1.4.2
2025-02-06 18:07:32,354:INFO:                pyod: 2.0.3
2025-02-06 18:07:32,354:INFO:            imblearn: 0.13.0
2025-02-06 18:07:32,354:INFO:   category_encoders: 2.7.0
2025-02-06 18:07:32,354:INFO:            lightgbm: 4.5.0
2025-02-06 18:07:32,354:INFO:               numba: 0.61.0
2025-02-06 18:07:32,354:INFO:            requests: 2.32.3
2025-02-06 18:07:32,354:INFO:          matplotlib: 3.7.5
2025-02-06 18:07:32,354:INFO:          scikitplot: 0.3.7
2025-02-06 18:07:32,354:INFO:         yellowbrick: 1.5
2025-02-06 18:07:32,354:INFO:              plotly: 5.24.1
2025-02-06 18:07:32,354:INFO:    plotly-resampler: Not installed
2025-02-06 18:07:32,354:INFO:             kaleido: 0.2.1
2025-02-06 18:07:32,354:INFO:           schemdraw: 0.15
2025-02-06 18:07:32,354:INFO:         statsmodels: 0.14.4
2025-02-06 18:07:32,354:INFO:              sktime: 0.26.0
2025-02-06 18:07:32,354:INFO:               tbats: 1.1.3
2025-02-06 18:07:32,354:INFO:            pmdarima: 2.0.4
2025-02-06 18:07:32,354:INFO:              psutil: 6.1.1
2025-02-06 18:07:32,354:INFO:          markupsafe: 3.0.2
2025-02-06 18:07:32,354:INFO:             pickle5: Not installed
2025-02-06 18:07:32,354:INFO:         cloudpickle: 3.1.1
2025-02-06 18:07:32,354:INFO:         deprecation: 2.1.0
2025-02-06 18:07:32,354:INFO:              xxhash: 3.5.0
2025-02-06 18:07:32,354:INFO:           wurlitzer: Not installed
2025-02-06 18:07:32,354:INFO:PyCaret optional dependencies:
2025-02-06 18:07:32,354:INFO:                shap: Not installed
2025-02-06 18:07:32,354:INFO:           interpret: Not installed
2025-02-06 18:07:32,354:INFO:                umap: Not installed
2025-02-06 18:07:32,354:INFO:     ydata_profiling: Not installed
2025-02-06 18:07:32,354:INFO:  explainerdashboard: Not installed
2025-02-06 18:07:32,354:INFO:             autoviz: Not installed
2025-02-06 18:07:32,354:INFO:           fairlearn: Not installed
2025-02-06 18:07:32,354:INFO:          deepchecks: Not installed
2025-02-06 18:07:32,354:INFO:             xgboost: Not installed
2025-02-06 18:07:32,354:INFO:            catboost: Not installed
2025-02-06 18:07:32,354:INFO:              kmodes: Not installed
2025-02-06 18:07:32,354:INFO:             mlxtend: Not installed
2025-02-06 18:07:32,354:INFO:       statsforecast: Not installed
2025-02-06 18:07:32,354:INFO:        tune_sklearn: Not installed
2025-02-06 18:07:32,354:INFO:                 ray: Not installed
2025-02-06 18:07:32,354:INFO:            hyperopt: Not installed
2025-02-06 18:07:32,354:INFO:              optuna: Not installed
2025-02-06 18:07:32,354:INFO:               skopt: Not installed
2025-02-06 18:07:32,354:INFO:              mlflow: Not installed
2025-02-06 18:07:32,354:INFO:              gradio: Not installed
2025-02-06 18:07:32,354:INFO:             fastapi: Not installed
2025-02-06 18:07:32,354:INFO:             uvicorn: Not installed
2025-02-06 18:07:32,354:INFO:              m2cgen: Not installed
2025-02-06 18:07:32,354:INFO:           evidently: Not installed
2025-02-06 18:07:32,354:INFO:               fugue: Not installed
2025-02-06 18:07:32,354:INFO:           streamlit: Not installed
2025-02-06 18:07:32,354:INFO:             prophet: Not installed
2025-02-06 18:07:32,354:INFO:None
2025-02-06 18:07:32,354:INFO:Set up data.
2025-02-06 18:07:32,361:INFO:Set up folding strategy.
2025-02-06 18:07:32,361:INFO:Set up train/test split.
2025-02-06 18:07:32,366:INFO:Set up index.
2025-02-06 18:07:32,366:INFO:Assigning column types.
2025-02-06 18:07:32,371:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:07:32,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,437:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,453:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:07:32,477:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:07:32,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,532:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:07:32,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,612:INFO:Preparing preprocessing pipeline...
2025-02-06 18:07:32,613:INFO:Set up simple imputation.
2025-02-06 18:07:32,632:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:07:32,634:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:07:32,634:INFO:Creating final display dataframe.
2025-02-06 18:07:32,694:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              10c9
2025-02-06 18:07:32,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:07:32,774:INFO:setup() successfully completed in 0.43s...............
2025-02-06 18:07:32,774:INFO:Initializing compare_models()
2025-02-06 18:07:32,774:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:07:32,774:INFO:Checking exceptions
2025-02-06 18:07:32,777:INFO:Preparing display monitor
2025-02-06 18:07:32,788:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:07:32,788:INFO:Total runtime is 0.0 minutes
2025-02-06 18:07:32,790:INFO:SubProcess create_model() called ==================================
2025-02-06 18:07:32,790:INFO:Initializing create_model()
2025-02-06 18:07:32,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EE3350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:32,790:INFO:Checking exceptions
2025-02-06 18:07:32,790:INFO:Importing libraries
2025-02-06 18:07:32,790:INFO:Copying training dataset
2025-02-06 18:07:32,796:INFO:Defining folds
2025-02-06 18:07:32,796:INFO:Declaring metric variables
2025-02-06 18:07:32,798:INFO:Importing untrained model
2025-02-06 18:07:32,799:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:07:32,802:INFO:Starting cross validation
2025-02-06 18:07:32,803:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:07:34,975:INFO:Calculating mean and std
2025-02-06 18:07:34,976:INFO:Creating metrics dataframe
2025-02-06 18:07:34,977:INFO:Uploading results into container
2025-02-06 18:07:34,978:INFO:Uploading model into container now
2025-02-06 18:07:34,978:INFO:_master_model_container: 1
2025-02-06 18:07:34,978:INFO:_display_container: 2
2025-02-06 18:07:34,978:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:34,979:INFO:create_model() successfully completed......................................
2025-02-06 18:07:35,080:INFO:SubProcess create_model() end ==================================
2025-02-06 18:07:35,080:INFO:Creating metrics dataframe
2025-02-06 18:07:35,083:INFO:Initializing Logistic Regression
2025-02-06 18:07:35,083:INFO:Total runtime is 0.03825599749883016 minutes
2025-02-06 18:07:35,085:INFO:SubProcess create_model() called ==================================
2025-02-06 18:07:35,085:INFO:Initializing create_model()
2025-02-06 18:07:35,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EE3350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:35,085:INFO:Checking exceptions
2025-02-06 18:07:35,085:INFO:Importing libraries
2025-02-06 18:07:35,085:INFO:Copying training dataset
2025-02-06 18:07:35,091:INFO:Defining folds
2025-02-06 18:07:35,091:INFO:Declaring metric variables
2025-02-06 18:07:35,093:INFO:Importing untrained model
2025-02-06 18:07:35,096:INFO:Logistic Regression Imported successfully
2025-02-06 18:07:35,099:INFO:Starting cross validation
2025-02-06 18:07:35,099:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:07:36,588:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:07:36,592:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:07:36,593:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:07:36,594:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:07:36,604:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:07:36,623:INFO:Calculating mean and std
2025-02-06 18:07:36,624:INFO:Creating metrics dataframe
2025-02-06 18:07:36,626:INFO:Uploading results into container
2025-02-06 18:07:36,626:INFO:Uploading model into container now
2025-02-06 18:07:36,626:INFO:_master_model_container: 2
2025-02-06 18:07:36,626:INFO:_display_container: 2
2025-02-06 18:07:36,626:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:07:36,627:INFO:create_model() successfully completed......................................
2025-02-06 18:07:36,707:INFO:SubProcess create_model() end ==================================
2025-02-06 18:07:36,708:INFO:Creating metrics dataframe
2025-02-06 18:07:36,711:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:07:36,714:INFO:Initializing create_model()
2025-02-06 18:07:36,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:36,715:INFO:Checking exceptions
2025-02-06 18:07:36,716:INFO:Importing libraries
2025-02-06 18:07:36,716:INFO:Copying training dataset
2025-02-06 18:07:36,721:INFO:Defining folds
2025-02-06 18:07:36,721:INFO:Declaring metric variables
2025-02-06 18:07:36,721:INFO:Importing untrained model
2025-02-06 18:07:36,721:INFO:Declaring custom model
2025-02-06 18:07:36,722:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:07:36,722:INFO:Cross validation set to False
2025-02-06 18:07:36,722:INFO:Fitting Model
2025-02-06 18:07:36,733:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:07:36,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
2025-02-06 18:07:36,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:07:36,734:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:07:36,734:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:07:36,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:07:36,734:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:07:36,806:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:36,806:INFO:create_model() successfully completed......................................
2025-02-06 18:07:36,897:INFO:_master_model_container: 2
2025-02-06 18:07:36,897:INFO:_display_container: 2
2025-02-06 18:07:36,897:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:36,897:INFO:compare_models() successfully completed......................................
2025-02-06 18:07:36,897:INFO:Initializing create_model()
2025-02-06 18:07:36,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:36,898:INFO:Checking exceptions
2025-02-06 18:07:36,904:INFO:Importing libraries
2025-02-06 18:07:36,904:INFO:Copying training dataset
2025-02-06 18:07:36,911:INFO:Defining folds
2025-02-06 18:07:36,911:INFO:Declaring metric variables
2025-02-06 18:07:36,912:INFO:Importing untrained model
2025-02-06 18:07:36,914:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:07:36,917:INFO:Starting cross validation
2025-02-06 18:07:36,918:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:07:38,666:INFO:Calculating mean and std
2025-02-06 18:07:38,667:INFO:Creating metrics dataframe
2025-02-06 18:07:38,670:INFO:Finalizing model
2025-02-06 18:07:38,686:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:07:38,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.
2025-02-06 18:07:38,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:07:38,687:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:07:38,688:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:07:38,688:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:07:38,688:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:07:38,797:INFO:Uploading results into container
2025-02-06 18:07:38,797:INFO:Uploading model into container now
2025-02-06 18:07:38,804:INFO:_master_model_container: 3
2025-02-06 18:07:38,804:INFO:_display_container: 3
2025-02-06 18:07:38,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:38,804:INFO:create_model() successfully completed......................................
2025-02-06 18:07:38,886:INFO:Initializing tune_model()
2025-02-06 18:07:38,886:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:07:38,886:INFO:Checking exceptions
2025-02-06 18:07:38,898:INFO:Copying training dataset
2025-02-06 18:07:38,903:INFO:Checking base model
2025-02-06 18:07:38,903:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:07:38,905:INFO:Declaring metric variables
2025-02-06 18:07:38,906:INFO:Defining Hyperparameters
2025-02-06 18:07:38,997:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:07:38,997:INFO:Tuning with n_jobs=-1
2025-02-06 18:07:38,997:INFO:Initializing RandomizedSearchCV
2025-02-06 18:07:55,309:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:07:55,311:INFO:Hyperparameter search completed
2025-02-06 18:07:55,311:INFO:SubProcess create_model() called ==================================
2025-02-06 18:07:55,311:INFO:Initializing create_model()
2025-02-06 18:07:55,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D66E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:07:55,311:INFO:Checking exceptions
2025-02-06 18:07:55,311:INFO:Importing libraries
2025-02-06 18:07:55,311:INFO:Copying training dataset
2025-02-06 18:07:55,320:INFO:Defining folds
2025-02-06 18:07:55,320:INFO:Declaring metric variables
2025-02-06 18:07:55,323:INFO:Importing untrained model
2025-02-06 18:07:55,323:INFO:Declaring custom model
2025-02-06 18:07:55,326:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:07:55,329:INFO:Starting cross validation
2025-02-06 18:07:55,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:07:58,401:INFO:Calculating mean and std
2025-02-06 18:07:58,402:INFO:Creating metrics dataframe
2025-02-06 18:07:58,405:INFO:Finalizing model
2025-02-06 18:07:58,419:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:07:58,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000758 seconds.
2025-02-06 18:07:58,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:07:58,420:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:07:58,420:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:07:58,420:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:07:58,420:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:07:59,008:INFO:Uploading results into container
2025-02-06 18:07:59,009:INFO:Uploading model into container now
2025-02-06 18:07:59,009:INFO:_master_model_container: 4
2025-02-06 18:07:59,009:INFO:_display_container: 4
2025-02-06 18:07:59,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:59,009:INFO:create_model() successfully completed......................................
2025-02-06 18:07:59,118:INFO:SubProcess create_model() end ==================================
2025-02-06 18:07:59,118:INFO:choose_better activated
2025-02-06 18:07:59,119:INFO:SubProcess create_model() called ==================================
2025-02-06 18:07:59,120:INFO:Initializing create_model()
2025-02-06 18:07:59,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:59,120:INFO:Checking exceptions
2025-02-06 18:07:59,121:INFO:Importing libraries
2025-02-06 18:07:59,121:INFO:Copying training dataset
2025-02-06 18:07:59,127:INFO:Defining folds
2025-02-06 18:07:59,127:INFO:Declaring metric variables
2025-02-06 18:07:59,127:INFO:Importing untrained model
2025-02-06 18:07:59,127:INFO:Declaring custom model
2025-02-06 18:07:59,127:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:07:59,127:INFO:Starting cross validation
2025-02-06 18:07:59,128:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:07:59,571:INFO:Calculating mean and std
2025-02-06 18:07:59,571:INFO:Creating metrics dataframe
2025-02-06 18:07:59,573:INFO:Finalizing model
2025-02-06 18:07:59,586:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:07:59,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.
2025-02-06 18:07:59,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:07:59,587:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:07:59,588:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:07:59,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:07:59,588:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:07:59,712:INFO:Uploading results into container
2025-02-06 18:07:59,713:INFO:Uploading model into container now
2025-02-06 18:07:59,713:INFO:_master_model_container: 5
2025-02-06 18:07:59,713:INFO:_display_container: 5
2025-02-06 18:07:59,714:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:59,714:INFO:create_model() successfully completed......................................
2025-02-06 18:07:59,799:INFO:SubProcess create_model() end ==================================
2025-02-06 18:07:59,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:07:59,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:07:59,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:07:59,799:INFO:choose_better completed
2025-02-06 18:07:59,805:INFO:_master_model_container: 5
2025-02-06 18:07:59,805:INFO:_display_container: 4
2025-02-06 18:07:59,806:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:07:59,806:INFO:tune_model() successfully completed......................................
2025-02-06 18:07:59,876:INFO:Initializing create_model()
2025-02-06 18:07:59,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:07:59,876:INFO:Checking exceptions
2025-02-06 18:07:59,884:INFO:Importing libraries
2025-02-06 18:07:59,884:INFO:Copying training dataset
2025-02-06 18:07:59,890:INFO:Defining folds
2025-02-06 18:07:59,890:INFO:Declaring metric variables
2025-02-06 18:07:59,891:INFO:Importing untrained model
2025-02-06 18:07:59,894:INFO:Logistic Regression Imported successfully
2025-02-06 18:07:59,897:INFO:Starting cross validation
2025-02-06 18:07:59,897:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:08:00,084:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,086:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,090:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,097:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,098:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,118:INFO:Calculating mean and std
2025-02-06 18:08:00,118:INFO:Creating metrics dataframe
2025-02-06 18:08:00,120:INFO:Finalizing model
2025-02-06 18:08:00,531:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,533:INFO:Uploading results into container
2025-02-06 18:08:00,534:INFO:Uploading model into container now
2025-02-06 18:08:00,537:INFO:_master_model_container: 6
2025-02-06 18:08:00,537:INFO:_display_container: 5
2025-02-06 18:08:00,538:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:08:00,538:INFO:create_model() successfully completed......................................
2025-02-06 18:08:00,613:INFO:Initializing tune_model()
2025-02-06 18:08:00,614:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:08:00,614:INFO:Checking exceptions
2025-02-06 18:08:00,622:INFO:Copying training dataset
2025-02-06 18:08:00,625:INFO:Checking base model
2025-02-06 18:08:00,626:INFO:Base model : Logistic Regression
2025-02-06 18:08:00,627:INFO:Declaring metric variables
2025-02-06 18:08:00,628:INFO:Defining Hyperparameters
2025-02-06 18:08:00,697:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:08:00,697:INFO:Tuning with n_jobs=-1
2025-02-06 18:08:00,697:INFO:Initializing RandomizedSearchCV
2025-02-06 18:08:00,765:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,769:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,769:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,775:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,784:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,788:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,793:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,813:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,819:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:00,830:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,269:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,274:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,281:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,297:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,318:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,697:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,720:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,798:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,848:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:01,862:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,024:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:08:02,024:INFO:Hyperparameter search completed
2025-02-06 18:08:02,024:INFO:SubProcess create_model() called ==================================
2025-02-06 18:08:02,025:INFO:Initializing create_model()
2025-02-06 18:08:02,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935A086D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:08:02,025:INFO:Checking exceptions
2025-02-06 18:08:02,025:INFO:Importing libraries
2025-02-06 18:08:02,025:INFO:Copying training dataset
2025-02-06 18:08:02,031:INFO:Defining folds
2025-02-06 18:08:02,031:INFO:Declaring metric variables
2025-02-06 18:08:02,033:INFO:Importing untrained model
2025-02-06 18:08:02,033:INFO:Declaring custom model
2025-02-06 18:08:02,035:INFO:Logistic Regression Imported successfully
2025-02-06 18:08:02,038:INFO:Starting cross validation
2025-02-06 18:08:02,039:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:08:02,400:INFO:Calculating mean and std
2025-02-06 18:08:02,400:INFO:Creating metrics dataframe
2025-02-06 18:08:02,403:INFO:Finalizing model
2025-02-06 18:08:02,652:INFO:Uploading results into container
2025-02-06 18:08:02,653:INFO:Uploading model into container now
2025-02-06 18:08:02,653:INFO:_master_model_container: 7
2025-02-06 18:08:02,653:INFO:_display_container: 6
2025-02-06 18:08:02,653:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:08:02,653:INFO:create_model() successfully completed......................................
2025-02-06 18:08:02,723:INFO:SubProcess create_model() end ==================================
2025-02-06 18:08:02,723:INFO:choose_better activated
2025-02-06 18:08:02,726:INFO:SubProcess create_model() called ==================================
2025-02-06 18:08:02,726:INFO:Initializing create_model()
2025-02-06 18:08:02,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:08:02,726:INFO:Checking exceptions
2025-02-06 18:08:02,727:INFO:Importing libraries
2025-02-06 18:08:02,727:INFO:Copying training dataset
2025-02-06 18:08:02,733:INFO:Defining folds
2025-02-06 18:08:02,733:INFO:Declaring metric variables
2025-02-06 18:08:02,733:INFO:Importing untrained model
2025-02-06 18:08:02,733:INFO:Declaring custom model
2025-02-06 18:08:02,734:INFO:Logistic Regression Imported successfully
2025-02-06 18:08:02,734:INFO:Starting cross validation
2025-02-06 18:08:02,734:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:08:02,912:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,916:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,922:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,929:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,931:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:02,950:INFO:Calculating mean and std
2025-02-06 18:08:02,950:INFO:Creating metrics dataframe
2025-02-06 18:08:02,951:INFO:Finalizing model
2025-02-06 18:08:03,362:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:08:03,362:INFO:Uploading results into container
2025-02-06 18:08:03,362:INFO:Uploading model into container now
2025-02-06 18:08:03,363:INFO:_master_model_container: 8
2025-02-06 18:08:03,363:INFO:_display_container: 7
2025-02-06 18:08:03,363:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:08:03,363:INFO:create_model() successfully completed......................................
2025-02-06 18:08:03,431:INFO:SubProcess create_model() end ==================================
2025-02-06 18:08:03,431:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:08:03,431:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:08:03,431:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:08:03,431:INFO:choose_better completed
2025-02-06 18:08:03,435:INFO:_master_model_container: 8
2025-02-06 18:08:03,435:INFO:_display_container: 6
2025-02-06 18:08:03,435:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:08:03,435:INFO:tune_model() successfully completed......................................
2025-02-06 18:08:03,495:INFO:Initializing compare_models()
2025-02-06 18:08:03,495:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:08:03,495:INFO:Checking exceptions
2025-02-06 18:08:03,498:INFO:Preparing display monitor
2025-02-06 18:08:03,507:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:08:03,507:INFO:Total runtime is 0.0 minutes
2025-02-06 18:08:03,509:INFO:SubProcess create_model() called ==================================
2025-02-06 18:08:03,509:INFO:Initializing create_model()
2025-02-06 18:08:03,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EE3750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:08:03,509:INFO:Checking exceptions
2025-02-06 18:08:03,509:INFO:Importing libraries
2025-02-06 18:08:03,509:INFO:Copying training dataset
2025-02-06 18:08:03,516:INFO:Defining folds
2025-02-06 18:08:03,516:INFO:Declaring metric variables
2025-02-06 18:08:03,518:INFO:Importing untrained model
2025-02-06 18:08:03,518:INFO:Declaring custom model
2025-02-06 18:08:03,519:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:08:03,523:INFO:Starting cross validation
2025-02-06 18:08:03,523:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:08:06,679:INFO:Calculating mean and std
2025-02-06 18:08:06,680:INFO:Creating metrics dataframe
2025-02-06 18:08:06,682:INFO:Uploading results into container
2025-02-06 18:08:06,682:INFO:Uploading model into container now
2025-02-06 18:08:06,683:INFO:_master_model_container: 9
2025-02-06 18:08:06,683:INFO:_display_container: 7
2025-02-06 18:08:06,683:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:08:06,683:INFO:create_model() successfully completed......................................
2025-02-06 18:08:06,765:INFO:SubProcess create_model() end ==================================
2025-02-06 18:08:06,765:INFO:Creating metrics dataframe
2025-02-06 18:08:06,768:INFO:Initializing custom model Logistic Regression
2025-02-06 18:08:06,768:INFO:Total runtime is 0.05435712734858195 minutes
2025-02-06 18:08:06,769:INFO:SubProcess create_model() called ==================================
2025-02-06 18:08:06,769:INFO:Initializing create_model()
2025-02-06 18:08:06,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EE3750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:08:06,769:INFO:Checking exceptions
2025-02-06 18:08:06,769:INFO:Importing libraries
2025-02-06 18:08:06,769:INFO:Copying training dataset
2025-02-06 18:08:06,776:INFO:Defining folds
2025-02-06 18:08:06,776:INFO:Declaring metric variables
2025-02-06 18:08:06,777:INFO:Importing untrained model
2025-02-06 18:08:06,777:INFO:Declaring custom model
2025-02-06 18:08:06,779:INFO:Logistic Regression Imported successfully
2025-02-06 18:08:06,782:INFO:Starting cross validation
2025-02-06 18:08:06,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:08:07,136:INFO:Calculating mean and std
2025-02-06 18:08:07,137:INFO:Creating metrics dataframe
2025-02-06 18:08:07,138:INFO:Uploading results into container
2025-02-06 18:08:07,138:INFO:Uploading model into container now
2025-02-06 18:08:07,138:INFO:_master_model_container: 10
2025-02-06 18:08:07,138:INFO:_display_container: 7
2025-02-06 18:08:07,138:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:08:07,139:INFO:create_model() successfully completed......................................
2025-02-06 18:08:07,210:INFO:SubProcess create_model() end ==================================
2025-02-06 18:08:07,210:INFO:Creating metrics dataframe
2025-02-06 18:08:07,213:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:08:07,217:INFO:Initializing create_model()
2025-02-06 18:08:07,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:08:07,217:INFO:Checking exceptions
2025-02-06 18:08:07,218:INFO:Importing libraries
2025-02-06 18:08:07,218:INFO:Copying training dataset
2025-02-06 18:08:07,224:INFO:Defining folds
2025-02-06 18:08:07,224:INFO:Declaring metric variables
2025-02-06 18:08:07,224:INFO:Importing untrained model
2025-02-06 18:08:07,224:INFO:Declaring custom model
2025-02-06 18:08:07,224:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:08:07,225:INFO:Cross validation set to False
2025-02-06 18:08:07,225:INFO:Fitting Model
2025-02-06 18:08:07,236:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:08:07,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-02-06 18:08:07,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:08:07,237:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:08:07,238:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:08:07,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:08:07,238:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:08:07,839:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:08:07,839:INFO:create_model() successfully completed......................................
2025-02-06 18:08:07,934:INFO:_master_model_container: 10
2025-02-06 18:08:07,934:INFO:_display_container: 7
2025-02-06 18:08:07,935:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:08:07,935:INFO:compare_models() successfully completed......................................
2025-02-06 18:08:07,935:INFO:Initializing predict_model()
2025-02-06 18:08:07,935:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021937B76520>)
2025-02-06 18:08:07,935:INFO:Checking exceptions
2025-02-06 18:08:07,935:INFO:Preloading libraries
2025-02-06 18:08:07,936:INFO:Set up data.
2025-02-06 18:08:07,944:INFO:Set up index.
2025-02-06 18:08:08,121:INFO:Initializing predict_model()
2025-02-06 18:08:08,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021971C6D260>)
2025-02-06 18:08:08,121:INFO:Checking exceptions
2025-02-06 18:08:08,121:INFO:Preloading libraries
2025-02-06 18:08:08,122:INFO:Set up data.
2025-02-06 18:08:08,126:INFO:Set up index.
2025-02-06 18:08:08,244:INFO:Initializing predict_model()
2025-02-06 18:08:08,244:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935F972E0>)
2025-02-06 18:08:08,244:INFO:Checking exceptions
2025-02-06 18:08:08,244:INFO:Preloading libraries
2025-02-06 18:08:08,246:INFO:Set up data.
2025-02-06 18:08:08,252:INFO:Set up index.
2025-02-06 18:08:08,347:INFO:Initializing predict_model()
2025-02-06 18:08:08,347:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935F15F50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935F972E0>)
2025-02-06 18:08:08,347:INFO:Checking exceptions
2025-02-06 18:08:08,347:INFO:Preloading libraries
2025-02-06 18:08:08,348:INFO:Set up data.
2025-02-06 18:08:08,352:INFO:Set up index.
2025-02-06 18:16:39,253:INFO:PyCaret ClassificationExperiment
2025-02-06 18:16:39,253:INFO:Logging name: clf-default-name
2025-02-06 18:16:39,253:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:16:39,253:INFO:version 3.3.2
2025-02-06 18:16:39,253:INFO:Initializing setup()
2025-02-06 18:16:39,253:INFO:self.USI: a0ae
2025-02-06 18:16:39,253:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:16:39,253:INFO:Checking environment
2025-02-06 18:16:39,253:INFO:python_version: 3.11.9
2025-02-06 18:16:39,253:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:16:39,253:INFO:machine: AMD64
2025-02-06 18:16:39,253:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:16:39,259:INFO:Memory: svmem(total=67771465728, available=48764833792, percent=28.0, used=19006631936, free=48764833792)
2025-02-06 18:16:39,259:INFO:Physical Core: 8
2025-02-06 18:16:39,259:INFO:Logical Core: 16
2025-02-06 18:16:39,259:INFO:Checking libraries
2025-02-06 18:16:39,259:INFO:System:
2025-02-06 18:16:39,259:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:16:39,259:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:16:39,259:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:16:39,259:INFO:PyCaret required dependencies:
2025-02-06 18:16:39,259:INFO:                 pip: 25.0
2025-02-06 18:16:39,259:INFO:          setuptools: 65.5.0
2025-02-06 18:16:39,259:INFO:             pycaret: 3.3.2
2025-02-06 18:16:39,259:INFO:             IPython: 8.32.0
2025-02-06 18:16:39,259:INFO:          ipywidgets: 8.1.5
2025-02-06 18:16:39,259:INFO:                tqdm: 4.67.1
2025-02-06 18:16:39,259:INFO:               numpy: 1.26.4
2025-02-06 18:16:39,259:INFO:              pandas: 2.1.4
2025-02-06 18:16:39,259:INFO:              jinja2: 3.1.5
2025-02-06 18:16:39,259:INFO:               scipy: 1.11.4
2025-02-06 18:16:39,259:INFO:              joblib: 1.3.2
2025-02-06 18:16:39,259:INFO:             sklearn: 1.4.2
2025-02-06 18:16:39,259:INFO:                pyod: 2.0.3
2025-02-06 18:16:39,259:INFO:            imblearn: 0.13.0
2025-02-06 18:16:39,259:INFO:   category_encoders: 2.7.0
2025-02-06 18:16:39,259:INFO:            lightgbm: 4.5.0
2025-02-06 18:16:39,259:INFO:               numba: 0.61.0
2025-02-06 18:16:39,259:INFO:            requests: 2.32.3
2025-02-06 18:16:39,259:INFO:          matplotlib: 3.7.5
2025-02-06 18:16:39,259:INFO:          scikitplot: 0.3.7
2025-02-06 18:16:39,259:INFO:         yellowbrick: 1.5
2025-02-06 18:16:39,260:INFO:              plotly: 5.24.1
2025-02-06 18:16:39,260:INFO:    plotly-resampler: Not installed
2025-02-06 18:16:39,260:INFO:             kaleido: 0.2.1
2025-02-06 18:16:39,260:INFO:           schemdraw: 0.15
2025-02-06 18:16:39,260:INFO:         statsmodels: 0.14.4
2025-02-06 18:16:39,260:INFO:              sktime: 0.26.0
2025-02-06 18:16:39,260:INFO:               tbats: 1.1.3
2025-02-06 18:16:39,260:INFO:            pmdarima: 2.0.4
2025-02-06 18:16:39,260:INFO:              psutil: 6.1.1
2025-02-06 18:16:39,260:INFO:          markupsafe: 3.0.2
2025-02-06 18:16:39,260:INFO:             pickle5: Not installed
2025-02-06 18:16:39,260:INFO:         cloudpickle: 3.1.1
2025-02-06 18:16:39,260:INFO:         deprecation: 2.1.0
2025-02-06 18:16:39,260:INFO:              xxhash: 3.5.0
2025-02-06 18:16:39,260:INFO:           wurlitzer: Not installed
2025-02-06 18:16:39,260:INFO:PyCaret optional dependencies:
2025-02-06 18:16:39,260:INFO:                shap: Not installed
2025-02-06 18:16:39,260:INFO:           interpret: Not installed
2025-02-06 18:16:39,260:INFO:                umap: Not installed
2025-02-06 18:16:39,260:INFO:     ydata_profiling: Not installed
2025-02-06 18:16:39,260:INFO:  explainerdashboard: Not installed
2025-02-06 18:16:39,260:INFO:             autoviz: Not installed
2025-02-06 18:16:39,260:INFO:           fairlearn: Not installed
2025-02-06 18:16:39,260:INFO:          deepchecks: Not installed
2025-02-06 18:16:39,260:INFO:             xgboost: Not installed
2025-02-06 18:16:39,260:INFO:            catboost: Not installed
2025-02-06 18:16:39,260:INFO:              kmodes: Not installed
2025-02-06 18:16:39,260:INFO:             mlxtend: Not installed
2025-02-06 18:16:39,260:INFO:       statsforecast: Not installed
2025-02-06 18:16:39,260:INFO:        tune_sklearn: Not installed
2025-02-06 18:16:39,260:INFO:                 ray: Not installed
2025-02-06 18:16:39,260:INFO:            hyperopt: Not installed
2025-02-06 18:16:39,260:INFO:              optuna: Not installed
2025-02-06 18:16:39,260:INFO:               skopt: Not installed
2025-02-06 18:16:39,260:INFO:              mlflow: Not installed
2025-02-06 18:16:39,260:INFO:              gradio: Not installed
2025-02-06 18:16:39,260:INFO:             fastapi: Not installed
2025-02-06 18:16:39,260:INFO:             uvicorn: Not installed
2025-02-06 18:16:39,260:INFO:              m2cgen: Not installed
2025-02-06 18:16:39,260:INFO:           evidently: Not installed
2025-02-06 18:16:39,260:INFO:               fugue: Not installed
2025-02-06 18:16:39,260:INFO:           streamlit: Not installed
2025-02-06 18:16:39,260:INFO:             prophet: Not installed
2025-02-06 18:16:39,260:INFO:None
2025-02-06 18:16:39,261:INFO:Set up data.
2025-02-06 18:16:39,269:INFO:Set up folding strategy.
2025-02-06 18:16:39,269:INFO:Set up train/test split.
2025-02-06 18:16:39,276:INFO:Set up index.
2025-02-06 18:16:39,276:INFO:Assigning column types.
2025-02-06 18:16:39,283:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:16:39,311:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,366:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:16:39,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:16:39,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,445:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:16:39,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,523:INFO:Preparing preprocessing pipeline...
2025-02-06 18:16:39,524:INFO:Set up simple imputation.
2025-02-06 18:16:39,544:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:16:39,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:16:39,546:INFO:Creating final display dataframe.
2025-02-06 18:16:39,606:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a0ae
2025-02-06 18:16:39,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:16:39,685:INFO:setup() successfully completed in 0.43s...............
2025-02-06 18:16:39,686:INFO:Initializing compare_models()
2025-02-06 18:16:39,686:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:16:39,686:INFO:Checking exceptions
2025-02-06 18:16:39,689:INFO:Preparing display monitor
2025-02-06 18:16:39,699:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:16:39,699:INFO:Total runtime is 0.0 minutes
2025-02-06 18:16:39,702:INFO:SubProcess create_model() called ==================================
2025-02-06 18:16:39,702:INFO:Initializing create_model()
2025-02-06 18:16:39,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBF0250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:16:39,702:INFO:Checking exceptions
2025-02-06 18:16:39,702:INFO:Importing libraries
2025-02-06 18:16:39,702:INFO:Copying training dataset
2025-02-06 18:16:39,708:INFO:Defining folds
2025-02-06 18:16:39,708:INFO:Declaring metric variables
2025-02-06 18:16:39,709:INFO:Importing untrained model
2025-02-06 18:16:39,711:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:16:39,714:INFO:Starting cross validation
2025-02-06 18:16:39,714:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:16:41,800:INFO:Calculating mean and std
2025-02-06 18:16:41,800:INFO:Creating metrics dataframe
2025-02-06 18:16:41,802:INFO:Uploading results into container
2025-02-06 18:16:41,803:INFO:Uploading model into container now
2025-02-06 18:16:41,803:INFO:_master_model_container: 1
2025-02-06 18:16:41,803:INFO:_display_container: 2
2025-02-06 18:16:41,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:16:41,804:INFO:create_model() successfully completed......................................
2025-02-06 18:16:41,919:INFO:SubProcess create_model() end ==================================
2025-02-06 18:16:41,919:INFO:Creating metrics dataframe
2025-02-06 18:16:41,922:INFO:Initializing Logistic Regression
2025-02-06 18:16:41,922:INFO:Total runtime is 0.037052412827809654 minutes
2025-02-06 18:16:41,924:INFO:SubProcess create_model() called ==================================
2025-02-06 18:16:41,924:INFO:Initializing create_model()
2025-02-06 18:16:41,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBF0250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:16:41,924:INFO:Checking exceptions
2025-02-06 18:16:41,924:INFO:Importing libraries
2025-02-06 18:16:41,924:INFO:Copying training dataset
2025-02-06 18:16:41,930:INFO:Defining folds
2025-02-06 18:16:41,930:INFO:Declaring metric variables
2025-02-06 18:16:41,932:INFO:Importing untrained model
2025-02-06 18:16:41,934:INFO:Logistic Regression Imported successfully
2025-02-06 18:16:41,937:INFO:Starting cross validation
2025-02-06 18:16:41,937:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:16:43,444:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:16:43,449:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:16:43,451:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:16:43,461:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:16:43,462:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:16:43,475:INFO:Calculating mean and std
2025-02-06 18:16:43,476:INFO:Creating metrics dataframe
2025-02-06 18:16:43,477:INFO:Uploading results into container
2025-02-06 18:16:43,477:INFO:Uploading model into container now
2025-02-06 18:16:43,477:INFO:_master_model_container: 2
2025-02-06 18:16:43,477:INFO:_display_container: 2
2025-02-06 18:16:43,477:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:16:43,477:INFO:create_model() successfully completed......................................
2025-02-06 18:16:43,556:INFO:SubProcess create_model() end ==================================
2025-02-06 18:16:43,556:INFO:Creating metrics dataframe
2025-02-06 18:16:43,560:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:16:43,564:INFO:Initializing create_model()
2025-02-06 18:16:43,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:16:43,564:INFO:Checking exceptions
2025-02-06 18:16:43,564:INFO:Importing libraries
2025-02-06 18:16:43,564:INFO:Copying training dataset
2025-02-06 18:16:43,570:INFO:Defining folds
2025-02-06 18:16:43,571:INFO:Declaring metric variables
2025-02-06 18:16:43,571:INFO:Importing untrained model
2025-02-06 18:16:43,571:INFO:Declaring custom model
2025-02-06 18:16:43,571:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:16:43,571:INFO:Cross validation set to False
2025-02-06 18:16:43,571:INFO:Fitting Model
2025-02-06 18:16:43,582:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:16:43,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.
2025-02-06 18:16:43,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:16:43,583:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:16:43,583:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:16:43,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:16:43,583:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:16:43,656:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:16:43,656:INFO:create_model() successfully completed......................................
2025-02-06 18:16:43,755:INFO:_master_model_container: 2
2025-02-06 18:16:43,755:INFO:_display_container: 2
2025-02-06 18:16:43,756:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:16:43,756:INFO:compare_models() successfully completed......................................
2025-02-06 18:16:43,756:INFO:Initializing create_model()
2025-02-06 18:16:43,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:16:43,756:INFO:Checking exceptions
2025-02-06 18:16:43,763:INFO:Importing libraries
2025-02-06 18:16:43,764:INFO:Copying training dataset
2025-02-06 18:16:43,770:INFO:Defining folds
2025-02-06 18:16:43,770:INFO:Declaring metric variables
2025-02-06 18:16:43,771:INFO:Importing untrained model
2025-02-06 18:16:43,773:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:16:43,775:INFO:Starting cross validation
2025-02-06 18:16:43,776:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:16:45,565:INFO:Calculating mean and std
2025-02-06 18:16:45,567:INFO:Creating metrics dataframe
2025-02-06 18:16:45,570:INFO:Finalizing model
2025-02-06 18:16:45,585:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:16:45,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000803 seconds.
2025-02-06 18:16:45,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:16:45,586:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:16:45,586:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:16:45,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:16:45,587:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:16:45,695:INFO:Uploading results into container
2025-02-06 18:16:45,696:INFO:Uploading model into container now
2025-02-06 18:16:45,701:INFO:_master_model_container: 3
2025-02-06 18:16:45,701:INFO:_display_container: 3
2025-02-06 18:16:45,701:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:16:45,702:INFO:create_model() successfully completed......................................
2025-02-06 18:16:45,792:INFO:Initializing tune_model()
2025-02-06 18:16:45,792:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:16:45,792:INFO:Checking exceptions
2025-02-06 18:16:45,801:INFO:Copying training dataset
2025-02-06 18:16:45,805:INFO:Checking base model
2025-02-06 18:16:45,805:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:16:45,806:INFO:Declaring metric variables
2025-02-06 18:16:45,808:INFO:Defining Hyperparameters
2025-02-06 18:16:45,880:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:16:45,880:INFO:Tuning with n_jobs=-1
2025-02-06 18:16:45,881:INFO:Initializing RandomizedSearchCV
2025-02-06 18:17:03,006:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:17:03,007:INFO:Hyperparameter search completed
2025-02-06 18:17:03,007:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:03,009:INFO:Initializing create_model()
2025-02-06 18:17:03,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D61150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:17:03,009:INFO:Checking exceptions
2025-02-06 18:17:03,009:INFO:Importing libraries
2025-02-06 18:17:03,009:INFO:Copying training dataset
2025-02-06 18:17:03,020:INFO:Defining folds
2025-02-06 18:17:03,020:INFO:Declaring metric variables
2025-02-06 18:17:03,023:INFO:Importing untrained model
2025-02-06 18:17:03,023:INFO:Declaring custom model
2025-02-06 18:17:03,026:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:03,030:INFO:Starting cross validation
2025-02-06 18:17:03,032:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:06,546:INFO:Calculating mean and std
2025-02-06 18:17:06,547:INFO:Creating metrics dataframe
2025-02-06 18:17:06,551:INFO:Finalizing model
2025-02-06 18:17:06,565:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:06,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000852 seconds.
2025-02-06 18:17:06,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:06,567:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:06,567:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:06,567:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:06,567:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:07,296:INFO:Uploading results into container
2025-02-06 18:17:07,297:INFO:Uploading model into container now
2025-02-06 18:17:07,298:INFO:_master_model_container: 4
2025-02-06 18:17:07,298:INFO:_display_container: 4
2025-02-06 18:17:07,298:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:07,298:INFO:create_model() successfully completed......................................
2025-02-06 18:17:07,403:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:07,403:INFO:choose_better activated
2025-02-06 18:17:07,405:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:07,405:INFO:Initializing create_model()
2025-02-06 18:17:07,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:07,406:INFO:Checking exceptions
2025-02-06 18:17:07,406:INFO:Importing libraries
2025-02-06 18:17:07,406:INFO:Copying training dataset
2025-02-06 18:17:07,414:INFO:Defining folds
2025-02-06 18:17:07,414:INFO:Declaring metric variables
2025-02-06 18:17:07,414:INFO:Importing untrained model
2025-02-06 18:17:07,414:INFO:Declaring custom model
2025-02-06 18:17:07,414:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:07,415:INFO:Starting cross validation
2025-02-06 18:17:07,415:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:07,856:INFO:Calculating mean and std
2025-02-06 18:17:07,856:INFO:Creating metrics dataframe
2025-02-06 18:17:07,857:INFO:Finalizing model
2025-02-06 18:17:07,872:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:07,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
2025-02-06 18:17:07,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:07,873:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:07,873:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:07,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:07,873:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:07,995:INFO:Uploading results into container
2025-02-06 18:17:07,995:INFO:Uploading model into container now
2025-02-06 18:17:07,996:INFO:_master_model_container: 5
2025-02-06 18:17:07,996:INFO:_display_container: 5
2025-02-06 18:17:07,996:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:07,996:INFO:create_model() successfully completed......................................
2025-02-06 18:17:08,087:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:08,087:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:17:08,087:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:17:08,088:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:17:08,088:INFO:choose_better completed
2025-02-06 18:17:08,094:INFO:_master_model_container: 5
2025-02-06 18:17:08,094:INFO:_display_container: 4
2025-02-06 18:17:08,094:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:08,094:INFO:tune_model() successfully completed......................................
2025-02-06 18:17:08,157:INFO:Initializing create_model()
2025-02-06 18:17:08,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:08,157:INFO:Checking exceptions
2025-02-06 18:17:08,164:INFO:Importing libraries
2025-02-06 18:17:08,165:INFO:Copying training dataset
2025-02-06 18:17:08,170:INFO:Defining folds
2025-02-06 18:17:08,170:INFO:Declaring metric variables
2025-02-06 18:17:08,171:INFO:Importing untrained model
2025-02-06 18:17:08,174:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:08,177:INFO:Starting cross validation
2025-02-06 18:17:08,177:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:08,354:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,357:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,380:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,391:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,402:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,416:INFO:Calculating mean and std
2025-02-06 18:17:08,416:INFO:Creating metrics dataframe
2025-02-06 18:17:08,419:INFO:Finalizing model
2025-02-06 18:17:08,839:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:08,842:INFO:Uploading results into container
2025-02-06 18:17:08,843:INFO:Uploading model into container now
2025-02-06 18:17:08,847:INFO:_master_model_container: 6
2025-02-06 18:17:08,847:INFO:_display_container: 5
2025-02-06 18:17:08,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:08,847:INFO:create_model() successfully completed......................................
2025-02-06 18:17:08,920:INFO:Initializing tune_model()
2025-02-06 18:17:08,920:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:17:08,920:INFO:Checking exceptions
2025-02-06 18:17:08,929:INFO:Copying training dataset
2025-02-06 18:17:08,932:INFO:Checking base model
2025-02-06 18:17:08,932:INFO:Base model : Logistic Regression
2025-02-06 18:17:08,934:INFO:Declaring metric variables
2025-02-06 18:17:08,935:INFO:Defining Hyperparameters
2025-02-06 18:17:09,022:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:17:09,022:INFO:Tuning with n_jobs=-1
2025-02-06 18:17:09,022:INFO:Initializing RandomizedSearchCV
2025-02-06 18:17:09,092:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,095:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,097:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,098:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,104:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,105:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,107:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,116:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,120:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,120:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,539:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,541:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,547:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,547:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,579:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,827:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,835:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,881:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,945:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:09,981:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:10,068:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:17:10,069:INFO:Hyperparameter search completed
2025-02-06 18:17:10,069:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:10,069:INFO:Initializing create_model()
2025-02-06 18:17:10,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935C38A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:17:10,069:INFO:Checking exceptions
2025-02-06 18:17:10,069:INFO:Importing libraries
2025-02-06 18:17:10,069:INFO:Copying training dataset
2025-02-06 18:17:10,075:INFO:Defining folds
2025-02-06 18:17:10,075:INFO:Declaring metric variables
2025-02-06 18:17:10,077:INFO:Importing untrained model
2025-02-06 18:17:10,077:INFO:Declaring custom model
2025-02-06 18:17:10,078:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:10,081:INFO:Starting cross validation
2025-02-06 18:17:10,081:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:10,454:INFO:Calculating mean and std
2025-02-06 18:17:10,455:INFO:Creating metrics dataframe
2025-02-06 18:17:10,458:INFO:Finalizing model
2025-02-06 18:17:10,709:INFO:Uploading results into container
2025-02-06 18:17:10,709:INFO:Uploading model into container now
2025-02-06 18:17:10,709:INFO:_master_model_container: 7
2025-02-06 18:17:10,709:INFO:_display_container: 6
2025-02-06 18:17:10,710:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:10,710:INFO:create_model() successfully completed......................................
2025-02-06 18:17:10,784:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:10,784:INFO:choose_better activated
2025-02-06 18:17:10,785:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:10,786:INFO:Initializing create_model()
2025-02-06 18:17:10,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:10,786:INFO:Checking exceptions
2025-02-06 18:17:10,787:INFO:Importing libraries
2025-02-06 18:17:10,787:INFO:Copying training dataset
2025-02-06 18:17:10,793:INFO:Defining folds
2025-02-06 18:17:10,793:INFO:Declaring metric variables
2025-02-06 18:17:10,793:INFO:Importing untrained model
2025-02-06 18:17:10,793:INFO:Declaring custom model
2025-02-06 18:17:10,793:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:10,793:INFO:Starting cross validation
2025-02-06 18:17:10,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:10,966:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:10,971:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:10,977:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:10,977:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:10,992:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:11,004:INFO:Calculating mean and std
2025-02-06 18:17:11,004:INFO:Creating metrics dataframe
2025-02-06 18:17:11,004:INFO:Finalizing model
2025-02-06 18:17:11,416:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:11,417:INFO:Uploading results into container
2025-02-06 18:17:11,417:INFO:Uploading model into container now
2025-02-06 18:17:11,417:INFO:_master_model_container: 8
2025-02-06 18:17:11,417:INFO:_display_container: 7
2025-02-06 18:17:11,417:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:11,417:INFO:create_model() successfully completed......................................
2025-02-06 18:17:11,492:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:11,492:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:17:11,492:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:17:11,493:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:17:11,493:INFO:choose_better completed
2025-02-06 18:17:11,497:INFO:_master_model_container: 8
2025-02-06 18:17:11,497:INFO:_display_container: 6
2025-02-06 18:17:11,497:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:11,497:INFO:tune_model() successfully completed......................................
2025-02-06 18:17:11,566:INFO:Initializing compare_models()
2025-02-06 18:17:11,566:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:17:11,566:INFO:Checking exceptions
2025-02-06 18:17:11,568:INFO:Preparing display monitor
2025-02-06 18:17:11,577:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:17:11,578:INFO:Total runtime is 1.6748905181884766e-05 minutes
2025-02-06 18:17:11,579:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:11,580:INFO:Initializing create_model()
2025-02-06 18:17:11,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937886810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:11,580:INFO:Checking exceptions
2025-02-06 18:17:11,580:INFO:Importing libraries
2025-02-06 18:17:11,580:INFO:Copying training dataset
2025-02-06 18:17:11,586:INFO:Defining folds
2025-02-06 18:17:11,586:INFO:Declaring metric variables
2025-02-06 18:17:11,587:INFO:Importing untrained model
2025-02-06 18:17:11,587:INFO:Declaring custom model
2025-02-06 18:17:11,589:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:11,592:INFO:Starting cross validation
2025-02-06 18:17:11,592:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:15,049:INFO:Calculating mean and std
2025-02-06 18:17:15,050:INFO:Creating metrics dataframe
2025-02-06 18:17:15,051:INFO:Uploading results into container
2025-02-06 18:17:15,052:INFO:Uploading model into container now
2025-02-06 18:17:15,053:INFO:_master_model_container: 9
2025-02-06 18:17:15,053:INFO:_display_container: 7
2025-02-06 18:17:15,053:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:15,053:INFO:create_model() successfully completed......................................
2025-02-06 18:17:15,145:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:15,146:INFO:Creating metrics dataframe
2025-02-06 18:17:15,149:INFO:Initializing custom model Logistic Regression
2025-02-06 18:17:15,149:INFO:Total runtime is 0.059529717763264975 minutes
2025-02-06 18:17:15,151:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:15,151:INFO:Initializing create_model()
2025-02-06 18:17:15,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937886810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:15,151:INFO:Checking exceptions
2025-02-06 18:17:15,151:INFO:Importing libraries
2025-02-06 18:17:15,151:INFO:Copying training dataset
2025-02-06 18:17:15,157:INFO:Defining folds
2025-02-06 18:17:15,157:INFO:Declaring metric variables
2025-02-06 18:17:15,159:INFO:Importing untrained model
2025-02-06 18:17:15,159:INFO:Declaring custom model
2025-02-06 18:17:15,161:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:15,164:INFO:Starting cross validation
2025-02-06 18:17:15,164:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:15,508:INFO:Calculating mean and std
2025-02-06 18:17:15,509:INFO:Creating metrics dataframe
2025-02-06 18:17:15,510:INFO:Uploading results into container
2025-02-06 18:17:15,510:INFO:Uploading model into container now
2025-02-06 18:17:15,511:INFO:_master_model_container: 10
2025-02-06 18:17:15,511:INFO:_display_container: 7
2025-02-06 18:17:15,511:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:15,511:INFO:create_model() successfully completed......................................
2025-02-06 18:17:15,588:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:15,588:INFO:Creating metrics dataframe
2025-02-06 18:17:15,592:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:17:15,595:INFO:Initializing create_model()
2025-02-06 18:17:15,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:15,595:INFO:Checking exceptions
2025-02-06 18:17:15,596:INFO:Importing libraries
2025-02-06 18:17:15,596:INFO:Copying training dataset
2025-02-06 18:17:15,602:INFO:Defining folds
2025-02-06 18:17:15,602:INFO:Declaring metric variables
2025-02-06 18:17:15,602:INFO:Importing untrained model
2025-02-06 18:17:15,602:INFO:Declaring custom model
2025-02-06 18:17:15,603:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:15,603:INFO:Cross validation set to False
2025-02-06 18:17:15,603:INFO:Fitting Model
2025-02-06 18:17:15,616:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:15,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.
2025-02-06 18:17:15,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:15,618:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:15,618:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:15,619:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:15,619:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:16,346:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:16,347:INFO:create_model() successfully completed......................................
2025-02-06 18:17:16,445:INFO:_master_model_container: 10
2025-02-06 18:17:16,445:INFO:_display_container: 7
2025-02-06 18:17:16,445:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:16,445:INFO:compare_models() successfully completed......................................
2025-02-06 18:17:16,446:INFO:Initializing predict_model()
2025-02-06 18:17:16,446:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81440>)
2025-02-06 18:17:16,446:INFO:Checking exceptions
2025-02-06 18:17:16,446:INFO:Preloading libraries
2025-02-06 18:17:16,447:INFO:Set up data.
2025-02-06 18:17:16,454:INFO:Set up index.
2025-02-06 18:17:16,615:INFO:Initializing predict_model()
2025-02-06 18:17:16,615:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81440>)
2025-02-06 18:17:16,615:INFO:Checking exceptions
2025-02-06 18:17:16,615:INFO:Preloading libraries
2025-02-06 18:17:16,616:INFO:Set up data.
2025-02-06 18:17:16,620:INFO:Set up index.
2025-02-06 18:17:16,739:INFO:Initializing predict_model()
2025-02-06 18:17:16,740:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81440>)
2025-02-06 18:17:16,740:INFO:Checking exceptions
2025-02-06 18:17:16,740:INFO:Preloading libraries
2025-02-06 18:17:16,741:INFO:Set up data.
2025-02-06 18:17:16,748:INFO:Set up index.
2025-02-06 18:17:16,857:INFO:Initializing predict_model()
2025-02-06 18:17:16,857:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935D3C290>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81440>)
2025-02-06 18:17:16,857:INFO:Checking exceptions
2025-02-06 18:17:16,857:INFO:Preloading libraries
2025-02-06 18:17:16,858:INFO:Set up data.
2025-02-06 18:17:16,862:INFO:Set up index.
2025-02-06 18:17:26,718:INFO:PyCaret ClassificationExperiment
2025-02-06 18:17:26,718:INFO:Logging name: clf-default-name
2025-02-06 18:17:26,718:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:17:26,718:INFO:version 3.3.2
2025-02-06 18:17:26,718:INFO:Initializing setup()
2025-02-06 18:17:26,718:INFO:self.USI: a559
2025-02-06 18:17:26,718:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:17:26,718:INFO:Checking environment
2025-02-06 18:17:26,718:INFO:python_version: 3.11.9
2025-02-06 18:17:26,718:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:17:26,718:INFO:machine: AMD64
2025-02-06 18:17:26,718:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:17:26,722:INFO:Memory: svmem(total=67771465728, available=46260056064, percent=31.7, used=21511409664, free=46260056064)
2025-02-06 18:17:26,722:INFO:Physical Core: 8
2025-02-06 18:17:26,722:INFO:Logical Core: 16
2025-02-06 18:17:26,722:INFO:Checking libraries
2025-02-06 18:17:26,722:INFO:System:
2025-02-06 18:17:26,722:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:17:26,722:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:17:26,722:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:17:26,722:INFO:PyCaret required dependencies:
2025-02-06 18:17:26,722:INFO:                 pip: 25.0
2025-02-06 18:17:26,722:INFO:          setuptools: 65.5.0
2025-02-06 18:17:26,722:INFO:             pycaret: 3.3.2
2025-02-06 18:17:26,722:INFO:             IPython: 8.32.0
2025-02-06 18:17:26,722:INFO:          ipywidgets: 8.1.5
2025-02-06 18:17:26,722:INFO:                tqdm: 4.67.1
2025-02-06 18:17:26,723:INFO:               numpy: 1.26.4
2025-02-06 18:17:26,723:INFO:              pandas: 2.1.4
2025-02-06 18:17:26,723:INFO:              jinja2: 3.1.5
2025-02-06 18:17:26,723:INFO:               scipy: 1.11.4
2025-02-06 18:17:26,723:INFO:              joblib: 1.3.2
2025-02-06 18:17:26,723:INFO:             sklearn: 1.4.2
2025-02-06 18:17:26,723:INFO:                pyod: 2.0.3
2025-02-06 18:17:26,723:INFO:            imblearn: 0.13.0
2025-02-06 18:17:26,723:INFO:   category_encoders: 2.7.0
2025-02-06 18:17:26,723:INFO:            lightgbm: 4.5.0
2025-02-06 18:17:26,723:INFO:               numba: 0.61.0
2025-02-06 18:17:26,723:INFO:            requests: 2.32.3
2025-02-06 18:17:26,723:INFO:          matplotlib: 3.7.5
2025-02-06 18:17:26,723:INFO:          scikitplot: 0.3.7
2025-02-06 18:17:26,723:INFO:         yellowbrick: 1.5
2025-02-06 18:17:26,723:INFO:              plotly: 5.24.1
2025-02-06 18:17:26,723:INFO:    plotly-resampler: Not installed
2025-02-06 18:17:26,723:INFO:             kaleido: 0.2.1
2025-02-06 18:17:26,723:INFO:           schemdraw: 0.15
2025-02-06 18:17:26,723:INFO:         statsmodels: 0.14.4
2025-02-06 18:17:26,723:INFO:              sktime: 0.26.0
2025-02-06 18:17:26,723:INFO:               tbats: 1.1.3
2025-02-06 18:17:26,723:INFO:            pmdarima: 2.0.4
2025-02-06 18:17:26,723:INFO:              psutil: 6.1.1
2025-02-06 18:17:26,723:INFO:          markupsafe: 3.0.2
2025-02-06 18:17:26,723:INFO:             pickle5: Not installed
2025-02-06 18:17:26,723:INFO:         cloudpickle: 3.1.1
2025-02-06 18:17:26,723:INFO:         deprecation: 2.1.0
2025-02-06 18:17:26,723:INFO:              xxhash: 3.5.0
2025-02-06 18:17:26,723:INFO:           wurlitzer: Not installed
2025-02-06 18:17:26,723:INFO:PyCaret optional dependencies:
2025-02-06 18:17:26,723:INFO:                shap: Not installed
2025-02-06 18:17:26,724:INFO:           interpret: Not installed
2025-02-06 18:17:26,724:INFO:                umap: Not installed
2025-02-06 18:17:26,724:INFO:     ydata_profiling: Not installed
2025-02-06 18:17:26,724:INFO:  explainerdashboard: Not installed
2025-02-06 18:17:26,724:INFO:             autoviz: Not installed
2025-02-06 18:17:26,724:INFO:           fairlearn: Not installed
2025-02-06 18:17:26,724:INFO:          deepchecks: Not installed
2025-02-06 18:17:26,724:INFO:             xgboost: Not installed
2025-02-06 18:17:26,724:INFO:            catboost: Not installed
2025-02-06 18:17:26,724:INFO:              kmodes: Not installed
2025-02-06 18:17:26,724:INFO:             mlxtend: Not installed
2025-02-06 18:17:26,724:INFO:       statsforecast: Not installed
2025-02-06 18:17:26,724:INFO:        tune_sklearn: Not installed
2025-02-06 18:17:26,724:INFO:                 ray: Not installed
2025-02-06 18:17:26,724:INFO:            hyperopt: Not installed
2025-02-06 18:17:26,724:INFO:              optuna: Not installed
2025-02-06 18:17:26,724:INFO:               skopt: Not installed
2025-02-06 18:17:26,724:INFO:              mlflow: Not installed
2025-02-06 18:17:26,724:INFO:              gradio: Not installed
2025-02-06 18:17:26,724:INFO:             fastapi: Not installed
2025-02-06 18:17:26,724:INFO:             uvicorn: Not installed
2025-02-06 18:17:26,724:INFO:              m2cgen: Not installed
2025-02-06 18:17:26,724:INFO:           evidently: Not installed
2025-02-06 18:17:26,724:INFO:               fugue: Not installed
2025-02-06 18:17:26,724:INFO:           streamlit: Not installed
2025-02-06 18:17:26,724:INFO:             prophet: Not installed
2025-02-06 18:17:26,724:INFO:None
2025-02-06 18:17:26,724:INFO:Set up data.
2025-02-06 18:17:26,730:INFO:Set up folding strategy.
2025-02-06 18:17:26,730:INFO:Set up train/test split.
2025-02-06 18:17:26,735:INFO:Set up index.
2025-02-06 18:17:26,735:INFO:Assigning column types.
2025-02-06 18:17:26,740:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:17:26,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,804:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,819:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:17:26,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:17:26,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,896:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:17:26,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:26,973:INFO:Preparing preprocessing pipeline...
2025-02-06 18:17:26,974:INFO:Set up simple imputation.
2025-02-06 18:17:26,994:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:17:26,995:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:17:26,995:INFO:Creating final display dataframe.
2025-02-06 18:17:27,058:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a559
2025-02-06 18:17:27,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:27,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:27,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:27,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:17:27,136:INFO:setup() successfully completed in 0.42s...............
2025-02-06 18:17:27,136:INFO:Initializing compare_models()
2025-02-06 18:17:27,136:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:17:27,136:INFO:Checking exceptions
2025-02-06 18:17:27,140:INFO:Preparing display monitor
2025-02-06 18:17:27,150:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:17:27,150:INFO:Total runtime is 0.0 minutes
2025-02-06 18:17:27,151:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:27,151:INFO:Initializing create_model()
2025-02-06 18:17:27,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C4D1010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:27,151:INFO:Checking exceptions
2025-02-06 18:17:27,151:INFO:Importing libraries
2025-02-06 18:17:27,151:INFO:Copying training dataset
2025-02-06 18:17:27,157:INFO:Defining folds
2025-02-06 18:17:27,157:INFO:Declaring metric variables
2025-02-06 18:17:27,158:INFO:Importing untrained model
2025-02-06 18:17:27,159:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:27,163:INFO:Starting cross validation
2025-02-06 18:17:27,163:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:27,678:INFO:Calculating mean and std
2025-02-06 18:17:27,679:INFO:Creating metrics dataframe
2025-02-06 18:17:27,680:INFO:Uploading results into container
2025-02-06 18:17:27,680:INFO:Uploading model into container now
2025-02-06 18:17:27,680:INFO:_master_model_container: 1
2025-02-06 18:17:27,681:INFO:_display_container: 2
2025-02-06 18:17:27,681:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:27,681:INFO:create_model() successfully completed......................................
2025-02-06 18:17:27,777:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:27,777:INFO:Creating metrics dataframe
2025-02-06 18:17:27,780:INFO:Initializing Logistic Regression
2025-02-06 18:17:27,780:INFO:Total runtime is 0.010510345300038656 minutes
2025-02-06 18:17:27,782:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:27,782:INFO:Initializing create_model()
2025-02-06 18:17:27,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C4D1010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:27,782:INFO:Checking exceptions
2025-02-06 18:17:27,782:INFO:Importing libraries
2025-02-06 18:17:27,782:INFO:Copying training dataset
2025-02-06 18:17:27,788:INFO:Defining folds
2025-02-06 18:17:27,788:INFO:Declaring metric variables
2025-02-06 18:17:27,790:INFO:Importing untrained model
2025-02-06 18:17:27,791:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:27,794:INFO:Starting cross validation
2025-02-06 18:17:27,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:27,975:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:27,987:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:27,991:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:27,992:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:28,001:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:28,014:INFO:Calculating mean and std
2025-02-06 18:17:28,014:INFO:Creating metrics dataframe
2025-02-06 18:17:28,015:INFO:Uploading results into container
2025-02-06 18:17:28,015:INFO:Uploading model into container now
2025-02-06 18:17:28,016:INFO:_master_model_container: 2
2025-02-06 18:17:28,016:INFO:_display_container: 2
2025-02-06 18:17:28,016:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:28,016:INFO:create_model() successfully completed......................................
2025-02-06 18:17:28,089:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:28,089:INFO:Creating metrics dataframe
2025-02-06 18:17:28,092:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:17:28,096:INFO:Initializing create_model()
2025-02-06 18:17:28,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:28,096:INFO:Checking exceptions
2025-02-06 18:17:28,096:INFO:Importing libraries
2025-02-06 18:17:28,096:INFO:Copying training dataset
2025-02-06 18:17:28,103:INFO:Defining folds
2025-02-06 18:17:28,103:INFO:Declaring metric variables
2025-02-06 18:17:28,103:INFO:Importing untrained model
2025-02-06 18:17:28,103:INFO:Declaring custom model
2025-02-06 18:17:28,104:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:28,104:INFO:Cross validation set to False
2025-02-06 18:17:28,104:INFO:Fitting Model
2025-02-06 18:17:28,115:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:28,116:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
2025-02-06 18:17:28,116:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:28,116:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:28,116:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:28,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:28,117:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:28,185:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:28,186:INFO:create_model() successfully completed......................................
2025-02-06 18:17:28,280:INFO:_master_model_container: 2
2025-02-06 18:17:28,280:INFO:_display_container: 2
2025-02-06 18:17:28,281:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:28,281:INFO:compare_models() successfully completed......................................
2025-02-06 18:17:28,281:INFO:Initializing create_model()
2025-02-06 18:17:28,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:28,281:INFO:Checking exceptions
2025-02-06 18:17:28,290:INFO:Importing libraries
2025-02-06 18:17:28,290:INFO:Copying training dataset
2025-02-06 18:17:28,297:INFO:Defining folds
2025-02-06 18:17:28,297:INFO:Declaring metric variables
2025-02-06 18:17:28,298:INFO:Importing untrained model
2025-02-06 18:17:28,300:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:28,303:INFO:Starting cross validation
2025-02-06 18:17:28,303:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:28,760:INFO:Calculating mean and std
2025-02-06 18:17:28,760:INFO:Creating metrics dataframe
2025-02-06 18:17:28,764:INFO:Finalizing model
2025-02-06 18:17:28,779:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:28,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.
2025-02-06 18:17:28,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:28,780:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:28,781:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:28,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:28,781:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:28,908:INFO:Uploading results into container
2025-02-06 18:17:28,908:INFO:Uploading model into container now
2025-02-06 18:17:28,914:INFO:_master_model_container: 3
2025-02-06 18:17:28,914:INFO:_display_container: 3
2025-02-06 18:17:28,914:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:28,914:INFO:create_model() successfully completed......................................
2025-02-06 18:17:29,014:INFO:Initializing tune_model()
2025-02-06 18:17:29,014:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:17:29,014:INFO:Checking exceptions
2025-02-06 18:17:29,023:INFO:Copying training dataset
2025-02-06 18:17:29,026:INFO:Checking base model
2025-02-06 18:17:29,027:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:17:29,029:INFO:Declaring metric variables
2025-02-06 18:17:29,030:INFO:Defining Hyperparameters
2025-02-06 18:17:29,127:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:17:29,127:INFO:Tuning with n_jobs=-1
2025-02-06 18:17:29,127:INFO:Initializing RandomizedSearchCV
2025-02-06 18:17:46,010:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:17:46,010:INFO:Hyperparameter search completed
2025-02-06 18:17:46,011:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:46,011:INFO:Initializing create_model()
2025-02-06 18:17:46,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D7C110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:17:46,011:INFO:Checking exceptions
2025-02-06 18:17:46,011:INFO:Importing libraries
2025-02-06 18:17:46,011:INFO:Copying training dataset
2025-02-06 18:17:46,020:INFO:Defining folds
2025-02-06 18:17:46,020:INFO:Declaring metric variables
2025-02-06 18:17:46,023:INFO:Importing untrained model
2025-02-06 18:17:46,023:INFO:Declaring custom model
2025-02-06 18:17:46,025:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:46,029:INFO:Starting cross validation
2025-02-06 18:17:46,030:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:49,886:INFO:Calculating mean and std
2025-02-06 18:17:49,887:INFO:Creating metrics dataframe
2025-02-06 18:17:49,891:INFO:Finalizing model
2025-02-06 18:17:49,906:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:49,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.
2025-02-06 18:17:49,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:49,908:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:49,908:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:49,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:49,908:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:50,648:INFO:Uploading results into container
2025-02-06 18:17:50,648:INFO:Uploading model into container now
2025-02-06 18:17:50,648:INFO:_master_model_container: 4
2025-02-06 18:17:50,648:INFO:_display_container: 4
2025-02-06 18:17:50,649:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:50,649:INFO:create_model() successfully completed......................................
2025-02-06 18:17:50,768:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:50,768:INFO:choose_better activated
2025-02-06 18:17:50,770:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:50,770:INFO:Initializing create_model()
2025-02-06 18:17:50,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:50,770:INFO:Checking exceptions
2025-02-06 18:17:50,771:INFO:Importing libraries
2025-02-06 18:17:50,771:INFO:Copying training dataset
2025-02-06 18:17:50,778:INFO:Defining folds
2025-02-06 18:17:50,778:INFO:Declaring metric variables
2025-02-06 18:17:50,779:INFO:Importing untrained model
2025-02-06 18:17:50,779:INFO:Declaring custom model
2025-02-06 18:17:50,780:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:50,780:INFO:Starting cross validation
2025-02-06 18:17:50,780:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:51,319:INFO:Calculating mean and std
2025-02-06 18:17:51,320:INFO:Creating metrics dataframe
2025-02-06 18:17:51,321:INFO:Finalizing model
2025-02-06 18:17:51,336:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:51,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001037 seconds.
2025-02-06 18:17:51,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:51,338:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:51,338:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:51,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:51,338:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:51,472:INFO:Uploading results into container
2025-02-06 18:17:51,473:INFO:Uploading model into container now
2025-02-06 18:17:51,473:INFO:_master_model_container: 5
2025-02-06 18:17:51,473:INFO:_display_container: 5
2025-02-06 18:17:51,473:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:51,473:INFO:create_model() successfully completed......................................
2025-02-06 18:17:51,562:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:51,562:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:17:51,563:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:17:51,563:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:17:51,563:INFO:choose_better completed
2025-02-06 18:17:51,568:INFO:_master_model_container: 5
2025-02-06 18:17:51,569:INFO:_display_container: 4
2025-02-06 18:17:51,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:51,570:INFO:tune_model() successfully completed......................................
2025-02-06 18:17:51,628:INFO:Initializing create_model()
2025-02-06 18:17:51,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:51,628:INFO:Checking exceptions
2025-02-06 18:17:51,636:INFO:Importing libraries
2025-02-06 18:17:51,636:INFO:Copying training dataset
2025-02-06 18:17:51,642:INFO:Defining folds
2025-02-06 18:17:51,642:INFO:Declaring metric variables
2025-02-06 18:17:51,644:INFO:Importing untrained model
2025-02-06 18:17:51,646:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:51,648:INFO:Starting cross validation
2025-02-06 18:17:51,649:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:51,833:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:51,840:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:51,843:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:51,845:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:51,849:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:51,858:INFO:Calculating mean and std
2025-02-06 18:17:51,858:INFO:Creating metrics dataframe
2025-02-06 18:17:51,861:INFO:Finalizing model
2025-02-06 18:17:52,287:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,289:INFO:Uploading results into container
2025-02-06 18:17:52,290:INFO:Uploading model into container now
2025-02-06 18:17:52,294:INFO:_master_model_container: 6
2025-02-06 18:17:52,294:INFO:_display_container: 5
2025-02-06 18:17:52,294:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:52,294:INFO:create_model() successfully completed......................................
2025-02-06 18:17:52,370:INFO:Initializing tune_model()
2025-02-06 18:17:52,370:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:17:52,370:INFO:Checking exceptions
2025-02-06 18:17:52,379:INFO:Copying training dataset
2025-02-06 18:17:52,385:INFO:Checking base model
2025-02-06 18:17:52,385:INFO:Base model : Logistic Regression
2025-02-06 18:17:52,387:INFO:Declaring metric variables
2025-02-06 18:17:52,389:INFO:Defining Hyperparameters
2025-02-06 18:17:52,492:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:17:52,492:INFO:Tuning with n_jobs=-1
2025-02-06 18:17:52,492:INFO:Initializing RandomizedSearchCV
2025-02-06 18:17:52,562:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,565:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,571:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,571:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,577:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,580:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,583:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,585:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,586:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:52,587:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,013:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,019:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,054:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,060:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,068:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,310:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,322:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,369:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,434:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,465:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:53,564:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:17:53,565:INFO:Hyperparameter search completed
2025-02-06 18:17:53,565:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:53,565:INFO:Initializing create_model()
2025-02-06 18:17:53,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937813A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:17:53,566:INFO:Checking exceptions
2025-02-06 18:17:53,566:INFO:Importing libraries
2025-02-06 18:17:53,566:INFO:Copying training dataset
2025-02-06 18:17:53,572:INFO:Defining folds
2025-02-06 18:17:53,572:INFO:Declaring metric variables
2025-02-06 18:17:53,574:INFO:Importing untrained model
2025-02-06 18:17:53,574:INFO:Declaring custom model
2025-02-06 18:17:53,576:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:53,579:INFO:Starting cross validation
2025-02-06 18:17:53,579:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:53,940:INFO:Calculating mean and std
2025-02-06 18:17:53,940:INFO:Creating metrics dataframe
2025-02-06 18:17:53,942:INFO:Finalizing model
2025-02-06 18:17:54,199:INFO:Uploading results into container
2025-02-06 18:17:54,200:INFO:Uploading model into container now
2025-02-06 18:17:54,200:INFO:_master_model_container: 7
2025-02-06 18:17:54,200:INFO:_display_container: 6
2025-02-06 18:17:54,201:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:54,201:INFO:create_model() successfully completed......................................
2025-02-06 18:17:54,273:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:54,274:INFO:choose_better activated
2025-02-06 18:17:54,275:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:54,275:INFO:Initializing create_model()
2025-02-06 18:17:54,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:54,275:INFO:Checking exceptions
2025-02-06 18:17:54,276:INFO:Importing libraries
2025-02-06 18:17:54,276:INFO:Copying training dataset
2025-02-06 18:17:54,282:INFO:Defining folds
2025-02-06 18:17:54,282:INFO:Declaring metric variables
2025-02-06 18:17:54,283:INFO:Importing untrained model
2025-02-06 18:17:54,283:INFO:Declaring custom model
2025-02-06 18:17:54,283:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:54,283:INFO:Starting cross validation
2025-02-06 18:17:54,283:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:54,463:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,468:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,470:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,475:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,478:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,490:INFO:Calculating mean and std
2025-02-06 18:17:54,490:INFO:Creating metrics dataframe
2025-02-06 18:17:54,491:INFO:Finalizing model
2025-02-06 18:17:54,900:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:17:54,900:INFO:Uploading results into container
2025-02-06 18:17:54,901:INFO:Uploading model into container now
2025-02-06 18:17:54,901:INFO:_master_model_container: 8
2025-02-06 18:17:54,901:INFO:_display_container: 7
2025-02-06 18:17:54,901:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:54,901:INFO:create_model() successfully completed......................................
2025-02-06 18:17:54,975:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:54,976:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:17:54,976:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:17:54,976:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:17:54,976:INFO:choose_better completed
2025-02-06 18:17:54,980:INFO:_master_model_container: 8
2025-02-06 18:17:54,981:INFO:_display_container: 6
2025-02-06 18:17:54,981:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:54,981:INFO:tune_model() successfully completed......................................
2025-02-06 18:17:55,044:INFO:Initializing compare_models()
2025-02-06 18:17:55,044:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:17:55,045:INFO:Checking exceptions
2025-02-06 18:17:55,047:INFO:Preparing display monitor
2025-02-06 18:17:55,056:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:17:55,056:INFO:Total runtime is 0.0 minutes
2025-02-06 18:17:55,059:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:55,059:INFO:Initializing create_model()
2025-02-06 18:17:55,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937ACEF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:55,059:INFO:Checking exceptions
2025-02-06 18:17:55,059:INFO:Importing libraries
2025-02-06 18:17:55,059:INFO:Copying training dataset
2025-02-06 18:17:55,065:INFO:Defining folds
2025-02-06 18:17:55,065:INFO:Declaring metric variables
2025-02-06 18:17:55,067:INFO:Importing untrained model
2025-02-06 18:17:55,067:INFO:Declaring custom model
2025-02-06 18:17:55,069:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:55,071:INFO:Starting cross validation
2025-02-06 18:17:55,072:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:58,105:INFO:Calculating mean and std
2025-02-06 18:17:58,106:INFO:Creating metrics dataframe
2025-02-06 18:17:58,107:INFO:Uploading results into container
2025-02-06 18:17:58,108:INFO:Uploading model into container now
2025-02-06 18:17:58,108:INFO:_master_model_container: 9
2025-02-06 18:17:58,108:INFO:_display_container: 7
2025-02-06 18:17:58,109:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:58,109:INFO:create_model() successfully completed......................................
2025-02-06 18:17:58,195:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:58,195:INFO:Creating metrics dataframe
2025-02-06 18:17:58,198:INFO:Initializing custom model Logistic Regression
2025-02-06 18:17:58,198:INFO:Total runtime is 0.05236339966456095 minutes
2025-02-06 18:17:58,201:INFO:SubProcess create_model() called ==================================
2025-02-06 18:17:58,201:INFO:Initializing create_model()
2025-02-06 18:17:58,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937ACEF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:58,201:INFO:Checking exceptions
2025-02-06 18:17:58,201:INFO:Importing libraries
2025-02-06 18:17:58,201:INFO:Copying training dataset
2025-02-06 18:17:58,207:INFO:Defining folds
2025-02-06 18:17:58,207:INFO:Declaring metric variables
2025-02-06 18:17:58,208:INFO:Importing untrained model
2025-02-06 18:17:58,208:INFO:Declaring custom model
2025-02-06 18:17:58,211:INFO:Logistic Regression Imported successfully
2025-02-06 18:17:58,214:INFO:Starting cross validation
2025-02-06 18:17:58,214:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:17:58,578:INFO:Calculating mean and std
2025-02-06 18:17:58,579:INFO:Creating metrics dataframe
2025-02-06 18:17:58,579:INFO:Uploading results into container
2025-02-06 18:17:58,581:INFO:Uploading model into container now
2025-02-06 18:17:58,581:INFO:_master_model_container: 10
2025-02-06 18:17:58,581:INFO:_display_container: 7
2025-02-06 18:17:58,581:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:17:58,582:INFO:create_model() successfully completed......................................
2025-02-06 18:17:58,689:INFO:SubProcess create_model() end ==================================
2025-02-06 18:17:58,689:INFO:Creating metrics dataframe
2025-02-06 18:17:58,694:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:17:58,698:INFO:Initializing create_model()
2025-02-06 18:17:58,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:17:58,698:INFO:Checking exceptions
2025-02-06 18:17:58,699:INFO:Importing libraries
2025-02-06 18:17:58,699:INFO:Copying training dataset
2025-02-06 18:17:58,704:INFO:Defining folds
2025-02-06 18:17:58,704:INFO:Declaring metric variables
2025-02-06 18:17:58,704:INFO:Importing untrained model
2025-02-06 18:17:58,704:INFO:Declaring custom model
2025-02-06 18:17:58,705:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:17:58,705:INFO:Cross validation set to False
2025-02-06 18:17:58,705:INFO:Fitting Model
2025-02-06 18:17:58,717:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:17:58,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000794 seconds.
2025-02-06 18:17:58,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:17:58,719:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:17:58,719:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:17:58,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:17:58,719:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:17:59,353:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:59,353:INFO:create_model() successfully completed......................................
2025-02-06 18:17:59,448:INFO:_master_model_container: 10
2025-02-06 18:17:59,448:INFO:_display_container: 7
2025-02-06 18:17:59,449:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:17:59,449:INFO:compare_models() successfully completed......................................
2025-02-06 18:17:59,450:INFO:Initializing predict_model()
2025-02-06 18:17:59,450:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021970436E80>)
2025-02-06 18:17:59,450:INFO:Checking exceptions
2025-02-06 18:17:59,450:INFO:Preloading libraries
2025-02-06 18:17:59,451:INFO:Set up data.
2025-02-06 18:17:59,460:INFO:Set up index.
2025-02-06 18:17:59,632:INFO:Initializing predict_model()
2025-02-06 18:17:59,632:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021970436E80>)
2025-02-06 18:17:59,632:INFO:Checking exceptions
2025-02-06 18:17:59,632:INFO:Preloading libraries
2025-02-06 18:17:59,633:INFO:Set up data.
2025-02-06 18:17:59,637:INFO:Set up index.
2025-02-06 18:17:59,748:INFO:Initializing predict_model()
2025-02-06 18:17:59,748:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021970436E80>)
2025-02-06 18:17:59,748:INFO:Checking exceptions
2025-02-06 18:17:59,748:INFO:Preloading libraries
2025-02-06 18:17:59,750:INFO:Set up data.
2025-02-06 18:17:59,757:INFO:Set up index.
2025-02-06 18:17:59,851:INFO:Initializing predict_model()
2025-02-06 18:17:59,851:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193795F390>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021970436E80>)
2025-02-06 18:17:59,851:INFO:Checking exceptions
2025-02-06 18:17:59,851:INFO:Preloading libraries
2025-02-06 18:17:59,852:INFO:Set up data.
2025-02-06 18:17:59,857:INFO:Set up index.
2025-02-06 18:18:03,960:INFO:PyCaret ClassificationExperiment
2025-02-06 18:18:03,960:INFO:Logging name: clf-default-name
2025-02-06 18:18:03,960:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:18:03,960:INFO:version 3.3.2
2025-02-06 18:18:03,960:INFO:Initializing setup()
2025-02-06 18:18:03,960:INFO:self.USI: 2d91
2025-02-06 18:18:03,960:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:18:03,961:INFO:Checking environment
2025-02-06 18:18:03,961:INFO:python_version: 3.11.9
2025-02-06 18:18:03,961:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:18:03,961:INFO:machine: AMD64
2025-02-06 18:18:03,961:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:18:03,965:INFO:Memory: svmem(total=67771465728, available=46111412224, percent=32.0, used=21660053504, free=46111412224)
2025-02-06 18:18:03,966:INFO:Physical Core: 8
2025-02-06 18:18:03,966:INFO:Logical Core: 16
2025-02-06 18:18:03,966:INFO:Checking libraries
2025-02-06 18:18:03,966:INFO:System:
2025-02-06 18:18:03,966:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:18:03,966:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:18:03,966:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:18:03,966:INFO:PyCaret required dependencies:
2025-02-06 18:18:03,966:INFO:                 pip: 25.0
2025-02-06 18:18:03,966:INFO:          setuptools: 65.5.0
2025-02-06 18:18:03,966:INFO:             pycaret: 3.3.2
2025-02-06 18:18:03,966:INFO:             IPython: 8.32.0
2025-02-06 18:18:03,966:INFO:          ipywidgets: 8.1.5
2025-02-06 18:18:03,966:INFO:                tqdm: 4.67.1
2025-02-06 18:18:03,966:INFO:               numpy: 1.26.4
2025-02-06 18:18:03,966:INFO:              pandas: 2.1.4
2025-02-06 18:18:03,966:INFO:              jinja2: 3.1.5
2025-02-06 18:18:03,966:INFO:               scipy: 1.11.4
2025-02-06 18:18:03,966:INFO:              joblib: 1.3.2
2025-02-06 18:18:03,966:INFO:             sklearn: 1.4.2
2025-02-06 18:18:03,966:INFO:                pyod: 2.0.3
2025-02-06 18:18:03,966:INFO:            imblearn: 0.13.0
2025-02-06 18:18:03,966:INFO:   category_encoders: 2.7.0
2025-02-06 18:18:03,966:INFO:            lightgbm: 4.5.0
2025-02-06 18:18:03,966:INFO:               numba: 0.61.0
2025-02-06 18:18:03,966:INFO:            requests: 2.32.3
2025-02-06 18:18:03,966:INFO:          matplotlib: 3.7.5
2025-02-06 18:18:03,966:INFO:          scikitplot: 0.3.7
2025-02-06 18:18:03,966:INFO:         yellowbrick: 1.5
2025-02-06 18:18:03,966:INFO:              plotly: 5.24.1
2025-02-06 18:18:03,966:INFO:    plotly-resampler: Not installed
2025-02-06 18:18:03,966:INFO:             kaleido: 0.2.1
2025-02-06 18:18:03,966:INFO:           schemdraw: 0.15
2025-02-06 18:18:03,966:INFO:         statsmodels: 0.14.4
2025-02-06 18:18:03,966:INFO:              sktime: 0.26.0
2025-02-06 18:18:03,966:INFO:               tbats: 1.1.3
2025-02-06 18:18:03,966:INFO:            pmdarima: 2.0.4
2025-02-06 18:18:03,966:INFO:              psutil: 6.1.1
2025-02-06 18:18:03,966:INFO:          markupsafe: 3.0.2
2025-02-06 18:18:03,966:INFO:             pickle5: Not installed
2025-02-06 18:18:03,966:INFO:         cloudpickle: 3.1.1
2025-02-06 18:18:03,966:INFO:         deprecation: 2.1.0
2025-02-06 18:18:03,966:INFO:              xxhash: 3.5.0
2025-02-06 18:18:03,966:INFO:           wurlitzer: Not installed
2025-02-06 18:18:03,966:INFO:PyCaret optional dependencies:
2025-02-06 18:18:03,966:INFO:                shap: Not installed
2025-02-06 18:18:03,966:INFO:           interpret: Not installed
2025-02-06 18:18:03,966:INFO:                umap: Not installed
2025-02-06 18:18:03,966:INFO:     ydata_profiling: Not installed
2025-02-06 18:18:03,966:INFO:  explainerdashboard: Not installed
2025-02-06 18:18:03,966:INFO:             autoviz: Not installed
2025-02-06 18:18:03,966:INFO:           fairlearn: Not installed
2025-02-06 18:18:03,966:INFO:          deepchecks: Not installed
2025-02-06 18:18:03,966:INFO:             xgboost: Not installed
2025-02-06 18:18:03,966:INFO:            catboost: Not installed
2025-02-06 18:18:03,966:INFO:              kmodes: Not installed
2025-02-06 18:18:03,966:INFO:             mlxtend: Not installed
2025-02-06 18:18:03,967:INFO:       statsforecast: Not installed
2025-02-06 18:18:03,967:INFO:        tune_sklearn: Not installed
2025-02-06 18:18:03,967:INFO:                 ray: Not installed
2025-02-06 18:18:03,967:INFO:            hyperopt: Not installed
2025-02-06 18:18:03,967:INFO:              optuna: Not installed
2025-02-06 18:18:03,967:INFO:               skopt: Not installed
2025-02-06 18:18:03,967:INFO:              mlflow: Not installed
2025-02-06 18:18:03,967:INFO:              gradio: Not installed
2025-02-06 18:18:03,967:INFO:             fastapi: Not installed
2025-02-06 18:18:03,967:INFO:             uvicorn: Not installed
2025-02-06 18:18:03,967:INFO:              m2cgen: Not installed
2025-02-06 18:18:03,967:INFO:           evidently: Not installed
2025-02-06 18:18:03,967:INFO:               fugue: Not installed
2025-02-06 18:18:03,967:INFO:           streamlit: Not installed
2025-02-06 18:18:03,967:INFO:             prophet: Not installed
2025-02-06 18:18:03,967:INFO:None
2025-02-06 18:18:03,967:INFO:Set up data.
2025-02-06 18:18:03,974:INFO:Set up folding strategy.
2025-02-06 18:18:03,975:INFO:Set up train/test split.
2025-02-06 18:18:03,980:INFO:Set up index.
2025-02-06 18:18:03,981:INFO:Assigning column types.
2025-02-06 18:18:03,988:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:18:04,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,070:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:18:04,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,133:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:18:04,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,148:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:18:04,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,232:INFO:Preparing preprocessing pipeline...
2025-02-06 18:18:04,233:INFO:Set up simple imputation.
2025-02-06 18:18:04,262:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:18:04,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:18:04,263:INFO:Creating final display dataframe.
2025-02-06 18:18:04,330:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              2d91
2025-02-06 18:18:04,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:18:04,408:INFO:setup() successfully completed in 0.45s...............
2025-02-06 18:18:04,408:INFO:Initializing compare_models()
2025-02-06 18:18:04,408:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:18:04,408:INFO:Checking exceptions
2025-02-06 18:18:04,412:INFO:Preparing display monitor
2025-02-06 18:18:04,422:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:18:04,422:INFO:Total runtime is 0.0 minutes
2025-02-06 18:18:04,424:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:04,424:INFO:Initializing create_model()
2025-02-06 18:18:04,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D46410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:04,424:INFO:Checking exceptions
2025-02-06 18:18:04,424:INFO:Importing libraries
2025-02-06 18:18:04,424:INFO:Copying training dataset
2025-02-06 18:18:04,430:INFO:Defining folds
2025-02-06 18:18:04,430:INFO:Declaring metric variables
2025-02-06 18:18:04,431:INFO:Importing untrained model
2025-02-06 18:18:04,433:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:04,435:INFO:Starting cross validation
2025-02-06 18:18:04,436:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:04,890:INFO:Calculating mean and std
2025-02-06 18:18:04,891:INFO:Creating metrics dataframe
2025-02-06 18:18:04,892:INFO:Uploading results into container
2025-02-06 18:18:04,892:INFO:Uploading model into container now
2025-02-06 18:18:04,893:INFO:_master_model_container: 1
2025-02-06 18:18:04,893:INFO:_display_container: 2
2025-02-06 18:18:04,893:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:04,893:INFO:create_model() successfully completed......................................
2025-02-06 18:18:04,993:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:04,993:INFO:Creating metrics dataframe
2025-02-06 18:18:04,996:INFO:Initializing Logistic Regression
2025-02-06 18:18:04,996:INFO:Total runtime is 0.009562087059020997 minutes
2025-02-06 18:18:04,997:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:04,998:INFO:Initializing create_model()
2025-02-06 18:18:04,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D46410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:04,998:INFO:Checking exceptions
2025-02-06 18:18:04,998:INFO:Importing libraries
2025-02-06 18:18:04,998:INFO:Copying training dataset
2025-02-06 18:18:05,004:INFO:Defining folds
2025-02-06 18:18:05,004:INFO:Declaring metric variables
2025-02-06 18:18:05,006:INFO:Importing untrained model
2025-02-06 18:18:05,007:INFO:Logistic Regression Imported successfully
2025-02-06 18:18:05,010:INFO:Starting cross validation
2025-02-06 18:18:05,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:05,189:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:05,194:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:05,198:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:05,215:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:05,215:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:05,231:INFO:Calculating mean and std
2025-02-06 18:18:05,231:INFO:Creating metrics dataframe
2025-02-06 18:18:05,232:INFO:Uploading results into container
2025-02-06 18:18:05,232:INFO:Uploading model into container now
2025-02-06 18:18:05,232:INFO:_master_model_container: 2
2025-02-06 18:18:05,232:INFO:_display_container: 2
2025-02-06 18:18:05,233:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:05,233:INFO:create_model() successfully completed......................................
2025-02-06 18:18:05,303:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:05,303:INFO:Creating metrics dataframe
2025-02-06 18:18:05,307:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:18:05,311:INFO:Initializing create_model()
2025-02-06 18:18:05,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:05,311:INFO:Checking exceptions
2025-02-06 18:18:05,312:INFO:Importing libraries
2025-02-06 18:18:05,312:INFO:Copying training dataset
2025-02-06 18:18:05,317:INFO:Defining folds
2025-02-06 18:18:05,317:INFO:Declaring metric variables
2025-02-06 18:18:05,318:INFO:Importing untrained model
2025-02-06 18:18:05,318:INFO:Declaring custom model
2025-02-06 18:18:05,318:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:05,318:INFO:Cross validation set to False
2025-02-06 18:18:05,318:INFO:Fitting Model
2025-02-06 18:18:05,328:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:18:05,330:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.
2025-02-06 18:18:05,330:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:18:05,330:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:18:05,331:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:18:05,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:18:05,331:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:18:05,412:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:05,412:INFO:create_model() successfully completed......................................
2025-02-06 18:18:05,517:INFO:_master_model_container: 2
2025-02-06 18:18:05,517:INFO:_display_container: 2
2025-02-06 18:18:05,517:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:05,517:INFO:compare_models() successfully completed......................................
2025-02-06 18:18:05,517:INFO:Initializing create_model()
2025-02-06 18:18:05,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:05,517:INFO:Checking exceptions
2025-02-06 18:18:05,523:INFO:Importing libraries
2025-02-06 18:18:05,523:INFO:Copying training dataset
2025-02-06 18:18:05,530:INFO:Defining folds
2025-02-06 18:18:05,530:INFO:Declaring metric variables
2025-02-06 18:18:05,532:INFO:Importing untrained model
2025-02-06 18:18:05,534:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:05,537:INFO:Starting cross validation
2025-02-06 18:18:05,538:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:05,998:INFO:Calculating mean and std
2025-02-06 18:18:05,998:INFO:Creating metrics dataframe
2025-02-06 18:18:06,002:INFO:Finalizing model
2025-02-06 18:18:06,016:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:18:06,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.
2025-02-06 18:18:06,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:18:06,017:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:18:06,017:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:18:06,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:18:06,018:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:18:06,166:INFO:Uploading results into container
2025-02-06 18:18:06,168:INFO:Uploading model into container now
2025-02-06 18:18:06,174:INFO:_master_model_container: 3
2025-02-06 18:18:06,174:INFO:_display_container: 3
2025-02-06 18:18:06,174:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:06,174:INFO:create_model() successfully completed......................................
2025-02-06 18:18:06,255:INFO:Initializing tune_model()
2025-02-06 18:18:06,255:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:18:06,255:INFO:Checking exceptions
2025-02-06 18:18:06,265:INFO:Copying training dataset
2025-02-06 18:18:06,269:INFO:Checking base model
2025-02-06 18:18:06,269:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:18:06,270:INFO:Declaring metric variables
2025-02-06 18:18:06,272:INFO:Defining Hyperparameters
2025-02-06 18:18:06,340:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:18:06,341:INFO:Tuning with n_jobs=-1
2025-02-06 18:18:06,341:INFO:Initializing RandomizedSearchCV
2025-02-06 18:18:20,994:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:18:20,995:INFO:Hyperparameter search completed
2025-02-06 18:18:20,996:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:20,996:INFO:Initializing create_model()
2025-02-06 18:18:20,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219378138D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:18:20,996:INFO:Checking exceptions
2025-02-06 18:18:20,996:INFO:Importing libraries
2025-02-06 18:18:20,996:INFO:Copying training dataset
2025-02-06 18:18:21,005:INFO:Defining folds
2025-02-06 18:18:21,005:INFO:Declaring metric variables
2025-02-06 18:18:21,008:INFO:Importing untrained model
2025-02-06 18:18:21,008:INFO:Declaring custom model
2025-02-06 18:18:21,011:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:21,014:INFO:Starting cross validation
2025-02-06 18:18:21,014:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:23,993:INFO:Calculating mean and std
2025-02-06 18:18:23,994:INFO:Creating metrics dataframe
2025-02-06 18:18:23,997:INFO:Finalizing model
2025-02-06 18:18:24,012:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:18:24,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.
2025-02-06 18:18:24,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:18:24,014:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:18:24,014:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:18:24,014:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:18:24,014:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:18:24,724:INFO:Uploading results into container
2025-02-06 18:18:24,724:INFO:Uploading model into container now
2025-02-06 18:18:24,725:INFO:_master_model_container: 4
2025-02-06 18:18:24,725:INFO:_display_container: 4
2025-02-06 18:18:24,725:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:24,725:INFO:create_model() successfully completed......................................
2025-02-06 18:18:24,809:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:24,809:INFO:choose_better activated
2025-02-06 18:18:24,811:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:24,812:INFO:Initializing create_model()
2025-02-06 18:18:24,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:24,812:INFO:Checking exceptions
2025-02-06 18:18:24,812:INFO:Importing libraries
2025-02-06 18:18:24,813:INFO:Copying training dataset
2025-02-06 18:18:24,821:INFO:Defining folds
2025-02-06 18:18:24,821:INFO:Declaring metric variables
2025-02-06 18:18:24,822:INFO:Importing untrained model
2025-02-06 18:18:24,822:INFO:Declaring custom model
2025-02-06 18:18:24,822:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:24,822:INFO:Starting cross validation
2025-02-06 18:18:24,822:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:25,227:INFO:Calculating mean and std
2025-02-06 18:18:25,227:INFO:Creating metrics dataframe
2025-02-06 18:18:25,228:INFO:Finalizing model
2025-02-06 18:18:25,243:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:18:25,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
2025-02-06 18:18:25,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:18:25,243:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:18:25,245:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:18:25,245:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:18:25,245:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:18:25,348:INFO:Uploading results into container
2025-02-06 18:18:25,348:INFO:Uploading model into container now
2025-02-06 18:18:25,349:INFO:_master_model_container: 5
2025-02-06 18:18:25,349:INFO:_display_container: 5
2025-02-06 18:18:25,349:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:25,349:INFO:create_model() successfully completed......................................
2025-02-06 18:18:25,433:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:25,433:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:18:25,433:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:18:25,433:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:18:25,433:INFO:choose_better completed
2025-02-06 18:18:25,439:INFO:_master_model_container: 5
2025-02-06 18:18:25,439:INFO:_display_container: 4
2025-02-06 18:18:25,440:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:25,440:INFO:tune_model() successfully completed......................................
2025-02-06 18:18:25,505:INFO:Initializing create_model()
2025-02-06 18:18:25,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:25,505:INFO:Checking exceptions
2025-02-06 18:18:25,512:INFO:Importing libraries
2025-02-06 18:18:25,512:INFO:Copying training dataset
2025-02-06 18:18:25,518:INFO:Defining folds
2025-02-06 18:18:25,518:INFO:Declaring metric variables
2025-02-06 18:18:25,520:INFO:Importing untrained model
2025-02-06 18:18:25,521:INFO:Logistic Regression Imported successfully
2025-02-06 18:18:25,524:INFO:Starting cross validation
2025-02-06 18:18:25,526:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:25,716:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:25,718:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:25,728:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:25,729:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:25,736:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:25,754:INFO:Calculating mean and std
2025-02-06 18:18:25,754:INFO:Creating metrics dataframe
2025-02-06 18:18:25,757:INFO:Finalizing model
2025-02-06 18:18:26,145:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,148:INFO:Uploading results into container
2025-02-06 18:18:26,148:INFO:Uploading model into container now
2025-02-06 18:18:26,153:INFO:_master_model_container: 6
2025-02-06 18:18:26,153:INFO:_display_container: 5
2025-02-06 18:18:26,153:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:26,153:INFO:create_model() successfully completed......................................
2025-02-06 18:18:26,223:INFO:Initializing tune_model()
2025-02-06 18:18:26,223:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:18:26,223:INFO:Checking exceptions
2025-02-06 18:18:26,231:INFO:Copying training dataset
2025-02-06 18:18:26,235:INFO:Checking base model
2025-02-06 18:18:26,235:INFO:Base model : Logistic Regression
2025-02-06 18:18:26,237:INFO:Declaring metric variables
2025-02-06 18:18:26,239:INFO:Defining Hyperparameters
2025-02-06 18:18:26,305:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:18:26,305:INFO:Tuning with n_jobs=-1
2025-02-06 18:18:26,305:INFO:Initializing RandomizedSearchCV
2025-02-06 18:18:26,373:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,376:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,379:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,382:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,385:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,386:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,386:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,388:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,393:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,398:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,799:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,807:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,844:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,847:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:26,862:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,120:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,161:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,176:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,218:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,265:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:27,347:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:18:27,348:INFO:Hyperparameter search completed
2025-02-06 18:18:27,348:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:27,348:INFO:Initializing create_model()
2025-02-06 18:18:27,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219355BD7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:18:27,349:INFO:Checking exceptions
2025-02-06 18:18:27,349:INFO:Importing libraries
2025-02-06 18:18:27,349:INFO:Copying training dataset
2025-02-06 18:18:27,355:INFO:Defining folds
2025-02-06 18:18:27,355:INFO:Declaring metric variables
2025-02-06 18:18:27,357:INFO:Importing untrained model
2025-02-06 18:18:27,357:INFO:Declaring custom model
2025-02-06 18:18:27,359:INFO:Logistic Regression Imported successfully
2025-02-06 18:18:27,361:INFO:Starting cross validation
2025-02-06 18:18:27,361:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:27,705:INFO:Calculating mean and std
2025-02-06 18:18:27,705:INFO:Creating metrics dataframe
2025-02-06 18:18:27,708:INFO:Finalizing model
2025-02-06 18:18:27,960:INFO:Uploading results into container
2025-02-06 18:18:27,961:INFO:Uploading model into container now
2025-02-06 18:18:27,961:INFO:_master_model_container: 7
2025-02-06 18:18:27,961:INFO:_display_container: 6
2025-02-06 18:18:27,961:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:27,961:INFO:create_model() successfully completed......................................
2025-02-06 18:18:28,030:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:28,030:INFO:choose_better activated
2025-02-06 18:18:28,032:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:28,032:INFO:Initializing create_model()
2025-02-06 18:18:28,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:28,033:INFO:Checking exceptions
2025-02-06 18:18:28,033:INFO:Importing libraries
2025-02-06 18:18:28,033:INFO:Copying training dataset
2025-02-06 18:18:28,040:INFO:Defining folds
2025-02-06 18:18:28,040:INFO:Declaring metric variables
2025-02-06 18:18:28,040:INFO:Importing untrained model
2025-02-06 18:18:28,040:INFO:Declaring custom model
2025-02-06 18:18:28,040:INFO:Logistic Regression Imported successfully
2025-02-06 18:18:28,040:INFO:Starting cross validation
2025-02-06 18:18:28,040:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:28,209:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,210:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,212:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,212:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,214:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,228:INFO:Calculating mean and std
2025-02-06 18:18:28,228:INFO:Creating metrics dataframe
2025-02-06 18:18:28,229:INFO:Finalizing model
2025-02-06 18:18:28,637:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:18:28,637:INFO:Uploading results into container
2025-02-06 18:18:28,637:INFO:Uploading model into container now
2025-02-06 18:18:28,638:INFO:_master_model_container: 8
2025-02-06 18:18:28,638:INFO:_display_container: 7
2025-02-06 18:18:28,638:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:28,638:INFO:create_model() successfully completed......................................
2025-02-06 18:18:28,708:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:28,708:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:18:28,709:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:18:28,709:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:18:28,709:INFO:choose_better completed
2025-02-06 18:18:28,713:INFO:_master_model_container: 8
2025-02-06 18:18:28,713:INFO:_display_container: 6
2025-02-06 18:18:28,713:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:28,713:INFO:tune_model() successfully completed......................................
2025-02-06 18:18:28,771:INFO:Initializing compare_models()
2025-02-06 18:18:28,771:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:18:28,771:INFO:Checking exceptions
2025-02-06 18:18:28,774:INFO:Preparing display monitor
2025-02-06 18:18:28,784:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:18:28,784:INFO:Total runtime is 0.0 minutes
2025-02-06 18:18:28,786:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:28,786:INFO:Initializing create_model()
2025-02-06 18:18:28,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935E8CC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:28,786:INFO:Checking exceptions
2025-02-06 18:18:28,786:INFO:Importing libraries
2025-02-06 18:18:28,786:INFO:Copying training dataset
2025-02-06 18:18:28,791:INFO:Defining folds
2025-02-06 18:18:28,791:INFO:Declaring metric variables
2025-02-06 18:18:28,793:INFO:Importing untrained model
2025-02-06 18:18:28,793:INFO:Declaring custom model
2025-02-06 18:18:28,794:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:28,797:INFO:Starting cross validation
2025-02-06 18:18:28,797:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:31,641:INFO:Calculating mean and std
2025-02-06 18:18:31,641:INFO:Creating metrics dataframe
2025-02-06 18:18:31,643:INFO:Uploading results into container
2025-02-06 18:18:31,643:INFO:Uploading model into container now
2025-02-06 18:18:31,643:INFO:_master_model_container: 9
2025-02-06 18:18:31,643:INFO:_display_container: 7
2025-02-06 18:18:31,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:31,644:INFO:create_model() successfully completed......................................
2025-02-06 18:18:31,737:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:31,737:INFO:Creating metrics dataframe
2025-02-06 18:18:31,740:INFO:Initializing custom model Logistic Regression
2025-02-06 18:18:31,740:INFO:Total runtime is 0.049280277887980145 minutes
2025-02-06 18:18:31,741:INFO:SubProcess create_model() called ==================================
2025-02-06 18:18:31,742:INFO:Initializing create_model()
2025-02-06 18:18:31,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935E8CC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:31,742:INFO:Checking exceptions
2025-02-06 18:18:31,742:INFO:Importing libraries
2025-02-06 18:18:31,742:INFO:Copying training dataset
2025-02-06 18:18:31,749:INFO:Defining folds
2025-02-06 18:18:31,749:INFO:Declaring metric variables
2025-02-06 18:18:31,750:INFO:Importing untrained model
2025-02-06 18:18:31,750:INFO:Declaring custom model
2025-02-06 18:18:31,752:INFO:Logistic Regression Imported successfully
2025-02-06 18:18:31,755:INFO:Starting cross validation
2025-02-06 18:18:31,755:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:18:32,120:INFO:Calculating mean and std
2025-02-06 18:18:32,120:INFO:Creating metrics dataframe
2025-02-06 18:18:32,122:INFO:Uploading results into container
2025-02-06 18:18:32,122:INFO:Uploading model into container now
2025-02-06 18:18:32,122:INFO:_master_model_container: 10
2025-02-06 18:18:32,122:INFO:_display_container: 7
2025-02-06 18:18:32,123:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:18:32,123:INFO:create_model() successfully completed......................................
2025-02-06 18:18:32,190:INFO:SubProcess create_model() end ==================================
2025-02-06 18:18:32,190:INFO:Creating metrics dataframe
2025-02-06 18:18:32,194:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:18:32,197:INFO:Initializing create_model()
2025-02-06 18:18:32,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:18:32,197:INFO:Checking exceptions
2025-02-06 18:18:32,198:INFO:Importing libraries
2025-02-06 18:18:32,198:INFO:Copying training dataset
2025-02-06 18:18:32,203:INFO:Defining folds
2025-02-06 18:18:32,203:INFO:Declaring metric variables
2025-02-06 18:18:32,203:INFO:Importing untrained model
2025-02-06 18:18:32,203:INFO:Declaring custom model
2025-02-06 18:18:32,204:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:18:32,204:INFO:Cross validation set to False
2025-02-06 18:18:32,204:INFO:Fitting Model
2025-02-06 18:18:32,216:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:18:32,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
2025-02-06 18:18:32,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:18:32,217:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:18:32,217:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:18:32,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:18:32,218:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:18:32,846:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:32,847:INFO:create_model() successfully completed......................................
2025-02-06 18:18:32,949:INFO:_master_model_container: 10
2025-02-06 18:18:32,949:INFO:_display_container: 7
2025-02-06 18:18:32,949:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:18:32,950:INFO:compare_models() successfully completed......................................
2025-02-06 18:18:32,950:INFO:Initializing predict_model()
2025-02-06 18:18:32,950:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC81EE0>)
2025-02-06 18:18:32,951:INFO:Checking exceptions
2025-02-06 18:18:32,951:INFO:Preloading libraries
2025-02-06 18:18:32,951:INFO:Set up data.
2025-02-06 18:18:32,959:INFO:Set up index.
2025-02-06 18:18:33,130:INFO:Initializing predict_model()
2025-02-06 18:18:33,130:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC81EE0>)
2025-02-06 18:18:33,130:INFO:Checking exceptions
2025-02-06 18:18:33,130:INFO:Preloading libraries
2025-02-06 18:18:33,131:INFO:Set up data.
2025-02-06 18:18:33,136:INFO:Set up index.
2025-02-06 18:18:33,255:INFO:Initializing predict_model()
2025-02-06 18:18:33,255:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021930F59760>)
2025-02-06 18:18:33,255:INFO:Checking exceptions
2025-02-06 18:18:33,255:INFO:Preloading libraries
2025-02-06 18:18:33,256:INFO:Set up data.
2025-02-06 18:18:33,263:INFO:Set up index.
2025-02-06 18:18:33,377:INFO:Initializing predict_model()
2025-02-06 18:18:33,377:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193BC2CF10>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021930F59760>)
2025-02-06 18:18:33,377:INFO:Checking exceptions
2025-02-06 18:18:33,377:INFO:Preloading libraries
2025-02-06 18:18:33,378:INFO:Set up data.
2025-02-06 18:18:33,383:INFO:Set up index.
2025-02-06 18:19:43,971:INFO:PyCaret ClassificationExperiment
2025-02-06 18:19:43,971:INFO:Logging name: clf-default-name
2025-02-06 18:19:43,971:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:19:43,971:INFO:version 3.3.2
2025-02-06 18:19:43,971:INFO:Initializing setup()
2025-02-06 18:19:43,971:INFO:self.USI: 8e64
2025-02-06 18:19:43,971:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:19:43,971:INFO:Checking environment
2025-02-06 18:19:43,971:INFO:python_version: 3.11.9
2025-02-06 18:19:43,971:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:19:43,971:INFO:machine: AMD64
2025-02-06 18:19:43,971:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:19:43,977:INFO:Memory: svmem(total=67771465728, available=46070403072, percent=32.0, used=21701062656, free=46070403072)
2025-02-06 18:19:43,977:INFO:Physical Core: 8
2025-02-06 18:19:43,977:INFO:Logical Core: 16
2025-02-06 18:19:43,977:INFO:Checking libraries
2025-02-06 18:19:43,977:INFO:System:
2025-02-06 18:19:43,977:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:19:43,977:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:19:43,977:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:19:43,977:INFO:PyCaret required dependencies:
2025-02-06 18:19:43,978:INFO:                 pip: 25.0
2025-02-06 18:19:43,978:INFO:          setuptools: 65.5.0
2025-02-06 18:19:43,978:INFO:             pycaret: 3.3.2
2025-02-06 18:19:43,978:INFO:             IPython: 8.32.0
2025-02-06 18:19:43,978:INFO:          ipywidgets: 8.1.5
2025-02-06 18:19:43,978:INFO:                tqdm: 4.67.1
2025-02-06 18:19:43,978:INFO:               numpy: 1.26.4
2025-02-06 18:19:43,978:INFO:              pandas: 2.1.4
2025-02-06 18:19:43,978:INFO:              jinja2: 3.1.5
2025-02-06 18:19:43,978:INFO:               scipy: 1.11.4
2025-02-06 18:19:43,978:INFO:              joblib: 1.3.2
2025-02-06 18:19:43,978:INFO:             sklearn: 1.4.2
2025-02-06 18:19:43,978:INFO:                pyod: 2.0.3
2025-02-06 18:19:43,978:INFO:            imblearn: 0.13.0
2025-02-06 18:19:43,978:INFO:   category_encoders: 2.7.0
2025-02-06 18:19:43,978:INFO:            lightgbm: 4.5.0
2025-02-06 18:19:43,978:INFO:               numba: 0.61.0
2025-02-06 18:19:43,978:INFO:            requests: 2.32.3
2025-02-06 18:19:43,978:INFO:          matplotlib: 3.7.5
2025-02-06 18:19:43,978:INFO:          scikitplot: 0.3.7
2025-02-06 18:19:43,978:INFO:         yellowbrick: 1.5
2025-02-06 18:19:43,978:INFO:              plotly: 5.24.1
2025-02-06 18:19:43,978:INFO:    plotly-resampler: Not installed
2025-02-06 18:19:43,978:INFO:             kaleido: 0.2.1
2025-02-06 18:19:43,978:INFO:           schemdraw: 0.15
2025-02-06 18:19:43,978:INFO:         statsmodels: 0.14.4
2025-02-06 18:19:43,978:INFO:              sktime: 0.26.0
2025-02-06 18:19:43,978:INFO:               tbats: 1.1.3
2025-02-06 18:19:43,978:INFO:            pmdarima: 2.0.4
2025-02-06 18:19:43,978:INFO:              psutil: 6.1.1
2025-02-06 18:19:43,978:INFO:          markupsafe: 3.0.2
2025-02-06 18:19:43,978:INFO:             pickle5: Not installed
2025-02-06 18:19:43,978:INFO:         cloudpickle: 3.1.1
2025-02-06 18:19:43,978:INFO:         deprecation: 2.1.0
2025-02-06 18:19:43,978:INFO:              xxhash: 3.5.0
2025-02-06 18:19:43,978:INFO:           wurlitzer: Not installed
2025-02-06 18:19:43,978:INFO:PyCaret optional dependencies:
2025-02-06 18:19:43,978:INFO:                shap: Not installed
2025-02-06 18:19:43,978:INFO:           interpret: Not installed
2025-02-06 18:19:43,978:INFO:                umap: Not installed
2025-02-06 18:19:43,978:INFO:     ydata_profiling: Not installed
2025-02-06 18:19:43,978:INFO:  explainerdashboard: Not installed
2025-02-06 18:19:43,978:INFO:             autoviz: Not installed
2025-02-06 18:19:43,979:INFO:           fairlearn: Not installed
2025-02-06 18:19:43,979:INFO:          deepchecks: Not installed
2025-02-06 18:19:43,979:INFO:             xgboost: Not installed
2025-02-06 18:19:43,979:INFO:            catboost: Not installed
2025-02-06 18:19:43,979:INFO:              kmodes: Not installed
2025-02-06 18:19:43,979:INFO:             mlxtend: Not installed
2025-02-06 18:19:43,979:INFO:       statsforecast: Not installed
2025-02-06 18:19:43,979:INFO:        tune_sklearn: Not installed
2025-02-06 18:19:43,979:INFO:                 ray: Not installed
2025-02-06 18:19:43,979:INFO:            hyperopt: Not installed
2025-02-06 18:19:43,979:INFO:              optuna: Not installed
2025-02-06 18:19:43,979:INFO:               skopt: Not installed
2025-02-06 18:19:43,979:INFO:              mlflow: Not installed
2025-02-06 18:19:43,979:INFO:              gradio: Not installed
2025-02-06 18:19:43,979:INFO:             fastapi: Not installed
2025-02-06 18:19:43,979:INFO:             uvicorn: Not installed
2025-02-06 18:19:43,979:INFO:              m2cgen: Not installed
2025-02-06 18:19:43,979:INFO:           evidently: Not installed
2025-02-06 18:19:43,979:INFO:               fugue: Not installed
2025-02-06 18:19:43,979:INFO:           streamlit: Not installed
2025-02-06 18:19:43,979:INFO:             prophet: Not installed
2025-02-06 18:19:43,979:INFO:None
2025-02-06 18:19:43,979:INFO:Set up data.
2025-02-06 18:19:43,987:INFO:Set up folding strategy.
2025-02-06 18:19:43,988:INFO:Set up train/test split.
2025-02-06 18:19:43,995:INFO:Set up index.
2025-02-06 18:19:43,995:INFO:Assigning column types.
2025-02-06 18:19:44,000:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:19:44,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,080:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:19:44,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:19:44,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,158:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:19:44,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,236:INFO:Preparing preprocessing pipeline...
2025-02-06 18:19:44,237:INFO:Set up simple imputation.
2025-02-06 18:19:44,257:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:19:44,258:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:19:44,258:INFO:Creating final display dataframe.
2025-02-06 18:19:44,319:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              8e64
2025-02-06 18:19:44,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:19:44,397:INFO:setup() successfully completed in 0.43s...............
2025-02-06 18:19:44,397:INFO:Initializing compare_models()
2025-02-06 18:19:44,397:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:19:44,397:INFO:Checking exceptions
2025-02-06 18:19:44,401:INFO:Preparing display monitor
2025-02-06 18:19:44,411:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:19:44,411:INFO:Total runtime is 0.0 minutes
2025-02-06 18:19:44,412:INFO:SubProcess create_model() called ==================================
2025-02-06 18:19:44,413:INFO:Initializing create_model()
2025-02-06 18:19:44,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBFE750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:19:44,413:INFO:Checking exceptions
2025-02-06 18:19:44,413:INFO:Importing libraries
2025-02-06 18:19:44,413:INFO:Copying training dataset
2025-02-06 18:19:44,419:INFO:Defining folds
2025-02-06 18:19:44,419:INFO:Declaring metric variables
2025-02-06 18:19:44,420:INFO:Importing untrained model
2025-02-06 18:19:44,422:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:19:44,424:INFO:Starting cross validation
2025-02-06 18:19:44,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:19:44,866:INFO:Calculating mean and std
2025-02-06 18:19:44,866:INFO:Creating metrics dataframe
2025-02-06 18:19:44,867:INFO:Uploading results into container
2025-02-06 18:19:44,868:INFO:Uploading model into container now
2025-02-06 18:19:44,868:INFO:_master_model_container: 1
2025-02-06 18:19:44,868:INFO:_display_container: 2
2025-02-06 18:19:44,868:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:19:44,868:INFO:create_model() successfully completed......................................
2025-02-06 18:19:44,968:INFO:SubProcess create_model() end ==================================
2025-02-06 18:19:44,968:INFO:Creating metrics dataframe
2025-02-06 18:19:44,971:INFO:Initializing Logistic Regression
2025-02-06 18:19:44,971:INFO:Total runtime is 0.009334897994995118 minutes
2025-02-06 18:19:44,972:INFO:SubProcess create_model() called ==================================
2025-02-06 18:19:44,973:INFO:Initializing create_model()
2025-02-06 18:19:44,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBFE750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:19:44,973:INFO:Checking exceptions
2025-02-06 18:19:44,973:INFO:Importing libraries
2025-02-06 18:19:44,973:INFO:Copying training dataset
2025-02-06 18:19:44,979:INFO:Defining folds
2025-02-06 18:19:44,979:INFO:Declaring metric variables
2025-02-06 18:19:44,980:INFO:Importing untrained model
2025-02-06 18:19:44,982:INFO:Logistic Regression Imported successfully
2025-02-06 18:19:44,985:INFO:Starting cross validation
2025-02-06 18:19:44,986:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:19:45,171:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:19:45,175:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:19:45,181:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:19:45,181:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:19:45,186:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:19:45,202:INFO:Calculating mean and std
2025-02-06 18:19:45,202:INFO:Creating metrics dataframe
2025-02-06 18:19:45,203:INFO:Uploading results into container
2025-02-06 18:19:45,203:INFO:Uploading model into container now
2025-02-06 18:19:45,203:INFO:_master_model_container: 2
2025-02-06 18:19:45,203:INFO:_display_container: 2
2025-02-06 18:19:45,203:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:19:45,204:INFO:create_model() successfully completed......................................
2025-02-06 18:19:45,284:INFO:SubProcess create_model() end ==================================
2025-02-06 18:19:45,284:INFO:Creating metrics dataframe
2025-02-06 18:19:45,287:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:19:45,291:INFO:Initializing create_model()
2025-02-06 18:19:45,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:19:45,291:INFO:Checking exceptions
2025-02-06 18:19:45,292:INFO:Importing libraries
2025-02-06 18:19:45,292:INFO:Copying training dataset
2025-02-06 18:19:45,298:INFO:Defining folds
2025-02-06 18:19:45,298:INFO:Declaring metric variables
2025-02-06 18:19:45,298:INFO:Importing untrained model
2025-02-06 18:19:45,298:INFO:Declaring custom model
2025-02-06 18:19:45,298:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:19:45,298:INFO:Cross validation set to False
2025-02-06 18:19:45,298:INFO:Fitting Model
2025-02-06 18:19:45,309:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:19:45,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.
2025-02-06 18:19:45,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:19:45,310:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:19:45,311:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:19:45,311:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:19:45,311:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:19:45,382:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:19:45,382:INFO:create_model() successfully completed......................................
2025-02-06 18:19:45,479:INFO:_master_model_container: 2
2025-02-06 18:19:45,480:INFO:_display_container: 2
2025-02-06 18:19:45,480:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:19:45,480:INFO:compare_models() successfully completed......................................
2025-02-06 18:19:45,480:INFO:Initializing create_model()
2025-02-06 18:19:45,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:19:45,480:INFO:Checking exceptions
2025-02-06 18:19:45,486:INFO:Importing libraries
2025-02-06 18:19:45,486:INFO:Copying training dataset
2025-02-06 18:19:45,493:INFO:Defining folds
2025-02-06 18:19:45,493:INFO:Declaring metric variables
2025-02-06 18:19:45,494:INFO:Importing untrained model
2025-02-06 18:19:45,496:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:19:45,499:INFO:Starting cross validation
2025-02-06 18:19:45,499:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:19:45,930:INFO:Calculating mean and std
2025-02-06 18:19:45,931:INFO:Creating metrics dataframe
2025-02-06 18:19:45,934:INFO:Finalizing model
2025-02-06 18:19:45,950:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:19:45,951:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.
2025-02-06 18:19:45,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:19:45,951:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:19:45,951:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:19:45,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:19:45,951:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:19:46,083:INFO:Uploading results into container
2025-02-06 18:19:46,083:INFO:Uploading model into container now
2025-02-06 18:19:46,090:INFO:_master_model_container: 3
2025-02-06 18:19:46,090:INFO:_display_container: 3
2025-02-06 18:19:46,090:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:19:46,090:INFO:create_model() successfully completed......................................
2025-02-06 18:19:46,209:INFO:Initializing tune_model()
2025-02-06 18:19:46,209:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:19:46,209:INFO:Checking exceptions
2025-02-06 18:19:46,218:INFO:Copying training dataset
2025-02-06 18:19:46,222:INFO:Checking base model
2025-02-06 18:19:46,222:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:19:46,224:INFO:Declaring metric variables
2025-02-06 18:19:46,225:INFO:Defining Hyperparameters
2025-02-06 18:19:46,307:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:19:46,307:INFO:Tuning with n_jobs=-1
2025-02-06 18:19:46,308:INFO:Initializing RandomizedSearchCV
2025-02-06 18:20:00,556:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:20:00,557:INFO:Hyperparameter search completed
2025-02-06 18:20:00,557:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:00,558:INFO:Initializing create_model()
2025-02-06 18:20:00,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193634D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:20:00,558:INFO:Checking exceptions
2025-02-06 18:20:00,558:INFO:Importing libraries
2025-02-06 18:20:00,558:INFO:Copying training dataset
2025-02-06 18:20:00,568:INFO:Defining folds
2025-02-06 18:20:00,568:INFO:Declaring metric variables
2025-02-06 18:20:00,570:INFO:Importing untrained model
2025-02-06 18:20:00,570:INFO:Declaring custom model
2025-02-06 18:20:00,573:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:20:00,576:INFO:Starting cross validation
2025-02-06 18:20:00,577:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:03,403:INFO:Calculating mean and std
2025-02-06 18:20:03,404:INFO:Creating metrics dataframe
2025-02-06 18:20:03,408:INFO:Finalizing model
2025-02-06 18:20:03,422:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:20:03,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
2025-02-06 18:20:03,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:20:03,423:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:20:03,423:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:20:03,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:20:03,423:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:20:03,985:INFO:Uploading results into container
2025-02-06 18:20:03,987:INFO:Uploading model into container now
2025-02-06 18:20:03,987:INFO:_master_model_container: 4
2025-02-06 18:20:03,987:INFO:_display_container: 4
2025-02-06 18:20:03,987:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:03,987:INFO:create_model() successfully completed......................................
2025-02-06 18:20:04,073:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:04,073:INFO:choose_better activated
2025-02-06 18:20:04,074:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:04,076:INFO:Initializing create_model()
2025-02-06 18:20:04,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:04,076:INFO:Checking exceptions
2025-02-06 18:20:04,077:INFO:Importing libraries
2025-02-06 18:20:04,077:INFO:Copying training dataset
2025-02-06 18:20:04,084:INFO:Defining folds
2025-02-06 18:20:04,084:INFO:Declaring metric variables
2025-02-06 18:20:04,084:INFO:Importing untrained model
2025-02-06 18:20:04,084:INFO:Declaring custom model
2025-02-06 18:20:04,085:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:20:04,085:INFO:Starting cross validation
2025-02-06 18:20:04,085:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:04,481:INFO:Calculating mean and std
2025-02-06 18:20:04,481:INFO:Creating metrics dataframe
2025-02-06 18:20:04,483:INFO:Finalizing model
2025-02-06 18:20:04,497:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:20:04,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.
2025-02-06 18:20:04,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:20:04,499:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:20:04,499:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:20:04,499:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:20:04,499:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:20:04,612:INFO:Uploading results into container
2025-02-06 18:20:04,612:INFO:Uploading model into container now
2025-02-06 18:20:04,613:INFO:_master_model_container: 5
2025-02-06 18:20:04,613:INFO:_display_container: 5
2025-02-06 18:20:04,613:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:04,613:INFO:create_model() successfully completed......................................
2025-02-06 18:20:04,701:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:04,701:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:20:04,702:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:20:04,702:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:20:04,702:INFO:choose_better completed
2025-02-06 18:20:04,707:INFO:_master_model_container: 5
2025-02-06 18:20:04,707:INFO:_display_container: 4
2025-02-06 18:20:04,707:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:04,707:INFO:tune_model() successfully completed......................................
2025-02-06 18:20:04,773:INFO:Initializing create_model()
2025-02-06 18:20:04,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:04,773:INFO:Checking exceptions
2025-02-06 18:20:04,780:INFO:Importing libraries
2025-02-06 18:20:04,780:INFO:Copying training dataset
2025-02-06 18:20:04,786:INFO:Defining folds
2025-02-06 18:20:04,786:INFO:Declaring metric variables
2025-02-06 18:20:04,787:INFO:Importing untrained model
2025-02-06 18:20:04,789:INFO:Logistic Regression Imported successfully
2025-02-06 18:20:04,792:INFO:Starting cross validation
2025-02-06 18:20:04,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:04,981:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:04,983:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:04,987:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:04,989:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:04,992:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,005:INFO:Calculating mean and std
2025-02-06 18:20:05,005:INFO:Creating metrics dataframe
2025-02-06 18:20:05,008:INFO:Finalizing model
2025-02-06 18:20:05,407:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,409:INFO:Uploading results into container
2025-02-06 18:20:05,409:INFO:Uploading model into container now
2025-02-06 18:20:05,413:INFO:_master_model_container: 6
2025-02-06 18:20:05,413:INFO:_display_container: 5
2025-02-06 18:20:05,413:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:20:05,413:INFO:create_model() successfully completed......................................
2025-02-06 18:20:05,484:INFO:Initializing tune_model()
2025-02-06 18:20:05,484:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:20:05,484:INFO:Checking exceptions
2025-02-06 18:20:05,492:INFO:Copying training dataset
2025-02-06 18:20:05,497:INFO:Checking base model
2025-02-06 18:20:05,497:INFO:Base model : Logistic Regression
2025-02-06 18:20:05,499:INFO:Declaring metric variables
2025-02-06 18:20:05,500:INFO:Defining Hyperparameters
2025-02-06 18:20:05,569:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:20:05,569:INFO:Tuning with n_jobs=-1
2025-02-06 18:20:05,569:INFO:Initializing RandomizedSearchCV
2025-02-06 18:20:05,633:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,637:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,639:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,641:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,642:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,647:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,651:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,653:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,654:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:05,669:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,076:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,078:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,105:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,112:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,112:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,390:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,402:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,441:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,451:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,529:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:06,589:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:20:06,590:INFO:Hyperparameter search completed
2025-02-06 18:20:06,590:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:06,590:INFO:Initializing create_model()
2025-02-06 18:20:06,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C4F51D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:20:06,591:INFO:Checking exceptions
2025-02-06 18:20:06,591:INFO:Importing libraries
2025-02-06 18:20:06,591:INFO:Copying training dataset
2025-02-06 18:20:06,597:INFO:Defining folds
2025-02-06 18:20:06,597:INFO:Declaring metric variables
2025-02-06 18:20:06,599:INFO:Importing untrained model
2025-02-06 18:20:06,599:INFO:Declaring custom model
2025-02-06 18:20:06,600:INFO:Logistic Regression Imported successfully
2025-02-06 18:20:06,602:INFO:Starting cross validation
2025-02-06 18:20:06,603:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:06,943:INFO:Calculating mean and std
2025-02-06 18:20:06,943:INFO:Creating metrics dataframe
2025-02-06 18:20:06,945:INFO:Finalizing model
2025-02-06 18:20:07,198:INFO:Uploading results into container
2025-02-06 18:20:07,199:INFO:Uploading model into container now
2025-02-06 18:20:07,199:INFO:_master_model_container: 7
2025-02-06 18:20:07,199:INFO:_display_container: 6
2025-02-06 18:20:07,199:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:20:07,199:INFO:create_model() successfully completed......................................
2025-02-06 18:20:07,268:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:07,268:INFO:choose_better activated
2025-02-06 18:20:07,270:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:07,270:INFO:Initializing create_model()
2025-02-06 18:20:07,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:07,270:INFO:Checking exceptions
2025-02-06 18:20:07,271:INFO:Importing libraries
2025-02-06 18:20:07,271:INFO:Copying training dataset
2025-02-06 18:20:07,277:INFO:Defining folds
2025-02-06 18:20:07,277:INFO:Declaring metric variables
2025-02-06 18:20:07,277:INFO:Importing untrained model
2025-02-06 18:20:07,277:INFO:Declaring custom model
2025-02-06 18:20:07,277:INFO:Logistic Regression Imported successfully
2025-02-06 18:20:07,277:INFO:Starting cross validation
2025-02-06 18:20:07,277:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:07,447:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,448:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,453:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,458:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,460:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,477:INFO:Calculating mean and std
2025-02-06 18:20:07,477:INFO:Creating metrics dataframe
2025-02-06 18:20:07,478:INFO:Finalizing model
2025-02-06 18:20:07,880:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:20:07,880:INFO:Uploading results into container
2025-02-06 18:20:07,880:INFO:Uploading model into container now
2025-02-06 18:20:07,881:INFO:_master_model_container: 8
2025-02-06 18:20:07,881:INFO:_display_container: 7
2025-02-06 18:20:07,881:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:20:07,881:INFO:create_model() successfully completed......................................
2025-02-06 18:20:07,952:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:07,953:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:20:07,953:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:20:07,953:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:20:07,953:INFO:choose_better completed
2025-02-06 18:20:07,957:INFO:_master_model_container: 8
2025-02-06 18:20:07,957:INFO:_display_container: 6
2025-02-06 18:20:07,958:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:20:07,958:INFO:tune_model() successfully completed......................................
2025-02-06 18:20:08,014:INFO:Initializing compare_models()
2025-02-06 18:20:08,014:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:20:08,014:INFO:Checking exceptions
2025-02-06 18:20:08,017:INFO:Preparing display monitor
2025-02-06 18:20:08,029:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:20:08,030:INFO:Total runtime is 1.6637643178304036e-05 minutes
2025-02-06 18:20:08,031:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:08,032:INFO:Initializing create_model()
2025-02-06 18:20:08,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021936359110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:08,032:INFO:Checking exceptions
2025-02-06 18:20:08,032:INFO:Importing libraries
2025-02-06 18:20:08,032:INFO:Copying training dataset
2025-02-06 18:20:08,039:INFO:Defining folds
2025-02-06 18:20:08,039:INFO:Declaring metric variables
2025-02-06 18:20:08,040:INFO:Importing untrained model
2025-02-06 18:20:08,041:INFO:Declaring custom model
2025-02-06 18:20:08,043:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:20:08,046:INFO:Starting cross validation
2025-02-06 18:20:08,046:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:10,859:INFO:Calculating mean and std
2025-02-06 18:20:10,860:INFO:Creating metrics dataframe
2025-02-06 18:20:10,861:INFO:Uploading results into container
2025-02-06 18:20:10,862:INFO:Uploading model into container now
2025-02-06 18:20:10,862:INFO:_master_model_container: 9
2025-02-06 18:20:10,862:INFO:_display_container: 7
2025-02-06 18:20:10,862:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:10,863:INFO:create_model() successfully completed......................................
2025-02-06 18:20:10,950:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:10,951:INFO:Creating metrics dataframe
2025-02-06 18:20:10,954:INFO:Initializing custom model Logistic Regression
2025-02-06 18:20:10,954:INFO:Total runtime is 0.04875950415929158 minutes
2025-02-06 18:20:10,956:INFO:SubProcess create_model() called ==================================
2025-02-06 18:20:10,956:INFO:Initializing create_model()
2025-02-06 18:20:10,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021936359110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:10,956:INFO:Checking exceptions
2025-02-06 18:20:10,956:INFO:Importing libraries
2025-02-06 18:20:10,956:INFO:Copying training dataset
2025-02-06 18:20:10,962:INFO:Defining folds
2025-02-06 18:20:10,963:INFO:Declaring metric variables
2025-02-06 18:20:10,964:INFO:Importing untrained model
2025-02-06 18:20:10,964:INFO:Declaring custom model
2025-02-06 18:20:10,967:INFO:Logistic Regression Imported successfully
2025-02-06 18:20:10,969:INFO:Starting cross validation
2025-02-06 18:20:10,970:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:20:11,332:INFO:Calculating mean and std
2025-02-06 18:20:11,333:INFO:Creating metrics dataframe
2025-02-06 18:20:11,334:INFO:Uploading results into container
2025-02-06 18:20:11,334:INFO:Uploading model into container now
2025-02-06 18:20:11,334:INFO:_master_model_container: 10
2025-02-06 18:20:11,334:INFO:_display_container: 7
2025-02-06 18:20:11,334:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:20:11,334:INFO:create_model() successfully completed......................................
2025-02-06 18:20:11,410:INFO:SubProcess create_model() end ==================================
2025-02-06 18:20:11,410:INFO:Creating metrics dataframe
2025-02-06 18:20:11,413:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:20:11,417:INFO:Initializing create_model()
2025-02-06 18:20:11,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:20:11,417:INFO:Checking exceptions
2025-02-06 18:20:11,418:INFO:Importing libraries
2025-02-06 18:20:11,418:INFO:Copying training dataset
2025-02-06 18:20:11,423:INFO:Defining folds
2025-02-06 18:20:11,423:INFO:Declaring metric variables
2025-02-06 18:20:11,423:INFO:Importing untrained model
2025-02-06 18:20:11,423:INFO:Declaring custom model
2025-02-06 18:20:11,423:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:20:11,424:INFO:Cross validation set to False
2025-02-06 18:20:11,424:INFO:Fitting Model
2025-02-06 18:20:11,435:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:20:11,435:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.
2025-02-06 18:20:11,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:20:11,436:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:20:11,436:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:20:11,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:20:11,436:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:20:11,976:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:11,976:INFO:create_model() successfully completed......................................
2025-02-06 18:20:12,073:INFO:_master_model_container: 10
2025-02-06 18:20:12,073:INFO:_display_container: 7
2025-02-06 18:20:12,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:20:12,073:INFO:compare_models() successfully completed......................................
2025-02-06 18:20:12,074:INFO:Initializing predict_model()
2025-02-06 18:20:12,074:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC81120>)
2025-02-06 18:20:12,074:INFO:Checking exceptions
2025-02-06 18:20:12,074:INFO:Preloading libraries
2025-02-06 18:20:12,075:INFO:Set up data.
2025-02-06 18:20:12,081:INFO:Set up index.
2025-02-06 18:20:12,248:INFO:Initializing predict_model()
2025-02-06 18:20:12,248:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:20:12,248:INFO:Checking exceptions
2025-02-06 18:20:12,248:INFO:Preloading libraries
2025-02-06 18:20:12,249:INFO:Set up data.
2025-02-06 18:20:12,253:INFO:Set up index.
2025-02-06 18:20:12,364:INFO:Initializing predict_model()
2025-02-06 18:20:12,364:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:20:12,364:INFO:Checking exceptions
2025-02-06 18:20:12,364:INFO:Preloading libraries
2025-02-06 18:20:12,365:INFO:Set up data.
2025-02-06 18:20:12,374:INFO:Set up index.
2025-02-06 18:20:12,477:INFO:Initializing predict_model()
2025-02-06 18:20:12,477:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021935E87B90>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:20:12,477:INFO:Checking exceptions
2025-02-06 18:20:12,477:INFO:Preloading libraries
2025-02-06 18:20:12,478:INFO:Set up data.
2025-02-06 18:20:12,481:INFO:Set up index.
2025-02-06 18:25:43,230:INFO:PyCaret ClassificationExperiment
2025-02-06 18:25:43,230:INFO:Logging name: clf-default-name
2025-02-06 18:25:43,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:25:43,230:INFO:version 3.3.2
2025-02-06 18:25:43,230:INFO:Initializing setup()
2025-02-06 18:25:43,230:INFO:self.USI: 3405
2025-02-06 18:25:43,230:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:25:43,230:INFO:Checking environment
2025-02-06 18:25:43,230:INFO:python_version: 3.11.9
2025-02-06 18:25:43,230:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:25:43,230:INFO:machine: AMD64
2025-02-06 18:25:43,231:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:25:43,234:INFO:Memory: svmem(total=67771465728, available=48793055232, percent=28.0, used=18978410496, free=48793055232)
2025-02-06 18:25:43,234:INFO:Physical Core: 8
2025-02-06 18:25:43,234:INFO:Logical Core: 16
2025-02-06 18:25:43,234:INFO:Checking libraries
2025-02-06 18:25:43,234:INFO:System:
2025-02-06 18:25:43,234:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:25:43,234:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:25:43,234:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:25:43,234:INFO:PyCaret required dependencies:
2025-02-06 18:25:43,234:INFO:                 pip: 25.0
2025-02-06 18:25:43,234:INFO:          setuptools: 65.5.0
2025-02-06 18:25:43,234:INFO:             pycaret: 3.3.2
2025-02-06 18:25:43,234:INFO:             IPython: 8.32.0
2025-02-06 18:25:43,234:INFO:          ipywidgets: 8.1.5
2025-02-06 18:25:43,234:INFO:                tqdm: 4.67.1
2025-02-06 18:25:43,234:INFO:               numpy: 1.26.4
2025-02-06 18:25:43,234:INFO:              pandas: 2.1.4
2025-02-06 18:25:43,234:INFO:              jinja2: 3.1.5
2025-02-06 18:25:43,234:INFO:               scipy: 1.11.4
2025-02-06 18:25:43,234:INFO:              joblib: 1.3.2
2025-02-06 18:25:43,234:INFO:             sklearn: 1.4.2
2025-02-06 18:25:43,234:INFO:                pyod: 2.0.3
2025-02-06 18:25:43,234:INFO:            imblearn: 0.13.0
2025-02-06 18:25:43,234:INFO:   category_encoders: 2.7.0
2025-02-06 18:25:43,234:INFO:            lightgbm: 4.5.0
2025-02-06 18:25:43,234:INFO:               numba: 0.61.0
2025-02-06 18:25:43,234:INFO:            requests: 2.32.3
2025-02-06 18:25:43,234:INFO:          matplotlib: 3.7.5
2025-02-06 18:25:43,234:INFO:          scikitplot: 0.3.7
2025-02-06 18:25:43,234:INFO:         yellowbrick: 1.5
2025-02-06 18:25:43,234:INFO:              plotly: 5.24.1
2025-02-06 18:25:43,234:INFO:    plotly-resampler: Not installed
2025-02-06 18:25:43,234:INFO:             kaleido: 0.2.1
2025-02-06 18:25:43,234:INFO:           schemdraw: 0.15
2025-02-06 18:25:43,234:INFO:         statsmodels: 0.14.4
2025-02-06 18:25:43,234:INFO:              sktime: 0.26.0
2025-02-06 18:25:43,234:INFO:               tbats: 1.1.3
2025-02-06 18:25:43,234:INFO:            pmdarima: 2.0.4
2025-02-06 18:25:43,234:INFO:              psutil: 6.1.1
2025-02-06 18:25:43,234:INFO:          markupsafe: 3.0.2
2025-02-06 18:25:43,234:INFO:             pickle5: Not installed
2025-02-06 18:25:43,234:INFO:         cloudpickle: 3.1.1
2025-02-06 18:25:43,234:INFO:         deprecation: 2.1.0
2025-02-06 18:25:43,234:INFO:              xxhash: 3.5.0
2025-02-06 18:25:43,234:INFO:           wurlitzer: Not installed
2025-02-06 18:25:43,234:INFO:PyCaret optional dependencies:
2025-02-06 18:25:43,234:INFO:                shap: Not installed
2025-02-06 18:25:43,234:INFO:           interpret: Not installed
2025-02-06 18:25:43,234:INFO:                umap: Not installed
2025-02-06 18:25:43,234:INFO:     ydata_profiling: Not installed
2025-02-06 18:25:43,234:INFO:  explainerdashboard: Not installed
2025-02-06 18:25:43,234:INFO:             autoviz: Not installed
2025-02-06 18:25:43,236:INFO:           fairlearn: Not installed
2025-02-06 18:25:43,236:INFO:          deepchecks: Not installed
2025-02-06 18:25:43,236:INFO:             xgboost: Not installed
2025-02-06 18:25:43,236:INFO:            catboost: Not installed
2025-02-06 18:25:43,236:INFO:              kmodes: Not installed
2025-02-06 18:25:43,236:INFO:             mlxtend: Not installed
2025-02-06 18:25:43,236:INFO:       statsforecast: Not installed
2025-02-06 18:25:43,236:INFO:        tune_sklearn: Not installed
2025-02-06 18:25:43,236:INFO:                 ray: Not installed
2025-02-06 18:25:43,236:INFO:            hyperopt: Not installed
2025-02-06 18:25:43,236:INFO:              optuna: Not installed
2025-02-06 18:25:43,236:INFO:               skopt: Not installed
2025-02-06 18:25:43,236:INFO:              mlflow: Not installed
2025-02-06 18:25:43,236:INFO:              gradio: Not installed
2025-02-06 18:25:43,236:INFO:             fastapi: Not installed
2025-02-06 18:25:43,236:INFO:             uvicorn: Not installed
2025-02-06 18:25:43,236:INFO:              m2cgen: Not installed
2025-02-06 18:25:43,236:INFO:           evidently: Not installed
2025-02-06 18:25:43,236:INFO:               fugue: Not installed
2025-02-06 18:25:43,236:INFO:           streamlit: Not installed
2025-02-06 18:25:43,236:INFO:             prophet: Not installed
2025-02-06 18:25:43,236:INFO:None
2025-02-06 18:25:43,236:INFO:Set up data.
2025-02-06 18:25:43,242:INFO:Set up folding strategy.
2025-02-06 18:25:43,242:INFO:Set up train/test split.
2025-02-06 18:25:43,247:INFO:Set up index.
2025-02-06 18:25:43,248:INFO:Assigning column types.
2025-02-06 18:25:43,252:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:25:43,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,332:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:25:43,357:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:25:43,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,411:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:25:43,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,492:INFO:Preparing preprocessing pipeline...
2025-02-06 18:25:43,493:INFO:Set up simple imputation.
2025-02-06 18:25:43,511:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:25:43,513:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:25:43,513:INFO:Creating final display dataframe.
2025-02-06 18:25:43,576:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              3405
2025-02-06 18:25:43,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:25:43,654:INFO:setup() successfully completed in 0.42s...............
2025-02-06 18:25:43,654:INFO:Initializing compare_models()
2025-02-06 18:25:43,654:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:25:43,654:INFO:Checking exceptions
2025-02-06 18:25:43,658:INFO:Preparing display monitor
2025-02-06 18:25:43,668:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:25:43,668:INFO:Total runtime is 0.0 minutes
2025-02-06 18:25:43,670:INFO:SubProcess create_model() called ==================================
2025-02-06 18:25:43,670:INFO:Initializing create_model()
2025-02-06 18:25:43,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021936386090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:25:43,670:INFO:Checking exceptions
2025-02-06 18:25:43,670:INFO:Importing libraries
2025-02-06 18:25:43,670:INFO:Copying training dataset
2025-02-06 18:25:43,676:INFO:Defining folds
2025-02-06 18:25:43,676:INFO:Declaring metric variables
2025-02-06 18:25:43,678:INFO:Importing untrained model
2025-02-06 18:25:43,680:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:25:43,683:INFO:Starting cross validation
2025-02-06 18:25:43,683:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:25:45,798:INFO:Calculating mean and std
2025-02-06 18:25:45,800:INFO:Creating metrics dataframe
2025-02-06 18:25:45,801:INFO:Uploading results into container
2025-02-06 18:25:45,801:INFO:Uploading model into container now
2025-02-06 18:25:45,801:INFO:_master_model_container: 1
2025-02-06 18:25:45,801:INFO:_display_container: 2
2025-02-06 18:25:45,802:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:25:45,802:INFO:create_model() successfully completed......................................
2025-02-06 18:25:45,901:INFO:SubProcess create_model() end ==================================
2025-02-06 18:25:45,902:INFO:Creating metrics dataframe
2025-02-06 18:25:45,904:INFO:Initializing Logistic Regression
2025-02-06 18:25:45,904:INFO:Total runtime is 0.037263023853302005 minutes
2025-02-06 18:25:45,906:INFO:SubProcess create_model() called ==================================
2025-02-06 18:25:45,906:INFO:Initializing create_model()
2025-02-06 18:25:45,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021936386090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:25:45,906:INFO:Checking exceptions
2025-02-06 18:25:45,906:INFO:Importing libraries
2025-02-06 18:25:45,906:INFO:Copying training dataset
2025-02-06 18:25:45,913:INFO:Defining folds
2025-02-06 18:25:45,913:INFO:Declaring metric variables
2025-02-06 18:25:45,914:INFO:Importing untrained model
2025-02-06 18:25:45,916:INFO:Logistic Regression Imported successfully
2025-02-06 18:25:45,918:INFO:Starting cross validation
2025-02-06 18:25:45,919:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:25:47,396:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:25:47,399:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:25:47,409:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:25:47,412:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:25:47,414:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:25:47,429:INFO:Calculating mean and std
2025-02-06 18:25:47,429:INFO:Creating metrics dataframe
2025-02-06 18:25:47,431:INFO:Uploading results into container
2025-02-06 18:25:47,432:INFO:Uploading model into container now
2025-02-06 18:25:47,432:INFO:_master_model_container: 2
2025-02-06 18:25:47,432:INFO:_display_container: 2
2025-02-06 18:25:47,432:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:25:47,432:INFO:create_model() successfully completed......................................
2025-02-06 18:25:47,515:INFO:SubProcess create_model() end ==================================
2025-02-06 18:25:47,515:INFO:Creating metrics dataframe
2025-02-06 18:25:47,519:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:25:47,522:INFO:Initializing create_model()
2025-02-06 18:25:47,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:25:47,522:INFO:Checking exceptions
2025-02-06 18:25:47,523:INFO:Importing libraries
2025-02-06 18:25:47,523:INFO:Copying training dataset
2025-02-06 18:25:47,529:INFO:Defining folds
2025-02-06 18:25:47,529:INFO:Declaring metric variables
2025-02-06 18:25:47,529:INFO:Importing untrained model
2025-02-06 18:25:47,529:INFO:Declaring custom model
2025-02-06 18:25:47,529:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:25:47,530:INFO:Cross validation set to False
2025-02-06 18:25:47,530:INFO:Fitting Model
2025-02-06 18:25:47,542:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:25:47,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
2025-02-06 18:25:47,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:25:47,543:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:25:47,543:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:25:47,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:25:47,543:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:25:47,609:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:25:47,609:INFO:create_model() successfully completed......................................
2025-02-06 18:25:47,705:INFO:_master_model_container: 2
2025-02-06 18:25:47,706:INFO:_display_container: 2
2025-02-06 18:25:47,706:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:25:47,706:INFO:compare_models() successfully completed......................................
2025-02-06 18:25:47,706:INFO:Initializing create_model()
2025-02-06 18:25:47,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:25:47,706:INFO:Checking exceptions
2025-02-06 18:25:47,717:INFO:Importing libraries
2025-02-06 18:25:47,717:INFO:Copying training dataset
2025-02-06 18:25:47,726:INFO:Defining folds
2025-02-06 18:25:47,726:INFO:Declaring metric variables
2025-02-06 18:25:47,728:INFO:Importing untrained model
2025-02-06 18:25:47,730:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:25:47,733:INFO:Starting cross validation
2025-02-06 18:25:47,734:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:25:49,487:INFO:Calculating mean and std
2025-02-06 18:25:49,488:INFO:Creating metrics dataframe
2025-02-06 18:25:49,502:INFO:Finalizing model
2025-02-06 18:25:49,525:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:25:49,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.
2025-02-06 18:25:49,527:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:25:49,527:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:25:49,527:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:25:49,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:25:49,527:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:25:49,645:INFO:Uploading results into container
2025-02-06 18:25:49,646:INFO:Uploading model into container now
2025-02-06 18:25:49,652:INFO:_master_model_container: 3
2025-02-06 18:25:49,652:INFO:_display_container: 3
2025-02-06 18:25:49,652:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:25:49,653:INFO:create_model() successfully completed......................................
2025-02-06 18:25:49,746:INFO:Initializing tune_model()
2025-02-06 18:25:49,746:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:25:49,746:INFO:Checking exceptions
2025-02-06 18:25:49,755:INFO:Copying training dataset
2025-02-06 18:25:49,758:INFO:Checking base model
2025-02-06 18:25:49,758:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:25:49,760:INFO:Declaring metric variables
2025-02-06 18:25:49,761:INFO:Defining Hyperparameters
2025-02-06 18:25:49,827:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:25:49,827:INFO:Tuning with n_jobs=-1
2025-02-06 18:25:49,827:INFO:Initializing RandomizedSearchCV
2025-02-06 18:26:06,071:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:26:06,071:INFO:Hyperparameter search completed
2025-02-06 18:26:06,071:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:06,071:INFO:Initializing create_model()
2025-02-06 18:26:06,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EBAB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:26:06,072:INFO:Checking exceptions
2025-02-06 18:26:06,072:INFO:Importing libraries
2025-02-06 18:26:06,072:INFO:Copying training dataset
2025-02-06 18:26:06,082:INFO:Defining folds
2025-02-06 18:26:06,082:INFO:Declaring metric variables
2025-02-06 18:26:06,085:INFO:Importing untrained model
2025-02-06 18:26:06,085:INFO:Declaring custom model
2025-02-06 18:26:06,088:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:26:06,092:INFO:Starting cross validation
2025-02-06 18:26:06,092:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:09,579:INFO:Calculating mean and std
2025-02-06 18:26:09,580:INFO:Creating metrics dataframe
2025-02-06 18:26:09,584:INFO:Finalizing model
2025-02-06 18:26:09,599:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:26:09,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000796 seconds.
2025-02-06 18:26:09,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:26:09,600:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:26:09,600:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:26:09,601:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:26:09,601:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:26:10,282:INFO:Uploading results into container
2025-02-06 18:26:10,283:INFO:Uploading model into container now
2025-02-06 18:26:10,284:INFO:_master_model_container: 4
2025-02-06 18:26:10,284:INFO:_display_container: 4
2025-02-06 18:26:10,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:10,284:INFO:create_model() successfully completed......................................
2025-02-06 18:26:10,415:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:10,415:INFO:choose_better activated
2025-02-06 18:26:10,417:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:10,417:INFO:Initializing create_model()
2025-02-06 18:26:10,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:10,417:INFO:Checking exceptions
2025-02-06 18:26:10,418:INFO:Importing libraries
2025-02-06 18:26:10,418:INFO:Copying training dataset
2025-02-06 18:26:10,425:INFO:Defining folds
2025-02-06 18:26:10,425:INFO:Declaring metric variables
2025-02-06 18:26:10,425:INFO:Importing untrained model
2025-02-06 18:26:10,425:INFO:Declaring custom model
2025-02-06 18:26:10,426:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:26:10,426:INFO:Starting cross validation
2025-02-06 18:26:10,426:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:11,061:INFO:Calculating mean and std
2025-02-06 18:26:11,061:INFO:Creating metrics dataframe
2025-02-06 18:26:11,062:INFO:Finalizing model
2025-02-06 18:26:11,079:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:26:11,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
2025-02-06 18:26:11,080:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:26:11,080:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:26:11,080:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:26:11,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:26:11,081:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:26:11,199:INFO:Uploading results into container
2025-02-06 18:26:11,200:INFO:Uploading model into container now
2025-02-06 18:26:11,200:INFO:_master_model_container: 5
2025-02-06 18:26:11,200:INFO:_display_container: 5
2025-02-06 18:26:11,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:11,200:INFO:create_model() successfully completed......................................
2025-02-06 18:26:11,284:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:11,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:26:11,285:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:26:11,285:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:26:11,286:INFO:choose_better completed
2025-02-06 18:26:11,291:INFO:_master_model_container: 5
2025-02-06 18:26:11,291:INFO:_display_container: 4
2025-02-06 18:26:11,291:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:11,291:INFO:tune_model() successfully completed......................................
2025-02-06 18:26:11,376:INFO:Initializing create_model()
2025-02-06 18:26:11,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:11,376:INFO:Checking exceptions
2025-02-06 18:26:11,382:INFO:Importing libraries
2025-02-06 18:26:11,382:INFO:Copying training dataset
2025-02-06 18:26:11,389:INFO:Defining folds
2025-02-06 18:26:11,389:INFO:Declaring metric variables
2025-02-06 18:26:11,391:INFO:Importing untrained model
2025-02-06 18:26:11,392:INFO:Logistic Regression Imported successfully
2025-02-06 18:26:11,395:INFO:Starting cross validation
2025-02-06 18:26:11,395:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:11,598:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:11,604:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:11,605:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:11,611:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:11,615:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:11,627:INFO:Calculating mean and std
2025-02-06 18:26:11,627:INFO:Creating metrics dataframe
2025-02-06 18:26:11,629:INFO:Finalizing model
2025-02-06 18:26:12,028:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,030:INFO:Uploading results into container
2025-02-06 18:26:12,031:INFO:Uploading model into container now
2025-02-06 18:26:12,034:INFO:_master_model_container: 6
2025-02-06 18:26:12,034:INFO:_display_container: 5
2025-02-06 18:26:12,035:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:26:12,035:INFO:create_model() successfully completed......................................
2025-02-06 18:26:12,109:INFO:Initializing tune_model()
2025-02-06 18:26:12,109:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:26:12,109:INFO:Checking exceptions
2025-02-06 18:26:12,117:INFO:Copying training dataset
2025-02-06 18:26:12,121:INFO:Checking base model
2025-02-06 18:26:12,121:INFO:Base model : Logistic Regression
2025-02-06 18:26:12,123:INFO:Declaring metric variables
2025-02-06 18:26:12,124:INFO:Defining Hyperparameters
2025-02-06 18:26:12,203:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:26:12,203:INFO:Tuning with n_jobs=-1
2025-02-06 18:26:12,203:INFO:Initializing RandomizedSearchCV
2025-02-06 18:26:12,272:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,275:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,276:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,279:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,283:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,290:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,290:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,291:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,292:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,316:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,709:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,711:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,737:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,755:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:12,756:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,020:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,035:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,061:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,121:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,163:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:13,251:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:26:13,251:INFO:Hyperparameter search completed
2025-02-06 18:26:13,251:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:13,252:INFO:Initializing create_model()
2025-02-06 18:26:13,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193634FA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:26:13,252:INFO:Checking exceptions
2025-02-06 18:26:13,252:INFO:Importing libraries
2025-02-06 18:26:13,252:INFO:Copying training dataset
2025-02-06 18:26:13,258:INFO:Defining folds
2025-02-06 18:26:13,258:INFO:Declaring metric variables
2025-02-06 18:26:13,260:INFO:Importing untrained model
2025-02-06 18:26:13,260:INFO:Declaring custom model
2025-02-06 18:26:13,262:INFO:Logistic Regression Imported successfully
2025-02-06 18:26:13,265:INFO:Starting cross validation
2025-02-06 18:26:13,265:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:13,605:INFO:Calculating mean and std
2025-02-06 18:26:13,605:INFO:Creating metrics dataframe
2025-02-06 18:26:13,608:INFO:Finalizing model
2025-02-06 18:26:13,861:INFO:Uploading results into container
2025-02-06 18:26:13,862:INFO:Uploading model into container now
2025-02-06 18:26:13,862:INFO:_master_model_container: 7
2025-02-06 18:26:13,862:INFO:_display_container: 6
2025-02-06 18:26:13,862:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:26:13,862:INFO:create_model() successfully completed......................................
2025-02-06 18:26:13,934:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:13,934:INFO:choose_better activated
2025-02-06 18:26:13,936:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:13,936:INFO:Initializing create_model()
2025-02-06 18:26:13,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:13,936:INFO:Checking exceptions
2025-02-06 18:26:13,937:INFO:Importing libraries
2025-02-06 18:26:13,937:INFO:Copying training dataset
2025-02-06 18:26:13,944:INFO:Defining folds
2025-02-06 18:26:13,944:INFO:Declaring metric variables
2025-02-06 18:26:13,944:INFO:Importing untrained model
2025-02-06 18:26:13,944:INFO:Declaring custom model
2025-02-06 18:26:13,944:INFO:Logistic Regression Imported successfully
2025-02-06 18:26:13,944:INFO:Starting cross validation
2025-02-06 18:26:13,945:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:14,115:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,123:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,123:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,124:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,125:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,143:INFO:Calculating mean and std
2025-02-06 18:26:14,143:INFO:Creating metrics dataframe
2025-02-06 18:26:14,144:INFO:Finalizing model
2025-02-06 18:26:14,580:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:26:14,581:INFO:Uploading results into container
2025-02-06 18:26:14,581:INFO:Uploading model into container now
2025-02-06 18:26:14,581:INFO:_master_model_container: 8
2025-02-06 18:26:14,581:INFO:_display_container: 7
2025-02-06 18:26:14,582:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:26:14,582:INFO:create_model() successfully completed......................................
2025-02-06 18:26:14,684:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:14,685:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:26:14,685:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:26:14,685:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:26:14,685:INFO:choose_better completed
2025-02-06 18:26:14,689:INFO:_master_model_container: 8
2025-02-06 18:26:14,689:INFO:_display_container: 6
2025-02-06 18:26:14,689:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:26:14,689:INFO:tune_model() successfully completed......................................
2025-02-06 18:26:14,763:INFO:Initializing compare_models()
2025-02-06 18:26:14,763:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:26:14,763:INFO:Checking exceptions
2025-02-06 18:26:14,766:INFO:Preparing display monitor
2025-02-06 18:26:14,775:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:26:14,775:INFO:Total runtime is 0.0 minutes
2025-02-06 18:26:14,777:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:14,777:INFO:Initializing create_model()
2025-02-06 18:26:14,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D3C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:14,777:INFO:Checking exceptions
2025-02-06 18:26:14,777:INFO:Importing libraries
2025-02-06 18:26:14,777:INFO:Copying training dataset
2025-02-06 18:26:14,783:INFO:Defining folds
2025-02-06 18:26:14,783:INFO:Declaring metric variables
2025-02-06 18:26:14,784:INFO:Importing untrained model
2025-02-06 18:26:14,784:INFO:Declaring custom model
2025-02-06 18:26:14,786:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:26:14,789:INFO:Starting cross validation
2025-02-06 18:26:14,789:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:17,964:INFO:Calculating mean and std
2025-02-06 18:26:17,965:INFO:Creating metrics dataframe
2025-02-06 18:26:17,967:INFO:Uploading results into container
2025-02-06 18:26:17,967:INFO:Uploading model into container now
2025-02-06 18:26:17,968:INFO:_master_model_container: 9
2025-02-06 18:26:17,968:INFO:_display_container: 7
2025-02-06 18:26:17,968:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:17,968:INFO:create_model() successfully completed......................................
2025-02-06 18:26:18,072:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:18,073:INFO:Creating metrics dataframe
2025-02-06 18:26:18,076:INFO:Initializing custom model Logistic Regression
2025-02-06 18:26:18,076:INFO:Total runtime is 0.05502089262008667 minutes
2025-02-06 18:26:18,078:INFO:SubProcess create_model() called ==================================
2025-02-06 18:26:18,078:INFO:Initializing create_model()
2025-02-06 18:26:18,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935D3C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:18,078:INFO:Checking exceptions
2025-02-06 18:26:18,078:INFO:Importing libraries
2025-02-06 18:26:18,078:INFO:Copying training dataset
2025-02-06 18:26:18,084:INFO:Defining folds
2025-02-06 18:26:18,084:INFO:Declaring metric variables
2025-02-06 18:26:18,086:INFO:Importing untrained model
2025-02-06 18:26:18,086:INFO:Declaring custom model
2025-02-06 18:26:18,088:INFO:Logistic Regression Imported successfully
2025-02-06 18:26:18,091:INFO:Starting cross validation
2025-02-06 18:26:18,091:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:26:18,432:INFO:Calculating mean and std
2025-02-06 18:26:18,433:INFO:Creating metrics dataframe
2025-02-06 18:26:18,434:INFO:Uploading results into container
2025-02-06 18:26:18,434:INFO:Uploading model into container now
2025-02-06 18:26:18,434:INFO:_master_model_container: 10
2025-02-06 18:26:18,434:INFO:_display_container: 7
2025-02-06 18:26:18,435:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:26:18,435:INFO:create_model() successfully completed......................................
2025-02-06 18:26:18,508:INFO:SubProcess create_model() end ==================================
2025-02-06 18:26:18,509:INFO:Creating metrics dataframe
2025-02-06 18:26:18,511:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:26:18,514:INFO:Initializing create_model()
2025-02-06 18:26:18,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:26:18,515:INFO:Checking exceptions
2025-02-06 18:26:18,515:INFO:Importing libraries
2025-02-06 18:26:18,515:INFO:Copying training dataset
2025-02-06 18:26:18,521:INFO:Defining folds
2025-02-06 18:26:18,522:INFO:Declaring metric variables
2025-02-06 18:26:18,522:INFO:Importing untrained model
2025-02-06 18:26:18,522:INFO:Declaring custom model
2025-02-06 18:26:18,522:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:26:18,522:INFO:Cross validation set to False
2025-02-06 18:26:18,522:INFO:Fitting Model
2025-02-06 18:26:18,534:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:26:18,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.
2025-02-06 18:26:18,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:26:18,535:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:26:18,535:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:26:18,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:26:18,535:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:26:19,112:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:19,112:INFO:create_model() successfully completed......................................
2025-02-06 18:26:19,209:INFO:_master_model_container: 10
2025-02-06 18:26:19,210:INFO:_display_container: 7
2025-02-06 18:26:19,210:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:26:19,210:INFO:compare_models() successfully completed......................................
2025-02-06 18:26:19,211:INFO:Initializing predict_model()
2025-02-06 18:26:19,211:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935C04FE0>)
2025-02-06 18:26:19,211:INFO:Checking exceptions
2025-02-06 18:26:19,211:INFO:Preloading libraries
2025-02-06 18:26:19,212:INFO:Set up data.
2025-02-06 18:26:19,219:INFO:Set up index.
2025-02-06 18:26:19,389:INFO:Initializing predict_model()
2025-02-06 18:26:19,389:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:26:19,389:INFO:Checking exceptions
2025-02-06 18:26:19,389:INFO:Preloading libraries
2025-02-06 18:26:19,389:INFO:Set up data.
2025-02-06 18:26:19,394:INFO:Set up index.
2025-02-06 18:26:19,512:INFO:Initializing predict_model()
2025-02-06 18:26:19,512:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:26:19,512:INFO:Checking exceptions
2025-02-06 18:26:19,512:INFO:Preloading libraries
2025-02-06 18:26:19,513:INFO:Set up data.
2025-02-06 18:26:19,521:INFO:Set up index.
2025-02-06 18:26:19,619:INFO:Initializing predict_model()
2025-02-06 18:26:19,619:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD0ED50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002196C2DA200>)
2025-02-06 18:26:19,619:INFO:Checking exceptions
2025-02-06 18:26:19,619:INFO:Preloading libraries
2025-02-06 18:26:19,620:INFO:Set up data.
2025-02-06 18:26:19,624:INFO:Set up index.
2025-02-06 18:27:10,853:INFO:PyCaret ClassificationExperiment
2025-02-06 18:27:10,853:INFO:Logging name: clf-default-name
2025-02-06 18:27:10,853:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:27:10,853:INFO:version 3.3.2
2025-02-06 18:27:10,853:INFO:Initializing setup()
2025-02-06 18:27:10,853:INFO:self.USI: 4e0e
2025-02-06 18:27:10,853:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:27:10,853:INFO:Checking environment
2025-02-06 18:27:10,853:INFO:python_version: 3.11.9
2025-02-06 18:27:10,853:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:27:10,853:INFO:machine: AMD64
2025-02-06 18:27:10,853:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:27:10,857:INFO:Memory: svmem(total=67771465728, available=46347059200, percent=31.6, used=21424406528, free=46347059200)
2025-02-06 18:27:10,857:INFO:Physical Core: 8
2025-02-06 18:27:10,857:INFO:Logical Core: 16
2025-02-06 18:27:10,857:INFO:Checking libraries
2025-02-06 18:27:10,857:INFO:System:
2025-02-06 18:27:10,857:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:27:10,857:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:27:10,857:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:27:10,857:INFO:PyCaret required dependencies:
2025-02-06 18:27:10,857:INFO:                 pip: 25.0
2025-02-06 18:27:10,857:INFO:          setuptools: 65.5.0
2025-02-06 18:27:10,857:INFO:             pycaret: 3.3.2
2025-02-06 18:27:10,857:INFO:             IPython: 8.32.0
2025-02-06 18:27:10,857:INFO:          ipywidgets: 8.1.5
2025-02-06 18:27:10,857:INFO:                tqdm: 4.67.1
2025-02-06 18:27:10,857:INFO:               numpy: 1.26.4
2025-02-06 18:27:10,857:INFO:              pandas: 2.1.4
2025-02-06 18:27:10,857:INFO:              jinja2: 3.1.5
2025-02-06 18:27:10,857:INFO:               scipy: 1.11.4
2025-02-06 18:27:10,857:INFO:              joblib: 1.3.2
2025-02-06 18:27:10,858:INFO:             sklearn: 1.4.2
2025-02-06 18:27:10,858:INFO:                pyod: 2.0.3
2025-02-06 18:27:10,858:INFO:            imblearn: 0.13.0
2025-02-06 18:27:10,858:INFO:   category_encoders: 2.7.0
2025-02-06 18:27:10,858:INFO:            lightgbm: 4.5.0
2025-02-06 18:27:10,858:INFO:               numba: 0.61.0
2025-02-06 18:27:10,858:INFO:            requests: 2.32.3
2025-02-06 18:27:10,858:INFO:          matplotlib: 3.7.5
2025-02-06 18:27:10,858:INFO:          scikitplot: 0.3.7
2025-02-06 18:27:10,858:INFO:         yellowbrick: 1.5
2025-02-06 18:27:10,858:INFO:              plotly: 5.24.1
2025-02-06 18:27:10,858:INFO:    plotly-resampler: Not installed
2025-02-06 18:27:10,858:INFO:             kaleido: 0.2.1
2025-02-06 18:27:10,858:INFO:           schemdraw: 0.15
2025-02-06 18:27:10,858:INFO:         statsmodels: 0.14.4
2025-02-06 18:27:10,858:INFO:              sktime: 0.26.0
2025-02-06 18:27:10,858:INFO:               tbats: 1.1.3
2025-02-06 18:27:10,858:INFO:            pmdarima: 2.0.4
2025-02-06 18:27:10,858:INFO:              psutil: 6.1.1
2025-02-06 18:27:10,858:INFO:          markupsafe: 3.0.2
2025-02-06 18:27:10,858:INFO:             pickle5: Not installed
2025-02-06 18:27:10,858:INFO:         cloudpickle: 3.1.1
2025-02-06 18:27:10,858:INFO:         deprecation: 2.1.0
2025-02-06 18:27:10,858:INFO:              xxhash: 3.5.0
2025-02-06 18:27:10,858:INFO:           wurlitzer: Not installed
2025-02-06 18:27:10,858:INFO:PyCaret optional dependencies:
2025-02-06 18:27:10,858:INFO:                shap: Not installed
2025-02-06 18:27:10,858:INFO:           interpret: Not installed
2025-02-06 18:27:10,858:INFO:                umap: Not installed
2025-02-06 18:27:10,858:INFO:     ydata_profiling: Not installed
2025-02-06 18:27:10,858:INFO:  explainerdashboard: Not installed
2025-02-06 18:27:10,858:INFO:             autoviz: Not installed
2025-02-06 18:27:10,858:INFO:           fairlearn: Not installed
2025-02-06 18:27:10,858:INFO:          deepchecks: Not installed
2025-02-06 18:27:10,858:INFO:             xgboost: Not installed
2025-02-06 18:27:10,858:INFO:            catboost: Not installed
2025-02-06 18:27:10,858:INFO:              kmodes: Not installed
2025-02-06 18:27:10,858:INFO:             mlxtend: Not installed
2025-02-06 18:27:10,858:INFO:       statsforecast: Not installed
2025-02-06 18:27:10,858:INFO:        tune_sklearn: Not installed
2025-02-06 18:27:10,858:INFO:                 ray: Not installed
2025-02-06 18:27:10,858:INFO:            hyperopt: Not installed
2025-02-06 18:27:10,858:INFO:              optuna: Not installed
2025-02-06 18:27:10,858:INFO:               skopt: Not installed
2025-02-06 18:27:10,858:INFO:              mlflow: Not installed
2025-02-06 18:27:10,858:INFO:              gradio: Not installed
2025-02-06 18:27:10,858:INFO:             fastapi: Not installed
2025-02-06 18:27:10,858:INFO:             uvicorn: Not installed
2025-02-06 18:27:10,858:INFO:              m2cgen: Not installed
2025-02-06 18:27:10,858:INFO:           evidently: Not installed
2025-02-06 18:27:10,858:INFO:               fugue: Not installed
2025-02-06 18:27:10,858:INFO:           streamlit: Not installed
2025-02-06 18:27:10,858:INFO:             prophet: Not installed
2025-02-06 18:27:10,858:INFO:None
2025-02-06 18:27:10,858:INFO:Set up data.
2025-02-06 18:27:10,863:INFO:Set up folding strategy.
2025-02-06 18:27:10,864:INFO:Set up train/test split.
2025-02-06 18:27:10,869:INFO:Set up index.
2025-02-06 18:27:10,869:INFO:Assigning column types.
2025-02-06 18:27:10,874:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:27:10,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:27:10,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:27:10,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:10,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:10,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:27:10,938:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:27:10,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:10,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:10,952:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:27:10,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:27:10,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:10,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:27:11,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,031:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:27:11,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,109:INFO:Preparing preprocessing pipeline...
2025-02-06 18:27:11,110:INFO:Set up simple imputation.
2025-02-06 18:27:11,130:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:27:11,131:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:27:11,131:INFO:Creating final display dataframe.
2025-02-06 18:27:11,193:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              4e0e
2025-02-06 18:27:11,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:27:11,272:INFO:setup() successfully completed in 0.42s...............
2025-02-06 18:27:11,272:INFO:Initializing compare_models()
2025-02-06 18:27:11,272:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:27:11,272:INFO:Checking exceptions
2025-02-06 18:27:11,275:INFO:Preparing display monitor
2025-02-06 18:27:11,285:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:27:11,285:INFO:Total runtime is 0.0 minutes
2025-02-06 18:27:11,287:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:11,287:INFO:Initializing create_model()
2025-02-06 18:27:11,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219381A3010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:11,287:INFO:Checking exceptions
2025-02-06 18:27:11,287:INFO:Importing libraries
2025-02-06 18:27:11,287:INFO:Copying training dataset
2025-02-06 18:27:11,295:INFO:Defining folds
2025-02-06 18:27:11,295:INFO:Declaring metric variables
2025-02-06 18:27:11,298:INFO:Importing untrained model
2025-02-06 18:27:11,300:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:11,303:INFO:Starting cross validation
2025-02-06 18:27:11,303:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:11,729:INFO:Calculating mean and std
2025-02-06 18:27:11,729:INFO:Creating metrics dataframe
2025-02-06 18:27:11,730:INFO:Uploading results into container
2025-02-06 18:27:11,730:INFO:Uploading model into container now
2025-02-06 18:27:11,730:INFO:_master_model_container: 1
2025-02-06 18:27:11,730:INFO:_display_container: 2
2025-02-06 18:27:11,731:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:11,731:INFO:create_model() successfully completed......................................
2025-02-06 18:27:11,824:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:11,825:INFO:Creating metrics dataframe
2025-02-06 18:27:11,827:INFO:Initializing Logistic Regression
2025-02-06 18:27:11,828:INFO:Total runtime is 0.009050079186757405 minutes
2025-02-06 18:27:11,829:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:11,830:INFO:Initializing create_model()
2025-02-06 18:27:11,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219381A3010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:11,830:INFO:Checking exceptions
2025-02-06 18:27:11,830:INFO:Importing libraries
2025-02-06 18:27:11,830:INFO:Copying training dataset
2025-02-06 18:27:11,836:INFO:Defining folds
2025-02-06 18:27:11,836:INFO:Declaring metric variables
2025-02-06 18:27:11,837:INFO:Importing untrained model
2025-02-06 18:27:11,839:INFO:Logistic Regression Imported successfully
2025-02-06 18:27:11,842:INFO:Starting cross validation
2025-02-06 18:27:11,843:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:12,044:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:12,049:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:12,053:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:12,059:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:12,061:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:12,071:INFO:Calculating mean and std
2025-02-06 18:27:12,071:INFO:Creating metrics dataframe
2025-02-06 18:27:12,072:INFO:Uploading results into container
2025-02-06 18:27:12,072:INFO:Uploading model into container now
2025-02-06 18:27:12,072:INFO:_master_model_container: 2
2025-02-06 18:27:12,072:INFO:_display_container: 2
2025-02-06 18:27:12,073:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:12,073:INFO:create_model() successfully completed......................................
2025-02-06 18:27:12,151:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:12,151:INFO:Creating metrics dataframe
2025-02-06 18:27:12,154:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:27:12,159:INFO:Initializing create_model()
2025-02-06 18:27:12,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:12,159:INFO:Checking exceptions
2025-02-06 18:27:12,160:INFO:Importing libraries
2025-02-06 18:27:12,160:INFO:Copying training dataset
2025-02-06 18:27:12,166:INFO:Defining folds
2025-02-06 18:27:12,166:INFO:Declaring metric variables
2025-02-06 18:27:12,166:INFO:Importing untrained model
2025-02-06 18:27:12,166:INFO:Declaring custom model
2025-02-06 18:27:12,167:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:12,167:INFO:Cross validation set to False
2025-02-06 18:27:12,167:INFO:Fitting Model
2025-02-06 18:27:12,178:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:27:12,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.
2025-02-06 18:27:12,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:27:12,179:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:27:12,179:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:27:12,179:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:27:12,179:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:27:12,246:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:12,246:INFO:create_model() successfully completed......................................
2025-02-06 18:27:12,341:INFO:_master_model_container: 2
2025-02-06 18:27:12,341:INFO:_display_container: 2
2025-02-06 18:27:12,341:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:12,341:INFO:compare_models() successfully completed......................................
2025-02-06 18:27:12,342:INFO:Initializing create_model()
2025-02-06 18:27:12,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:12,342:INFO:Checking exceptions
2025-02-06 18:27:12,351:INFO:Importing libraries
2025-02-06 18:27:12,351:INFO:Copying training dataset
2025-02-06 18:27:12,359:INFO:Defining folds
2025-02-06 18:27:12,359:INFO:Declaring metric variables
2025-02-06 18:27:12,360:INFO:Importing untrained model
2025-02-06 18:27:12,362:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:12,365:INFO:Starting cross validation
2025-02-06 18:27:12,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:12,777:INFO:Calculating mean and std
2025-02-06 18:27:12,777:INFO:Creating metrics dataframe
2025-02-06 18:27:12,782:INFO:Finalizing model
2025-02-06 18:27:12,796:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:27:12,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
2025-02-06 18:27:12,798:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:27:12,798:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:27:12,798:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:27:12,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:27:12,798:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:27:12,922:INFO:Uploading results into container
2025-02-06 18:27:12,923:INFO:Uploading model into container now
2025-02-06 18:27:12,928:INFO:_master_model_container: 3
2025-02-06 18:27:12,928:INFO:_display_container: 3
2025-02-06 18:27:12,928:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:12,928:INFO:create_model() successfully completed......................................
2025-02-06 18:27:13,019:INFO:Initializing tune_model()
2025-02-06 18:27:13,019:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:27:13,019:INFO:Checking exceptions
2025-02-06 18:27:13,030:INFO:Copying training dataset
2025-02-06 18:27:13,033:INFO:Checking base model
2025-02-06 18:27:13,033:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:27:13,035:INFO:Declaring metric variables
2025-02-06 18:27:13,036:INFO:Defining Hyperparameters
2025-02-06 18:27:13,106:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:27:13,106:INFO:Tuning with n_jobs=-1
2025-02-06 18:27:13,106:INFO:Initializing RandomizedSearchCV
2025-02-06 18:27:27,833:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:27:27,834:INFO:Hyperparameter search completed
2025-02-06 18:27:27,834:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:27,835:INFO:Initializing create_model()
2025-02-06 18:27:27,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193788B610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:27:27,835:INFO:Checking exceptions
2025-02-06 18:27:27,835:INFO:Importing libraries
2025-02-06 18:27:27,835:INFO:Copying training dataset
2025-02-06 18:27:27,844:INFO:Defining folds
2025-02-06 18:27:27,845:INFO:Declaring metric variables
2025-02-06 18:27:27,847:INFO:Importing untrained model
2025-02-06 18:27:27,847:INFO:Declaring custom model
2025-02-06 18:27:27,849:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:27,853:INFO:Starting cross validation
2025-02-06 18:27:27,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:30,799:INFO:Calculating mean and std
2025-02-06 18:27:30,800:INFO:Creating metrics dataframe
2025-02-06 18:27:30,804:INFO:Finalizing model
2025-02-06 18:27:30,818:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:27:30,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.
2025-02-06 18:27:30,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:27:30,820:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:27:30,820:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:27:30,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:27:30,820:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:27:31,453:INFO:Uploading results into container
2025-02-06 18:27:31,453:INFO:Uploading model into container now
2025-02-06 18:27:31,454:INFO:_master_model_container: 4
2025-02-06 18:27:31,454:INFO:_display_container: 4
2025-02-06 18:27:31,454:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:31,454:INFO:create_model() successfully completed......................................
2025-02-06 18:27:31,538:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:31,538:INFO:choose_better activated
2025-02-06 18:27:31,540:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:31,540:INFO:Initializing create_model()
2025-02-06 18:27:31,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:31,540:INFO:Checking exceptions
2025-02-06 18:27:31,541:INFO:Importing libraries
2025-02-06 18:27:31,541:INFO:Copying training dataset
2025-02-06 18:27:31,550:INFO:Defining folds
2025-02-06 18:27:31,550:INFO:Declaring metric variables
2025-02-06 18:27:31,550:INFO:Importing untrained model
2025-02-06 18:27:31,550:INFO:Declaring custom model
2025-02-06 18:27:31,550:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:31,550:INFO:Starting cross validation
2025-02-06 18:27:31,551:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:31,964:INFO:Calculating mean and std
2025-02-06 18:27:31,964:INFO:Creating metrics dataframe
2025-02-06 18:27:31,965:INFO:Finalizing model
2025-02-06 18:27:31,979:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:27:31,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.
2025-02-06 18:27:31,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:27:31,980:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:27:31,980:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:27:31,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:27:31,981:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:27:32,093:INFO:Uploading results into container
2025-02-06 18:27:32,093:INFO:Uploading model into container now
2025-02-06 18:27:32,093:INFO:_master_model_container: 5
2025-02-06 18:27:32,093:INFO:_display_container: 5
2025-02-06 18:27:32,094:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:32,094:INFO:create_model() successfully completed......................................
2025-02-06 18:27:32,208:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:32,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:27:32,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:27:32,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:27:32,209:INFO:choose_better completed
2025-02-06 18:27:32,213:INFO:_master_model_container: 5
2025-02-06 18:27:32,213:INFO:_display_container: 4
2025-02-06 18:27:32,213:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:32,213:INFO:tune_model() successfully completed......................................
2025-02-06 18:27:32,287:INFO:Initializing create_model()
2025-02-06 18:27:32,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:32,287:INFO:Checking exceptions
2025-02-06 18:27:32,293:INFO:Importing libraries
2025-02-06 18:27:32,294:INFO:Copying training dataset
2025-02-06 18:27:32,301:INFO:Defining folds
2025-02-06 18:27:32,301:INFO:Declaring metric variables
2025-02-06 18:27:32,303:INFO:Importing untrained model
2025-02-06 18:27:32,304:INFO:Logistic Regression Imported successfully
2025-02-06 18:27:32,307:INFO:Starting cross validation
2025-02-06 18:27:32,308:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:32,483:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,484:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,486:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,491:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,494:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,507:INFO:Calculating mean and std
2025-02-06 18:27:32,507:INFO:Creating metrics dataframe
2025-02-06 18:27:32,510:INFO:Finalizing model
2025-02-06 18:27:32,915:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:32,918:INFO:Uploading results into container
2025-02-06 18:27:32,918:INFO:Uploading model into container now
2025-02-06 18:27:32,922:INFO:_master_model_container: 6
2025-02-06 18:27:32,922:INFO:_display_container: 5
2025-02-06 18:27:32,922:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:32,922:INFO:create_model() successfully completed......................................
2025-02-06 18:27:32,995:INFO:Initializing tune_model()
2025-02-06 18:27:32,995:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:27:32,995:INFO:Checking exceptions
2025-02-06 18:27:33,003:INFO:Copying training dataset
2025-02-06 18:27:33,007:INFO:Checking base model
2025-02-06 18:27:33,007:INFO:Base model : Logistic Regression
2025-02-06 18:27:33,008:INFO:Declaring metric variables
2025-02-06 18:27:33,010:INFO:Defining Hyperparameters
2025-02-06 18:27:33,092:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:27:33,092:INFO:Tuning with n_jobs=-1
2025-02-06 18:27:33,092:INFO:Initializing RandomizedSearchCV
2025-02-06 18:27:33,164:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,167:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,167:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,174:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,174:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,174:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,180:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,187:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,188:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,196:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,601:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,609:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,609:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,630:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,647:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,910:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,967:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:33,994:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,001:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,040:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,137:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:27:34,137:INFO:Hyperparameter search completed
2025-02-06 18:27:34,137:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:34,138:INFO:Initializing create_model()
2025-02-06 18:27:34,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CD0DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:27:34,138:INFO:Checking exceptions
2025-02-06 18:27:34,138:INFO:Importing libraries
2025-02-06 18:27:34,138:INFO:Copying training dataset
2025-02-06 18:27:34,144:INFO:Defining folds
2025-02-06 18:27:34,144:INFO:Declaring metric variables
2025-02-06 18:27:34,146:INFO:Importing untrained model
2025-02-06 18:27:34,146:INFO:Declaring custom model
2025-02-06 18:27:34,148:INFO:Logistic Regression Imported successfully
2025-02-06 18:27:34,151:INFO:Starting cross validation
2025-02-06 18:27:34,151:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:34,481:INFO:Calculating mean and std
2025-02-06 18:27:34,482:INFO:Creating metrics dataframe
2025-02-06 18:27:34,484:INFO:Finalizing model
2025-02-06 18:27:34,738:INFO:Uploading results into container
2025-02-06 18:27:34,738:INFO:Uploading model into container now
2025-02-06 18:27:34,738:INFO:_master_model_container: 7
2025-02-06 18:27:34,738:INFO:_display_container: 6
2025-02-06 18:27:34,739:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:34,739:INFO:create_model() successfully completed......................................
2025-02-06 18:27:34,815:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:34,816:INFO:choose_better activated
2025-02-06 18:27:34,817:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:34,817:INFO:Initializing create_model()
2025-02-06 18:27:34,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:34,817:INFO:Checking exceptions
2025-02-06 18:27:34,818:INFO:Importing libraries
2025-02-06 18:27:34,818:INFO:Copying training dataset
2025-02-06 18:27:34,824:INFO:Defining folds
2025-02-06 18:27:34,824:INFO:Declaring metric variables
2025-02-06 18:27:34,824:INFO:Importing untrained model
2025-02-06 18:27:34,824:INFO:Declaring custom model
2025-02-06 18:27:34,825:INFO:Logistic Regression Imported successfully
2025-02-06 18:27:34,825:INFO:Starting cross validation
2025-02-06 18:27:34,825:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:34,991:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,993:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,995:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:34,995:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:35,000:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:35,012:INFO:Calculating mean and std
2025-02-06 18:27:35,013:INFO:Creating metrics dataframe
2025-02-06 18:27:35,013:INFO:Finalizing model
2025-02-06 18:27:35,420:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:27:35,421:INFO:Uploading results into container
2025-02-06 18:27:35,421:INFO:Uploading model into container now
2025-02-06 18:27:35,421:INFO:_master_model_container: 8
2025-02-06 18:27:35,421:INFO:_display_container: 7
2025-02-06 18:27:35,421:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:35,421:INFO:create_model() successfully completed......................................
2025-02-06 18:27:35,488:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:35,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:27:35,489:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:27:35,489:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:27:35,489:INFO:choose_better completed
2025-02-06 18:27:35,494:INFO:_master_model_container: 8
2025-02-06 18:27:35,494:INFO:_display_container: 6
2025-02-06 18:27:35,494:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:35,494:INFO:tune_model() successfully completed......................................
2025-02-06 18:27:35,554:INFO:Initializing compare_models()
2025-02-06 18:27:35,554:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:27:35,554:INFO:Checking exceptions
2025-02-06 18:27:35,556:INFO:Preparing display monitor
2025-02-06 18:27:35,566:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:27:35,567:INFO:Total runtime is 1.6748905181884766e-05 minutes
2025-02-06 18:27:35,568:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:35,568:INFO:Initializing create_model()
2025-02-06 18:27:35,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935BF7A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:35,568:INFO:Checking exceptions
2025-02-06 18:27:35,568:INFO:Importing libraries
2025-02-06 18:27:35,568:INFO:Copying training dataset
2025-02-06 18:27:35,575:INFO:Defining folds
2025-02-06 18:27:35,575:INFO:Declaring metric variables
2025-02-06 18:27:35,576:INFO:Importing untrained model
2025-02-06 18:27:35,576:INFO:Declaring custom model
2025-02-06 18:27:35,578:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:35,580:INFO:Starting cross validation
2025-02-06 18:27:35,581:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:38,531:INFO:Calculating mean and std
2025-02-06 18:27:38,531:INFO:Creating metrics dataframe
2025-02-06 18:27:38,534:INFO:Uploading results into container
2025-02-06 18:27:38,534:INFO:Uploading model into container now
2025-02-06 18:27:38,534:INFO:_master_model_container: 9
2025-02-06 18:27:38,535:INFO:_display_container: 7
2025-02-06 18:27:38,535:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:38,535:INFO:create_model() successfully completed......................................
2025-02-06 18:27:38,622:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:38,622:INFO:Creating metrics dataframe
2025-02-06 18:27:38,625:INFO:Initializing custom model Logistic Regression
2025-02-06 18:27:38,625:INFO:Total runtime is 0.050984235604604085 minutes
2025-02-06 18:27:38,627:INFO:SubProcess create_model() called ==================================
2025-02-06 18:27:38,627:INFO:Initializing create_model()
2025-02-06 18:27:38,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935BF7A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:38,627:INFO:Checking exceptions
2025-02-06 18:27:38,627:INFO:Importing libraries
2025-02-06 18:27:38,627:INFO:Copying training dataset
2025-02-06 18:27:38,633:INFO:Defining folds
2025-02-06 18:27:38,633:INFO:Declaring metric variables
2025-02-06 18:27:38,635:INFO:Importing untrained model
2025-02-06 18:27:38,635:INFO:Declaring custom model
2025-02-06 18:27:38,637:INFO:Logistic Regression Imported successfully
2025-02-06 18:27:38,640:INFO:Starting cross validation
2025-02-06 18:27:38,640:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:27:38,994:INFO:Calculating mean and std
2025-02-06 18:27:38,995:INFO:Creating metrics dataframe
2025-02-06 18:27:38,995:INFO:Uploading results into container
2025-02-06 18:27:38,996:INFO:Uploading model into container now
2025-02-06 18:27:38,996:INFO:_master_model_container: 10
2025-02-06 18:27:38,996:INFO:_display_container: 7
2025-02-06 18:27:38,996:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:27:38,996:INFO:create_model() successfully completed......................................
2025-02-06 18:27:39,073:INFO:SubProcess create_model() end ==================================
2025-02-06 18:27:39,073:INFO:Creating metrics dataframe
2025-02-06 18:27:39,076:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:27:39,079:INFO:Initializing create_model()
2025-02-06 18:27:39,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:27:39,079:INFO:Checking exceptions
2025-02-06 18:27:39,080:INFO:Importing libraries
2025-02-06 18:27:39,080:INFO:Copying training dataset
2025-02-06 18:27:39,086:INFO:Defining folds
2025-02-06 18:27:39,086:INFO:Declaring metric variables
2025-02-06 18:27:39,086:INFO:Importing untrained model
2025-02-06 18:27:39,086:INFO:Declaring custom model
2025-02-06 18:27:39,087:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:27:39,087:INFO:Cross validation set to False
2025-02-06 18:27:39,087:INFO:Fitting Model
2025-02-06 18:27:39,100:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:27:39,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.
2025-02-06 18:27:39,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:27:39,101:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:27:39,113:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:27:39,113:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:27:39,114:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:27:39,663:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:39,663:INFO:create_model() successfully completed......................................
2025-02-06 18:27:39,759:INFO:_master_model_container: 10
2025-02-06 18:27:39,759:INFO:_display_container: 7
2025-02-06 18:27:39,759:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:27:39,760:INFO:compare_models() successfully completed......................................
2025-02-06 18:27:39,760:INFO:Initializing predict_model()
2025-02-06 18:27:39,761:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021937B76840>)
2025-02-06 18:27:39,761:INFO:Checking exceptions
2025-02-06 18:27:39,761:INFO:Preloading libraries
2025-02-06 18:27:39,762:INFO:Set up data.
2025-02-06 18:27:39,767:INFO:Set up index.
2025-02-06 18:27:39,922:INFO:Initializing predict_model()
2025-02-06 18:27:39,922:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021937B76840>)
2025-02-06 18:27:39,922:INFO:Checking exceptions
2025-02-06 18:27:39,922:INFO:Preloading libraries
2025-02-06 18:27:39,923:INFO:Set up data.
2025-02-06 18:27:39,928:INFO:Set up index.
2025-02-06 18:27:40,040:INFO:Initializing predict_model()
2025-02-06 18:27:40,041:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021937B76840>)
2025-02-06 18:27:40,041:INFO:Checking exceptions
2025-02-06 18:27:40,041:INFO:Preloading libraries
2025-02-06 18:27:40,042:INFO:Set up data.
2025-02-06 18:27:40,050:INFO:Set up index.
2025-02-06 18:27:40,148:INFO:Initializing predict_model()
2025-02-06 18:27:40,148:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021938075E50>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021937B76840>)
2025-02-06 18:27:40,148:INFO:Checking exceptions
2025-02-06 18:27:40,148:INFO:Preloading libraries
2025-02-06 18:27:40,150:INFO:Set up data.
2025-02-06 18:27:40,154:INFO:Set up index.
2025-02-06 18:28:23,072:INFO:PyCaret ClassificationExperiment
2025-02-06 18:28:23,072:INFO:Logging name: clf-default-name
2025-02-06 18:28:23,072:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:28:23,072:INFO:version 3.3.2
2025-02-06 18:28:23,072:INFO:Initializing setup()
2025-02-06 18:28:23,072:INFO:self.USI: c2f6
2025-02-06 18:28:23,072:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:28:23,072:INFO:Checking environment
2025-02-06 18:28:23,072:INFO:python_version: 3.11.9
2025-02-06 18:28:23,072:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:28:23,072:INFO:machine: AMD64
2025-02-06 18:28:23,072:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:28:23,076:INFO:Memory: svmem(total=67771465728, available=46304296960, percent=31.7, used=21467168768, free=46304296960)
2025-02-06 18:28:23,076:INFO:Physical Core: 8
2025-02-06 18:28:23,076:INFO:Logical Core: 16
2025-02-06 18:28:23,076:INFO:Checking libraries
2025-02-06 18:28:23,076:INFO:System:
2025-02-06 18:28:23,076:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:28:23,076:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:28:23,076:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:28:23,076:INFO:PyCaret required dependencies:
2025-02-06 18:28:23,076:INFO:                 pip: 25.0
2025-02-06 18:28:23,076:INFO:          setuptools: 65.5.0
2025-02-06 18:28:23,076:INFO:             pycaret: 3.3.2
2025-02-06 18:28:23,076:INFO:             IPython: 8.32.0
2025-02-06 18:28:23,076:INFO:          ipywidgets: 8.1.5
2025-02-06 18:28:23,076:INFO:                tqdm: 4.67.1
2025-02-06 18:28:23,076:INFO:               numpy: 1.26.4
2025-02-06 18:28:23,076:INFO:              pandas: 2.1.4
2025-02-06 18:28:23,076:INFO:              jinja2: 3.1.5
2025-02-06 18:28:23,076:INFO:               scipy: 1.11.4
2025-02-06 18:28:23,076:INFO:              joblib: 1.3.2
2025-02-06 18:28:23,076:INFO:             sklearn: 1.4.2
2025-02-06 18:28:23,076:INFO:                pyod: 2.0.3
2025-02-06 18:28:23,076:INFO:            imblearn: 0.13.0
2025-02-06 18:28:23,076:INFO:   category_encoders: 2.7.0
2025-02-06 18:28:23,076:INFO:            lightgbm: 4.5.0
2025-02-06 18:28:23,076:INFO:               numba: 0.61.0
2025-02-06 18:28:23,076:INFO:            requests: 2.32.3
2025-02-06 18:28:23,076:INFO:          matplotlib: 3.7.5
2025-02-06 18:28:23,076:INFO:          scikitplot: 0.3.7
2025-02-06 18:28:23,076:INFO:         yellowbrick: 1.5
2025-02-06 18:28:23,076:INFO:              plotly: 5.24.1
2025-02-06 18:28:23,076:INFO:    plotly-resampler: Not installed
2025-02-06 18:28:23,076:INFO:             kaleido: 0.2.1
2025-02-06 18:28:23,076:INFO:           schemdraw: 0.15
2025-02-06 18:28:23,076:INFO:         statsmodels: 0.14.4
2025-02-06 18:28:23,076:INFO:              sktime: 0.26.0
2025-02-06 18:28:23,076:INFO:               tbats: 1.1.3
2025-02-06 18:28:23,076:INFO:            pmdarima: 2.0.4
2025-02-06 18:28:23,076:INFO:              psutil: 6.1.1
2025-02-06 18:28:23,076:INFO:          markupsafe: 3.0.2
2025-02-06 18:28:23,076:INFO:             pickle5: Not installed
2025-02-06 18:28:23,076:INFO:         cloudpickle: 3.1.1
2025-02-06 18:28:23,076:INFO:         deprecation: 2.1.0
2025-02-06 18:28:23,076:INFO:              xxhash: 3.5.0
2025-02-06 18:28:23,076:INFO:           wurlitzer: Not installed
2025-02-06 18:28:23,076:INFO:PyCaret optional dependencies:
2025-02-06 18:28:23,076:INFO:                shap: Not installed
2025-02-06 18:28:23,076:INFO:           interpret: Not installed
2025-02-06 18:28:23,076:INFO:                umap: Not installed
2025-02-06 18:28:23,076:INFO:     ydata_profiling: Not installed
2025-02-06 18:28:23,076:INFO:  explainerdashboard: Not installed
2025-02-06 18:28:23,076:INFO:             autoviz: Not installed
2025-02-06 18:28:23,076:INFO:           fairlearn: Not installed
2025-02-06 18:28:23,076:INFO:          deepchecks: Not installed
2025-02-06 18:28:23,076:INFO:             xgboost: Not installed
2025-02-06 18:28:23,076:INFO:            catboost: Not installed
2025-02-06 18:28:23,078:INFO:              kmodes: Not installed
2025-02-06 18:28:23,078:INFO:             mlxtend: Not installed
2025-02-06 18:28:23,078:INFO:       statsforecast: Not installed
2025-02-06 18:28:23,078:INFO:        tune_sklearn: Not installed
2025-02-06 18:28:23,078:INFO:                 ray: Not installed
2025-02-06 18:28:23,078:INFO:            hyperopt: Not installed
2025-02-06 18:28:23,078:INFO:              optuna: Not installed
2025-02-06 18:28:23,078:INFO:               skopt: Not installed
2025-02-06 18:28:23,078:INFO:              mlflow: Not installed
2025-02-06 18:28:23,078:INFO:              gradio: Not installed
2025-02-06 18:28:23,078:INFO:             fastapi: Not installed
2025-02-06 18:28:23,078:INFO:             uvicorn: Not installed
2025-02-06 18:28:23,078:INFO:              m2cgen: Not installed
2025-02-06 18:28:23,078:INFO:           evidently: Not installed
2025-02-06 18:28:23,078:INFO:               fugue: Not installed
2025-02-06 18:28:23,078:INFO:           streamlit: Not installed
2025-02-06 18:28:23,078:INFO:             prophet: Not installed
2025-02-06 18:28:23,078:INFO:None
2025-02-06 18:28:23,078:INFO:Set up data.
2025-02-06 18:28:23,084:INFO:Set up folding strategy.
2025-02-06 18:28:23,084:INFO:Set up train/test split.
2025-02-06 18:28:23,091:INFO:Set up index.
2025-02-06 18:28:23,091:INFO:Assigning column types.
2025-02-06 18:28:23,097:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:28:23,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,121:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,176:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:28:23,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:28:23,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,256:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:28:23,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,336:INFO:Preparing preprocessing pipeline...
2025-02-06 18:28:23,337:INFO:Set up simple imputation.
2025-02-06 18:28:23,357:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:28:23,360:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 18:28:23,360:INFO:Creating final display dataframe.
2025-02-06 18:28:23,425:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                 5
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              c2f6
2025-02-06 18:28:23,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:28:23,514:INFO:setup() successfully completed in 0.44s...............
2025-02-06 18:28:23,514:INFO:Initializing compare_models()
2025-02-06 18:28:23,514:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:28:23,514:INFO:Checking exceptions
2025-02-06 18:28:23,518:INFO:Preparing display monitor
2025-02-06 18:28:23,527:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:28:23,527:INFO:Total runtime is 0.0 minutes
2025-02-06 18:28:23,530:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:23,530:INFO:Initializing create_model()
2025-02-06 18:28:23,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBFFF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:23,530:INFO:Checking exceptions
2025-02-06 18:28:23,530:INFO:Importing libraries
2025-02-06 18:28:23,530:INFO:Copying training dataset
2025-02-06 18:28:23,537:INFO:Defining folds
2025-02-06 18:28:23,537:INFO:Declaring metric variables
2025-02-06 18:28:23,538:INFO:Importing untrained model
2025-02-06 18:28:23,541:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:23,546:INFO:Starting cross validation
2025-02-06 18:28:23,546:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:23,992:INFO:Calculating mean and std
2025-02-06 18:28:23,992:INFO:Creating metrics dataframe
2025-02-06 18:28:23,994:INFO:Uploading results into container
2025-02-06 18:28:23,994:INFO:Uploading model into container now
2025-02-06 18:28:23,994:INFO:_master_model_container: 1
2025-02-06 18:28:23,994:INFO:_display_container: 2
2025-02-06 18:28:23,994:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:23,994:INFO:create_model() successfully completed......................................
2025-02-06 18:28:24,084:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:24,084:INFO:Creating metrics dataframe
2025-02-06 18:28:24,087:INFO:Initializing Logistic Regression
2025-02-06 18:28:24,088:INFO:Total runtime is 0.009342356522878011 minutes
2025-02-06 18:28:24,089:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:24,089:INFO:Initializing create_model()
2025-02-06 18:28:24,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CBFFF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:24,089:INFO:Checking exceptions
2025-02-06 18:28:24,089:INFO:Importing libraries
2025-02-06 18:28:24,089:INFO:Copying training dataset
2025-02-06 18:28:24,095:INFO:Defining folds
2025-02-06 18:28:24,095:INFO:Declaring metric variables
2025-02-06 18:28:24,096:INFO:Importing untrained model
2025-02-06 18:28:24,098:INFO:Logistic Regression Imported successfully
2025-02-06 18:28:24,101:INFO:Starting cross validation
2025-02-06 18:28:24,101:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:24,274:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:24,279:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:24,280:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:24,282:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:24,286:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:24,299:INFO:Calculating mean and std
2025-02-06 18:28:24,299:INFO:Creating metrics dataframe
2025-02-06 18:28:24,300:INFO:Uploading results into container
2025-02-06 18:28:24,301:INFO:Uploading model into container now
2025-02-06 18:28:24,301:INFO:_master_model_container: 2
2025-02-06 18:28:24,301:INFO:_display_container: 2
2025-02-06 18:28:24,301:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:24,301:INFO:create_model() successfully completed......................................
2025-02-06 18:28:24,378:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:24,378:INFO:Creating metrics dataframe
2025-02-06 18:28:24,381:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:28:24,384:INFO:Initializing create_model()
2025-02-06 18:28:24,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:24,384:INFO:Checking exceptions
2025-02-06 18:28:24,385:INFO:Importing libraries
2025-02-06 18:28:24,385:INFO:Copying training dataset
2025-02-06 18:28:24,392:INFO:Defining folds
2025-02-06 18:28:24,392:INFO:Declaring metric variables
2025-02-06 18:28:24,392:INFO:Importing untrained model
2025-02-06 18:28:24,392:INFO:Declaring custom model
2025-02-06 18:28:24,392:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:24,392:INFO:Cross validation set to False
2025-02-06 18:28:24,392:INFO:Fitting Model
2025-02-06 18:28:24,404:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:28:24,405:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
2025-02-06 18:28:24,405:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:28:24,405:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:28:24,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:28:24,406:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:28:24,406:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:28:24,482:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:24,482:INFO:create_model() successfully completed......................................
2025-02-06 18:28:24,584:INFO:_master_model_container: 2
2025-02-06 18:28:24,584:INFO:_display_container: 2
2025-02-06 18:28:24,585:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:24,585:INFO:compare_models() successfully completed......................................
2025-02-06 18:28:24,585:INFO:Initializing create_model()
2025-02-06 18:28:24,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:24,585:INFO:Checking exceptions
2025-02-06 18:28:24,592:INFO:Importing libraries
2025-02-06 18:28:24,592:INFO:Copying training dataset
2025-02-06 18:28:24,599:INFO:Defining folds
2025-02-06 18:28:24,599:INFO:Declaring metric variables
2025-02-06 18:28:24,600:INFO:Importing untrained model
2025-02-06 18:28:24,601:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:24,605:INFO:Starting cross validation
2025-02-06 18:28:24,605:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:25,038:INFO:Calculating mean and std
2025-02-06 18:28:25,038:INFO:Creating metrics dataframe
2025-02-06 18:28:25,043:INFO:Finalizing model
2025-02-06 18:28:25,058:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:28:25,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.
2025-02-06 18:28:25,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:28:25,059:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:28:25,059:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:28:25,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:28:25,060:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:28:25,177:INFO:Uploading results into container
2025-02-06 18:28:25,177:INFO:Uploading model into container now
2025-02-06 18:28:25,182:INFO:_master_model_container: 3
2025-02-06 18:28:25,182:INFO:_display_container: 3
2025-02-06 18:28:25,184:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:25,184:INFO:create_model() successfully completed......................................
2025-02-06 18:28:25,271:INFO:Initializing tune_model()
2025-02-06 18:28:25,271:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:28:25,271:INFO:Checking exceptions
2025-02-06 18:28:25,281:INFO:Copying training dataset
2025-02-06 18:28:25,287:INFO:Checking base model
2025-02-06 18:28:25,287:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:28:25,288:INFO:Declaring metric variables
2025-02-06 18:28:25,290:INFO:Defining Hyperparameters
2025-02-06 18:28:25,365:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:28:25,365:INFO:Tuning with n_jobs=-1
2025-02-06 18:28:25,365:INFO:Initializing RandomizedSearchCV
2025-02-06 18:28:40,172:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:28:40,173:INFO:Hyperparameter search completed
2025-02-06 18:28:40,173:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:40,173:INFO:Initializing create_model()
2025-02-06 18:28:40,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219350A2E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:28:40,173:INFO:Checking exceptions
2025-02-06 18:28:40,173:INFO:Importing libraries
2025-02-06 18:28:40,173:INFO:Copying training dataset
2025-02-06 18:28:40,182:INFO:Defining folds
2025-02-06 18:28:40,182:INFO:Declaring metric variables
2025-02-06 18:28:40,184:INFO:Importing untrained model
2025-02-06 18:28:40,184:INFO:Declaring custom model
2025-02-06 18:28:40,186:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:40,189:INFO:Starting cross validation
2025-02-06 18:28:40,190:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:43,199:INFO:Calculating mean and std
2025-02-06 18:28:43,200:INFO:Creating metrics dataframe
2025-02-06 18:28:43,204:INFO:Finalizing model
2025-02-06 18:28:43,219:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:28:43,220:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
2025-02-06 18:28:43,220:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:28:43,220:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:28:43,220:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:28:43,220:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:28:43,220:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:28:43,801:INFO:Uploading results into container
2025-02-06 18:28:43,801:INFO:Uploading model into container now
2025-02-06 18:28:43,802:INFO:_master_model_container: 4
2025-02-06 18:28:43,802:INFO:_display_container: 4
2025-02-06 18:28:43,802:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:43,802:INFO:create_model() successfully completed......................................
2025-02-06 18:28:43,887:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:43,887:INFO:choose_better activated
2025-02-06 18:28:43,891:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:43,891:INFO:Initializing create_model()
2025-02-06 18:28:43,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:43,891:INFO:Checking exceptions
2025-02-06 18:28:43,892:INFO:Importing libraries
2025-02-06 18:28:43,892:INFO:Copying training dataset
2025-02-06 18:28:43,900:INFO:Defining folds
2025-02-06 18:28:43,900:INFO:Declaring metric variables
2025-02-06 18:28:43,900:INFO:Importing untrained model
2025-02-06 18:28:43,900:INFO:Declaring custom model
2025-02-06 18:28:43,901:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:43,901:INFO:Starting cross validation
2025-02-06 18:28:43,901:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:44,298:INFO:Calculating mean and std
2025-02-06 18:28:44,298:INFO:Creating metrics dataframe
2025-02-06 18:28:44,300:INFO:Finalizing model
2025-02-06 18:28:44,313:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:28:44,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
2025-02-06 18:28:44,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:28:44,315:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:28:44,315:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:28:44,315:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:28:44,315:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:28:44,428:INFO:Uploading results into container
2025-02-06 18:28:44,428:INFO:Uploading model into container now
2025-02-06 18:28:44,428:INFO:_master_model_container: 5
2025-02-06 18:28:44,428:INFO:_display_container: 5
2025-02-06 18:28:44,429:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:44,429:INFO:create_model() successfully completed......................................
2025-02-06 18:28:44,515:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:44,515:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7778
2025-02-06 18:28:44,516:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7906
2025-02-06 18:28:44,516:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:28:44,516:INFO:choose_better completed
2025-02-06 18:28:44,521:INFO:_master_model_container: 5
2025-02-06 18:28:44,521:INFO:_display_container: 4
2025-02-06 18:28:44,522:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:44,522:INFO:tune_model() successfully completed......................................
2025-02-06 18:28:44,584:INFO:Initializing create_model()
2025-02-06 18:28:44,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:44,585:INFO:Checking exceptions
2025-02-06 18:28:44,591:INFO:Importing libraries
2025-02-06 18:28:44,591:INFO:Copying training dataset
2025-02-06 18:28:44,598:INFO:Defining folds
2025-02-06 18:28:44,598:INFO:Declaring metric variables
2025-02-06 18:28:44,599:INFO:Importing untrained model
2025-02-06 18:28:44,601:INFO:Logistic Regression Imported successfully
2025-02-06 18:28:44,605:INFO:Starting cross validation
2025-02-06 18:28:44,605:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:44,795:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:44,798:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:44,801:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:44,803:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:44,809:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:44,824:INFO:Calculating mean and std
2025-02-06 18:28:44,824:INFO:Creating metrics dataframe
2025-02-06 18:28:44,827:INFO:Finalizing model
2025-02-06 18:28:45,235:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,237:INFO:Uploading results into container
2025-02-06 18:28:45,237:INFO:Uploading model into container now
2025-02-06 18:28:45,242:INFO:_master_model_container: 6
2025-02-06 18:28:45,242:INFO:_display_container: 5
2025-02-06 18:28:45,243:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:45,243:INFO:create_model() successfully completed......................................
2025-02-06 18:28:45,321:INFO:Initializing tune_model()
2025-02-06 18:28:45,321:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:28:45,321:INFO:Checking exceptions
2025-02-06 18:28:45,330:INFO:Copying training dataset
2025-02-06 18:28:45,334:INFO:Checking base model
2025-02-06 18:28:45,334:INFO:Base model : Logistic Regression
2025-02-06 18:28:45,335:INFO:Declaring metric variables
2025-02-06 18:28:45,337:INFO:Defining Hyperparameters
2025-02-06 18:28:45,404:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:28:45,404:INFO:Tuning with n_jobs=-1
2025-02-06 18:28:45,404:INFO:Initializing RandomizedSearchCV
2025-02-06 18:28:45,470:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,473:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,477:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,480:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,485:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,489:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,492:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,495:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,495:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,509:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,942:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,975:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,975:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,990:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:45,991:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,239:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,281:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,292:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,297:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,375:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:46,453:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 200, 'actual_estimator__C': 1}
2025-02-06 18:28:46,454:INFO:Hyperparameter search completed
2025-02-06 18:28:46,454:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:46,454:INFO:Initializing create_model()
2025-02-06 18:28:46,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935C89210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 200, 'C': 1})
2025-02-06 18:28:46,454:INFO:Checking exceptions
2025-02-06 18:28:46,454:INFO:Importing libraries
2025-02-06 18:28:46,454:INFO:Copying training dataset
2025-02-06 18:28:46,461:INFO:Defining folds
2025-02-06 18:28:46,461:INFO:Declaring metric variables
2025-02-06 18:28:46,463:INFO:Importing untrained model
2025-02-06 18:28:46,463:INFO:Declaring custom model
2025-02-06 18:28:46,465:INFO:Logistic Regression Imported successfully
2025-02-06 18:28:46,467:INFO:Starting cross validation
2025-02-06 18:28:46,468:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:46,825:INFO:Calculating mean and std
2025-02-06 18:28:46,825:INFO:Creating metrics dataframe
2025-02-06 18:28:46,827:INFO:Finalizing model
2025-02-06 18:28:47,081:INFO:Uploading results into container
2025-02-06 18:28:47,082:INFO:Uploading model into container now
2025-02-06 18:28:47,082:INFO:_master_model_container: 7
2025-02-06 18:28:47,082:INFO:_display_container: 6
2025-02-06 18:28:47,082:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:47,082:INFO:create_model() successfully completed......................................
2025-02-06 18:28:47,151:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:47,151:INFO:choose_better activated
2025-02-06 18:28:47,153:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:47,153:INFO:Initializing create_model()
2025-02-06 18:28:47,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:47,153:INFO:Checking exceptions
2025-02-06 18:28:47,153:INFO:Importing libraries
2025-02-06 18:28:47,153:INFO:Copying training dataset
2025-02-06 18:28:47,159:INFO:Defining folds
2025-02-06 18:28:47,159:INFO:Declaring metric variables
2025-02-06 18:28:47,159:INFO:Importing untrained model
2025-02-06 18:28:47,159:INFO:Declaring custom model
2025-02-06 18:28:47,160:INFO:Logistic Regression Imported successfully
2025-02-06 18:28:47,160:INFO:Starting cross validation
2025-02-06 18:28:47,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:47,327:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,330:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,331:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,344:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,348:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,368:INFO:Calculating mean and std
2025-02-06 18:28:47,368:INFO:Creating metrics dataframe
2025-02-06 18:28:47,369:INFO:Finalizing model
2025-02-06 18:28:47,777:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-06 18:28:47,777:INFO:Uploading results into container
2025-02-06 18:28:47,778:INFO:Uploading model into container now
2025-02-06 18:28:47,778:INFO:_master_model_container: 8
2025-02-06 18:28:47,778:INFO:_display_container: 7
2025-02-06 18:28:47,778:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:47,778:INFO:create_model() successfully completed......................................
2025-02-06 18:28:47,880:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:47,880:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7732
2025-02-06 18:28:47,880:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7801
2025-02-06 18:28:47,880:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:28:47,880:INFO:choose_better completed
2025-02-06 18:28:47,884:INFO:_master_model_container: 8
2025-02-06 18:28:47,884:INFO:_display_container: 6
2025-02-06 18:28:47,884:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:47,884:INFO:tune_model() successfully completed......................................
2025-02-06 18:28:47,955:INFO:Initializing compare_models()
2025-02-06 18:28:47,955:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:28:47,955:INFO:Checking exceptions
2025-02-06 18:28:47,958:INFO:Preparing display monitor
2025-02-06 18:28:47,967:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:28:47,967:INFO:Total runtime is 0.0 minutes
2025-02-06 18:28:47,969:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:47,969:INFO:Initializing create_model()
2025-02-06 18:28:47,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EF3B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:47,969:INFO:Checking exceptions
2025-02-06 18:28:47,969:INFO:Importing libraries
2025-02-06 18:28:47,969:INFO:Copying training dataset
2025-02-06 18:28:47,975:INFO:Defining folds
2025-02-06 18:28:47,975:INFO:Declaring metric variables
2025-02-06 18:28:47,977:INFO:Importing untrained model
2025-02-06 18:28:47,977:INFO:Declaring custom model
2025-02-06 18:28:47,978:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:47,981:INFO:Starting cross validation
2025-02-06 18:28:47,981:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:51,084:INFO:Calculating mean and std
2025-02-06 18:28:51,085:INFO:Creating metrics dataframe
2025-02-06 18:28:51,088:INFO:Uploading results into container
2025-02-06 18:28:51,088:INFO:Uploading model into container now
2025-02-06 18:28:51,088:INFO:_master_model_container: 9
2025-02-06 18:28:51,088:INFO:_display_container: 7
2025-02-06 18:28:51,088:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:51,088:INFO:create_model() successfully completed......................................
2025-02-06 18:28:51,192:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:51,192:INFO:Creating metrics dataframe
2025-02-06 18:28:51,195:INFO:Initializing custom model Logistic Regression
2025-02-06 18:28:51,195:INFO:Total runtime is 0.05380017360051473 minutes
2025-02-06 18:28:51,197:INFO:SubProcess create_model() called ==================================
2025-02-06 18:28:51,197:INFO:Initializing create_model()
2025-02-06 18:28:51,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935EF3B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:51,197:INFO:Checking exceptions
2025-02-06 18:28:51,197:INFO:Importing libraries
2025-02-06 18:28:51,197:INFO:Copying training dataset
2025-02-06 18:28:51,203:INFO:Defining folds
2025-02-06 18:28:51,203:INFO:Declaring metric variables
2025-02-06 18:28:51,206:INFO:Importing untrained model
2025-02-06 18:28:51,206:INFO:Declaring custom model
2025-02-06 18:28:51,208:INFO:Logistic Regression Imported successfully
2025-02-06 18:28:51,211:INFO:Starting cross validation
2025-02-06 18:28:51,211:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:28:51,584:INFO:Calculating mean and std
2025-02-06 18:28:51,585:INFO:Creating metrics dataframe
2025-02-06 18:28:51,586:INFO:Uploading results into container
2025-02-06 18:28:51,586:INFO:Uploading model into container now
2025-02-06 18:28:51,587:INFO:_master_model_container: 10
2025-02-06 18:28:51,587:INFO:_display_container: 7
2025-02-06 18:28:51,587:INFO:LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:28:51,587:INFO:create_model() successfully completed......................................
2025-02-06 18:28:51,664:INFO:SubProcess create_model() end ==================================
2025-02-06 18:28:51,664:INFO:Creating metrics dataframe
2025-02-06 18:28:51,667:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:28:51,670:INFO:Initializing create_model()
2025-02-06 18:28:51,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:28:51,671:INFO:Checking exceptions
2025-02-06 18:28:51,671:INFO:Importing libraries
2025-02-06 18:28:51,671:INFO:Copying training dataset
2025-02-06 18:28:51,677:INFO:Defining folds
2025-02-06 18:28:51,677:INFO:Declaring metric variables
2025-02-06 18:28:51,678:INFO:Importing untrained model
2025-02-06 18:28:51,678:INFO:Declaring custom model
2025-02-06 18:28:51,678:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:28:51,678:INFO:Cross validation set to False
2025-02-06 18:28:51,678:INFO:Fitting Model
2025-02-06 18:28:51,690:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:28:51,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
2025-02-06 18:28:51,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:28:51,691:INFO:[LightGBM] [Info] Total Bins 6543
2025-02-06 18:28:51,691:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:28:51,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:28:51,691:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:28:52,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:52,400:INFO:create_model() successfully completed......................................
2025-02-06 18:28:52,497:INFO:_master_model_container: 10
2025-02-06 18:28:52,497:INFO:_display_container: 7
2025-02-06 18:28:52,497:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:28:52,497:INFO:compare_models() successfully completed......................................
2025-02-06 18:28:52,499:INFO:Initializing predict_model()
2025-02-06 18:28:52,499:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193C4EE8E0>)
2025-02-06 18:28:52,499:INFO:Checking exceptions
2025-02-06 18:28:52,499:INFO:Preloading libraries
2025-02-06 18:28:52,500:INFO:Set up data.
2025-02-06 18:28:52,506:INFO:Set up index.
2025-02-06 18:28:52,677:INFO:Initializing predict_model()
2025-02-06 18:28:52,678:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193C4EE8E0>)
2025-02-06 18:28:52,678:INFO:Checking exceptions
2025-02-06 18:28:52,678:INFO:Preloading libraries
2025-02-06 18:28:52,678:INFO:Set up data.
2025-02-06 18:28:52,682:INFO:Set up index.
2025-02-06 18:28:52,810:INFO:Initializing predict_model()
2025-02-06 18:28:52,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193C4EE8E0>)
2025-02-06 18:28:52,810:INFO:Checking exceptions
2025-02-06 18:28:52,810:INFO:Preloading libraries
2025-02-06 18:28:52,811:INFO:Set up data.
2025-02-06 18:28:52,818:INFO:Set up index.
2025-02-06 18:28:52,914:INFO:Initializing predict_model()
2025-02-06 18:28:52,914:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193633C2D0>, estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=200,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193C4EE8E0>)
2025-02-06 18:28:52,914:INFO:Checking exceptions
2025-02-06 18:28:52,914:INFO:Preloading libraries
2025-02-06 18:28:52,915:INFO:Set up data.
2025-02-06 18:28:52,919:INFO:Set up index.
2025-02-06 18:50:49,090:INFO:PyCaret ClassificationExperiment
2025-02-06 18:50:49,090:INFO:Logging name: clf-default-name
2025-02-06 18:50:49,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:50:49,090:INFO:version 3.3.2
2025-02-06 18:50:49,090:INFO:Initializing setup()
2025-02-06 18:50:49,090:INFO:self.USI: 0082
2025-02-06 18:50:49,090:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:50:49,090:INFO:Checking environment
2025-02-06 18:50:49,090:INFO:python_version: 3.11.9
2025-02-06 18:50:49,090:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:50:49,091:INFO:machine: AMD64
2025-02-06 18:50:49,091:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:50:49,095:INFO:Memory: svmem(total=67771465728, available=48471797760, percent=28.5, used=19299667968, free=48471797760)
2025-02-06 18:50:49,095:INFO:Physical Core: 8
2025-02-06 18:50:49,095:INFO:Logical Core: 16
2025-02-06 18:50:49,095:INFO:Checking libraries
2025-02-06 18:50:49,095:INFO:System:
2025-02-06 18:50:49,095:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:50:49,095:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:50:49,095:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:50:49,096:INFO:PyCaret required dependencies:
2025-02-06 18:50:49,096:INFO:                 pip: 25.0
2025-02-06 18:50:49,096:INFO:          setuptools: 65.5.0
2025-02-06 18:50:49,096:INFO:             pycaret: 3.3.2
2025-02-06 18:50:49,096:INFO:             IPython: 8.32.0
2025-02-06 18:50:49,096:INFO:          ipywidgets: 8.1.5
2025-02-06 18:50:49,096:INFO:                tqdm: 4.67.1
2025-02-06 18:50:49,096:INFO:               numpy: 1.26.4
2025-02-06 18:50:49,096:INFO:              pandas: 2.1.4
2025-02-06 18:50:49,096:INFO:              jinja2: 3.1.5
2025-02-06 18:50:49,096:INFO:               scipy: 1.11.4
2025-02-06 18:50:49,096:INFO:              joblib: 1.3.2
2025-02-06 18:50:49,096:INFO:             sklearn: 1.4.2
2025-02-06 18:50:49,096:INFO:                pyod: 2.0.3
2025-02-06 18:50:49,096:INFO:            imblearn: 0.13.0
2025-02-06 18:50:49,096:INFO:   category_encoders: 2.7.0
2025-02-06 18:50:49,096:INFO:            lightgbm: 4.5.0
2025-02-06 18:50:49,096:INFO:               numba: 0.61.0
2025-02-06 18:50:49,096:INFO:            requests: 2.32.3
2025-02-06 18:50:49,096:INFO:          matplotlib: 3.7.5
2025-02-06 18:50:49,096:INFO:          scikitplot: 0.3.7
2025-02-06 18:50:49,096:INFO:         yellowbrick: 1.5
2025-02-06 18:50:49,096:INFO:              plotly: 5.24.1
2025-02-06 18:50:49,096:INFO:    plotly-resampler: Not installed
2025-02-06 18:50:49,096:INFO:             kaleido: 0.2.1
2025-02-06 18:50:49,096:INFO:           schemdraw: 0.15
2025-02-06 18:50:49,096:INFO:         statsmodels: 0.14.4
2025-02-06 18:50:49,096:INFO:              sktime: 0.26.0
2025-02-06 18:50:49,096:INFO:               tbats: 1.1.3
2025-02-06 18:50:49,096:INFO:            pmdarima: 2.0.4
2025-02-06 18:50:49,096:INFO:              psutil: 6.1.1
2025-02-06 18:50:49,096:INFO:          markupsafe: 3.0.2
2025-02-06 18:50:49,096:INFO:             pickle5: Not installed
2025-02-06 18:50:49,096:INFO:         cloudpickle: 3.1.1
2025-02-06 18:50:49,096:INFO:         deprecation: 2.1.0
2025-02-06 18:50:49,096:INFO:              xxhash: 3.5.0
2025-02-06 18:50:49,096:INFO:           wurlitzer: Not installed
2025-02-06 18:50:49,096:INFO:PyCaret optional dependencies:
2025-02-06 18:50:49,096:INFO:                shap: Not installed
2025-02-06 18:50:49,096:INFO:           interpret: Not installed
2025-02-06 18:50:49,096:INFO:                umap: Not installed
2025-02-06 18:50:49,096:INFO:     ydata_profiling: Not installed
2025-02-06 18:50:49,096:INFO:  explainerdashboard: Not installed
2025-02-06 18:50:49,096:INFO:             autoviz: Not installed
2025-02-06 18:50:49,096:INFO:           fairlearn: Not installed
2025-02-06 18:50:49,096:INFO:          deepchecks: Not installed
2025-02-06 18:50:49,096:INFO:             xgboost: Not installed
2025-02-06 18:50:49,096:INFO:            catboost: Not installed
2025-02-06 18:50:49,096:INFO:              kmodes: Not installed
2025-02-06 18:50:49,096:INFO:             mlxtend: Not installed
2025-02-06 18:50:49,096:INFO:       statsforecast: Not installed
2025-02-06 18:50:49,096:INFO:        tune_sklearn: Not installed
2025-02-06 18:50:49,096:INFO:                 ray: Not installed
2025-02-06 18:50:49,096:INFO:            hyperopt: Not installed
2025-02-06 18:50:49,096:INFO:              optuna: Not installed
2025-02-06 18:50:49,096:INFO:               skopt: Not installed
2025-02-06 18:50:49,096:INFO:              mlflow: Not installed
2025-02-06 18:50:49,096:INFO:              gradio: Not installed
2025-02-06 18:50:49,096:INFO:             fastapi: Not installed
2025-02-06 18:50:49,096:INFO:             uvicorn: Not installed
2025-02-06 18:50:49,096:INFO:              m2cgen: Not installed
2025-02-06 18:50:49,096:INFO:           evidently: Not installed
2025-02-06 18:50:49,096:INFO:               fugue: Not installed
2025-02-06 18:50:49,096:INFO:           streamlit: Not installed
2025-02-06 18:50:49,096:INFO:             prophet: Not installed
2025-02-06 18:50:49,097:INFO:None
2025-02-06 18:50:49,097:INFO:Set up data.
2025-02-06 18:50:49,102:INFO:Set up folding strategy.
2025-02-06 18:50:49,102:INFO:Set up train/test split.
2025-02-06 18:50:49,107:INFO:Set up index.
2025-02-06 18:50:49,107:INFO:Assigning column types.
2025-02-06 18:50:49,112:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:50:49,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,141:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,195:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:50:49,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,258:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:50:49,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,272:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:50:49,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,352:INFO:Preparing preprocessing pipeline...
2025-02-06 18:50:49,353:INFO:Set up simple imputation.
2025-02-06 18:50:49,353:INFO:Set up feature normalization.
2025-02-06 18:50:49,376:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:50:49,378:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 18:50:49,378:INFO:Creating final display dataframe.
2025-02-06 18:50:49,450:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              0082
2025-02-06 18:50:49,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:50:49,529:INFO:setup() successfully completed in 0.44s...............
2025-02-06 18:50:49,529:INFO:Initializing compare_models()
2025-02-06 18:50:49,529:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:50:49,529:INFO:Checking exceptions
2025-02-06 18:50:49,532:INFO:Preparing display monitor
2025-02-06 18:50:49,542:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:50:49,542:INFO:Total runtime is 0.0 minutes
2025-02-06 18:50:49,544:INFO:SubProcess create_model() called ==================================
2025-02-06 18:50:49,544:INFO:Initializing create_model()
2025-02-06 18:50:49,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193DE6F850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:50:49,544:INFO:Checking exceptions
2025-02-06 18:50:49,544:INFO:Importing libraries
2025-02-06 18:50:49,544:INFO:Copying training dataset
2025-02-06 18:50:49,550:INFO:Defining folds
2025-02-06 18:50:49,550:INFO:Declaring metric variables
2025-02-06 18:50:49,551:INFO:Importing untrained model
2025-02-06 18:50:49,552:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:50:49,556:INFO:Starting cross validation
2025-02-06 18:50:49,556:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:50:51,696:INFO:Calculating mean and std
2025-02-06 18:50:51,696:INFO:Creating metrics dataframe
2025-02-06 18:50:51,698:INFO:Uploading results into container
2025-02-06 18:50:51,698:INFO:Uploading model into container now
2025-02-06 18:50:51,699:INFO:_master_model_container: 1
2025-02-06 18:50:51,699:INFO:_display_container: 2
2025-02-06 18:50:51,699:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:50:51,700:INFO:create_model() successfully completed......................................
2025-02-06 18:50:51,818:INFO:SubProcess create_model() end ==================================
2025-02-06 18:50:51,818:INFO:Creating metrics dataframe
2025-02-06 18:50:51,822:INFO:Initializing Logistic Regression
2025-02-06 18:50:51,822:INFO:Total runtime is 0.03799408276875814 minutes
2025-02-06 18:50:51,823:INFO:SubProcess create_model() called ==================================
2025-02-06 18:50:51,823:INFO:Initializing create_model()
2025-02-06 18:50:51,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193DE6F850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:50:51,823:INFO:Checking exceptions
2025-02-06 18:50:51,823:INFO:Importing libraries
2025-02-06 18:50:51,823:INFO:Copying training dataset
2025-02-06 18:50:51,830:INFO:Defining folds
2025-02-06 18:50:51,830:INFO:Declaring metric variables
2025-02-06 18:50:51,832:INFO:Importing untrained model
2025-02-06 18:50:51,833:INFO:Logistic Regression Imported successfully
2025-02-06 18:50:51,837:INFO:Starting cross validation
2025-02-06 18:50:51,837:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:50:53,172:INFO:Calculating mean and std
2025-02-06 18:50:53,173:INFO:Creating metrics dataframe
2025-02-06 18:50:53,174:INFO:Uploading results into container
2025-02-06 18:50:53,174:INFO:Uploading model into container now
2025-02-06 18:50:53,175:INFO:_master_model_container: 2
2025-02-06 18:50:53,175:INFO:_display_container: 2
2025-02-06 18:50:53,175:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:50:53,175:INFO:create_model() successfully completed......................................
2025-02-06 18:50:53,271:INFO:SubProcess create_model() end ==================================
2025-02-06 18:50:53,271:INFO:Creating metrics dataframe
2025-02-06 18:50:53,275:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:50:53,280:INFO:Initializing create_model()
2025-02-06 18:50:53,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:50:53,280:INFO:Checking exceptions
2025-02-06 18:50:53,281:INFO:Importing libraries
2025-02-06 18:50:53,281:INFO:Copying training dataset
2025-02-06 18:50:53,286:INFO:Defining folds
2025-02-06 18:50:53,286:INFO:Declaring metric variables
2025-02-06 18:50:53,286:INFO:Importing untrained model
2025-02-06 18:50:53,286:INFO:Declaring custom model
2025-02-06 18:50:53,286:INFO:Logistic Regression Imported successfully
2025-02-06 18:50:53,288:INFO:Cross validation set to False
2025-02-06 18:50:53,288:INFO:Fitting Model
2025-02-06 18:50:53,316:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:50:53,316:INFO:create_model() successfully completed......................................
2025-02-06 18:50:53,398:INFO:_master_model_container: 2
2025-02-06 18:50:53,398:INFO:_display_container: 2
2025-02-06 18:50:53,398:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:50:53,398:INFO:compare_models() successfully completed......................................
2025-02-06 18:50:53,398:INFO:Initializing create_model()
2025-02-06 18:50:53,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:50:53,398:INFO:Checking exceptions
2025-02-06 18:50:53,405:INFO:Importing libraries
2025-02-06 18:50:53,406:INFO:Copying training dataset
2025-02-06 18:50:53,410:INFO:Defining folds
2025-02-06 18:50:53,410:INFO:Declaring metric variables
2025-02-06 18:50:53,413:INFO:Importing untrained model
2025-02-06 18:50:53,414:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:50:53,417:INFO:Starting cross validation
2025-02-06 18:50:53,418:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:50:55,120:INFO:Calculating mean and std
2025-02-06 18:50:55,121:INFO:Creating metrics dataframe
2025-02-06 18:50:55,124:INFO:Finalizing model
2025-02-06 18:50:55,145:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:50:55,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-02-06 18:50:55,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:50:55,146:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:50:55,147:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:50:55,147:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:50:55,147:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:50:55,244:INFO:Uploading results into container
2025-02-06 18:50:55,245:INFO:Uploading model into container now
2025-02-06 18:50:55,250:INFO:_master_model_container: 3
2025-02-06 18:50:55,250:INFO:_display_container: 3
2025-02-06 18:50:55,250:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:50:55,250:INFO:create_model() successfully completed......................................
2025-02-06 18:50:55,335:INFO:Initializing tune_model()
2025-02-06 18:50:55,335:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 500], 'max_depth': [-1, 10, 20], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0, 0.1, 0.5]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:50:55,335:INFO:Checking exceptions
2025-02-06 18:50:55,344:INFO:Copying training dataset
2025-02-06 18:50:55,349:INFO:Checking base model
2025-02-06 18:50:55,349:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:50:55,351:INFO:Declaring metric variables
2025-02-06 18:50:55,352:INFO:Defining Hyperparameters
2025-02-06 18:50:55,441:INFO:custom_grid: {'actual_estimator__num_leaves': [31, 50, 70], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 500], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__subsample': [0.8, 1.0], 'actual_estimator__colsample_bytree': [0.8, 1.0], 'actual_estimator__reg_alpha': [0, 0.1, 0.5], 'actual_estimator__reg_lambda': [0, 0.1, 0.5]}
2025-02-06 18:50:55,441:INFO:Tuning with n_jobs=-1
2025-02-06 18:50:55,441:INFO:Initializing RandomizedSearchCV
2025-02-06 18:51:08,571:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 500, 'actual_estimator__max_depth': 20, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 18:51:08,571:INFO:Hyperparameter search completed
2025-02-06 18:51:08,571:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:08,572:INFO:Initializing create_model()
2025-02-06 18:51:08,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935BF7A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8})
2025-02-06 18:51:08,572:INFO:Checking exceptions
2025-02-06 18:51:08,572:INFO:Importing libraries
2025-02-06 18:51:08,572:INFO:Copying training dataset
2025-02-06 18:51:08,580:INFO:Defining folds
2025-02-06 18:51:08,580:INFO:Declaring metric variables
2025-02-06 18:51:08,582:INFO:Importing untrained model
2025-02-06 18:51:08,583:INFO:Declaring custom model
2025-02-06 18:51:08,585:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:51:08,589:INFO:Starting cross validation
2025-02-06 18:51:08,590:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:11,028:INFO:Calculating mean and std
2025-02-06 18:51:11,029:INFO:Creating metrics dataframe
2025-02-06 18:51:11,033:INFO:Finalizing model
2025-02-06 18:51:11,051:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:51:11,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
2025-02-06 18:51:11,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:51:11,052:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:51:11,052:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:51:11,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:51:11,052:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:51:11,704:INFO:Uploading results into container
2025-02-06 18:51:11,705:INFO:Uploading model into container now
2025-02-06 18:51:11,705:INFO:_master_model_container: 4
2025-02-06 18:51:11,705:INFO:_display_container: 4
2025-02-06 18:51:11,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:11,705:INFO:create_model() successfully completed......................................
2025-02-06 18:51:11,789:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:11,790:INFO:choose_better activated
2025-02-06 18:51:11,791:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:11,792:INFO:Initializing create_model()
2025-02-06 18:51:11,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:11,792:INFO:Checking exceptions
2025-02-06 18:51:11,793:INFO:Importing libraries
2025-02-06 18:51:11,793:INFO:Copying training dataset
2025-02-06 18:51:11,801:INFO:Defining folds
2025-02-06 18:51:11,801:INFO:Declaring metric variables
2025-02-06 18:51:11,801:INFO:Importing untrained model
2025-02-06 18:51:11,801:INFO:Declaring custom model
2025-02-06 18:51:11,801:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:51:11,802:INFO:Starting cross validation
2025-02-06 18:51:11,802:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:12,144:INFO:Calculating mean and std
2025-02-06 18:51:12,144:INFO:Creating metrics dataframe
2025-02-06 18:51:12,145:INFO:Finalizing model
2025-02-06 18:51:12,162:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:51:12,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
2025-02-06 18:51:12,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:51:12,163:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:51:12,163:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:51:12,164:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:51:12,164:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:51:12,285:INFO:Uploading results into container
2025-02-06 18:51:12,285:INFO:Uploading model into container now
2025-02-06 18:51:12,285:INFO:_master_model_container: 5
2025-02-06 18:51:12,285:INFO:_display_container: 5
2025-02-06 18:51:12,285:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:12,285:INFO:create_model() successfully completed......................................
2025-02-06 18:51:12,369:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:12,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7769
2025-02-06 18:51:12,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7911
2025-02-06 18:51:12,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:51:12,370:INFO:choose_better completed
2025-02-06 18:51:12,375:INFO:_master_model_container: 5
2025-02-06 18:51:12,375:INFO:_display_container: 4
2025-02-06 18:51:12,376:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:12,376:INFO:tune_model() successfully completed......................................
2025-02-06 18:51:12,431:INFO:Initializing create_model()
2025-02-06 18:51:12,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:12,431:INFO:Checking exceptions
2025-02-06 18:51:12,437:INFO:Importing libraries
2025-02-06 18:51:12,437:INFO:Copying training dataset
2025-02-06 18:51:12,443:INFO:Defining folds
2025-02-06 18:51:12,443:INFO:Declaring metric variables
2025-02-06 18:51:12,445:INFO:Importing untrained model
2025-02-06 18:51:12,446:INFO:Logistic Regression Imported successfully
2025-02-06 18:51:12,449:INFO:Starting cross validation
2025-02-06 18:51:12,449:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:12,494:INFO:Calculating mean and std
2025-02-06 18:51:12,494:INFO:Creating metrics dataframe
2025-02-06 18:51:12,496:INFO:Finalizing model
2025-02-06 18:51:12,526:INFO:Uploading results into container
2025-02-06 18:51:12,526:INFO:Uploading model into container now
2025-02-06 18:51:12,529:INFO:_master_model_container: 6
2025-02-06 18:51:12,529:INFO:_display_container: 5
2025-02-06 18:51:12,530:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:51:12,530:INFO:create_model() successfully completed......................................
2025-02-06 18:51:12,597:INFO:Initializing tune_model()
2025-02-06 18:51:12,597:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:51:12,597:INFO:Checking exceptions
2025-02-06 18:51:12,606:INFO:Copying training dataset
2025-02-06 18:51:12,610:INFO:Checking base model
2025-02-06 18:51:12,610:INFO:Base model : Logistic Regression
2025-02-06 18:51:12,611:INFO:Declaring metric variables
2025-02-06 18:51:12,613:INFO:Defining Hyperparameters
2025-02-06 18:51:12,697:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:51:12,697:INFO:Tuning with n_jobs=-1
2025-02-06 18:51:12,697:INFO:Initializing RandomizedSearchCV
2025-02-06 18:51:12,895:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 18:51:12,895:INFO:Hyperparameter search completed
2025-02-06 18:51:12,895:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:12,896:INFO:Initializing create_model()
2025-02-06 18:51:12,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021935E17A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 18:51:12,896:INFO:Checking exceptions
2025-02-06 18:51:12,896:INFO:Importing libraries
2025-02-06 18:51:12,896:INFO:Copying training dataset
2025-02-06 18:51:12,902:INFO:Defining folds
2025-02-06 18:51:12,902:INFO:Declaring metric variables
2025-02-06 18:51:12,904:INFO:Importing untrained model
2025-02-06 18:51:12,904:INFO:Declaring custom model
2025-02-06 18:51:12,906:INFO:Logistic Regression Imported successfully
2025-02-06 18:51:12,908:INFO:Starting cross validation
2025-02-06 18:51:12,909:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:12,964:INFO:Calculating mean and std
2025-02-06 18:51:12,964:INFO:Creating metrics dataframe
2025-02-06 18:51:12,967:INFO:Finalizing model
2025-02-06 18:51:13,000:INFO:Uploading results into container
2025-02-06 18:51:13,000:INFO:Uploading model into container now
2025-02-06 18:51:13,000:INFO:_master_model_container: 7
2025-02-06 18:51:13,000:INFO:_display_container: 6
2025-02-06 18:51:13,000:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:51:13,000:INFO:create_model() successfully completed......................................
2025-02-06 18:51:13,068:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:13,068:INFO:choose_better activated
2025-02-06 18:51:13,070:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:13,070:INFO:Initializing create_model()
2025-02-06 18:51:13,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:13,070:INFO:Checking exceptions
2025-02-06 18:51:13,071:INFO:Importing libraries
2025-02-06 18:51:13,071:INFO:Copying training dataset
2025-02-06 18:51:13,077:INFO:Defining folds
2025-02-06 18:51:13,077:INFO:Declaring metric variables
2025-02-06 18:51:13,077:INFO:Importing untrained model
2025-02-06 18:51:13,077:INFO:Declaring custom model
2025-02-06 18:51:13,077:INFO:Logistic Regression Imported successfully
2025-02-06 18:51:13,077:INFO:Starting cross validation
2025-02-06 18:51:13,078:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:13,122:INFO:Calculating mean and std
2025-02-06 18:51:13,122:INFO:Creating metrics dataframe
2025-02-06 18:51:13,122:INFO:Finalizing model
2025-02-06 18:51:13,150:INFO:Uploading results into container
2025-02-06 18:51:13,150:INFO:Uploading model into container now
2025-02-06 18:51:13,151:INFO:_master_model_container: 8
2025-02-06 18:51:13,151:INFO:_display_container: 7
2025-02-06 18:51:13,151:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:51:13,151:INFO:create_model() successfully completed......................................
2025-02-06 18:51:13,220:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:13,220:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7832
2025-02-06 18:51:13,220:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7833
2025-02-06 18:51:13,220:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:51:13,220:INFO:choose_better completed
2025-02-06 18:51:13,224:INFO:_master_model_container: 8
2025-02-06 18:51:13,224:INFO:_display_container: 6
2025-02-06 18:51:13,225:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:51:13,225:INFO:tune_model() successfully completed......................................
2025-02-06 18:51:13,276:INFO:Initializing compare_models()
2025-02-06 18:51:13,276:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:51:13,276:INFO:Checking exceptions
2025-02-06 18:51:13,278:INFO:Preparing display monitor
2025-02-06 18:51:13,289:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:51:13,289:INFO:Total runtime is 0.0 minutes
2025-02-06 18:51:13,291:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:13,291:INFO:Initializing create_model()
2025-02-06 18:51:13,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219404E4490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:13,291:INFO:Checking exceptions
2025-02-06 18:51:13,291:INFO:Importing libraries
2025-02-06 18:51:13,291:INFO:Copying training dataset
2025-02-06 18:51:13,297:INFO:Defining folds
2025-02-06 18:51:13,297:INFO:Declaring metric variables
2025-02-06 18:51:13,299:INFO:Importing untrained model
2025-02-06 18:51:13,299:INFO:Declaring custom model
2025-02-06 18:51:13,300:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:51:13,303:INFO:Starting cross validation
2025-02-06 18:51:13,304:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:15,555:INFO:Calculating mean and std
2025-02-06 18:51:15,556:INFO:Creating metrics dataframe
2025-02-06 18:51:15,558:INFO:Uploading results into container
2025-02-06 18:51:15,558:INFO:Uploading model into container now
2025-02-06 18:51:15,558:INFO:_master_model_container: 9
2025-02-06 18:51:15,558:INFO:_display_container: 7
2025-02-06 18:51:15,559:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:15,559:INFO:create_model() successfully completed......................................
2025-02-06 18:51:15,653:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:15,654:INFO:Creating metrics dataframe
2025-02-06 18:51:15,656:INFO:Initializing custom model Logistic Regression
2025-02-06 18:51:15,657:INFO:Total runtime is 0.03947450319925944 minutes
2025-02-06 18:51:15,658:INFO:SubProcess create_model() called ==================================
2025-02-06 18:51:15,658:INFO:Initializing create_model()
2025-02-06 18:51:15,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219404E4490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:15,658:INFO:Checking exceptions
2025-02-06 18:51:15,658:INFO:Importing libraries
2025-02-06 18:51:15,658:INFO:Copying training dataset
2025-02-06 18:51:15,665:INFO:Defining folds
2025-02-06 18:51:15,665:INFO:Declaring metric variables
2025-02-06 18:51:15,666:INFO:Importing untrained model
2025-02-06 18:51:15,666:INFO:Declaring custom model
2025-02-06 18:51:15,668:INFO:Logistic Regression Imported successfully
2025-02-06 18:51:15,671:INFO:Starting cross validation
2025-02-06 18:51:15,672:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:51:15,715:INFO:Calculating mean and std
2025-02-06 18:51:15,715:INFO:Creating metrics dataframe
2025-02-06 18:51:15,716:INFO:Uploading results into container
2025-02-06 18:51:15,716:INFO:Uploading model into container now
2025-02-06 18:51:15,717:INFO:_master_model_container: 10
2025-02-06 18:51:15,717:INFO:_display_container: 7
2025-02-06 18:51:15,717:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:51:15,717:INFO:create_model() successfully completed......................................
2025-02-06 18:51:15,790:INFO:SubProcess create_model() end ==================================
2025-02-06 18:51:15,790:INFO:Creating metrics dataframe
2025-02-06 18:51:15,795:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:51:15,799:INFO:Initializing create_model()
2025-02-06 18:51:15,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:51:15,799:INFO:Checking exceptions
2025-02-06 18:51:15,800:INFO:Importing libraries
2025-02-06 18:51:15,800:INFO:Copying training dataset
2025-02-06 18:51:15,806:INFO:Defining folds
2025-02-06 18:51:15,806:INFO:Declaring metric variables
2025-02-06 18:51:15,806:INFO:Importing untrained model
2025-02-06 18:51:15,806:INFO:Declaring custom model
2025-02-06 18:51:15,806:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:51:15,807:INFO:Cross validation set to False
2025-02-06 18:51:15,807:INFO:Fitting Model
2025-02-06 18:51:15,821:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:51:15,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
2025-02-06 18:51:15,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:51:15,822:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:51:15,823:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:51:15,823:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:51:15,823:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:51:16,265:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:16,265:INFO:create_model() successfully completed......................................
2025-02-06 18:51:16,363:INFO:_master_model_container: 10
2025-02-06 18:51:16,364:INFO:_display_container: 7
2025-02-06 18:51:16,364:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:51:16,364:INFO:compare_models() successfully completed......................................
2025-02-06 18:51:16,365:INFO:Initializing predict_model()
2025-02-06 18:51:16,365:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219404D5760>)
2025-02-06 18:51:16,366:INFO:Checking exceptions
2025-02-06 18:51:16,366:INFO:Preloading libraries
2025-02-06 18:51:16,367:INFO:Set up data.
2025-02-06 18:51:16,373:INFO:Set up index.
2025-02-06 18:51:16,533:INFO:Initializing predict_model()
2025-02-06 18:51:16,533:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.01, max_depth=20,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021971C6D260>)
2025-02-06 18:51:16,533:INFO:Checking exceptions
2025-02-06 18:51:16,533:INFO:Preloading libraries
2025-02-06 18:51:16,534:INFO:Set up data.
2025-02-06 18:51:16,539:INFO:Set up index.
2025-02-06 18:51:16,663:INFO:Initializing predict_model()
2025-02-06 18:51:16,663:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021971C6D260>)
2025-02-06 18:51:16,663:INFO:Checking exceptions
2025-02-06 18:51:16,663:INFO:Preloading libraries
2025-02-06 18:51:16,664:INFO:Set up data.
2025-02-06 18:51:16,671:INFO:Set up index.
2025-02-06 18:51:16,766:INFO:Initializing predict_model()
2025-02-06 18:51:16,767:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CD77D90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021971C6D260>)
2025-02-06 18:51:16,767:INFO:Checking exceptions
2025-02-06 18:51:16,767:INFO:Preloading libraries
2025-02-06 18:51:16,767:INFO:Set up data.
2025-02-06 18:51:16,772:INFO:Set up index.
2025-02-06 18:55:57,693:INFO:PyCaret ClassificationExperiment
2025-02-06 18:55:57,693:INFO:Logging name: clf-default-name
2025-02-06 18:55:57,693:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:55:57,693:INFO:version 3.3.2
2025-02-06 18:55:57,693:INFO:Initializing setup()
2025-02-06 18:55:57,693:INFO:self.USI: 3ad0
2025-02-06 18:55:57,693:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:55:57,693:INFO:Checking environment
2025-02-06 18:55:57,693:INFO:python_version: 3.11.9
2025-02-06 18:55:57,693:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:55:57,693:INFO:machine: AMD64
2025-02-06 18:55:57,693:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:55:57,697:INFO:Memory: svmem(total=67771465728, available=46012112896, percent=32.1, used=21759352832, free=46012112896)
2025-02-06 18:55:57,697:INFO:Physical Core: 8
2025-02-06 18:55:57,697:INFO:Logical Core: 16
2025-02-06 18:55:57,697:INFO:Checking libraries
2025-02-06 18:55:57,697:INFO:System:
2025-02-06 18:55:57,697:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:55:57,697:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:55:57,697:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:55:57,697:INFO:PyCaret required dependencies:
2025-02-06 18:55:57,697:INFO:                 pip: 25.0
2025-02-06 18:55:57,697:INFO:          setuptools: 65.5.0
2025-02-06 18:55:57,697:INFO:             pycaret: 3.3.2
2025-02-06 18:55:57,697:INFO:             IPython: 8.32.0
2025-02-06 18:55:57,697:INFO:          ipywidgets: 8.1.5
2025-02-06 18:55:57,697:INFO:                tqdm: 4.67.1
2025-02-06 18:55:57,697:INFO:               numpy: 1.26.4
2025-02-06 18:55:57,697:INFO:              pandas: 2.1.4
2025-02-06 18:55:57,697:INFO:              jinja2: 3.1.5
2025-02-06 18:55:57,697:INFO:               scipy: 1.11.4
2025-02-06 18:55:57,697:INFO:              joblib: 1.3.2
2025-02-06 18:55:57,697:INFO:             sklearn: 1.4.2
2025-02-06 18:55:57,697:INFO:                pyod: 2.0.3
2025-02-06 18:55:57,697:INFO:            imblearn: 0.13.0
2025-02-06 18:55:57,697:INFO:   category_encoders: 2.7.0
2025-02-06 18:55:57,697:INFO:            lightgbm: 4.5.0
2025-02-06 18:55:57,697:INFO:               numba: 0.61.0
2025-02-06 18:55:57,697:INFO:            requests: 2.32.3
2025-02-06 18:55:57,697:INFO:          matplotlib: 3.7.5
2025-02-06 18:55:57,697:INFO:          scikitplot: 0.3.7
2025-02-06 18:55:57,697:INFO:         yellowbrick: 1.5
2025-02-06 18:55:57,697:INFO:              plotly: 5.24.1
2025-02-06 18:55:57,697:INFO:    plotly-resampler: Not installed
2025-02-06 18:55:57,697:INFO:             kaleido: 0.2.1
2025-02-06 18:55:57,697:INFO:           schemdraw: 0.15
2025-02-06 18:55:57,697:INFO:         statsmodels: 0.14.4
2025-02-06 18:55:57,697:INFO:              sktime: 0.26.0
2025-02-06 18:55:57,697:INFO:               tbats: 1.1.3
2025-02-06 18:55:57,697:INFO:            pmdarima: 2.0.4
2025-02-06 18:55:57,697:INFO:              psutil: 6.1.1
2025-02-06 18:55:57,697:INFO:          markupsafe: 3.0.2
2025-02-06 18:55:57,697:INFO:             pickle5: Not installed
2025-02-06 18:55:57,697:INFO:         cloudpickle: 3.1.1
2025-02-06 18:55:57,697:INFO:         deprecation: 2.1.0
2025-02-06 18:55:57,697:INFO:              xxhash: 3.5.0
2025-02-06 18:55:57,697:INFO:           wurlitzer: Not installed
2025-02-06 18:55:57,697:INFO:PyCaret optional dependencies:
2025-02-06 18:55:57,697:INFO:                shap: Not installed
2025-02-06 18:55:57,697:INFO:           interpret: Not installed
2025-02-06 18:55:57,697:INFO:                umap: Not installed
2025-02-06 18:55:57,697:INFO:     ydata_profiling: Not installed
2025-02-06 18:55:57,697:INFO:  explainerdashboard: Not installed
2025-02-06 18:55:57,697:INFO:             autoviz: Not installed
2025-02-06 18:55:57,697:INFO:           fairlearn: Not installed
2025-02-06 18:55:57,697:INFO:          deepchecks: Not installed
2025-02-06 18:55:57,697:INFO:             xgboost: Not installed
2025-02-06 18:55:57,697:INFO:            catboost: Not installed
2025-02-06 18:55:57,697:INFO:              kmodes: Not installed
2025-02-06 18:55:57,697:INFO:             mlxtend: Not installed
2025-02-06 18:55:57,697:INFO:       statsforecast: Not installed
2025-02-06 18:55:57,698:INFO:        tune_sklearn: Not installed
2025-02-06 18:55:57,698:INFO:                 ray: Not installed
2025-02-06 18:55:57,698:INFO:            hyperopt: Not installed
2025-02-06 18:55:57,698:INFO:              optuna: Not installed
2025-02-06 18:55:57,698:INFO:               skopt: Not installed
2025-02-06 18:55:57,698:INFO:              mlflow: Not installed
2025-02-06 18:55:57,698:INFO:              gradio: Not installed
2025-02-06 18:55:57,698:INFO:             fastapi: Not installed
2025-02-06 18:55:57,698:INFO:             uvicorn: Not installed
2025-02-06 18:55:57,698:INFO:              m2cgen: Not installed
2025-02-06 18:55:57,698:INFO:           evidently: Not installed
2025-02-06 18:55:57,698:INFO:               fugue: Not installed
2025-02-06 18:55:57,698:INFO:           streamlit: Not installed
2025-02-06 18:55:57,698:INFO:             prophet: Not installed
2025-02-06 18:55:57,698:INFO:None
2025-02-06 18:55:57,698:INFO:Set up data.
2025-02-06 18:55:57,706:INFO:Set up folding strategy.
2025-02-06 18:55:57,706:INFO:Set up train/test split.
2025-02-06 18:55:57,715:INFO:Set up index.
2025-02-06 18:55:57,716:INFO:Assigning column types.
2025-02-06 18:55:57,723:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:55:57,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,753:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,808:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:55:57,832:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:55:57,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,886:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:55:57,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:57,965:INFO:Preparing preprocessing pipeline...
2025-02-06 18:55:57,967:INFO:Set up simple imputation.
2025-02-06 18:55:57,967:INFO:Set up feature normalization.
2025-02-06 18:55:57,990:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:55:57,991:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 18:55:57,991:INFO:Creating final display dataframe.
2025-02-06 18:55:58,065:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              3ad0
2025-02-06 18:55:58,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:58,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:58,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:58,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:55:58,143:INFO:setup() successfully completed in 0.45s...............
2025-02-06 18:55:58,143:INFO:Initializing compare_models()
2025-02-06 18:55:58,143:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:55:58,143:INFO:Checking exceptions
2025-02-06 18:55:58,147:INFO:Preparing display monitor
2025-02-06 18:55:58,157:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:55:58,157:INFO:Total runtime is 8.364518483479818e-06 minutes
2025-02-06 18:55:58,158:INFO:SubProcess create_model() called ==================================
2025-02-06 18:55:58,159:INFO:Initializing create_model()
2025-02-06 18:55:58,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CDE7B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:55:58,159:INFO:Checking exceptions
2025-02-06 18:55:58,159:INFO:Importing libraries
2025-02-06 18:55:58,159:INFO:Copying training dataset
2025-02-06 18:55:58,164:INFO:Defining folds
2025-02-06 18:55:58,164:INFO:Declaring metric variables
2025-02-06 18:55:58,165:INFO:Importing untrained model
2025-02-06 18:55:58,167:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:55:58,170:INFO:Starting cross validation
2025-02-06 18:55:58,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:55:58,836:INFO:Calculating mean and std
2025-02-06 18:55:58,836:INFO:Creating metrics dataframe
2025-02-06 18:55:58,838:INFO:Uploading results into container
2025-02-06 18:55:58,838:INFO:Uploading model into container now
2025-02-06 18:55:58,838:INFO:_master_model_container: 1
2025-02-06 18:55:58,838:INFO:_display_container: 2
2025-02-06 18:55:58,839:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:55:58,839:INFO:create_model() successfully completed......................................
2025-02-06 18:55:58,948:INFO:SubProcess create_model() end ==================================
2025-02-06 18:55:58,948:INFO:Creating metrics dataframe
2025-02-06 18:55:58,952:INFO:Initializing Logistic Regression
2025-02-06 18:55:58,952:INFO:Total runtime is 0.01324983835220337 minutes
2025-02-06 18:55:58,953:INFO:SubProcess create_model() called ==================================
2025-02-06 18:55:58,953:INFO:Initializing create_model()
2025-02-06 18:55:58,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CDE7B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:55:58,953:INFO:Checking exceptions
2025-02-06 18:55:58,953:INFO:Importing libraries
2025-02-06 18:55:58,953:INFO:Copying training dataset
2025-02-06 18:55:58,959:INFO:Defining folds
2025-02-06 18:55:58,959:INFO:Declaring metric variables
2025-02-06 18:55:58,961:INFO:Importing untrained model
2025-02-06 18:55:58,962:INFO:Logistic Regression Imported successfully
2025-02-06 18:55:58,964:INFO:Starting cross validation
2025-02-06 18:55:58,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:55:59,022:INFO:Calculating mean and std
2025-02-06 18:55:59,022:INFO:Creating metrics dataframe
2025-02-06 18:55:59,023:INFO:Uploading results into container
2025-02-06 18:55:59,023:INFO:Uploading model into container now
2025-02-06 18:55:59,023:INFO:_master_model_container: 2
2025-02-06 18:55:59,023:INFO:_display_container: 2
2025-02-06 18:55:59,024:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:55:59,024:INFO:create_model() successfully completed......................................
2025-02-06 18:55:59,091:INFO:SubProcess create_model() end ==================================
2025-02-06 18:55:59,091:INFO:Creating metrics dataframe
2025-02-06 18:55:59,094:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:55:59,098:INFO:Initializing create_model()
2025-02-06 18:55:59,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:55:59,098:INFO:Checking exceptions
2025-02-06 18:55:59,099:INFO:Importing libraries
2025-02-06 18:55:59,099:INFO:Copying training dataset
2025-02-06 18:55:59,105:INFO:Defining folds
2025-02-06 18:55:59,105:INFO:Declaring metric variables
2025-02-06 18:55:59,105:INFO:Importing untrained model
2025-02-06 18:55:59,105:INFO:Declaring custom model
2025-02-06 18:55:59,105:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:55:59,106:INFO:Cross validation set to False
2025-02-06 18:55:59,106:INFO:Fitting Model
2025-02-06 18:55:59,118:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:55:59,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
2025-02-06 18:55:59,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:55:59,119:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:55:59,120:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:55:59,120:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:55:59,120:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:55:59,176:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:55:59,176:INFO:create_model() successfully completed......................................
2025-02-06 18:55:59,267:INFO:_master_model_container: 2
2025-02-06 18:55:59,267:INFO:_display_container: 2
2025-02-06 18:55:59,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:55:59,268:INFO:compare_models() successfully completed......................................
2025-02-06 18:55:59,268:INFO:Initializing create_model()
2025-02-06 18:55:59,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:55:59,268:INFO:Checking exceptions
2025-02-06 18:55:59,276:INFO:Importing libraries
2025-02-06 18:55:59,276:INFO:Copying training dataset
2025-02-06 18:55:59,283:INFO:Defining folds
2025-02-06 18:55:59,283:INFO:Declaring metric variables
2025-02-06 18:55:59,284:INFO:Importing untrained model
2025-02-06 18:55:59,285:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:55:59,289:INFO:Starting cross validation
2025-02-06 18:55:59,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:00,138:INFO:Calculating mean and std
2025-02-06 18:56:00,138:INFO:Creating metrics dataframe
2025-02-06 18:56:00,141:INFO:Finalizing model
2025-02-06 18:56:00,159:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:56:00,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.
2025-02-06 18:56:00,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:56:00,160:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:56:00,160:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:56:00,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:56:00,160:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:56:00,255:INFO:Uploading results into container
2025-02-06 18:56:00,256:INFO:Uploading model into container now
2025-02-06 18:56:00,262:INFO:_master_model_container: 3
2025-02-06 18:56:00,262:INFO:_display_container: 3
2025-02-06 18:56:00,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:00,263:INFO:create_model() successfully completed......................................
2025-02-06 18:56:00,378:INFO:Initializing tune_model()
2025-02-06 18:56:00,378:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31, 50], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [5, 10], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:56:00,378:INFO:Checking exceptions
2025-02-06 18:56:00,388:INFO:Copying training dataset
2025-02-06 18:56:00,392:INFO:Checking base model
2025-02-06 18:56:00,392:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:56:00,393:INFO:Declaring metric variables
2025-02-06 18:56:00,395:INFO:Defining Hyperparameters
2025-02-06 18:56:00,495:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31, 50], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [5, 10], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 18:56:00,495:INFO:Tuning with n_jobs=-1
2025-02-06 18:56:00,495:INFO:Initializing RandomizedSearchCV
2025-02-06 18:56:12,508:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 18:56:12,510:INFO:Hyperparameter search completed
2025-02-06 18:56:12,510:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:12,510:INFO:Initializing create_model()
2025-02-06 18:56:12,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219379CE010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 50, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.6})
2025-02-06 18:56:12,510:INFO:Checking exceptions
2025-02-06 18:56:12,510:INFO:Importing libraries
2025-02-06 18:56:12,510:INFO:Copying training dataset
2025-02-06 18:56:12,519:INFO:Defining folds
2025-02-06 18:56:12,519:INFO:Declaring metric variables
2025-02-06 18:56:12,522:INFO:Importing untrained model
2025-02-06 18:56:12,522:INFO:Declaring custom model
2025-02-06 18:56:12,524:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:56:12,527:INFO:Starting cross validation
2025-02-06 18:56:12,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:13,554:INFO:Calculating mean and std
2025-02-06 18:56:13,555:INFO:Creating metrics dataframe
2025-02-06 18:56:13,558:INFO:Finalizing model
2025-02-06 18:56:13,578:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:56:13,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
2025-02-06 18:56:13,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:56:13,579:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:56:13,579:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:56:13,579:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:56:13,580:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:56:13,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:56:13,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:56:13,709:INFO:Uploading results into container
2025-02-06 18:56:13,710:INFO:Uploading model into container now
2025-02-06 18:56:13,710:INFO:_master_model_container: 4
2025-02-06 18:56:13,710:INFO:_display_container: 4
2025-02-06 18:56:13,710:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:13,711:INFO:create_model() successfully completed......................................
2025-02-06 18:56:13,806:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:13,806:INFO:choose_better activated
2025-02-06 18:56:13,808:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:13,808:INFO:Initializing create_model()
2025-02-06 18:56:13,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:13,808:INFO:Checking exceptions
2025-02-06 18:56:13,809:INFO:Importing libraries
2025-02-06 18:56:13,809:INFO:Copying training dataset
2025-02-06 18:56:13,815:INFO:Defining folds
2025-02-06 18:56:13,815:INFO:Declaring metric variables
2025-02-06 18:56:13,815:INFO:Importing untrained model
2025-02-06 18:56:13,815:INFO:Declaring custom model
2025-02-06 18:56:13,815:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:56:13,815:INFO:Starting cross validation
2025-02-06 18:56:13,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:14,460:INFO:Calculating mean and std
2025-02-06 18:56:14,461:INFO:Creating metrics dataframe
2025-02-06 18:56:14,462:INFO:Finalizing model
2025-02-06 18:56:14,480:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:56:14,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.
2025-02-06 18:56:14,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:56:14,480:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:56:14,480:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:56:14,481:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:56:14,481:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:56:14,585:INFO:Uploading results into container
2025-02-06 18:56:14,586:INFO:Uploading model into container now
2025-02-06 18:56:14,586:INFO:_master_model_container: 5
2025-02-06 18:56:14,586:INFO:_display_container: 5
2025-02-06 18:56:14,586:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:14,586:INFO:create_model() successfully completed......................................
2025-02-06 18:56:14,677:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:14,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 18:56:14,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7947
2025-02-06 18:56:14,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:56:14,678:INFO:choose_better completed
2025-02-06 18:56:14,683:INFO:_master_model_container: 5
2025-02-06 18:56:14,683:INFO:_display_container: 4
2025-02-06 18:56:14,684:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:14,684:INFO:tune_model() successfully completed......................................
2025-02-06 18:56:14,750:INFO:Initializing create_model()
2025-02-06 18:56:14,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:14,750:INFO:Checking exceptions
2025-02-06 18:56:14,757:INFO:Importing libraries
2025-02-06 18:56:14,757:INFO:Copying training dataset
2025-02-06 18:56:14,764:INFO:Defining folds
2025-02-06 18:56:14,764:INFO:Declaring metric variables
2025-02-06 18:56:14,765:INFO:Importing untrained model
2025-02-06 18:56:14,766:INFO:Logistic Regression Imported successfully
2025-02-06 18:56:14,769:INFO:Starting cross validation
2025-02-06 18:56:14,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:14,864:INFO:Calculating mean and std
2025-02-06 18:56:14,864:INFO:Creating metrics dataframe
2025-02-06 18:56:14,866:INFO:Finalizing model
2025-02-06 18:56:14,895:INFO:Uploading results into container
2025-02-06 18:56:14,896:INFO:Uploading model into container now
2025-02-06 18:56:14,900:INFO:_master_model_container: 6
2025-02-06 18:56:14,900:INFO:_display_container: 5
2025-02-06 18:56:14,900:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:56:14,900:INFO:create_model() successfully completed......................................
2025-02-06 18:56:14,980:INFO:Initializing tune_model()
2025-02-06 18:56:14,981:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:56:14,981:INFO:Checking exceptions
2025-02-06 18:56:14,990:INFO:Copying training dataset
2025-02-06 18:56:14,994:INFO:Checking base model
2025-02-06 18:56:14,994:INFO:Base model : Logistic Regression
2025-02-06 18:56:14,995:INFO:Declaring metric variables
2025-02-06 18:56:14,997:INFO:Defining Hyperparameters
2025-02-06 18:56:15,062:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:56:15,062:INFO:Tuning with n_jobs=-1
2025-02-06 18:56:15,062:INFO:Initializing RandomizedSearchCV
2025-02-06 18:56:15,440:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 18:56:15,440:INFO:Hyperparameter search completed
2025-02-06 18:56:15,440:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:15,441:INFO:Initializing create_model()
2025-02-06 18:56:15,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219403FFD50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 18:56:15,441:INFO:Checking exceptions
2025-02-06 18:56:15,441:INFO:Importing libraries
2025-02-06 18:56:15,441:INFO:Copying training dataset
2025-02-06 18:56:15,447:INFO:Defining folds
2025-02-06 18:56:15,447:INFO:Declaring metric variables
2025-02-06 18:56:15,449:INFO:Importing untrained model
2025-02-06 18:56:15,449:INFO:Declaring custom model
2025-02-06 18:56:15,451:INFO:Logistic Regression Imported successfully
2025-02-06 18:56:15,454:INFO:Starting cross validation
2025-02-06 18:56:15,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:15,512:INFO:Calculating mean and std
2025-02-06 18:56:15,512:INFO:Creating metrics dataframe
2025-02-06 18:56:15,515:INFO:Finalizing model
2025-02-06 18:56:15,538:INFO:Uploading results into container
2025-02-06 18:56:15,540:INFO:Uploading model into container now
2025-02-06 18:56:15,540:INFO:_master_model_container: 7
2025-02-06 18:56:15,540:INFO:_display_container: 6
2025-02-06 18:56:15,540:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:56:15,540:INFO:create_model() successfully completed......................................
2025-02-06 18:56:15,612:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:15,612:INFO:choose_better activated
2025-02-06 18:56:15,614:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:15,614:INFO:Initializing create_model()
2025-02-06 18:56:15,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:15,614:INFO:Checking exceptions
2025-02-06 18:56:15,615:INFO:Importing libraries
2025-02-06 18:56:15,615:INFO:Copying training dataset
2025-02-06 18:56:15,621:INFO:Defining folds
2025-02-06 18:56:15,621:INFO:Declaring metric variables
2025-02-06 18:56:15,621:INFO:Importing untrained model
2025-02-06 18:56:15,621:INFO:Declaring custom model
2025-02-06 18:56:15,621:INFO:Logistic Regression Imported successfully
2025-02-06 18:56:15,621:INFO:Starting cross validation
2025-02-06 18:56:15,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:15,679:INFO:Calculating mean and std
2025-02-06 18:56:15,679:INFO:Creating metrics dataframe
2025-02-06 18:56:15,680:INFO:Finalizing model
2025-02-06 18:56:15,707:INFO:Uploading results into container
2025-02-06 18:56:15,708:INFO:Uploading model into container now
2025-02-06 18:56:15,708:INFO:_master_model_container: 8
2025-02-06 18:56:15,708:INFO:_display_container: 7
2025-02-06 18:56:15,708:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:56:15,708:INFO:create_model() successfully completed......................................
2025-02-06 18:56:15,782:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:15,782:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 18:56:15,782:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 18:56:15,782:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:56:15,782:INFO:choose_better completed
2025-02-06 18:56:15,787:INFO:_master_model_container: 8
2025-02-06 18:56:15,787:INFO:_display_container: 6
2025-02-06 18:56:15,787:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:56:15,787:INFO:tune_model() successfully completed......................................
2025-02-06 18:56:15,848:INFO:Initializing compare_models()
2025-02-06 18:56:15,848:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:56:15,848:INFO:Checking exceptions
2025-02-06 18:56:15,851:INFO:Preparing display monitor
2025-02-06 18:56:15,860:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:56:15,860:INFO:Total runtime is 0.0 minutes
2025-02-06 18:56:15,861:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:15,863:INFO:Initializing create_model()
2025-02-06 18:56:15,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C56D390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:15,863:INFO:Checking exceptions
2025-02-06 18:56:15,863:INFO:Importing libraries
2025-02-06 18:56:15,863:INFO:Copying training dataset
2025-02-06 18:56:15,868:INFO:Defining folds
2025-02-06 18:56:15,868:INFO:Declaring metric variables
2025-02-06 18:56:15,869:INFO:Importing untrained model
2025-02-06 18:56:15,869:INFO:Declaring custom model
2025-02-06 18:56:15,871:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:56:15,874:INFO:Starting cross validation
2025-02-06 18:56:15,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:16,870:INFO:Calculating mean and std
2025-02-06 18:56:16,870:INFO:Creating metrics dataframe
2025-02-06 18:56:16,872:INFO:Uploading results into container
2025-02-06 18:56:16,872:INFO:Uploading model into container now
2025-02-06 18:56:16,872:INFO:_master_model_container: 9
2025-02-06 18:56:16,872:INFO:_display_container: 7
2025-02-06 18:56:16,873:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:16,873:INFO:create_model() successfully completed......................................
2025-02-06 18:56:16,980:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:16,980:INFO:Creating metrics dataframe
2025-02-06 18:56:16,983:INFO:Initializing custom model Logistic Regression
2025-02-06 18:56:16,983:INFO:Total runtime is 0.018710788091023764 minutes
2025-02-06 18:56:16,984:INFO:SubProcess create_model() called ==================================
2025-02-06 18:56:16,984:INFO:Initializing create_model()
2025-02-06 18:56:16,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C56D390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:16,984:INFO:Checking exceptions
2025-02-06 18:56:16,984:INFO:Importing libraries
2025-02-06 18:56:16,984:INFO:Copying training dataset
2025-02-06 18:56:16,991:INFO:Defining folds
2025-02-06 18:56:16,991:INFO:Declaring metric variables
2025-02-06 18:56:16,993:INFO:Importing untrained model
2025-02-06 18:56:16,993:INFO:Declaring custom model
2025-02-06 18:56:16,994:INFO:Logistic Regression Imported successfully
2025-02-06 18:56:16,999:INFO:Starting cross validation
2025-02-06 18:56:16,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:56:17,058:INFO:Calculating mean and std
2025-02-06 18:56:17,058:INFO:Creating metrics dataframe
2025-02-06 18:56:17,058:INFO:Uploading results into container
2025-02-06 18:56:17,059:INFO:Uploading model into container now
2025-02-06 18:56:17,059:INFO:_master_model_container: 10
2025-02-06 18:56:17,059:INFO:_display_container: 7
2025-02-06 18:56:17,059:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:56:17,059:INFO:create_model() successfully completed......................................
2025-02-06 18:56:17,135:INFO:SubProcess create_model() end ==================================
2025-02-06 18:56:17,136:INFO:Creating metrics dataframe
2025-02-06 18:56:17,139:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:56:17,143:INFO:Initializing create_model()
2025-02-06 18:56:17,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:56:17,143:INFO:Checking exceptions
2025-02-06 18:56:17,144:INFO:Importing libraries
2025-02-06 18:56:17,144:INFO:Copying training dataset
2025-02-06 18:56:17,149:INFO:Defining folds
2025-02-06 18:56:17,149:INFO:Declaring metric variables
2025-02-06 18:56:17,149:INFO:Importing untrained model
2025-02-06 18:56:17,149:INFO:Declaring custom model
2025-02-06 18:56:17,150:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:56:17,150:INFO:Cross validation set to False
2025-02-06 18:56:17,150:INFO:Fitting Model
2025-02-06 18:56:17,165:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:56:17,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-02-06 18:56:17,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:56:17,166:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:56:17,166:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:56:17,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:56:17,166:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:56:17,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:56:17,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:56:17,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:17,243:INFO:create_model() successfully completed......................................
2025-02-06 18:56:17,336:INFO:_master_model_container: 10
2025-02-06 18:56:17,336:INFO:_display_container: 7
2025-02-06 18:56:17,337:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:56:17,337:INFO:compare_models() successfully completed......................................
2025-02-06 18:56:17,338:INFO:Initializing predict_model()
2025-02-06 18:56:17,338:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CA8B9C0>)
2025-02-06 18:56:17,338:INFO:Checking exceptions
2025-02-06 18:56:17,338:INFO:Preloading libraries
2025-02-06 18:56:17,339:INFO:Set up data.
2025-02-06 18:56:17,345:INFO:Set up index.
2025-02-06 18:56:17,478:INFO:Initializing predict_model()
2025-02-06 18:56:17,478:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021940404720>)
2025-02-06 18:56:17,478:INFO:Checking exceptions
2025-02-06 18:56:17,478:INFO:Preloading libraries
2025-02-06 18:56:17,479:INFO:Set up data.
2025-02-06 18:56:17,483:INFO:Set up index.
2025-02-06 18:56:17,592:INFO:Initializing predict_model()
2025-02-06 18:56:17,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021940404720>)
2025-02-06 18:56:17,592:INFO:Checking exceptions
2025-02-06 18:56:17,592:INFO:Preloading libraries
2025-02-06 18:56:17,593:INFO:Set up data.
2025-02-06 18:56:17,601:INFO:Set up index.
2025-02-06 18:56:17,701:INFO:Initializing predict_model()
2025-02-06 18:56:17,701:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193DEACB90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021940404720>)
2025-02-06 18:56:17,701:INFO:Checking exceptions
2025-02-06 18:56:17,701:INFO:Preloading libraries
2025-02-06 18:56:17,702:INFO:Set up data.
2025-02-06 18:56:17,706:INFO:Set up index.
2025-02-06 18:57:04,359:INFO:PyCaret ClassificationExperiment
2025-02-06 18:57:04,359:INFO:Logging name: clf-default-name
2025-02-06 18:57:04,359:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 18:57:04,359:INFO:version 3.3.2
2025-02-06 18:57:04,359:INFO:Initializing setup()
2025-02-06 18:57:04,359:INFO:self.USI: 82ed
2025-02-06 18:57:04,359:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 18:57:04,359:INFO:Checking environment
2025-02-06 18:57:04,359:INFO:python_version: 3.11.9
2025-02-06 18:57:04,359:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 18:57:04,359:INFO:machine: AMD64
2025-02-06 18:57:04,359:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 18:57:04,363:INFO:Memory: svmem(total=67771465728, available=46021251072, percent=32.1, used=21750214656, free=46021251072)
2025-02-06 18:57:04,363:INFO:Physical Core: 8
2025-02-06 18:57:04,363:INFO:Logical Core: 16
2025-02-06 18:57:04,363:INFO:Checking libraries
2025-02-06 18:57:04,363:INFO:System:
2025-02-06 18:57:04,363:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 18:57:04,363:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 18:57:04,363:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 18:57:04,363:INFO:PyCaret required dependencies:
2025-02-06 18:57:04,363:INFO:                 pip: 25.0
2025-02-06 18:57:04,363:INFO:          setuptools: 65.5.0
2025-02-06 18:57:04,363:INFO:             pycaret: 3.3.2
2025-02-06 18:57:04,363:INFO:             IPython: 8.32.0
2025-02-06 18:57:04,363:INFO:          ipywidgets: 8.1.5
2025-02-06 18:57:04,363:INFO:                tqdm: 4.67.1
2025-02-06 18:57:04,363:INFO:               numpy: 1.26.4
2025-02-06 18:57:04,363:INFO:              pandas: 2.1.4
2025-02-06 18:57:04,363:INFO:              jinja2: 3.1.5
2025-02-06 18:57:04,363:INFO:               scipy: 1.11.4
2025-02-06 18:57:04,363:INFO:              joblib: 1.3.2
2025-02-06 18:57:04,363:INFO:             sklearn: 1.4.2
2025-02-06 18:57:04,363:INFO:                pyod: 2.0.3
2025-02-06 18:57:04,363:INFO:            imblearn: 0.13.0
2025-02-06 18:57:04,363:INFO:   category_encoders: 2.7.0
2025-02-06 18:57:04,363:INFO:            lightgbm: 4.5.0
2025-02-06 18:57:04,363:INFO:               numba: 0.61.0
2025-02-06 18:57:04,363:INFO:            requests: 2.32.3
2025-02-06 18:57:04,363:INFO:          matplotlib: 3.7.5
2025-02-06 18:57:04,363:INFO:          scikitplot: 0.3.7
2025-02-06 18:57:04,363:INFO:         yellowbrick: 1.5
2025-02-06 18:57:04,363:INFO:              plotly: 5.24.1
2025-02-06 18:57:04,363:INFO:    plotly-resampler: Not installed
2025-02-06 18:57:04,363:INFO:             kaleido: 0.2.1
2025-02-06 18:57:04,363:INFO:           schemdraw: 0.15
2025-02-06 18:57:04,363:INFO:         statsmodels: 0.14.4
2025-02-06 18:57:04,363:INFO:              sktime: 0.26.0
2025-02-06 18:57:04,364:INFO:               tbats: 1.1.3
2025-02-06 18:57:04,364:INFO:            pmdarima: 2.0.4
2025-02-06 18:57:04,364:INFO:              psutil: 6.1.1
2025-02-06 18:57:04,364:INFO:          markupsafe: 3.0.2
2025-02-06 18:57:04,364:INFO:             pickle5: Not installed
2025-02-06 18:57:04,364:INFO:         cloudpickle: 3.1.1
2025-02-06 18:57:04,364:INFO:         deprecation: 2.1.0
2025-02-06 18:57:04,364:INFO:              xxhash: 3.5.0
2025-02-06 18:57:04,364:INFO:           wurlitzer: Not installed
2025-02-06 18:57:04,364:INFO:PyCaret optional dependencies:
2025-02-06 18:57:04,364:INFO:                shap: Not installed
2025-02-06 18:57:04,364:INFO:           interpret: Not installed
2025-02-06 18:57:04,364:INFO:                umap: Not installed
2025-02-06 18:57:04,364:INFO:     ydata_profiling: Not installed
2025-02-06 18:57:04,364:INFO:  explainerdashboard: Not installed
2025-02-06 18:57:04,364:INFO:             autoviz: Not installed
2025-02-06 18:57:04,364:INFO:           fairlearn: Not installed
2025-02-06 18:57:04,364:INFO:          deepchecks: Not installed
2025-02-06 18:57:04,364:INFO:             xgboost: Not installed
2025-02-06 18:57:04,364:INFO:            catboost: Not installed
2025-02-06 18:57:04,364:INFO:              kmodes: Not installed
2025-02-06 18:57:04,364:INFO:             mlxtend: Not installed
2025-02-06 18:57:04,364:INFO:       statsforecast: Not installed
2025-02-06 18:57:04,364:INFO:        tune_sklearn: Not installed
2025-02-06 18:57:04,364:INFO:                 ray: Not installed
2025-02-06 18:57:04,364:INFO:            hyperopt: Not installed
2025-02-06 18:57:04,364:INFO:              optuna: Not installed
2025-02-06 18:57:04,364:INFO:               skopt: Not installed
2025-02-06 18:57:04,364:INFO:              mlflow: Not installed
2025-02-06 18:57:04,364:INFO:              gradio: Not installed
2025-02-06 18:57:04,364:INFO:             fastapi: Not installed
2025-02-06 18:57:04,364:INFO:             uvicorn: Not installed
2025-02-06 18:57:04,364:INFO:              m2cgen: Not installed
2025-02-06 18:57:04,364:INFO:           evidently: Not installed
2025-02-06 18:57:04,364:INFO:               fugue: Not installed
2025-02-06 18:57:04,364:INFO:           streamlit: Not installed
2025-02-06 18:57:04,364:INFO:             prophet: Not installed
2025-02-06 18:57:04,364:INFO:None
2025-02-06 18:57:04,364:INFO:Set up data.
2025-02-06 18:57:04,370:INFO:Set up folding strategy.
2025-02-06 18:57:04,370:INFO:Set up train/test split.
2025-02-06 18:57:04,375:INFO:Set up index.
2025-02-06 18:57:04,375:INFO:Assigning column types.
2025-02-06 18:57:04,380:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 18:57:04,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,458:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 18:57:04,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,523:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 18:57:04,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,539:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 18:57:04,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,617:INFO:Preparing preprocessing pipeline...
2025-02-06 18:57:04,618:INFO:Set up simple imputation.
2025-02-06 18:57:04,618:INFO:Set up feature normalization.
2025-02-06 18:57:04,641:INFO:Finished creating preprocessing pipeline.
2025-02-06 18:57:04,642:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 18:57:04,642:INFO:Creating final display dataframe.
2025-02-06 18:57:04,714:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              82ed
2025-02-06 18:57:04,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 18:57:04,791:INFO:setup() successfully completed in 0.43s...............
2025-02-06 18:57:04,791:INFO:Initializing compare_models()
2025-02-06 18:57:04,791:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:57:04,791:INFO:Checking exceptions
2025-02-06 18:57:04,795:INFO:Preparing display monitor
2025-02-06 18:57:04,805:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 18:57:04,805:INFO:Total runtime is 0.0 minutes
2025-02-06 18:57:04,807:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:04,807:INFO:Initializing create_model()
2025-02-06 18:57:04,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C553A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:04,807:INFO:Checking exceptions
2025-02-06 18:57:04,807:INFO:Importing libraries
2025-02-06 18:57:04,807:INFO:Copying training dataset
2025-02-06 18:57:04,813:INFO:Defining folds
2025-02-06 18:57:04,813:INFO:Declaring metric variables
2025-02-06 18:57:04,814:INFO:Importing untrained model
2025-02-06 18:57:04,816:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:04,819:INFO:Starting cross validation
2025-02-06 18:57:04,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:05,533:INFO:Calculating mean and std
2025-02-06 18:57:05,533:INFO:Creating metrics dataframe
2025-02-06 18:57:05,535:INFO:Uploading results into container
2025-02-06 18:57:05,535:INFO:Uploading model into container now
2025-02-06 18:57:05,536:INFO:_master_model_container: 1
2025-02-06 18:57:05,536:INFO:_display_container: 2
2025-02-06 18:57:05,536:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:05,536:INFO:create_model() successfully completed......................................
2025-02-06 18:57:05,639:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:05,639:INFO:Creating metrics dataframe
2025-02-06 18:57:05,642:INFO:Initializing Logistic Regression
2025-02-06 18:57:05,642:INFO:Total runtime is 0.013937183221181234 minutes
2025-02-06 18:57:05,643:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:05,643:INFO:Initializing create_model()
2025-02-06 18:57:05,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C553A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:05,643:INFO:Checking exceptions
2025-02-06 18:57:05,643:INFO:Importing libraries
2025-02-06 18:57:05,643:INFO:Copying training dataset
2025-02-06 18:57:05,649:INFO:Defining folds
2025-02-06 18:57:05,649:INFO:Declaring metric variables
2025-02-06 18:57:05,650:INFO:Importing untrained model
2025-02-06 18:57:05,652:INFO:Logistic Regression Imported successfully
2025-02-06 18:57:05,655:INFO:Starting cross validation
2025-02-06 18:57:05,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:05,722:INFO:Calculating mean and std
2025-02-06 18:57:05,722:INFO:Creating metrics dataframe
2025-02-06 18:57:05,722:INFO:Uploading results into container
2025-02-06 18:57:05,723:INFO:Uploading model into container now
2025-02-06 18:57:05,723:INFO:_master_model_container: 2
2025-02-06 18:57:05,723:INFO:_display_container: 2
2025-02-06 18:57:05,723:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:05,723:INFO:create_model() successfully completed......................................
2025-02-06 18:57:05,798:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:05,798:INFO:Creating metrics dataframe
2025-02-06 18:57:05,801:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:57:05,805:INFO:Initializing create_model()
2025-02-06 18:57:05,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:05,806:INFO:Checking exceptions
2025-02-06 18:57:05,806:INFO:Importing libraries
2025-02-06 18:57:05,806:INFO:Copying training dataset
2025-02-06 18:57:05,813:INFO:Defining folds
2025-02-06 18:57:05,813:INFO:Declaring metric variables
2025-02-06 18:57:05,813:INFO:Importing untrained model
2025-02-06 18:57:05,813:INFO:Declaring custom model
2025-02-06 18:57:05,813:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:05,814:INFO:Cross validation set to False
2025-02-06 18:57:05,814:INFO:Fitting Model
2025-02-06 18:57:05,827:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:57:05,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.
2025-02-06 18:57:05,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:57:05,828:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:57:05,828:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:57:05,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:57:05,829:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:57:05,886:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:05,886:INFO:create_model() successfully completed......................................
2025-02-06 18:57:05,981:INFO:_master_model_container: 2
2025-02-06 18:57:05,981:INFO:_display_container: 2
2025-02-06 18:57:05,981:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:05,981:INFO:compare_models() successfully completed......................................
2025-02-06 18:57:05,981:INFO:Initializing create_model()
2025-02-06 18:57:05,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:05,982:INFO:Checking exceptions
2025-02-06 18:57:05,991:INFO:Importing libraries
2025-02-06 18:57:05,991:INFO:Copying training dataset
2025-02-06 18:57:06,001:INFO:Defining folds
2025-02-06 18:57:06,001:INFO:Declaring metric variables
2025-02-06 18:57:06,003:INFO:Importing untrained model
2025-02-06 18:57:06,005:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:06,008:INFO:Starting cross validation
2025-02-06 18:57:06,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:06,749:INFO:Calculating mean and std
2025-02-06 18:57:06,749:INFO:Creating metrics dataframe
2025-02-06 18:57:06,753:INFO:Finalizing model
2025-02-06 18:57:06,771:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:57:06,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.
2025-02-06 18:57:06,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:57:06,771:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:57:06,771:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:57:06,772:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:57:06,772:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:57:06,862:INFO:Uploading results into container
2025-02-06 18:57:06,863:INFO:Uploading model into container now
2025-02-06 18:57:06,868:INFO:_master_model_container: 3
2025-02-06 18:57:06,869:INFO:_display_container: 3
2025-02-06 18:57:06,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:06,869:INFO:create_model() successfully completed......................................
2025-02-06 18:57:06,978:INFO:Initializing tune_model()
2025-02-06 18:57:06,978:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31, 50], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [5, 10], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:57:06,978:INFO:Checking exceptions
2025-02-06 18:57:06,988:INFO:Copying training dataset
2025-02-06 18:57:06,992:INFO:Checking base model
2025-02-06 18:57:06,992:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 18:57:06,993:INFO:Declaring metric variables
2025-02-06 18:57:06,995:INFO:Defining Hyperparameters
2025-02-06 18:57:07,064:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31, 50], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [5, 10], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 18:57:07,064:INFO:Tuning with n_jobs=-1
2025-02-06 18:57:07,064:INFO:Initializing RandomizedSearchCV
2025-02-06 18:57:20,125:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 18:57:20,126:INFO:Hyperparameter search completed
2025-02-06 18:57:20,126:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:20,127:INFO:Initializing create_model()
2025-02-06 18:57:20,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937F58090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 50, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.6})
2025-02-06 18:57:20,127:INFO:Checking exceptions
2025-02-06 18:57:20,127:INFO:Importing libraries
2025-02-06 18:57:20,127:INFO:Copying training dataset
2025-02-06 18:57:20,137:INFO:Defining folds
2025-02-06 18:57:20,137:INFO:Declaring metric variables
2025-02-06 18:57:20,139:INFO:Importing untrained model
2025-02-06 18:57:20,139:INFO:Declaring custom model
2025-02-06 18:57:20,142:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:20,145:INFO:Starting cross validation
2025-02-06 18:57:20,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:21,087:INFO:Calculating mean and std
2025-02-06 18:57:21,088:INFO:Creating metrics dataframe
2025-02-06 18:57:21,091:INFO:Finalizing model
2025-02-06 18:57:21,110:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:57:21,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.
2025-02-06 18:57:21,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:57:21,111:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:57:21,111:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:57:21,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:57:21,111:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:57:21,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:57:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:57:21,269:INFO:Uploading results into container
2025-02-06 18:57:21,270:INFO:Uploading model into container now
2025-02-06 18:57:21,271:INFO:_master_model_container: 4
2025-02-06 18:57:21,271:INFO:_display_container: 4
2025-02-06 18:57:21,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:21,271:INFO:create_model() successfully completed......................................
2025-02-06 18:57:21,386:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:21,386:INFO:choose_better activated
2025-02-06 18:57:21,388:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:21,388:INFO:Initializing create_model()
2025-02-06 18:57:21,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:21,388:INFO:Checking exceptions
2025-02-06 18:57:21,389:INFO:Importing libraries
2025-02-06 18:57:21,389:INFO:Copying training dataset
2025-02-06 18:57:21,395:INFO:Defining folds
2025-02-06 18:57:21,395:INFO:Declaring metric variables
2025-02-06 18:57:21,395:INFO:Importing untrained model
2025-02-06 18:57:21,395:INFO:Declaring custom model
2025-02-06 18:57:21,396:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:21,396:INFO:Starting cross validation
2025-02-06 18:57:21,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:22,089:INFO:Calculating mean and std
2025-02-06 18:57:22,089:INFO:Creating metrics dataframe
2025-02-06 18:57:22,091:INFO:Finalizing model
2025-02-06 18:57:22,109:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:57:22,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.
2025-02-06 18:57:22,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:57:22,110:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:57:22,110:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:57:22,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:57:22,110:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:57:22,223:INFO:Uploading results into container
2025-02-06 18:57:22,224:INFO:Uploading model into container now
2025-02-06 18:57:22,224:INFO:_master_model_container: 5
2025-02-06 18:57:22,224:INFO:_display_container: 5
2025-02-06 18:57:22,224:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:22,224:INFO:create_model() successfully completed......................................
2025-02-06 18:57:22,320:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:22,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 18:57:22,321:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7947
2025-02-06 18:57:22,321:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 18:57:22,321:INFO:choose_better completed
2025-02-06 18:57:22,326:INFO:_master_model_container: 5
2025-02-06 18:57:22,326:INFO:_display_container: 4
2025-02-06 18:57:22,326:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:22,326:INFO:tune_model() successfully completed......................................
2025-02-06 18:57:22,405:INFO:Initializing create_model()
2025-02-06 18:57:22,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:22,405:INFO:Checking exceptions
2025-02-06 18:57:22,413:INFO:Importing libraries
2025-02-06 18:57:22,413:INFO:Copying training dataset
2025-02-06 18:57:22,419:INFO:Defining folds
2025-02-06 18:57:22,419:INFO:Declaring metric variables
2025-02-06 18:57:22,420:INFO:Importing untrained model
2025-02-06 18:57:22,422:INFO:Logistic Regression Imported successfully
2025-02-06 18:57:22,425:INFO:Starting cross validation
2025-02-06 18:57:22,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:22,494:INFO:Calculating mean and std
2025-02-06 18:57:22,494:INFO:Creating metrics dataframe
2025-02-06 18:57:22,498:INFO:Finalizing model
2025-02-06 18:57:22,535:INFO:Uploading results into container
2025-02-06 18:57:22,535:INFO:Uploading model into container now
2025-02-06 18:57:22,541:INFO:_master_model_container: 6
2025-02-06 18:57:22,541:INFO:_display_container: 5
2025-02-06 18:57:22,541:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:22,541:INFO:create_model() successfully completed......................................
2025-02-06 18:57:22,632:INFO:Initializing tune_model()
2025-02-06 18:57:22,632:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 18:57:22,632:INFO:Checking exceptions
2025-02-06 18:57:22,640:INFO:Copying training dataset
2025-02-06 18:57:22,644:INFO:Checking base model
2025-02-06 18:57:22,644:INFO:Base model : Logistic Regression
2025-02-06 18:57:22,645:INFO:Declaring metric variables
2025-02-06 18:57:22,648:INFO:Defining Hyperparameters
2025-02-06 18:57:22,721:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 18:57:22,721:INFO:Tuning with n_jobs=-1
2025-02-06 18:57:22,721:INFO:Initializing RandomizedSearchCV
2025-02-06 18:57:23,089:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 18:57:23,089:INFO:Hyperparameter search completed
2025-02-06 18:57:23,089:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:23,089:INFO:Initializing create_model()
2025-02-06 18:57:23,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021934F31990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 18:57:23,089:INFO:Checking exceptions
2025-02-06 18:57:23,089:INFO:Importing libraries
2025-02-06 18:57:23,089:INFO:Copying training dataset
2025-02-06 18:57:23,094:INFO:Defining folds
2025-02-06 18:57:23,095:INFO:Declaring metric variables
2025-02-06 18:57:23,096:INFO:Importing untrained model
2025-02-06 18:57:23,096:INFO:Declaring custom model
2025-02-06 18:57:23,098:INFO:Logistic Regression Imported successfully
2025-02-06 18:57:23,100:INFO:Starting cross validation
2025-02-06 18:57:23,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:23,157:INFO:Calculating mean and std
2025-02-06 18:57:23,157:INFO:Creating metrics dataframe
2025-02-06 18:57:23,159:INFO:Finalizing model
2025-02-06 18:57:23,184:INFO:Uploading results into container
2025-02-06 18:57:23,185:INFO:Uploading model into container now
2025-02-06 18:57:23,185:INFO:_master_model_container: 7
2025-02-06 18:57:23,185:INFO:_display_container: 6
2025-02-06 18:57:23,185:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:23,185:INFO:create_model() successfully completed......................................
2025-02-06 18:57:23,260:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:23,260:INFO:choose_better activated
2025-02-06 18:57:23,263:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:23,263:INFO:Initializing create_model()
2025-02-06 18:57:23,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:23,263:INFO:Checking exceptions
2025-02-06 18:57:23,264:INFO:Importing libraries
2025-02-06 18:57:23,264:INFO:Copying training dataset
2025-02-06 18:57:23,269:INFO:Defining folds
2025-02-06 18:57:23,269:INFO:Declaring metric variables
2025-02-06 18:57:23,270:INFO:Importing untrained model
2025-02-06 18:57:23,270:INFO:Declaring custom model
2025-02-06 18:57:23,270:INFO:Logistic Regression Imported successfully
2025-02-06 18:57:23,270:INFO:Starting cross validation
2025-02-06 18:57:23,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:23,327:INFO:Calculating mean and std
2025-02-06 18:57:23,327:INFO:Creating metrics dataframe
2025-02-06 18:57:23,328:INFO:Finalizing model
2025-02-06 18:57:23,357:INFO:Uploading results into container
2025-02-06 18:57:23,357:INFO:Uploading model into container now
2025-02-06 18:57:23,357:INFO:_master_model_container: 8
2025-02-06 18:57:23,357:INFO:_display_container: 7
2025-02-06 18:57:23,357:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:23,357:INFO:create_model() successfully completed......................................
2025-02-06 18:57:23,428:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:23,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 18:57:23,429:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 18:57:23,429:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 18:57:23,429:INFO:choose_better completed
2025-02-06 18:57:23,434:INFO:_master_model_container: 8
2025-02-06 18:57:23,434:INFO:_display_container: 6
2025-02-06 18:57:23,434:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:23,434:INFO:tune_model() successfully completed......................................
2025-02-06 18:57:23,499:INFO:Initializing compare_models()
2025-02-06 18:57:23,499:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 18:57:23,499:INFO:Checking exceptions
2025-02-06 18:57:23,501:INFO:Preparing display monitor
2025-02-06 18:57:23,510:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 18:57:23,510:INFO:Total runtime is 0.0 minutes
2025-02-06 18:57:23,512:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:23,512:INFO:Initializing create_model()
2025-02-06 18:57:23,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002194045B4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:23,512:INFO:Checking exceptions
2025-02-06 18:57:23,512:INFO:Importing libraries
2025-02-06 18:57:23,512:INFO:Copying training dataset
2025-02-06 18:57:23,518:INFO:Defining folds
2025-02-06 18:57:23,518:INFO:Declaring metric variables
2025-02-06 18:57:23,520:INFO:Importing untrained model
2025-02-06 18:57:23,520:INFO:Declaring custom model
2025-02-06 18:57:23,521:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:23,524:INFO:Starting cross validation
2025-02-06 18:57:23,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:24,516:INFO:Calculating mean and std
2025-02-06 18:57:24,517:INFO:Creating metrics dataframe
2025-02-06 18:57:24,518:INFO:Uploading results into container
2025-02-06 18:57:24,519:INFO:Uploading model into container now
2025-02-06 18:57:24,519:INFO:_master_model_container: 9
2025-02-06 18:57:24,519:INFO:_display_container: 7
2025-02-06 18:57:24,520:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:24,520:INFO:create_model() successfully completed......................................
2025-02-06 18:57:24,643:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:24,643:INFO:Creating metrics dataframe
2025-02-06 18:57:24,646:INFO:Initializing custom model Logistic Regression
2025-02-06 18:57:24,646:INFO:Total runtime is 0.018929521242777508 minutes
2025-02-06 18:57:24,648:INFO:SubProcess create_model() called ==================================
2025-02-06 18:57:24,648:INFO:Initializing create_model()
2025-02-06 18:57:24,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002194045B4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:24,648:INFO:Checking exceptions
2025-02-06 18:57:24,648:INFO:Importing libraries
2025-02-06 18:57:24,648:INFO:Copying training dataset
2025-02-06 18:57:24,655:INFO:Defining folds
2025-02-06 18:57:24,655:INFO:Declaring metric variables
2025-02-06 18:57:24,656:INFO:Importing untrained model
2025-02-06 18:57:24,657:INFO:Declaring custom model
2025-02-06 18:57:24,658:INFO:Logistic Regression Imported successfully
2025-02-06 18:57:24,661:INFO:Starting cross validation
2025-02-06 18:57:24,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 18:57:24,720:INFO:Calculating mean and std
2025-02-06 18:57:24,721:INFO:Creating metrics dataframe
2025-02-06 18:57:24,721:INFO:Uploading results into container
2025-02-06 18:57:24,721:INFO:Uploading model into container now
2025-02-06 18:57:24,721:INFO:_master_model_container: 10
2025-02-06 18:57:24,721:INFO:_display_container: 7
2025-02-06 18:57:24,722:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 18:57:24,722:INFO:create_model() successfully completed......................................
2025-02-06 18:57:24,798:INFO:SubProcess create_model() end ==================================
2025-02-06 18:57:24,798:INFO:Creating metrics dataframe
2025-02-06 18:57:24,802:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 18:57:24,805:INFO:Initializing create_model()
2025-02-06 18:57:24,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 18:57:24,805:INFO:Checking exceptions
2025-02-06 18:57:24,806:INFO:Importing libraries
2025-02-06 18:57:24,806:INFO:Copying training dataset
2025-02-06 18:57:24,813:INFO:Defining folds
2025-02-06 18:57:24,813:INFO:Declaring metric variables
2025-02-06 18:57:24,813:INFO:Importing untrained model
2025-02-06 18:57:24,813:INFO:Declaring custom model
2025-02-06 18:57:24,813:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 18:57:24,813:INFO:Cross validation set to False
2025-02-06 18:57:24,814:INFO:Fitting Model
2025-02-06 18:57:24,828:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 18:57:24,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-02-06 18:57:24,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 18:57:24,828:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 18:57:24,828:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 18:57:24,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 18:57:24,829:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 18:57:24,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:57:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 18:57:24,929:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:24,929:INFO:create_model() successfully completed......................................
2025-02-06 18:57:25,027:INFO:_master_model_container: 10
2025-02-06 18:57:25,027:INFO:_display_container: 7
2025-02-06 18:57:25,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 18:57:25,028:INFO:compare_models() successfully completed......................................
2025-02-06 18:57:25,028:INFO:Initializing predict_model()
2025-02-06 18:57:25,028:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193E1CC2C0>)
2025-02-06 18:57:25,028:INFO:Checking exceptions
2025-02-06 18:57:25,028:INFO:Preloading libraries
2025-02-06 18:57:25,029:INFO:Set up data.
2025-02-06 18:57:25,036:INFO:Set up index.
2025-02-06 18:57:25,166:INFO:Initializing predict_model()
2025-02-06 18:57:25,166:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219380EAFC0>)
2025-02-06 18:57:25,166:INFO:Checking exceptions
2025-02-06 18:57:25,166:INFO:Preloading libraries
2025-02-06 18:57:25,167:INFO:Set up data.
2025-02-06 18:57:25,172:INFO:Set up index.
2025-02-06 18:57:25,280:INFO:Initializing predict_model()
2025-02-06 18:57:25,280:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219380EAFC0>)
2025-02-06 18:57:25,280:INFO:Checking exceptions
2025-02-06 18:57:25,280:INFO:Preloading libraries
2025-02-06 18:57:25,281:INFO:Set up data.
2025-02-06 18:57:25,290:INFO:Set up index.
2025-02-06 18:57:25,394:INFO:Initializing predict_model()
2025-02-06 18:57:25,394:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CDEBF10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219380EAFC0>)
2025-02-06 18:57:25,394:INFO:Checking exceptions
2025-02-06 18:57:25,395:INFO:Preloading libraries
2025-02-06 18:57:25,395:INFO:Set up data.
2025-02-06 18:57:25,399:INFO:Set up index.
2025-02-06 19:00:08,447:INFO:PyCaret ClassificationExperiment
2025-02-06 19:00:08,447:INFO:Logging name: clf-default-name
2025-02-06 19:00:08,447:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:00:08,447:INFO:version 3.3.2
2025-02-06 19:00:08,447:INFO:Initializing setup()
2025-02-06 19:00:08,447:INFO:self.USI: 63ef
2025-02-06 19:00:08,447:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:00:08,447:INFO:Checking environment
2025-02-06 19:00:08,447:INFO:python_version: 3.11.9
2025-02-06 19:00:08,447:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:00:08,447:INFO:machine: AMD64
2025-02-06 19:00:08,447:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:00:08,451:INFO:Memory: svmem(total=67771465728, available=45977702400, percent=32.2, used=21793763328, free=45977702400)
2025-02-06 19:00:08,451:INFO:Physical Core: 8
2025-02-06 19:00:08,451:INFO:Logical Core: 16
2025-02-06 19:00:08,451:INFO:Checking libraries
2025-02-06 19:00:08,451:INFO:System:
2025-02-06 19:00:08,451:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:00:08,451:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:00:08,451:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:00:08,451:INFO:PyCaret required dependencies:
2025-02-06 19:00:08,451:INFO:                 pip: 25.0
2025-02-06 19:00:08,451:INFO:          setuptools: 65.5.0
2025-02-06 19:00:08,451:INFO:             pycaret: 3.3.2
2025-02-06 19:00:08,451:INFO:             IPython: 8.32.0
2025-02-06 19:00:08,451:INFO:          ipywidgets: 8.1.5
2025-02-06 19:00:08,451:INFO:                tqdm: 4.67.1
2025-02-06 19:00:08,451:INFO:               numpy: 1.26.4
2025-02-06 19:00:08,451:INFO:              pandas: 2.1.4
2025-02-06 19:00:08,451:INFO:              jinja2: 3.1.5
2025-02-06 19:00:08,451:INFO:               scipy: 1.11.4
2025-02-06 19:00:08,451:INFO:              joblib: 1.3.2
2025-02-06 19:00:08,451:INFO:             sklearn: 1.4.2
2025-02-06 19:00:08,451:INFO:                pyod: 2.0.3
2025-02-06 19:00:08,451:INFO:            imblearn: 0.13.0
2025-02-06 19:00:08,451:INFO:   category_encoders: 2.7.0
2025-02-06 19:00:08,451:INFO:            lightgbm: 4.5.0
2025-02-06 19:00:08,451:INFO:               numba: 0.61.0
2025-02-06 19:00:08,451:INFO:            requests: 2.32.3
2025-02-06 19:00:08,451:INFO:          matplotlib: 3.7.5
2025-02-06 19:00:08,451:INFO:          scikitplot: 0.3.7
2025-02-06 19:00:08,451:INFO:         yellowbrick: 1.5
2025-02-06 19:00:08,451:INFO:              plotly: 5.24.1
2025-02-06 19:00:08,451:INFO:    plotly-resampler: Not installed
2025-02-06 19:00:08,451:INFO:             kaleido: 0.2.1
2025-02-06 19:00:08,451:INFO:           schemdraw: 0.15
2025-02-06 19:00:08,451:INFO:         statsmodels: 0.14.4
2025-02-06 19:00:08,451:INFO:              sktime: 0.26.0
2025-02-06 19:00:08,451:INFO:               tbats: 1.1.3
2025-02-06 19:00:08,451:INFO:            pmdarima: 2.0.4
2025-02-06 19:00:08,451:INFO:              psutil: 6.1.1
2025-02-06 19:00:08,451:INFO:          markupsafe: 3.0.2
2025-02-06 19:00:08,451:INFO:             pickle5: Not installed
2025-02-06 19:00:08,451:INFO:         cloudpickle: 3.1.1
2025-02-06 19:00:08,451:INFO:         deprecation: 2.1.0
2025-02-06 19:00:08,451:INFO:              xxhash: 3.5.0
2025-02-06 19:00:08,451:INFO:           wurlitzer: Not installed
2025-02-06 19:00:08,451:INFO:PyCaret optional dependencies:
2025-02-06 19:00:08,452:INFO:                shap: Not installed
2025-02-06 19:00:08,452:INFO:           interpret: Not installed
2025-02-06 19:00:08,452:INFO:                umap: Not installed
2025-02-06 19:00:08,452:INFO:     ydata_profiling: Not installed
2025-02-06 19:00:08,452:INFO:  explainerdashboard: Not installed
2025-02-06 19:00:08,452:INFO:             autoviz: Not installed
2025-02-06 19:00:08,452:INFO:           fairlearn: Not installed
2025-02-06 19:00:08,452:INFO:          deepchecks: Not installed
2025-02-06 19:00:08,452:INFO:             xgboost: Not installed
2025-02-06 19:00:08,452:INFO:            catboost: Not installed
2025-02-06 19:00:08,452:INFO:              kmodes: Not installed
2025-02-06 19:00:08,452:INFO:             mlxtend: Not installed
2025-02-06 19:00:08,452:INFO:       statsforecast: Not installed
2025-02-06 19:00:08,452:INFO:        tune_sklearn: Not installed
2025-02-06 19:00:08,452:INFO:                 ray: Not installed
2025-02-06 19:00:08,452:INFO:            hyperopt: Not installed
2025-02-06 19:00:08,452:INFO:              optuna: Not installed
2025-02-06 19:00:08,452:INFO:               skopt: Not installed
2025-02-06 19:00:08,452:INFO:              mlflow: Not installed
2025-02-06 19:00:08,452:INFO:              gradio: Not installed
2025-02-06 19:00:08,452:INFO:             fastapi: Not installed
2025-02-06 19:00:08,452:INFO:             uvicorn: Not installed
2025-02-06 19:00:08,452:INFO:              m2cgen: Not installed
2025-02-06 19:00:08,452:INFO:           evidently: Not installed
2025-02-06 19:00:08,452:INFO:               fugue: Not installed
2025-02-06 19:00:08,452:INFO:           streamlit: Not installed
2025-02-06 19:00:08,452:INFO:             prophet: Not installed
2025-02-06 19:00:08,452:INFO:None
2025-02-06 19:00:08,452:INFO:Set up data.
2025-02-06 19:00:08,459:INFO:Set up folding strategy.
2025-02-06 19:00:08,459:INFO:Set up train/test split.
2025-02-06 19:00:08,465:INFO:Set up index.
2025-02-06 19:00:08,465:INFO:Assigning column types.
2025-02-06 19:00:08,471:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:00:08,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,495:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,534:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,549:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:00:08,573:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:08,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,626:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:00:08,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,704:INFO:Preparing preprocessing pipeline...
2025-02-06 19:00:08,705:INFO:Set up simple imputation.
2025-02-06 19:00:08,705:INFO:Set up feature normalization.
2025-02-06 19:00:08,727:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:00:08,729:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:00:08,729:INFO:Creating final display dataframe.
2025-02-06 19:00:08,801:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              63ef
2025-02-06 19:00:08,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:08,879:INFO:setup() successfully completed in 0.43s...............
2025-02-06 19:00:08,879:INFO:Initializing compare_models()
2025-02-06 19:00:08,879:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:00:08,879:INFO:Checking exceptions
2025-02-06 19:00:08,883:INFO:Preparing display monitor
2025-02-06 19:00:08,893:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:00:08,893:INFO:Total runtime is 0.0 minutes
2025-02-06 19:00:08,895:INFO:SubProcess create_model() called ==================================
2025-02-06 19:00:08,895:INFO:Initializing create_model()
2025-02-06 19:00:08,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5CA9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:00:08,895:INFO:Checking exceptions
2025-02-06 19:00:08,895:INFO:Importing libraries
2025-02-06 19:00:08,895:INFO:Copying training dataset
2025-02-06 19:00:08,900:INFO:Defining folds
2025-02-06 19:00:08,900:INFO:Declaring metric variables
2025-02-06 19:00:08,902:INFO:Importing untrained model
2025-02-06 19:00:08,903:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:00:08,906:INFO:Starting cross validation
2025-02-06 19:00:08,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:00:09,640:INFO:Calculating mean and std
2025-02-06 19:00:09,641:INFO:Creating metrics dataframe
2025-02-06 19:00:09,643:INFO:Uploading results into container
2025-02-06 19:00:09,643:INFO:Uploading model into container now
2025-02-06 19:00:09,643:INFO:_master_model_container: 1
2025-02-06 19:00:09,643:INFO:_display_container: 2
2025-02-06 19:00:09,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:00:09,644:INFO:create_model() successfully completed......................................
2025-02-06 19:00:09,765:INFO:SubProcess create_model() end ==================================
2025-02-06 19:00:09,765:INFO:Creating metrics dataframe
2025-02-06 19:00:09,768:INFO:Initializing Logistic Regression
2025-02-06 19:00:09,768:INFO:Total runtime is 0.014585459232330322 minutes
2025-02-06 19:00:09,769:INFO:SubProcess create_model() called ==================================
2025-02-06 19:00:09,769:INFO:Initializing create_model()
2025-02-06 19:00:09,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5CA9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:00:09,769:INFO:Checking exceptions
2025-02-06 19:00:09,770:INFO:Importing libraries
2025-02-06 19:00:09,770:INFO:Copying training dataset
2025-02-06 19:00:09,775:INFO:Defining folds
2025-02-06 19:00:09,775:INFO:Declaring metric variables
2025-02-06 19:00:09,777:INFO:Importing untrained model
2025-02-06 19:00:09,778:INFO:Logistic Regression Imported successfully
2025-02-06 19:00:09,781:INFO:Starting cross validation
2025-02-06 19:00:09,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:00:09,853:INFO:Calculating mean and std
2025-02-06 19:00:09,853:INFO:Creating metrics dataframe
2025-02-06 19:00:09,854:INFO:Uploading results into container
2025-02-06 19:00:09,854:INFO:Uploading model into container now
2025-02-06 19:00:09,854:INFO:_master_model_container: 2
2025-02-06 19:00:09,854:INFO:_display_container: 2
2025-02-06 19:00:09,854:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:00:09,854:INFO:create_model() successfully completed......................................
2025-02-06 19:00:09,934:INFO:SubProcess create_model() end ==================================
2025-02-06 19:00:09,934:INFO:Creating metrics dataframe
2025-02-06 19:00:09,937:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:00:09,941:INFO:Initializing create_model()
2025-02-06 19:00:09,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:00:09,941:INFO:Checking exceptions
2025-02-06 19:00:09,942:INFO:Importing libraries
2025-02-06 19:00:09,942:INFO:Copying training dataset
2025-02-06 19:00:09,948:INFO:Defining folds
2025-02-06 19:00:09,948:INFO:Declaring metric variables
2025-02-06 19:00:09,948:INFO:Importing untrained model
2025-02-06 19:00:09,948:INFO:Declaring custom model
2025-02-06 19:00:09,948:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:00:09,949:INFO:Cross validation set to False
2025-02-06 19:00:09,949:INFO:Fitting Model
2025-02-06 19:00:09,964:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:00:09,965:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.
2025-02-06 19:00:09,965:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:00:09,965:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:00:09,965:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:00:09,965:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:00:09,965:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:00:10,041:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:00:10,041:INFO:create_model() successfully completed......................................
2025-02-06 19:00:10,135:INFO:_master_model_container: 2
2025-02-06 19:00:10,135:INFO:_display_container: 2
2025-02-06 19:00:10,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:00:10,136:INFO:compare_models() successfully completed......................................
2025-02-06 19:00:10,136:INFO:Initializing create_model()
2025-02-06 19:00:10,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193C5C5890>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:00:10,136:INFO:Checking exceptions
2025-02-06 19:00:50,807:INFO:PyCaret ClassificationExperiment
2025-02-06 19:00:50,807:INFO:Logging name: clf-default-name
2025-02-06 19:00:50,807:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:00:50,807:INFO:version 3.3.2
2025-02-06 19:00:50,807:INFO:Initializing setup()
2025-02-06 19:00:50,807:INFO:self.USI: 0ad2
2025-02-06 19:00:50,807:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:00:50,807:INFO:Checking environment
2025-02-06 19:00:50,807:INFO:python_version: 3.11.9
2025-02-06 19:00:50,807:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:00:50,807:INFO:machine: AMD64
2025-02-06 19:00:50,807:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:00:50,811:INFO:Memory: svmem(total=67771465728, available=45874376704, percent=32.3, used=21897089024, free=45874376704)
2025-02-06 19:00:50,811:INFO:Physical Core: 8
2025-02-06 19:00:50,811:INFO:Logical Core: 16
2025-02-06 19:00:50,811:INFO:Checking libraries
2025-02-06 19:00:50,811:INFO:System:
2025-02-06 19:00:50,811:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:00:50,811:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:00:50,811:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:00:50,811:INFO:PyCaret required dependencies:
2025-02-06 19:00:50,811:INFO:                 pip: 25.0
2025-02-06 19:00:50,811:INFO:          setuptools: 65.5.0
2025-02-06 19:00:50,811:INFO:             pycaret: 3.3.2
2025-02-06 19:00:50,811:INFO:             IPython: 8.32.0
2025-02-06 19:00:50,811:INFO:          ipywidgets: 8.1.5
2025-02-06 19:00:50,811:INFO:                tqdm: 4.67.1
2025-02-06 19:00:50,811:INFO:               numpy: 1.26.4
2025-02-06 19:00:50,812:INFO:              pandas: 2.1.4
2025-02-06 19:00:50,812:INFO:              jinja2: 3.1.5
2025-02-06 19:00:50,812:INFO:               scipy: 1.11.4
2025-02-06 19:00:50,812:INFO:              joblib: 1.3.2
2025-02-06 19:00:50,812:INFO:             sklearn: 1.4.2
2025-02-06 19:00:50,812:INFO:                pyod: 2.0.3
2025-02-06 19:00:50,812:INFO:            imblearn: 0.13.0
2025-02-06 19:00:50,812:INFO:   category_encoders: 2.7.0
2025-02-06 19:00:50,812:INFO:            lightgbm: 4.5.0
2025-02-06 19:00:50,812:INFO:               numba: 0.61.0
2025-02-06 19:00:50,812:INFO:            requests: 2.32.3
2025-02-06 19:00:50,812:INFO:          matplotlib: 3.7.5
2025-02-06 19:00:50,812:INFO:          scikitplot: 0.3.7
2025-02-06 19:00:50,812:INFO:         yellowbrick: 1.5
2025-02-06 19:00:50,812:INFO:              plotly: 5.24.1
2025-02-06 19:00:50,812:INFO:    plotly-resampler: Not installed
2025-02-06 19:00:50,812:INFO:             kaleido: 0.2.1
2025-02-06 19:00:50,812:INFO:           schemdraw: 0.15
2025-02-06 19:00:50,812:INFO:         statsmodels: 0.14.4
2025-02-06 19:00:50,812:INFO:              sktime: 0.26.0
2025-02-06 19:00:50,812:INFO:               tbats: 1.1.3
2025-02-06 19:00:50,812:INFO:            pmdarima: 2.0.4
2025-02-06 19:00:50,812:INFO:              psutil: 6.1.1
2025-02-06 19:00:50,812:INFO:          markupsafe: 3.0.2
2025-02-06 19:00:50,812:INFO:             pickle5: Not installed
2025-02-06 19:00:50,812:INFO:         cloudpickle: 3.1.1
2025-02-06 19:00:50,812:INFO:         deprecation: 2.1.0
2025-02-06 19:00:50,812:INFO:              xxhash: 3.5.0
2025-02-06 19:00:50,812:INFO:           wurlitzer: Not installed
2025-02-06 19:00:50,812:INFO:PyCaret optional dependencies:
2025-02-06 19:00:50,812:INFO:                shap: Not installed
2025-02-06 19:00:50,812:INFO:           interpret: Not installed
2025-02-06 19:00:50,812:INFO:                umap: Not installed
2025-02-06 19:00:50,812:INFO:     ydata_profiling: Not installed
2025-02-06 19:00:50,812:INFO:  explainerdashboard: Not installed
2025-02-06 19:00:50,812:INFO:             autoviz: Not installed
2025-02-06 19:00:50,812:INFO:           fairlearn: Not installed
2025-02-06 19:00:50,812:INFO:          deepchecks: Not installed
2025-02-06 19:00:50,812:INFO:             xgboost: Not installed
2025-02-06 19:00:50,812:INFO:            catboost: Not installed
2025-02-06 19:00:50,812:INFO:              kmodes: Not installed
2025-02-06 19:00:50,812:INFO:             mlxtend: Not installed
2025-02-06 19:00:50,812:INFO:       statsforecast: Not installed
2025-02-06 19:00:50,812:INFO:        tune_sklearn: Not installed
2025-02-06 19:00:50,812:INFO:                 ray: Not installed
2025-02-06 19:00:50,812:INFO:            hyperopt: Not installed
2025-02-06 19:00:50,812:INFO:              optuna: Not installed
2025-02-06 19:00:50,812:INFO:               skopt: Not installed
2025-02-06 19:00:50,812:INFO:              mlflow: Not installed
2025-02-06 19:00:50,812:INFO:              gradio: Not installed
2025-02-06 19:00:50,812:INFO:             fastapi: Not installed
2025-02-06 19:00:50,812:INFO:             uvicorn: Not installed
2025-02-06 19:00:50,812:INFO:              m2cgen: Not installed
2025-02-06 19:00:50,812:INFO:           evidently: Not installed
2025-02-06 19:00:50,812:INFO:               fugue: Not installed
2025-02-06 19:00:50,812:INFO:           streamlit: Not installed
2025-02-06 19:00:50,812:INFO:             prophet: Not installed
2025-02-06 19:00:50,812:INFO:None
2025-02-06 19:00:50,812:INFO:Set up data.
2025-02-06 19:00:50,819:INFO:Set up folding strategy.
2025-02-06 19:00:50,819:INFO:Set up train/test split.
2025-02-06 19:00:50,824:INFO:Set up index.
2025-02-06 19:00:50,824:INFO:Assigning column types.
2025-02-06 19:00:50,828:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:00:50,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,853:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,892:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:00:50,930:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,970:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:00:50,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:50,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:00:51,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,062:INFO:Preparing preprocessing pipeline...
2025-02-06 19:00:51,063:INFO:Set up simple imputation.
2025-02-06 19:00:51,064:INFO:Set up feature normalization.
2025-02-06 19:00:51,086:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:00:51,088:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:00:51,088:INFO:Creating final display dataframe.
2025-02-06 19:00:51,158:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              0ad2
2025-02-06 19:00:51,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:00:51,238:INFO:setup() successfully completed in 0.43s...............
2025-02-06 19:00:51,238:INFO:Initializing compare_models()
2025-02-06 19:00:51,238:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB8A6D0>, include=['xgboost', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB8A6D0>, 'include': ['xgboost', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:00:51,238:INFO:Checking exceptions
2025-02-06 19:02:25,426:INFO:gpu_param set to False
2025-02-06 19:02:25,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:02:25,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:02:25,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:02:25,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:15,143:INFO:gpu_param set to False
2025-02-06 19:03:15,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:15,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:15,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:15,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,332:INFO:PyCaret ClassificationExperiment
2025-02-06 19:03:16,332:INFO:Logging name: clf-default-name
2025-02-06 19:03:16,332:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:03:16,332:INFO:version 3.3.2
2025-02-06 19:03:16,332:INFO:Initializing setup()
2025-02-06 19:03:16,332:INFO:self.USI: 5880
2025-02-06 19:03:16,332:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:03:16,332:INFO:Checking environment
2025-02-06 19:03:16,332:INFO:python_version: 3.11.9
2025-02-06 19:03:16,332:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:03:16,332:INFO:machine: AMD64
2025-02-06 19:03:16,332:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:03:16,336:INFO:Memory: svmem(total=67771465728, available=45923356672, percent=32.2, used=21848109056, free=45923356672)
2025-02-06 19:03:16,336:INFO:Physical Core: 8
2025-02-06 19:03:16,336:INFO:Logical Core: 16
2025-02-06 19:03:16,336:INFO:Checking libraries
2025-02-06 19:03:16,336:INFO:System:
2025-02-06 19:03:16,336:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:03:16,336:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:03:16,336:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:03:16,336:INFO:PyCaret required dependencies:
2025-02-06 19:03:16,336:INFO:                 pip: 25.0
2025-02-06 19:03:16,336:INFO:          setuptools: 65.5.0
2025-02-06 19:03:16,336:INFO:             pycaret: 3.3.2
2025-02-06 19:03:16,336:INFO:             IPython: 8.32.0
2025-02-06 19:03:16,336:INFO:          ipywidgets: 8.1.5
2025-02-06 19:03:16,336:INFO:                tqdm: 4.67.1
2025-02-06 19:03:16,336:INFO:               numpy: 1.26.4
2025-02-06 19:03:16,336:INFO:              pandas: 2.1.4
2025-02-06 19:03:16,336:INFO:              jinja2: 3.1.5
2025-02-06 19:03:16,336:INFO:               scipy: 1.11.4
2025-02-06 19:03:16,336:INFO:              joblib: 1.3.2
2025-02-06 19:03:16,336:INFO:             sklearn: 1.4.2
2025-02-06 19:03:16,336:INFO:                pyod: 2.0.3
2025-02-06 19:03:16,336:INFO:            imblearn: 0.13.0
2025-02-06 19:03:16,336:INFO:   category_encoders: 2.7.0
2025-02-06 19:03:16,337:INFO:            lightgbm: 4.5.0
2025-02-06 19:03:16,337:INFO:               numba: 0.61.0
2025-02-06 19:03:16,337:INFO:            requests: 2.32.3
2025-02-06 19:03:16,337:INFO:          matplotlib: 3.7.5
2025-02-06 19:03:16,337:INFO:          scikitplot: 0.3.7
2025-02-06 19:03:16,337:INFO:         yellowbrick: 1.5
2025-02-06 19:03:16,337:INFO:              plotly: 5.24.1
2025-02-06 19:03:16,337:INFO:    plotly-resampler: Not installed
2025-02-06 19:03:16,337:INFO:             kaleido: 0.2.1
2025-02-06 19:03:16,337:INFO:           schemdraw: 0.15
2025-02-06 19:03:16,337:INFO:         statsmodels: 0.14.4
2025-02-06 19:03:16,337:INFO:              sktime: 0.26.0
2025-02-06 19:03:16,337:INFO:               tbats: 1.1.3
2025-02-06 19:03:16,337:INFO:            pmdarima: 2.0.4
2025-02-06 19:03:16,337:INFO:              psutil: 6.1.1
2025-02-06 19:03:16,337:INFO:          markupsafe: 3.0.2
2025-02-06 19:03:16,337:INFO:             pickle5: Not installed
2025-02-06 19:03:16,337:INFO:         cloudpickle: 3.1.1
2025-02-06 19:03:16,337:INFO:         deprecation: 2.1.0
2025-02-06 19:03:16,337:INFO:              xxhash: 3.5.0
2025-02-06 19:03:16,337:INFO:           wurlitzer: Not installed
2025-02-06 19:03:16,337:INFO:PyCaret optional dependencies:
2025-02-06 19:03:16,337:INFO:                shap: Not installed
2025-02-06 19:03:16,337:INFO:           interpret: Not installed
2025-02-06 19:03:16,337:INFO:                umap: Not installed
2025-02-06 19:03:16,337:INFO:     ydata_profiling: Not installed
2025-02-06 19:03:16,337:INFO:  explainerdashboard: Not installed
2025-02-06 19:03:16,337:INFO:             autoviz: Not installed
2025-02-06 19:03:16,337:INFO:           fairlearn: Not installed
2025-02-06 19:03:16,337:INFO:          deepchecks: Not installed
2025-02-06 19:03:16,337:INFO:             xgboost: Not installed
2025-02-06 19:03:16,337:INFO:            catboost: Not installed
2025-02-06 19:03:16,337:INFO:              kmodes: Not installed
2025-02-06 19:03:16,337:INFO:             mlxtend: Not installed
2025-02-06 19:03:16,337:INFO:       statsforecast: Not installed
2025-02-06 19:03:16,337:INFO:        tune_sklearn: Not installed
2025-02-06 19:03:16,337:INFO:                 ray: Not installed
2025-02-06 19:03:16,337:INFO:            hyperopt: Not installed
2025-02-06 19:03:16,337:INFO:              optuna: Not installed
2025-02-06 19:03:16,337:INFO:               skopt: Not installed
2025-02-06 19:03:16,337:INFO:              mlflow: Not installed
2025-02-06 19:03:16,337:INFO:              gradio: Not installed
2025-02-06 19:03:16,337:INFO:             fastapi: Not installed
2025-02-06 19:03:16,337:INFO:             uvicorn: Not installed
2025-02-06 19:03:16,337:INFO:              m2cgen: Not installed
2025-02-06 19:03:16,337:INFO:           evidently: Not installed
2025-02-06 19:03:16,337:INFO:               fugue: Not installed
2025-02-06 19:03:16,337:INFO:           streamlit: Not installed
2025-02-06 19:03:16,337:INFO:             prophet: Not installed
2025-02-06 19:03:16,337:INFO:None
2025-02-06 19:03:16,337:INFO:Set up data.
2025-02-06 19:03:16,343:INFO:Set up folding strategy.
2025-02-06 19:03:16,343:INFO:Set up train/test split.
2025-02-06 19:03:16,348:INFO:Set up index.
2025-02-06 19:03:16,348:INFO:Assigning column types.
2025-02-06 19:03:16,354:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:03:16,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,378:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,435:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:03:16,460:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,499:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:16,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,514:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:03:16,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,594:INFO:Preparing preprocessing pipeline...
2025-02-06 19:03:16,594:INFO:Set up simple imputation.
2025-02-06 19:03:16,594:INFO:Set up feature normalization.
2025-02-06 19:03:16,617:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:03:16,619:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:03:16,619:INFO:Creating final display dataframe.
2025-02-06 19:03:16,689:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5880
2025-02-06 19:03:16,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:16,767:INFO:setup() successfully completed in 0.44s...............
2025-02-06 19:03:16,767:INFO:Initializing compare_models()
2025-02-06 19:03:16,767:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, include=['gbc', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, 'include': ['gbc', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:03:16,767:INFO:Checking exceptions
2025-02-06 19:03:16,771:INFO:Preparing display monitor
2025-02-06 19:03:16,781:INFO:Initializing Gradient Boosting Classifier
2025-02-06 19:03:16,781:INFO:Total runtime is 0.0 minutes
2025-02-06 19:03:16,783:INFO:SubProcess create_model() called ==================================
2025-02-06 19:03:16,783:INFO:Initializing create_model()
2025-02-06 19:03:16,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219409A5010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:03:16,783:INFO:Checking exceptions
2025-02-06 19:03:16,783:INFO:Importing libraries
2025-02-06 19:03:16,783:INFO:Copying training dataset
2025-02-06 19:03:16,790:INFO:Defining folds
2025-02-06 19:03:16,790:INFO:Declaring metric variables
2025-02-06 19:03:16,791:INFO:Importing untrained model
2025-02-06 19:03:16,793:INFO:Gradient Boosting Classifier Imported successfully
2025-02-06 19:03:16,795:INFO:Starting cross validation
2025-02-06 19:03:16,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:03:18,908:INFO:Calculating mean and std
2025-02-06 19:03:18,908:INFO:Creating metrics dataframe
2025-02-06 19:03:18,909:INFO:Uploading results into container
2025-02-06 19:03:18,909:INFO:Uploading model into container now
2025-02-06 19:03:18,911:INFO:_master_model_container: 1
2025-02-06 19:03:18,911:INFO:_display_container: 2
2025-02-06 19:03:18,911:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-06 19:03:18,911:INFO:create_model() successfully completed......................................
2025-02-06 19:03:19,015:INFO:SubProcess create_model() end ==================================
2025-02-06 19:03:19,016:INFO:Creating metrics dataframe
2025-02-06 19:03:19,018:INFO:Initializing Logistic Regression
2025-02-06 19:03:19,019:INFO:Total runtime is 0.03729758262634277 minutes
2025-02-06 19:03:19,020:INFO:SubProcess create_model() called ==================================
2025-02-06 19:03:19,020:INFO:Initializing create_model()
2025-02-06 19:03:19,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219409A5010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:03:19,020:INFO:Checking exceptions
2025-02-06 19:03:19,020:INFO:Importing libraries
2025-02-06 19:03:19,021:INFO:Copying training dataset
2025-02-06 19:03:19,027:INFO:Defining folds
2025-02-06 19:03:19,027:INFO:Declaring metric variables
2025-02-06 19:03:19,029:INFO:Importing untrained model
2025-02-06 19:03:19,031:INFO:Logistic Regression Imported successfully
2025-02-06 19:03:19,034:INFO:Starting cross validation
2025-02-06 19:03:19,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:03:19,091:INFO:Calculating mean and std
2025-02-06 19:03:19,091:INFO:Creating metrics dataframe
2025-02-06 19:03:19,093:INFO:Uploading results into container
2025-02-06 19:03:19,093:INFO:Uploading model into container now
2025-02-06 19:03:19,093:INFO:_master_model_container: 2
2025-02-06 19:03:19,093:INFO:_display_container: 2
2025-02-06 19:03:19,093:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:03:19,093:INFO:create_model() successfully completed......................................
2025-02-06 19:03:19,183:INFO:SubProcess create_model() end ==================================
2025-02-06 19:03:19,183:INFO:Creating metrics dataframe
2025-02-06 19:03:19,188:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:03:19,192:INFO:Initializing create_model()
2025-02-06 19:03:19,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:03:19,192:INFO:Checking exceptions
2025-02-06 19:03:19,193:INFO:Importing libraries
2025-02-06 19:03:19,193:INFO:Copying training dataset
2025-02-06 19:03:19,198:INFO:Defining folds
2025-02-06 19:03:19,198:INFO:Declaring metric variables
2025-02-06 19:03:19,199:INFO:Importing untrained model
2025-02-06 19:03:19,199:INFO:Declaring custom model
2025-02-06 19:03:19,199:INFO:Gradient Boosting Classifier Imported successfully
2025-02-06 19:03:19,199:INFO:Cross validation set to False
2025-02-06 19:03:19,199:INFO:Fitting Model
2025-02-06 19:03:21,168:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-06 19:03:21,169:INFO:create_model() successfully completed......................................
2025-02-06 19:03:21,274:INFO:_master_model_container: 2
2025-02-06 19:03:21,274:INFO:_display_container: 2
2025-02-06 19:03:21,274:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-06 19:03:21,274:INFO:compare_models() successfully completed......................................
2025-02-06 19:03:21,274:INFO:Initializing create_model()
2025-02-06 19:03:21,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:03:21,274:INFO:Checking exceptions
2025-02-06 19:03:21,281:INFO:Importing libraries
2025-02-06 19:03:21,281:INFO:Copying training dataset
2025-02-06 19:03:21,287:INFO:Defining folds
2025-02-06 19:03:21,287:INFO:Declaring metric variables
2025-02-06 19:03:21,289:INFO:Importing untrained model
2025-02-06 19:03:21,291:INFO:Gradient Boosting Classifier Imported successfully
2025-02-06 19:03:21,294:INFO:Starting cross validation
2025-02-06 19:03:21,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:03:23,385:INFO:Calculating mean and std
2025-02-06 19:03:23,385:INFO:Creating metrics dataframe
2025-02-06 19:03:23,388:INFO:Finalizing model
2025-02-06 19:03:25,332:INFO:Uploading results into container
2025-02-06 19:03:25,333:INFO:Uploading model into container now
2025-02-06 19:03:25,337:INFO:_master_model_container: 3
2025-02-06 19:03:25,338:INFO:_display_container: 3
2025-02-06 19:03:25,338:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-06 19:03:25,338:INFO:create_model() successfully completed......................................
2025-02-06 19:03:25,424:INFO:Initializing tune_model()
2025-02-06 19:03:25,424:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940206910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31, 50], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [5, 10], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:03:25,424:INFO:Checking exceptions
2025-02-06 19:03:25,434:INFO:Copying training dataset
2025-02-06 19:03:25,437:INFO:Checking base model
2025-02-06 19:03:25,437:INFO:Base model : Gradient Boosting Classifier
2025-02-06 19:03:25,439:INFO:Declaring metric variables
2025-02-06 19:03:25,440:INFO:Defining Hyperparameters
2025-02-06 19:03:25,527:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31, 50], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [5, 10], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:03:25,527:INFO:Tuning with n_jobs=-1
2025-02-06 19:03:25,528:INFO:Initializing RandomizedSearchCV
2025-02-06 19:03:55,898:INFO:gpu_param set to False
2025-02-06 19:03:55,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:55,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:55,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:55,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,572:INFO:PyCaret ClassificationExperiment
2025-02-06 19:03:56,572:INFO:Logging name: clf-default-name
2025-02-06 19:03:56,572:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:03:56,572:INFO:version 3.3.2
2025-02-06 19:03:56,572:INFO:Initializing setup()
2025-02-06 19:03:56,572:INFO:self.USI: 8a01
2025-02-06 19:03:56,572:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:03:56,572:INFO:Checking environment
2025-02-06 19:03:56,572:INFO:python_version: 3.11.9
2025-02-06 19:03:56,572:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:03:56,572:INFO:machine: AMD64
2025-02-06 19:03:56,572:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:03:56,576:INFO:Memory: svmem(total=67771465728, available=48529674240, percent=28.4, used=19241791488, free=48529674240)
2025-02-06 19:03:56,576:INFO:Physical Core: 8
2025-02-06 19:03:56,576:INFO:Logical Core: 16
2025-02-06 19:03:56,576:INFO:Checking libraries
2025-02-06 19:03:56,576:INFO:System:
2025-02-06 19:03:56,576:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:03:56,576:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:03:56,576:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:03:56,576:INFO:PyCaret required dependencies:
2025-02-06 19:03:56,576:INFO:                 pip: 25.0
2025-02-06 19:03:56,576:INFO:          setuptools: 65.5.0
2025-02-06 19:03:56,576:INFO:             pycaret: 3.3.2
2025-02-06 19:03:56,576:INFO:             IPython: 8.32.0
2025-02-06 19:03:56,576:INFO:          ipywidgets: 8.1.5
2025-02-06 19:03:56,576:INFO:                tqdm: 4.67.1
2025-02-06 19:03:56,576:INFO:               numpy: 1.26.4
2025-02-06 19:03:56,576:INFO:              pandas: 2.1.4
2025-02-06 19:03:56,576:INFO:              jinja2: 3.1.5
2025-02-06 19:03:56,576:INFO:               scipy: 1.11.4
2025-02-06 19:03:56,576:INFO:              joblib: 1.3.2
2025-02-06 19:03:56,576:INFO:             sklearn: 1.4.2
2025-02-06 19:03:56,576:INFO:                pyod: 2.0.3
2025-02-06 19:03:56,576:INFO:            imblearn: 0.13.0
2025-02-06 19:03:56,576:INFO:   category_encoders: 2.7.0
2025-02-06 19:03:56,576:INFO:            lightgbm: 4.5.0
2025-02-06 19:03:56,576:INFO:               numba: 0.61.0
2025-02-06 19:03:56,576:INFO:            requests: 2.32.3
2025-02-06 19:03:56,576:INFO:          matplotlib: 3.7.5
2025-02-06 19:03:56,576:INFO:          scikitplot: 0.3.7
2025-02-06 19:03:56,576:INFO:         yellowbrick: 1.5
2025-02-06 19:03:56,576:INFO:              plotly: 5.24.1
2025-02-06 19:03:56,577:INFO:    plotly-resampler: Not installed
2025-02-06 19:03:56,577:INFO:             kaleido: 0.2.1
2025-02-06 19:03:56,577:INFO:           schemdraw: 0.15
2025-02-06 19:03:56,577:INFO:         statsmodels: 0.14.4
2025-02-06 19:03:56,577:INFO:              sktime: 0.26.0
2025-02-06 19:03:56,577:INFO:               tbats: 1.1.3
2025-02-06 19:03:56,577:INFO:            pmdarima: 2.0.4
2025-02-06 19:03:56,577:INFO:              psutil: 6.1.1
2025-02-06 19:03:56,577:INFO:          markupsafe: 3.0.2
2025-02-06 19:03:56,577:INFO:             pickle5: Not installed
2025-02-06 19:03:56,577:INFO:         cloudpickle: 3.1.1
2025-02-06 19:03:56,577:INFO:         deprecation: 2.1.0
2025-02-06 19:03:56,577:INFO:              xxhash: 3.5.0
2025-02-06 19:03:56,577:INFO:           wurlitzer: Not installed
2025-02-06 19:03:56,577:INFO:PyCaret optional dependencies:
2025-02-06 19:03:56,577:INFO:                shap: Not installed
2025-02-06 19:03:56,577:INFO:           interpret: Not installed
2025-02-06 19:03:56,577:INFO:                umap: Not installed
2025-02-06 19:03:56,577:INFO:     ydata_profiling: Not installed
2025-02-06 19:03:56,577:INFO:  explainerdashboard: Not installed
2025-02-06 19:03:56,577:INFO:             autoviz: Not installed
2025-02-06 19:03:56,577:INFO:           fairlearn: Not installed
2025-02-06 19:03:56,577:INFO:          deepchecks: Not installed
2025-02-06 19:03:56,577:INFO:             xgboost: Not installed
2025-02-06 19:03:56,577:INFO:            catboost: Not installed
2025-02-06 19:03:56,577:INFO:              kmodes: Not installed
2025-02-06 19:03:56,577:INFO:             mlxtend: Not installed
2025-02-06 19:03:56,577:INFO:       statsforecast: Not installed
2025-02-06 19:03:56,577:INFO:        tune_sklearn: Not installed
2025-02-06 19:03:56,577:INFO:                 ray: Not installed
2025-02-06 19:03:56,577:INFO:            hyperopt: Not installed
2025-02-06 19:03:56,577:INFO:              optuna: Not installed
2025-02-06 19:03:56,577:INFO:               skopt: Not installed
2025-02-06 19:03:56,577:INFO:              mlflow: Not installed
2025-02-06 19:03:56,577:INFO:              gradio: Not installed
2025-02-06 19:03:56,577:INFO:             fastapi: Not installed
2025-02-06 19:03:56,577:INFO:             uvicorn: Not installed
2025-02-06 19:03:56,577:INFO:              m2cgen: Not installed
2025-02-06 19:03:56,577:INFO:           evidently: Not installed
2025-02-06 19:03:56,577:INFO:               fugue: Not installed
2025-02-06 19:03:56,577:INFO:           streamlit: Not installed
2025-02-06 19:03:56,577:INFO:             prophet: Not installed
2025-02-06 19:03:56,577:INFO:None
2025-02-06 19:03:56,577:INFO:Set up data.
2025-02-06 19:03:56,583:INFO:Set up folding strategy.
2025-02-06 19:03:56,583:INFO:Set up train/test split.
2025-02-06 19:03:56,588:INFO:Set up index.
2025-02-06 19:03:56,588:INFO:Assigning column types.
2025-02-06 19:03:56,593:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:03:56,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,657:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,672:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:03:56,695:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,734:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:03:56,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,750:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:03:56,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,831:INFO:Preparing preprocessing pipeline...
2025-02-06 19:03:56,833:INFO:Set up simple imputation.
2025-02-06 19:03:56,833:INFO:Set up feature normalization.
2025-02-06 19:03:56,855:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:03:56,857:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:03:56,857:INFO:Creating final display dataframe.
2025-02-06 19:03:56,930:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8a01
2025-02-06 19:03:56,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:56,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:57,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:57,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:03:57,008:INFO:setup() successfully completed in 0.44s...............
2025-02-06 19:03:57,008:INFO:Initializing compare_models()
2025-02-06 19:03:57,008:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:03:57,008:INFO:Checking exceptions
2025-02-06 19:03:57,013:INFO:Preparing display monitor
2025-02-06 19:03:57,022:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:03:57,022:INFO:Total runtime is 0.0 minutes
2025-02-06 19:03:57,024:INFO:SubProcess create_model() called ==================================
2025-02-06 19:03:57,024:INFO:Initializing create_model()
2025-02-06 19:03:57,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940ADC410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:03:57,024:INFO:Checking exceptions
2025-02-06 19:03:57,024:INFO:Importing libraries
2025-02-06 19:03:57,024:INFO:Copying training dataset
2025-02-06 19:03:57,030:INFO:Defining folds
2025-02-06 19:03:57,030:INFO:Declaring metric variables
2025-02-06 19:03:57,031:INFO:Importing untrained model
2025-02-06 19:03:57,033:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:03:57,036:INFO:Starting cross validation
2025-02-06 19:03:57,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:03:59,948:INFO:Calculating mean and std
2025-02-06 19:03:59,948:INFO:Creating metrics dataframe
2025-02-06 19:03:59,950:INFO:Uploading results into container
2025-02-06 19:03:59,950:INFO:Uploading model into container now
2025-02-06 19:03:59,950:INFO:_master_model_container: 1
2025-02-06 19:03:59,950:INFO:_display_container: 2
2025-02-06 19:03:59,952:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:03:59,952:INFO:create_model() successfully completed......................................
2025-02-06 19:04:00,091:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:00,091:INFO:Creating metrics dataframe
2025-02-06 19:04:00,094:INFO:Initializing Logistic Regression
2025-02-06 19:04:00,094:INFO:Total runtime is 0.0512008269627889 minutes
2025-02-06 19:04:00,096:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:00,096:INFO:Initializing create_model()
2025-02-06 19:04:00,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940ADC410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:00,096:INFO:Checking exceptions
2025-02-06 19:04:00,096:INFO:Importing libraries
2025-02-06 19:04:00,096:INFO:Copying training dataset
2025-02-06 19:04:00,102:INFO:Defining folds
2025-02-06 19:04:00,102:INFO:Declaring metric variables
2025-02-06 19:04:00,104:INFO:Importing untrained model
2025-02-06 19:04:00,106:INFO:Logistic Regression Imported successfully
2025-02-06 19:04:00,109:INFO:Starting cross validation
2025-02-06 19:04:00,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:01,519:INFO:Calculating mean and std
2025-02-06 19:04:01,520:INFO:Creating metrics dataframe
2025-02-06 19:04:01,521:INFO:Uploading results into container
2025-02-06 19:04:01,521:INFO:Uploading model into container now
2025-02-06 19:04:01,521:INFO:_master_model_container: 2
2025-02-06 19:04:01,521:INFO:_display_container: 2
2025-02-06 19:04:01,522:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:01,522:INFO:create_model() successfully completed......................................
2025-02-06 19:04:01,628:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:01,628:INFO:Creating metrics dataframe
2025-02-06 19:04:01,632:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:04:01,637:INFO:Initializing create_model()
2025-02-06 19:04:01,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:01,637:INFO:Checking exceptions
2025-02-06 19:04:01,638:INFO:Importing libraries
2025-02-06 19:04:01,638:INFO:Copying training dataset
2025-02-06 19:04:01,645:INFO:Defining folds
2025-02-06 19:04:01,645:INFO:Declaring metric variables
2025-02-06 19:04:01,646:INFO:Importing untrained model
2025-02-06 19:04:01,646:INFO:Declaring custom model
2025-02-06 19:04:01,646:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:01,646:INFO:Cross validation set to False
2025-02-06 19:04:01,646:INFO:Fitting Model
2025-02-06 19:04:01,662:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:04:01,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000680 seconds.
2025-02-06 19:04:01,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:04:01,663:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:04:01,663:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:04:01,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:04:01,664:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:04:01,743:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:01,743:INFO:create_model() successfully completed......................................
2025-02-06 19:04:01,866:INFO:_master_model_container: 2
2025-02-06 19:04:01,866:INFO:_display_container: 2
2025-02-06 19:04:01,866:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:01,866:INFO:compare_models() successfully completed......................................
2025-02-06 19:04:01,866:INFO:Initializing create_model()
2025-02-06 19:04:01,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:01,866:INFO:Checking exceptions
2025-02-06 19:04:01,872:INFO:Importing libraries
2025-02-06 19:04:01,873:INFO:Copying training dataset
2025-02-06 19:04:01,879:INFO:Defining folds
2025-02-06 19:04:01,879:INFO:Declaring metric variables
2025-02-06 19:04:01,881:INFO:Importing untrained model
2025-02-06 19:04:01,882:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:01,885:INFO:Starting cross validation
2025-02-06 19:04:01,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:02,602:INFO:Calculating mean and std
2025-02-06 19:04:02,602:INFO:Creating metrics dataframe
2025-02-06 19:04:02,607:INFO:Finalizing model
2025-02-06 19:04:02,625:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:04:02,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.
2025-02-06 19:04:02,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:04:02,626:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:04:02,627:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:04:02,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:04:02,627:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:04:02,740:INFO:Uploading results into container
2025-02-06 19:04:02,740:INFO:Uploading model into container now
2025-02-06 19:04:02,747:INFO:_master_model_container: 3
2025-02-06 19:04:02,747:INFO:_display_container: 3
2025-02-06 19:04:02,747:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:02,748:INFO:create_model() successfully completed......................................
2025-02-06 19:04:02,867:INFO:Initializing tune_model()
2025-02-06 19:04:02,867:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31, 50], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [5, 10], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:04:02,867:INFO:Checking exceptions
2025-02-06 19:04:02,877:INFO:Copying training dataset
2025-02-06 19:04:02,881:INFO:Checking base model
2025-02-06 19:04:02,881:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:04:02,882:INFO:Declaring metric variables
2025-02-06 19:04:02,884:INFO:Defining Hyperparameters
2025-02-06 19:04:02,974:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31, 50], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [5, 10], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:04:02,974:INFO:Tuning with n_jobs=-1
2025-02-06 19:04:02,974:INFO:Initializing RandomizedSearchCV
2025-02-06 19:04:16,253:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 19:04:16,254:INFO:Hyperparameter search completed
2025-02-06 19:04:16,254:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:16,254:INFO:Initializing create_model()
2025-02-06 19:04:16,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219404AD710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 50, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.6})
2025-02-06 19:04:16,254:INFO:Checking exceptions
2025-02-06 19:04:16,255:INFO:Importing libraries
2025-02-06 19:04:16,255:INFO:Copying training dataset
2025-02-06 19:04:16,267:INFO:Defining folds
2025-02-06 19:04:16,267:INFO:Declaring metric variables
2025-02-06 19:04:16,270:INFO:Importing untrained model
2025-02-06 19:04:16,270:INFO:Declaring custom model
2025-02-06 19:04:16,273:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:16,277:INFO:Starting cross validation
2025-02-06 19:04:16,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:17,299:INFO:Calculating mean and std
2025-02-06 19:04:17,300:INFO:Creating metrics dataframe
2025-02-06 19:04:17,304:INFO:Finalizing model
2025-02-06 19:04:17,320:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:04:17,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-02-06 19:04:17,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:04:17,321:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:04:17,321:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:04:17,321:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:04:17,321:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:04:17,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:04:17,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:04:17,454:INFO:Uploading results into container
2025-02-06 19:04:17,456:INFO:Uploading model into container now
2025-02-06 19:04:17,456:INFO:_master_model_container: 4
2025-02-06 19:04:17,456:INFO:_display_container: 4
2025-02-06 19:04:17,457:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:17,457:INFO:create_model() successfully completed......................................
2025-02-06 19:04:17,576:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:17,576:INFO:choose_better activated
2025-02-06 19:04:17,578:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:17,578:INFO:Initializing create_model()
2025-02-06 19:04:17,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:17,578:INFO:Checking exceptions
2025-02-06 19:04:17,579:INFO:Importing libraries
2025-02-06 19:04:17,579:INFO:Copying training dataset
2025-02-06 19:04:17,585:INFO:Defining folds
2025-02-06 19:04:17,585:INFO:Declaring metric variables
2025-02-06 19:04:17,585:INFO:Importing untrained model
2025-02-06 19:04:17,585:INFO:Declaring custom model
2025-02-06 19:04:17,585:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:17,585:INFO:Starting cross validation
2025-02-06 19:04:17,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:18,197:INFO:Calculating mean and std
2025-02-06 19:04:18,197:INFO:Creating metrics dataframe
2025-02-06 19:04:18,198:INFO:Finalizing model
2025-02-06 19:04:18,216:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:04:18,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.
2025-02-06 19:04:18,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:04:18,217:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:04:18,217:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:04:18,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:04:18,217:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:04:18,320:INFO:Uploading results into container
2025-02-06 19:04:18,320:INFO:Uploading model into container now
2025-02-06 19:04:18,320:INFO:_master_model_container: 5
2025-02-06 19:04:18,320:INFO:_display_container: 5
2025-02-06 19:04:18,321:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:18,321:INFO:create_model() successfully completed......................................
2025-02-06 19:04:18,436:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:18,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:04:18,437:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7947
2025-02-06 19:04:18,437:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:04:18,437:INFO:choose_better completed
2025-02-06 19:04:18,442:INFO:_master_model_container: 5
2025-02-06 19:04:18,442:INFO:_display_container: 4
2025-02-06 19:04:18,442:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:18,442:INFO:tune_model() successfully completed......................................
2025-02-06 19:04:18,521:INFO:Initializing create_model()
2025-02-06 19:04:18,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:18,521:INFO:Checking exceptions
2025-02-06 19:04:18,528:INFO:Importing libraries
2025-02-06 19:04:18,529:INFO:Copying training dataset
2025-02-06 19:04:18,535:INFO:Defining folds
2025-02-06 19:04:18,535:INFO:Declaring metric variables
2025-02-06 19:04:18,536:INFO:Importing untrained model
2025-02-06 19:04:18,537:INFO:Logistic Regression Imported successfully
2025-02-06 19:04:18,540:INFO:Starting cross validation
2025-02-06 19:04:18,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:18,606:INFO:Calculating mean and std
2025-02-06 19:04:18,606:INFO:Creating metrics dataframe
2025-02-06 19:04:18,609:INFO:Finalizing model
2025-02-06 19:04:18,639:INFO:Uploading results into container
2025-02-06 19:04:18,639:INFO:Uploading model into container now
2025-02-06 19:04:18,644:INFO:_master_model_container: 6
2025-02-06 19:04:18,644:INFO:_display_container: 5
2025-02-06 19:04:18,645:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:18,645:INFO:create_model() successfully completed......................................
2025-02-06 19:04:18,740:INFO:Initializing tune_model()
2025-02-06 19:04:18,740:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:04:18,740:INFO:Checking exceptions
2025-02-06 19:04:18,748:INFO:Copying training dataset
2025-02-06 19:04:18,753:INFO:Checking base model
2025-02-06 19:04:18,753:INFO:Base model : Logistic Regression
2025-02-06 19:04:18,754:INFO:Declaring metric variables
2025-02-06 19:04:18,755:INFO:Defining Hyperparameters
2025-02-06 19:04:18,840:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:04:18,841:INFO:Tuning with n_jobs=-1
2025-02-06 19:04:18,841:INFO:Initializing RandomizedSearchCV
2025-02-06 19:04:19,263:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:04:19,263:INFO:Hyperparameter search completed
2025-02-06 19:04:19,263:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:19,263:INFO:Initializing create_model()
2025-02-06 19:04:19,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193793C090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:04:19,263:INFO:Checking exceptions
2025-02-06 19:04:19,263:INFO:Importing libraries
2025-02-06 19:04:19,263:INFO:Copying training dataset
2025-02-06 19:04:19,269:INFO:Defining folds
2025-02-06 19:04:19,269:INFO:Declaring metric variables
2025-02-06 19:04:19,271:INFO:Importing untrained model
2025-02-06 19:04:19,271:INFO:Declaring custom model
2025-02-06 19:04:19,272:INFO:Logistic Regression Imported successfully
2025-02-06 19:04:19,275:INFO:Starting cross validation
2025-02-06 19:04:19,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:19,334:INFO:Calculating mean and std
2025-02-06 19:04:19,334:INFO:Creating metrics dataframe
2025-02-06 19:04:19,336:INFO:Finalizing model
2025-02-06 19:04:19,359:INFO:Uploading results into container
2025-02-06 19:04:19,360:INFO:Uploading model into container now
2025-02-06 19:04:19,360:INFO:_master_model_container: 7
2025-02-06 19:04:19,360:INFO:_display_container: 6
2025-02-06 19:04:19,360:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:19,360:INFO:create_model() successfully completed......................................
2025-02-06 19:04:19,455:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:19,455:INFO:choose_better activated
2025-02-06 19:04:19,457:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:19,458:INFO:Initializing create_model()
2025-02-06 19:04:19,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:19,458:INFO:Checking exceptions
2025-02-06 19:04:19,458:INFO:Importing libraries
2025-02-06 19:04:19,458:INFO:Copying training dataset
2025-02-06 19:04:19,465:INFO:Defining folds
2025-02-06 19:04:19,465:INFO:Declaring metric variables
2025-02-06 19:04:19,465:INFO:Importing untrained model
2025-02-06 19:04:19,465:INFO:Declaring custom model
2025-02-06 19:04:19,465:INFO:Logistic Regression Imported successfully
2025-02-06 19:04:19,465:INFO:Starting cross validation
2025-02-06 19:04:19,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:19,521:INFO:Calculating mean and std
2025-02-06 19:04:19,522:INFO:Creating metrics dataframe
2025-02-06 19:04:19,523:INFO:Finalizing model
2025-02-06 19:04:19,549:INFO:Uploading results into container
2025-02-06 19:04:19,549:INFO:Uploading model into container now
2025-02-06 19:04:19,549:INFO:_master_model_container: 8
2025-02-06 19:04:19,549:INFO:_display_container: 7
2025-02-06 19:04:19,550:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:19,550:INFO:create_model() successfully completed......................................
2025-02-06 19:04:19,648:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:19,648:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:04:19,649:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:04:19,649:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:04:19,649:INFO:choose_better completed
2025-02-06 19:04:19,654:INFO:_master_model_container: 8
2025-02-06 19:04:19,654:INFO:_display_container: 6
2025-02-06 19:04:19,654:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:19,654:INFO:tune_model() successfully completed......................................
2025-02-06 19:04:19,731:INFO:Initializing compare_models()
2025-02-06 19:04:19,732:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:04:19,732:INFO:Checking exceptions
2025-02-06 19:04:19,734:INFO:Preparing display monitor
2025-02-06 19:04:19,744:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:04:19,744:INFO:Total runtime is 0.0 minutes
2025-02-06 19:04:19,745:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:19,746:INFO:Initializing create_model()
2025-02-06 19:04:19,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F8E7CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:19,746:INFO:Checking exceptions
2025-02-06 19:04:19,746:INFO:Importing libraries
2025-02-06 19:04:19,746:INFO:Copying training dataset
2025-02-06 19:04:19,752:INFO:Defining folds
2025-02-06 19:04:19,752:INFO:Declaring metric variables
2025-02-06 19:04:19,753:INFO:Importing untrained model
2025-02-06 19:04:19,753:INFO:Declaring custom model
2025-02-06 19:04:19,755:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:19,758:INFO:Starting cross validation
2025-02-06 19:04:19,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:20,952:INFO:Calculating mean and std
2025-02-06 19:04:20,953:INFO:Creating metrics dataframe
2025-02-06 19:04:20,954:INFO:Uploading results into container
2025-02-06 19:04:20,955:INFO:Uploading model into container now
2025-02-06 19:04:20,955:INFO:_master_model_container: 9
2025-02-06 19:04:20,955:INFO:_display_container: 7
2025-02-06 19:04:20,955:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:20,955:INFO:create_model() successfully completed......................................
2025-02-06 19:04:21,095:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:21,095:INFO:Creating metrics dataframe
2025-02-06 19:04:21,098:INFO:Initializing custom model Logistic Regression
2025-02-06 19:04:21,098:INFO:Total runtime is 0.02256808280944824 minutes
2025-02-06 19:04:21,100:INFO:SubProcess create_model() called ==================================
2025-02-06 19:04:21,100:INFO:Initializing create_model()
2025-02-06 19:04:21,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F8E7CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:21,100:INFO:Checking exceptions
2025-02-06 19:04:21,100:INFO:Importing libraries
2025-02-06 19:04:21,100:INFO:Copying training dataset
2025-02-06 19:04:21,109:INFO:Defining folds
2025-02-06 19:04:21,109:INFO:Declaring metric variables
2025-02-06 19:04:21,111:INFO:Importing untrained model
2025-02-06 19:04:21,111:INFO:Declaring custom model
2025-02-06 19:04:21,112:INFO:Logistic Regression Imported successfully
2025-02-06 19:04:21,116:INFO:Starting cross validation
2025-02-06 19:04:21,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:04:21,197:INFO:Calculating mean and std
2025-02-06 19:04:21,197:INFO:Creating metrics dataframe
2025-02-06 19:04:21,198:INFO:Uploading results into container
2025-02-06 19:04:21,198:INFO:Uploading model into container now
2025-02-06 19:04:21,198:INFO:_master_model_container: 10
2025-02-06 19:04:21,198:INFO:_display_container: 7
2025-02-06 19:04:21,198:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:04:21,198:INFO:create_model() successfully completed......................................
2025-02-06 19:04:21,298:INFO:SubProcess create_model() end ==================================
2025-02-06 19:04:21,298:INFO:Creating metrics dataframe
2025-02-06 19:04:21,301:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:04:21,305:INFO:Initializing create_model()
2025-02-06 19:04:21,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:04:21,305:INFO:Checking exceptions
2025-02-06 19:04:21,306:INFO:Importing libraries
2025-02-06 19:04:21,306:INFO:Copying training dataset
2025-02-06 19:04:21,312:INFO:Defining folds
2025-02-06 19:04:21,312:INFO:Declaring metric variables
2025-02-06 19:04:21,312:INFO:Importing untrained model
2025-02-06 19:04:21,312:INFO:Declaring custom model
2025-02-06 19:04:21,312:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:04:21,312:INFO:Cross validation set to False
2025-02-06 19:04:21,313:INFO:Fitting Model
2025-02-06 19:04:21,327:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:04:21,328:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-02-06 19:04:21,328:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:04:21,328:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:04:21,328:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:04:21,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:04:21,328:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:04:21,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:04:21,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:04:21,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:21,434:INFO:create_model() successfully completed......................................
2025-02-06 19:04:21,559:INFO:_master_model_container: 10
2025-02-06 19:04:21,559:INFO:_display_container: 7
2025-02-06 19:04:21,559:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:04:21,559:INFO:compare_models() successfully completed......................................
2025-02-06 19:04:21,560:INFO:Initializing predict_model()
2025-02-06 19:04:21,560:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219704F7C40>)
2025-02-06 19:04:21,560:INFO:Checking exceptions
2025-02-06 19:04:21,560:INFO:Preloading libraries
2025-02-06 19:04:21,562:INFO:Set up data.
2025-02-06 19:04:21,567:INFO:Set up index.
2025-02-06 19:04:21,727:INFO:Initializing predict_model()
2025-02-06 19:04:21,727:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=10,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219704F7C40>)
2025-02-06 19:04:21,728:INFO:Checking exceptions
2025-02-06 19:04:21,728:INFO:Preloading libraries
2025-02-06 19:04:21,729:INFO:Set up data.
2025-02-06 19:04:21,733:INFO:Set up index.
2025-02-06 19:04:21,867:INFO:Initializing predict_model()
2025-02-06 19:04:21,867:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219704F7C40>)
2025-02-06 19:04:21,867:INFO:Checking exceptions
2025-02-06 19:04:21,867:INFO:Preloading libraries
2025-02-06 19:04:21,868:INFO:Set up data.
2025-02-06 19:04:21,874:INFO:Set up index.
2025-02-06 19:04:22,008:INFO:Initializing predict_model()
2025-02-06 19:04:22,009:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940223650>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219704F7C40>)
2025-02-06 19:04:22,009:INFO:Checking exceptions
2025-02-06 19:04:22,009:INFO:Preloading libraries
2025-02-06 19:04:22,010:INFO:Set up data.
2025-02-06 19:04:22,014:INFO:Set up index.
2025-02-06 19:07:10,043:INFO:PyCaret ClassificationExperiment
2025-02-06 19:07:10,043:INFO:Logging name: clf-default-name
2025-02-06 19:07:10,043:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:07:10,043:INFO:version 3.3.2
2025-02-06 19:07:10,043:INFO:Initializing setup()
2025-02-06 19:07:10,043:INFO:self.USI: f22d
2025-02-06 19:07:10,043:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:07:10,043:INFO:Checking environment
2025-02-06 19:07:10,043:INFO:python_version: 3.11.9
2025-02-06 19:07:10,043:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:07:10,043:INFO:machine: AMD64
2025-02-06 19:07:10,043:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:07:10,048:INFO:Memory: svmem(total=67771465728, available=45988085760, percent=32.1, used=21783379968, free=45988085760)
2025-02-06 19:07:10,048:INFO:Physical Core: 8
2025-02-06 19:07:10,048:INFO:Logical Core: 16
2025-02-06 19:07:10,048:INFO:Checking libraries
2025-02-06 19:07:10,048:INFO:System:
2025-02-06 19:07:10,048:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:07:10,048:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:07:10,048:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:07:10,048:INFO:PyCaret required dependencies:
2025-02-06 19:07:10,048:INFO:                 pip: 25.0
2025-02-06 19:07:10,048:INFO:          setuptools: 65.5.0
2025-02-06 19:07:10,048:INFO:             pycaret: 3.3.2
2025-02-06 19:07:10,048:INFO:             IPython: 8.32.0
2025-02-06 19:07:10,048:INFO:          ipywidgets: 8.1.5
2025-02-06 19:07:10,048:INFO:                tqdm: 4.67.1
2025-02-06 19:07:10,048:INFO:               numpy: 1.26.4
2025-02-06 19:07:10,048:INFO:              pandas: 2.1.4
2025-02-06 19:07:10,048:INFO:              jinja2: 3.1.5
2025-02-06 19:07:10,048:INFO:               scipy: 1.11.4
2025-02-06 19:07:10,048:INFO:              joblib: 1.3.2
2025-02-06 19:07:10,048:INFO:             sklearn: 1.4.2
2025-02-06 19:07:10,048:INFO:                pyod: 2.0.3
2025-02-06 19:07:10,048:INFO:            imblearn: 0.13.0
2025-02-06 19:07:10,048:INFO:   category_encoders: 2.7.0
2025-02-06 19:07:10,048:INFO:            lightgbm: 4.5.0
2025-02-06 19:07:10,048:INFO:               numba: 0.61.0
2025-02-06 19:07:10,048:INFO:            requests: 2.32.3
2025-02-06 19:07:10,048:INFO:          matplotlib: 3.7.5
2025-02-06 19:07:10,048:INFO:          scikitplot: 0.3.7
2025-02-06 19:07:10,048:INFO:         yellowbrick: 1.5
2025-02-06 19:07:10,048:INFO:              plotly: 5.24.1
2025-02-06 19:07:10,048:INFO:    plotly-resampler: Not installed
2025-02-06 19:07:10,048:INFO:             kaleido: 0.2.1
2025-02-06 19:07:10,048:INFO:           schemdraw: 0.15
2025-02-06 19:07:10,048:INFO:         statsmodels: 0.14.4
2025-02-06 19:07:10,048:INFO:              sktime: 0.26.0
2025-02-06 19:07:10,048:INFO:               tbats: 1.1.3
2025-02-06 19:07:10,048:INFO:            pmdarima: 2.0.4
2025-02-06 19:07:10,048:INFO:              psutil: 6.1.1
2025-02-06 19:07:10,048:INFO:          markupsafe: 3.0.2
2025-02-06 19:07:10,048:INFO:             pickle5: Not installed
2025-02-06 19:07:10,048:INFO:         cloudpickle: 3.1.1
2025-02-06 19:07:10,048:INFO:         deprecation: 2.1.0
2025-02-06 19:07:10,048:INFO:              xxhash: 3.5.0
2025-02-06 19:07:10,048:INFO:           wurlitzer: Not installed
2025-02-06 19:07:10,048:INFO:PyCaret optional dependencies:
2025-02-06 19:07:10,048:INFO:                shap: Not installed
2025-02-06 19:07:10,048:INFO:           interpret: Not installed
2025-02-06 19:07:10,048:INFO:                umap: Not installed
2025-02-06 19:07:10,048:INFO:     ydata_profiling: Not installed
2025-02-06 19:07:10,048:INFO:  explainerdashboard: Not installed
2025-02-06 19:07:10,048:INFO:             autoviz: Not installed
2025-02-06 19:07:10,048:INFO:           fairlearn: Not installed
2025-02-06 19:07:10,048:INFO:          deepchecks: Not installed
2025-02-06 19:07:10,048:INFO:             xgboost: Not installed
2025-02-06 19:07:10,048:INFO:            catboost: Not installed
2025-02-06 19:07:10,048:INFO:              kmodes: Not installed
2025-02-06 19:07:10,048:INFO:             mlxtend: Not installed
2025-02-06 19:07:10,048:INFO:       statsforecast: Not installed
2025-02-06 19:07:10,048:INFO:        tune_sklearn: Not installed
2025-02-06 19:07:10,048:INFO:                 ray: Not installed
2025-02-06 19:07:10,049:INFO:            hyperopt: Not installed
2025-02-06 19:07:10,049:INFO:              optuna: Not installed
2025-02-06 19:07:10,049:INFO:               skopt: Not installed
2025-02-06 19:07:10,049:INFO:              mlflow: Not installed
2025-02-06 19:07:10,049:INFO:              gradio: Not installed
2025-02-06 19:07:10,049:INFO:             fastapi: Not installed
2025-02-06 19:07:10,049:INFO:             uvicorn: Not installed
2025-02-06 19:07:10,049:INFO:              m2cgen: Not installed
2025-02-06 19:07:10,049:INFO:           evidently: Not installed
2025-02-06 19:07:10,049:INFO:               fugue: Not installed
2025-02-06 19:07:10,049:INFO:           streamlit: Not installed
2025-02-06 19:07:10,049:INFO:             prophet: Not installed
2025-02-06 19:07:10,049:INFO:None
2025-02-06 19:07:10,049:INFO:Set up data.
2025-02-06 19:07:10,054:INFO:Set up folding strategy.
2025-02-06 19:07:10,054:INFO:Set up train/test split.
2025-02-06 19:07:10,059:INFO:Set up index.
2025-02-06 19:07:10,059:INFO:Assigning column types.
2025-02-06 19:07:10,064:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:07:10,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,132:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:07:10,171:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:07:10,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,224:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:07:10,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,302:INFO:Preparing preprocessing pipeline...
2025-02-06 19:07:10,303:INFO:Set up simple imputation.
2025-02-06 19:07:10,303:INFO:Set up feature normalization.
2025-02-06 19:07:10,326:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:07:10,328:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:07:10,328:INFO:Creating final display dataframe.
2025-02-06 19:07:10,402:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              f22d
2025-02-06 19:07:10,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:07:10,481:INFO:setup() successfully completed in 0.44s...............
2025-02-06 19:07:10,481:INFO:Initializing compare_models()
2025-02-06 19:07:10,481:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:07:10,481:INFO:Checking exceptions
2025-02-06 19:07:10,485:INFO:Preparing display monitor
2025-02-06 19:07:10,494:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:07:10,494:INFO:Total runtime is 0.0 minutes
2025-02-06 19:07:10,496:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:10,496:INFO:Initializing create_model()
2025-02-06 19:07:10,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F8AA3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:10,496:INFO:Checking exceptions
2025-02-06 19:07:10,496:INFO:Importing libraries
2025-02-06 19:07:10,496:INFO:Copying training dataset
2025-02-06 19:07:10,502:INFO:Defining folds
2025-02-06 19:07:10,502:INFO:Declaring metric variables
2025-02-06 19:07:10,504:INFO:Importing untrained model
2025-02-06 19:07:10,505:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:10,508:INFO:Starting cross validation
2025-02-06 19:07:10,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:11,310:INFO:Calculating mean and std
2025-02-06 19:07:11,310:INFO:Creating metrics dataframe
2025-02-06 19:07:11,311:INFO:Uploading results into container
2025-02-06 19:07:11,312:INFO:Uploading model into container now
2025-02-06 19:07:11,312:INFO:_master_model_container: 1
2025-02-06 19:07:11,312:INFO:_display_container: 2
2025-02-06 19:07:11,312:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:11,312:INFO:create_model() successfully completed......................................
2025-02-06 19:07:11,438:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:11,438:INFO:Creating metrics dataframe
2025-02-06 19:07:11,441:INFO:Initializing Logistic Regression
2025-02-06 19:07:11,441:INFO:Total runtime is 0.01578293244043986 minutes
2025-02-06 19:07:11,442:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:11,443:INFO:Initializing create_model()
2025-02-06 19:07:11,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F8AA3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:11,443:INFO:Checking exceptions
2025-02-06 19:07:11,443:INFO:Importing libraries
2025-02-06 19:07:11,443:INFO:Copying training dataset
2025-02-06 19:07:11,449:INFO:Defining folds
2025-02-06 19:07:11,449:INFO:Declaring metric variables
2025-02-06 19:07:11,450:INFO:Importing untrained model
2025-02-06 19:07:11,451:INFO:Logistic Regression Imported successfully
2025-02-06 19:07:11,454:INFO:Starting cross validation
2025-02-06 19:07:11,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:11,521:INFO:Calculating mean and std
2025-02-06 19:07:11,522:INFO:Creating metrics dataframe
2025-02-06 19:07:11,523:INFO:Uploading results into container
2025-02-06 19:07:11,523:INFO:Uploading model into container now
2025-02-06 19:07:11,523:INFO:_master_model_container: 2
2025-02-06 19:07:11,523:INFO:_display_container: 2
2025-02-06 19:07:11,523:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:11,523:INFO:create_model() successfully completed......................................
2025-02-06 19:07:11,626:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:11,626:INFO:Creating metrics dataframe
2025-02-06 19:07:11,630:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:07:11,634:INFO:Initializing create_model()
2025-02-06 19:07:11,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:11,634:INFO:Checking exceptions
2025-02-06 19:07:11,635:INFO:Importing libraries
2025-02-06 19:07:11,635:INFO:Copying training dataset
2025-02-06 19:07:11,640:INFO:Defining folds
2025-02-06 19:07:11,640:INFO:Declaring metric variables
2025-02-06 19:07:11,640:INFO:Importing untrained model
2025-02-06 19:07:11,640:INFO:Declaring custom model
2025-02-06 19:07:11,641:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:11,641:INFO:Cross validation set to False
2025-02-06 19:07:11,641:INFO:Fitting Model
2025-02-06 19:07:11,654:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:07:11,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-02-06 19:07:11,654:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:07:11,655:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:07:11,655:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:07:11,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:07:11,655:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:07:11,710:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:11,710:INFO:create_model() successfully completed......................................
2025-02-06 19:07:11,826:INFO:_master_model_container: 2
2025-02-06 19:07:11,826:INFO:_display_container: 2
2025-02-06 19:07:11,826:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:11,826:INFO:compare_models() successfully completed......................................
2025-02-06 19:07:11,826:INFO:Initializing create_model()
2025-02-06 19:07:11,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:11,826:INFO:Checking exceptions
2025-02-06 19:07:11,832:INFO:Importing libraries
2025-02-06 19:07:11,832:INFO:Copying training dataset
2025-02-06 19:07:11,838:INFO:Defining folds
2025-02-06 19:07:11,838:INFO:Declaring metric variables
2025-02-06 19:07:11,840:INFO:Importing untrained model
2025-02-06 19:07:11,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:11,844:INFO:Starting cross validation
2025-02-06 19:07:11,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:12,540:INFO:Calculating mean and std
2025-02-06 19:07:12,540:INFO:Creating metrics dataframe
2025-02-06 19:07:12,543:INFO:Finalizing model
2025-02-06 19:07:12,562:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:07:12,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.
2025-02-06 19:07:12,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:07:12,563:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:07:12,563:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:07:12,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:07:12,564:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:07:12,661:INFO:Uploading results into container
2025-02-06 19:07:12,661:INFO:Uploading model into container now
2025-02-06 19:07:12,668:INFO:_master_model_container: 3
2025-02-06 19:07:12,668:INFO:_display_container: 3
2025-02-06 19:07:12,668:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:12,668:INFO:create_model() successfully completed......................................
2025-02-06 19:07:12,796:INFO:Initializing tune_model()
2025-02-06 19:07:12,796:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [5], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:07:12,796:INFO:Checking exceptions
2025-02-06 19:07:12,805:INFO:Copying training dataset
2025-02-06 19:07:12,809:INFO:Checking base model
2025-02-06 19:07:12,809:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:07:12,810:INFO:Declaring metric variables
2025-02-06 19:07:12,812:INFO:Defining Hyperparameters
2025-02-06 19:07:12,924:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [5], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:07:12,924:INFO:Tuning with n_jobs=-1
2025-02-06 19:07:12,924:INFO:Initializing RandomizedSearchCV
2025-02-06 19:07:22,405:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 31, 'actual_estimator__n_estimators': 300, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 19:07:22,406:INFO:Hyperparameter search completed
2025-02-06 19:07:22,406:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:22,407:INFO:Initializing create_model()
2025-02-06 19:07:22,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F92B5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 1, 'reg_alpha': 1, 'num_leaves': 31, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.6})
2025-02-06 19:07:22,407:INFO:Checking exceptions
2025-02-06 19:07:22,407:INFO:Importing libraries
2025-02-06 19:07:22,407:INFO:Copying training dataset
2025-02-06 19:07:22,416:INFO:Defining folds
2025-02-06 19:07:22,416:INFO:Declaring metric variables
2025-02-06 19:07:22,419:INFO:Importing untrained model
2025-02-06 19:07:22,419:INFO:Declaring custom model
2025-02-06 19:07:22,422:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:22,426:INFO:Starting cross validation
2025-02-06 19:07:22,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:23,687:INFO:Calculating mean and std
2025-02-06 19:07:23,688:INFO:Creating metrics dataframe
2025-02-06 19:07:23,691:INFO:Finalizing model
2025-02-06 19:07:23,711:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:07:23,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
2025-02-06 19:07:23,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:07:23,712:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:07:23,712:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:07:23,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:07:23,712:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:07:23,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:23,897:INFO:Uploading results into container
2025-02-06 19:07:23,898:INFO:Uploading model into container now
2025-02-06 19:07:23,898:INFO:_master_model_container: 4
2025-02-06 19:07:23,898:INFO:_display_container: 4
2025-02-06 19:07:23,898:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:23,899:INFO:create_model() successfully completed......................................
2025-02-06 19:07:24,024:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:24,024:INFO:choose_better activated
2025-02-06 19:07:24,026:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:24,026:INFO:Initializing create_model()
2025-02-06 19:07:24,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:24,026:INFO:Checking exceptions
2025-02-06 19:07:24,027:INFO:Importing libraries
2025-02-06 19:07:24,027:INFO:Copying training dataset
2025-02-06 19:07:24,033:INFO:Defining folds
2025-02-06 19:07:24,033:INFO:Declaring metric variables
2025-02-06 19:07:24,033:INFO:Importing untrained model
2025-02-06 19:07:24,033:INFO:Declaring custom model
2025-02-06 19:07:24,035:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:24,035:INFO:Starting cross validation
2025-02-06 19:07:24,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:24,766:INFO:Calculating mean and std
2025-02-06 19:07:24,766:INFO:Creating metrics dataframe
2025-02-06 19:07:24,767:INFO:Finalizing model
2025-02-06 19:07:24,785:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:07:24,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
2025-02-06 19:07:24,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:07:24,786:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:07:24,787:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:07:24,787:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:07:24,787:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:07:24,879:INFO:Uploading results into container
2025-02-06 19:07:24,879:INFO:Uploading model into container now
2025-02-06 19:07:24,881:INFO:_master_model_container: 5
2025-02-06 19:07:24,881:INFO:_display_container: 5
2025-02-06 19:07:24,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:24,881:INFO:create_model() successfully completed......................................
2025-02-06 19:07:24,999:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:24,999:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:07:24,999:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7908
2025-02-06 19:07:25,000:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:07:25,000:INFO:choose_better completed
2025-02-06 19:07:25,004:INFO:_master_model_container: 5
2025-02-06 19:07:25,004:INFO:_display_container: 4
2025-02-06 19:07:25,004:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:25,004:INFO:tune_model() successfully completed......................................
2025-02-06 19:07:25,092:INFO:Initializing create_model()
2025-02-06 19:07:25,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:25,093:INFO:Checking exceptions
2025-02-06 19:07:25,099:INFO:Importing libraries
2025-02-06 19:07:25,099:INFO:Copying training dataset
2025-02-06 19:07:25,104:INFO:Defining folds
2025-02-06 19:07:25,104:INFO:Declaring metric variables
2025-02-06 19:07:25,106:INFO:Importing untrained model
2025-02-06 19:07:25,108:INFO:Logistic Regression Imported successfully
2025-02-06 19:07:25,111:INFO:Starting cross validation
2025-02-06 19:07:25,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:25,191:INFO:Calculating mean and std
2025-02-06 19:07:25,191:INFO:Creating metrics dataframe
2025-02-06 19:07:25,193:INFO:Finalizing model
2025-02-06 19:07:25,226:INFO:Uploading results into container
2025-02-06 19:07:25,227:INFO:Uploading model into container now
2025-02-06 19:07:25,231:INFO:_master_model_container: 6
2025-02-06 19:07:25,232:INFO:_display_container: 5
2025-02-06 19:07:25,232:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:25,232:INFO:create_model() successfully completed......................................
2025-02-06 19:07:25,334:INFO:Initializing tune_model()
2025-02-06 19:07:25,334:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:07:25,334:INFO:Checking exceptions
2025-02-06 19:07:25,344:INFO:Copying training dataset
2025-02-06 19:07:25,348:INFO:Checking base model
2025-02-06 19:07:25,348:INFO:Base model : Logistic Regression
2025-02-06 19:07:25,349:INFO:Declaring metric variables
2025-02-06 19:07:25,351:INFO:Defining Hyperparameters
2025-02-06 19:07:25,445:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:07:25,445:INFO:Tuning with n_jobs=-1
2025-02-06 19:07:25,445:INFO:Initializing RandomizedSearchCV
2025-02-06 19:07:25,873:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:07:25,873:INFO:Hyperparameter search completed
2025-02-06 19:07:25,873:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:25,874:INFO:Initializing create_model()
2025-02-06 19:07:25,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5C56D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:07:25,874:INFO:Checking exceptions
2025-02-06 19:07:25,874:INFO:Importing libraries
2025-02-06 19:07:25,874:INFO:Copying training dataset
2025-02-06 19:07:25,881:INFO:Defining folds
2025-02-06 19:07:25,881:INFO:Declaring metric variables
2025-02-06 19:07:25,883:INFO:Importing untrained model
2025-02-06 19:07:25,883:INFO:Declaring custom model
2025-02-06 19:07:25,885:INFO:Logistic Regression Imported successfully
2025-02-06 19:07:25,888:INFO:Starting cross validation
2025-02-06 19:07:25,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:25,945:INFO:Calculating mean and std
2025-02-06 19:07:25,945:INFO:Creating metrics dataframe
2025-02-06 19:07:25,947:INFO:Finalizing model
2025-02-06 19:07:25,972:INFO:Uploading results into container
2025-02-06 19:07:25,973:INFO:Uploading model into container now
2025-02-06 19:07:25,973:INFO:_master_model_container: 7
2025-02-06 19:07:25,973:INFO:_display_container: 6
2025-02-06 19:07:25,973:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:25,973:INFO:create_model() successfully completed......................................
2025-02-06 19:07:26,074:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:26,074:INFO:choose_better activated
2025-02-06 19:07:26,075:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:26,076:INFO:Initializing create_model()
2025-02-06 19:07:26,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:26,076:INFO:Checking exceptions
2025-02-06 19:07:26,077:INFO:Importing libraries
2025-02-06 19:07:26,077:INFO:Copying training dataset
2025-02-06 19:07:26,083:INFO:Defining folds
2025-02-06 19:07:26,083:INFO:Declaring metric variables
2025-02-06 19:07:26,083:INFO:Importing untrained model
2025-02-06 19:07:26,083:INFO:Declaring custom model
2025-02-06 19:07:26,083:INFO:Logistic Regression Imported successfully
2025-02-06 19:07:26,084:INFO:Starting cross validation
2025-02-06 19:07:26,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:26,139:INFO:Calculating mean and std
2025-02-06 19:07:26,139:INFO:Creating metrics dataframe
2025-02-06 19:07:26,139:INFO:Finalizing model
2025-02-06 19:07:26,167:INFO:Uploading results into container
2025-02-06 19:07:26,167:INFO:Uploading model into container now
2025-02-06 19:07:26,168:INFO:_master_model_container: 8
2025-02-06 19:07:26,168:INFO:_display_container: 7
2025-02-06 19:07:26,168:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:26,168:INFO:create_model() successfully completed......................................
2025-02-06 19:07:26,263:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:26,264:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:07:26,264:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:07:26,264:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:07:26,264:INFO:choose_better completed
2025-02-06 19:07:26,268:INFO:_master_model_container: 8
2025-02-06 19:07:26,268:INFO:_display_container: 6
2025-02-06 19:07:26,269:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:26,269:INFO:tune_model() successfully completed......................................
2025-02-06 19:07:26,363:INFO:Initializing compare_models()
2025-02-06 19:07:26,363:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:07:26,363:INFO:Checking exceptions
2025-02-06 19:07:26,367:INFO:Preparing display monitor
2025-02-06 19:07:26,376:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:07:26,376:INFO:Total runtime is 0.0 minutes
2025-02-06 19:07:26,378:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:26,378:INFO:Initializing create_model()
2025-02-06 19:07:26,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5AB310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:26,379:INFO:Checking exceptions
2025-02-06 19:07:26,379:INFO:Importing libraries
2025-02-06 19:07:26,379:INFO:Copying training dataset
2025-02-06 19:07:26,384:INFO:Defining folds
2025-02-06 19:07:26,384:INFO:Declaring metric variables
2025-02-06 19:07:26,386:INFO:Importing untrained model
2025-02-06 19:07:26,386:INFO:Declaring custom model
2025-02-06 19:07:26,388:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:26,390:INFO:Starting cross validation
2025-02-06 19:07:26,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:27,700:INFO:Calculating mean and std
2025-02-06 19:07:27,700:INFO:Creating metrics dataframe
2025-02-06 19:07:27,702:INFO:Uploading results into container
2025-02-06 19:07:27,702:INFO:Uploading model into container now
2025-02-06 19:07:27,702:INFO:_master_model_container: 9
2025-02-06 19:07:27,702:INFO:_display_container: 7
2025-02-06 19:07:27,703:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:27,703:INFO:create_model() successfully completed......................................
2025-02-06 19:07:27,827:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:27,827:INFO:Creating metrics dataframe
2025-02-06 19:07:27,830:INFO:Initializing custom model Logistic Regression
2025-02-06 19:07:27,830:INFO:Total runtime is 0.02423553466796875 minutes
2025-02-06 19:07:27,831:INFO:SubProcess create_model() called ==================================
2025-02-06 19:07:27,832:INFO:Initializing create_model()
2025-02-06 19:07:27,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5AB310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:27,832:INFO:Checking exceptions
2025-02-06 19:07:27,832:INFO:Importing libraries
2025-02-06 19:07:27,832:INFO:Copying training dataset
2025-02-06 19:07:27,839:INFO:Defining folds
2025-02-06 19:07:27,839:INFO:Declaring metric variables
2025-02-06 19:07:27,840:INFO:Importing untrained model
2025-02-06 19:07:27,840:INFO:Declaring custom model
2025-02-06 19:07:27,842:INFO:Logistic Regression Imported successfully
2025-02-06 19:07:27,845:INFO:Starting cross validation
2025-02-06 19:07:27,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:07:27,902:INFO:Calculating mean and std
2025-02-06 19:07:27,902:INFO:Creating metrics dataframe
2025-02-06 19:07:27,903:INFO:Uploading results into container
2025-02-06 19:07:27,903:INFO:Uploading model into container now
2025-02-06 19:07:27,903:INFO:_master_model_container: 10
2025-02-06 19:07:27,903:INFO:_display_container: 7
2025-02-06 19:07:27,903:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:07:27,903:INFO:create_model() successfully completed......................................
2025-02-06 19:07:28,003:INFO:SubProcess create_model() end ==================================
2025-02-06 19:07:28,003:INFO:Creating metrics dataframe
2025-02-06 19:07:28,008:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:07:28,012:INFO:Initializing create_model()
2025-02-06 19:07:28,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:07:28,012:INFO:Checking exceptions
2025-02-06 19:07:28,012:INFO:Importing libraries
2025-02-06 19:07:28,012:INFO:Copying training dataset
2025-02-06 19:07:28,018:INFO:Defining folds
2025-02-06 19:07:28,018:INFO:Declaring metric variables
2025-02-06 19:07:28,018:INFO:Importing untrained model
2025-02-06 19:07:28,018:INFO:Declaring custom model
2025-02-06 19:07:28,019:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:07:28,019:INFO:Cross validation set to False
2025-02-06 19:07:28,019:INFO:Fitting Model
2025-02-06 19:07:28,034:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:07:28,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-02-06 19:07:28,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:07:28,035:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:07:28,035:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:07:28,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:07:28,035:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:07:28,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:07:28,184:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:28,184:INFO:create_model() successfully completed......................................
2025-02-06 19:07:28,308:INFO:_master_model_container: 10
2025-02-06 19:07:28,308:INFO:_display_container: 7
2025-02-06 19:07:28,308:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:07:28,308:INFO:compare_models() successfully completed......................................
2025-02-06 19:07:28,309:INFO:Initializing predict_model()
2025-02-06 19:07:28,309:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219404D4360>)
2025-02-06 19:07:28,309:INFO:Checking exceptions
2025-02-06 19:07:28,309:INFO:Preloading libraries
2025-02-06 19:07:28,310:INFO:Set up data.
2025-02-06 19:07:28,316:INFO:Set up index.
2025-02-06 19:07:28,481:INFO:Initializing predict_model()
2025-02-06 19:07:28,481:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.01, max_depth=5,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=300, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC83380>)
2025-02-06 19:07:28,481:INFO:Checking exceptions
2025-02-06 19:07:28,481:INFO:Preloading libraries
2025-02-06 19:07:28,482:INFO:Set up data.
2025-02-06 19:07:28,486:INFO:Set up index.
2025-02-06 19:07:28,624:INFO:Initializing predict_model()
2025-02-06 19:07:28,625:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC83380>)
2025-02-06 19:07:28,625:INFO:Checking exceptions
2025-02-06 19:07:28,625:INFO:Preloading libraries
2025-02-06 19:07:28,626:INFO:Set up data.
2025-02-06 19:07:28,632:INFO:Set up index.
2025-02-06 19:07:28,758:INFO:Initializing predict_model()
2025-02-06 19:07:28,758:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002193CB7D890>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC83380>)
2025-02-06 19:07:28,758:INFO:Checking exceptions
2025-02-06 19:07:28,758:INFO:Preloading libraries
2025-02-06 19:07:28,759:INFO:Set up data.
2025-02-06 19:07:28,762:INFO:Set up index.
2025-02-06 19:08:00,666:INFO:PyCaret ClassificationExperiment
2025-02-06 19:08:00,666:INFO:Logging name: clf-default-name
2025-02-06 19:08:00,667:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:08:00,667:INFO:version 3.3.2
2025-02-06 19:08:00,667:INFO:Initializing setup()
2025-02-06 19:08:00,667:INFO:self.USI: d822
2025-02-06 19:08:00,667:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:08:00,667:INFO:Checking environment
2025-02-06 19:08:00,667:INFO:python_version: 3.11.9
2025-02-06 19:08:00,667:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:08:00,667:INFO:machine: AMD64
2025-02-06 19:08:00,667:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:08:00,671:INFO:Memory: svmem(total=67771465728, available=45877116928, percent=32.3, used=21894348800, free=45877116928)
2025-02-06 19:08:00,671:INFO:Physical Core: 8
2025-02-06 19:08:00,671:INFO:Logical Core: 16
2025-02-06 19:08:00,671:INFO:Checking libraries
2025-02-06 19:08:00,671:INFO:System:
2025-02-06 19:08:00,671:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:08:00,671:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:08:00,671:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:08:00,671:INFO:PyCaret required dependencies:
2025-02-06 19:08:00,671:INFO:                 pip: 25.0
2025-02-06 19:08:00,671:INFO:          setuptools: 65.5.0
2025-02-06 19:08:00,671:INFO:             pycaret: 3.3.2
2025-02-06 19:08:00,671:INFO:             IPython: 8.32.0
2025-02-06 19:08:00,671:INFO:          ipywidgets: 8.1.5
2025-02-06 19:08:00,671:INFO:                tqdm: 4.67.1
2025-02-06 19:08:00,671:INFO:               numpy: 1.26.4
2025-02-06 19:08:00,671:INFO:              pandas: 2.1.4
2025-02-06 19:08:00,671:INFO:              jinja2: 3.1.5
2025-02-06 19:08:00,671:INFO:               scipy: 1.11.4
2025-02-06 19:08:00,671:INFO:              joblib: 1.3.2
2025-02-06 19:08:00,671:INFO:             sklearn: 1.4.2
2025-02-06 19:08:00,671:INFO:                pyod: 2.0.3
2025-02-06 19:08:00,671:INFO:            imblearn: 0.13.0
2025-02-06 19:08:00,671:INFO:   category_encoders: 2.7.0
2025-02-06 19:08:00,671:INFO:            lightgbm: 4.5.0
2025-02-06 19:08:00,671:INFO:               numba: 0.61.0
2025-02-06 19:08:00,671:INFO:            requests: 2.32.3
2025-02-06 19:08:00,671:INFO:          matplotlib: 3.7.5
2025-02-06 19:08:00,671:INFO:          scikitplot: 0.3.7
2025-02-06 19:08:00,671:INFO:         yellowbrick: 1.5
2025-02-06 19:08:00,671:INFO:              plotly: 5.24.1
2025-02-06 19:08:00,671:INFO:    plotly-resampler: Not installed
2025-02-06 19:08:00,671:INFO:             kaleido: 0.2.1
2025-02-06 19:08:00,671:INFO:           schemdraw: 0.15
2025-02-06 19:08:00,671:INFO:         statsmodels: 0.14.4
2025-02-06 19:08:00,671:INFO:              sktime: 0.26.0
2025-02-06 19:08:00,672:INFO:               tbats: 1.1.3
2025-02-06 19:08:00,672:INFO:            pmdarima: 2.0.4
2025-02-06 19:08:00,672:INFO:              psutil: 6.1.1
2025-02-06 19:08:00,672:INFO:          markupsafe: 3.0.2
2025-02-06 19:08:00,672:INFO:             pickle5: Not installed
2025-02-06 19:08:00,672:INFO:         cloudpickle: 3.1.1
2025-02-06 19:08:00,672:INFO:         deprecation: 2.1.0
2025-02-06 19:08:00,672:INFO:              xxhash: 3.5.0
2025-02-06 19:08:00,672:INFO:           wurlitzer: Not installed
2025-02-06 19:08:00,672:INFO:PyCaret optional dependencies:
2025-02-06 19:08:00,672:INFO:                shap: Not installed
2025-02-06 19:08:00,672:INFO:           interpret: Not installed
2025-02-06 19:08:00,672:INFO:                umap: Not installed
2025-02-06 19:08:00,672:INFO:     ydata_profiling: Not installed
2025-02-06 19:08:00,672:INFO:  explainerdashboard: Not installed
2025-02-06 19:08:00,672:INFO:             autoviz: Not installed
2025-02-06 19:08:00,672:INFO:           fairlearn: Not installed
2025-02-06 19:08:00,672:INFO:          deepchecks: Not installed
2025-02-06 19:08:00,672:INFO:             xgboost: Not installed
2025-02-06 19:08:00,672:INFO:            catboost: Not installed
2025-02-06 19:08:00,672:INFO:              kmodes: Not installed
2025-02-06 19:08:00,672:INFO:             mlxtend: Not installed
2025-02-06 19:08:00,672:INFO:       statsforecast: Not installed
2025-02-06 19:08:00,672:INFO:        tune_sklearn: Not installed
2025-02-06 19:08:00,672:INFO:                 ray: Not installed
2025-02-06 19:08:00,672:INFO:            hyperopt: Not installed
2025-02-06 19:08:00,672:INFO:              optuna: Not installed
2025-02-06 19:08:00,672:INFO:               skopt: Not installed
2025-02-06 19:08:00,672:INFO:              mlflow: Not installed
2025-02-06 19:08:00,672:INFO:              gradio: Not installed
2025-02-06 19:08:00,672:INFO:             fastapi: Not installed
2025-02-06 19:08:00,672:INFO:             uvicorn: Not installed
2025-02-06 19:08:00,672:INFO:              m2cgen: Not installed
2025-02-06 19:08:00,672:INFO:           evidently: Not installed
2025-02-06 19:08:00,672:INFO:               fugue: Not installed
2025-02-06 19:08:00,672:INFO:           streamlit: Not installed
2025-02-06 19:08:00,672:INFO:             prophet: Not installed
2025-02-06 19:08:00,672:INFO:None
2025-02-06 19:08:00,672:INFO:Set up data.
2025-02-06 19:08:00,679:INFO:Set up folding strategy.
2025-02-06 19:08:00,679:INFO:Set up train/test split.
2025-02-06 19:08:00,684:INFO:Set up index.
2025-02-06 19:08:00,684:INFO:Assigning column types.
2025-02-06 19:08:00,689:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:08:00,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,767:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:08:00,791:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:08:00,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,846:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:08:00,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:00,941:INFO:Preparing preprocessing pipeline...
2025-02-06 19:08:00,942:INFO:Set up simple imputation.
2025-02-06 19:08:00,942:INFO:Set up feature normalization.
2025-02-06 19:08:00,965:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:08:00,967:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:08:00,967:INFO:Creating final display dataframe.
2025-02-06 19:08:01,039:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              d822
2025-02-06 19:08:01,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:01,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:01,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:01,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:08:01,117:INFO:setup() successfully completed in 0.45s...............
2025-02-06 19:08:01,117:INFO:Initializing compare_models()
2025-02-06 19:08:01,117:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:08:01,118:INFO:Checking exceptions
2025-02-06 19:08:01,122:INFO:Preparing display monitor
2025-02-06 19:08:01,131:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:08:01,132:INFO:Total runtime is 1.663366953531901e-05 minutes
2025-02-06 19:08:01,133:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:01,133:INFO:Initializing create_model()
2025-02-06 19:08:01,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940A73E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:01,133:INFO:Checking exceptions
2025-02-06 19:08:01,133:INFO:Importing libraries
2025-02-06 19:08:01,133:INFO:Copying training dataset
2025-02-06 19:08:01,140:INFO:Defining folds
2025-02-06 19:08:01,140:INFO:Declaring metric variables
2025-02-06 19:08:01,140:INFO:Importing untrained model
2025-02-06 19:08:01,142:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:01,145:INFO:Starting cross validation
2025-02-06 19:08:01,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:01,821:INFO:Calculating mean and std
2025-02-06 19:08:01,821:INFO:Creating metrics dataframe
2025-02-06 19:08:01,822:INFO:Uploading results into container
2025-02-06 19:08:01,823:INFO:Uploading model into container now
2025-02-06 19:08:01,823:INFO:_master_model_container: 1
2025-02-06 19:08:01,823:INFO:_display_container: 2
2025-02-06 19:08:01,823:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:01,823:INFO:create_model() successfully completed......................................
2025-02-06 19:08:01,950:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:01,951:INFO:Creating metrics dataframe
2025-02-06 19:08:01,953:INFO:Initializing Logistic Regression
2025-02-06 19:08:01,953:INFO:Total runtime is 0.013701311747233073 minutes
2025-02-06 19:08:01,955:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:01,955:INFO:Initializing create_model()
2025-02-06 19:08:01,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940A73E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:01,955:INFO:Checking exceptions
2025-02-06 19:08:01,955:INFO:Importing libraries
2025-02-06 19:08:01,955:INFO:Copying training dataset
2025-02-06 19:08:01,961:INFO:Defining folds
2025-02-06 19:08:01,961:INFO:Declaring metric variables
2025-02-06 19:08:01,962:INFO:Importing untrained model
2025-02-06 19:08:01,964:INFO:Logistic Regression Imported successfully
2025-02-06 19:08:01,966:INFO:Starting cross validation
2025-02-06 19:08:01,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:02,025:INFO:Calculating mean and std
2025-02-06 19:08:02,025:INFO:Creating metrics dataframe
2025-02-06 19:08:02,025:INFO:Uploading results into container
2025-02-06 19:08:02,026:INFO:Uploading model into container now
2025-02-06 19:08:02,026:INFO:_master_model_container: 2
2025-02-06 19:08:02,026:INFO:_display_container: 2
2025-02-06 19:08:02,026:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:02,027:INFO:create_model() successfully completed......................................
2025-02-06 19:08:02,123:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:02,123:INFO:Creating metrics dataframe
2025-02-06 19:08:02,127:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:08:02,130:INFO:Initializing create_model()
2025-02-06 19:08:02,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:02,131:INFO:Checking exceptions
2025-02-06 19:08:02,131:INFO:Importing libraries
2025-02-06 19:08:02,131:INFO:Copying training dataset
2025-02-06 19:08:02,138:INFO:Defining folds
2025-02-06 19:08:02,138:INFO:Declaring metric variables
2025-02-06 19:08:02,138:INFO:Importing untrained model
2025-02-06 19:08:02,138:INFO:Declaring custom model
2025-02-06 19:08:02,138:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:02,138:INFO:Cross validation set to False
2025-02-06 19:08:02,138:INFO:Fitting Model
2025-02-06 19:08:02,151:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:08:02,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.
2025-02-06 19:08:02,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:08:02,152:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:08:02,152:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:08:02,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:08:02,153:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:08:02,231:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:02,231:INFO:create_model() successfully completed......................................
2025-02-06 19:08:02,362:INFO:_master_model_container: 2
2025-02-06 19:08:02,362:INFO:_display_container: 2
2025-02-06 19:08:02,362:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:02,362:INFO:compare_models() successfully completed......................................
2025-02-06 19:08:02,362:INFO:Initializing create_model()
2025-02-06 19:08:02,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:02,363:INFO:Checking exceptions
2025-02-06 19:08:02,368:INFO:Importing libraries
2025-02-06 19:08:02,368:INFO:Copying training dataset
2025-02-06 19:08:02,375:INFO:Defining folds
2025-02-06 19:08:02,375:INFO:Declaring metric variables
2025-02-06 19:08:02,376:INFO:Importing untrained model
2025-02-06 19:08:02,378:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:02,381:INFO:Starting cross validation
2025-02-06 19:08:02,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:03,132:INFO:Calculating mean and std
2025-02-06 19:08:03,132:INFO:Creating metrics dataframe
2025-02-06 19:08:03,137:INFO:Finalizing model
2025-02-06 19:08:03,156:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:08:03,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.
2025-02-06 19:08:03,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:08:03,158:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:08:03,158:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:08:03,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:08:03,158:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:08:03,266:INFO:Uploading results into container
2025-02-06 19:08:03,266:INFO:Uploading model into container now
2025-02-06 19:08:03,273:INFO:_master_model_container: 3
2025-02-06 19:08:03,273:INFO:_display_container: 3
2025-02-06 19:08:03,273:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:03,273:INFO:create_model() successfully completed......................................
2025-02-06 19:08:03,397:INFO:Initializing tune_model()
2025-02-06 19:08:03,397:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [20, 31], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:08:03,397:INFO:Checking exceptions
2025-02-06 19:08:03,406:INFO:Copying training dataset
2025-02-06 19:08:03,411:INFO:Checking base model
2025-02-06 19:08:03,411:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:08:03,413:INFO:Declaring metric variables
2025-02-06 19:08:03,415:INFO:Defining Hyperparameters
2025-02-06 19:08:03,529:INFO:custom_grid: {'actual_estimator__num_leaves': [20, 31], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:08:03,529:INFO:Tuning with n_jobs=-1
2025-02-06 19:08:03,529:INFO:Initializing RandomizedSearchCV
2025-02-06 19:08:09,276:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 31, 'actual_estimator__n_estimators': 200, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 19:08:09,277:INFO:Hyperparameter search completed
2025-02-06 19:08:09,277:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:09,278:INFO:Initializing create_model()
2025-02-06 19:08:09,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193C5AD710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'num_leaves': 31, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.6})
2025-02-06 19:08:09,278:INFO:Checking exceptions
2025-02-06 19:08:09,278:INFO:Importing libraries
2025-02-06 19:08:09,278:INFO:Copying training dataset
2025-02-06 19:08:09,288:INFO:Defining folds
2025-02-06 19:08:09,288:INFO:Declaring metric variables
2025-02-06 19:08:09,290:INFO:Importing untrained model
2025-02-06 19:08:09,290:INFO:Declaring custom model
2025-02-06 19:08:09,293:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:09,298:INFO:Starting cross validation
2025-02-06 19:08:09,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:09,764:INFO:Calculating mean and std
2025-02-06 19:08:09,766:INFO:Creating metrics dataframe
2025-02-06 19:08:09,769:INFO:Finalizing model
2025-02-06 19:08:09,787:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:08:09,788:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.
2025-02-06 19:08:09,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:08:09,788:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:08:09,789:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:08:09,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:08:09,789:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:08:09,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:09,876:INFO:Uploading results into container
2025-02-06 19:08:09,877:INFO:Uploading model into container now
2025-02-06 19:08:09,877:INFO:_master_model_container: 4
2025-02-06 19:08:09,877:INFO:_display_container: 4
2025-02-06 19:08:09,877:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:09,877:INFO:create_model() successfully completed......................................
2025-02-06 19:08:10,003:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:10,003:INFO:choose_better activated
2025-02-06 19:08:10,006:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:10,006:INFO:Initializing create_model()
2025-02-06 19:08:10,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:10,006:INFO:Checking exceptions
2025-02-06 19:08:10,007:INFO:Importing libraries
2025-02-06 19:08:10,007:INFO:Copying training dataset
2025-02-06 19:08:10,013:INFO:Defining folds
2025-02-06 19:08:10,013:INFO:Declaring metric variables
2025-02-06 19:08:10,013:INFO:Importing untrained model
2025-02-06 19:08:10,013:INFO:Declaring custom model
2025-02-06 19:08:10,014:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:10,014:INFO:Starting cross validation
2025-02-06 19:08:10,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:10,676:INFO:Calculating mean and std
2025-02-06 19:08:10,676:INFO:Creating metrics dataframe
2025-02-06 19:08:10,677:INFO:Finalizing model
2025-02-06 19:08:10,695:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:08:10,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.
2025-02-06 19:08:10,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:08:10,696:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:08:10,696:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:08:10,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:08:10,696:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:08:10,803:INFO:Uploading results into container
2025-02-06 19:08:10,804:INFO:Uploading model into container now
2025-02-06 19:08:10,804:INFO:_master_model_container: 5
2025-02-06 19:08:10,804:INFO:_display_container: 5
2025-02-06 19:08:10,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:10,804:INFO:create_model() successfully completed......................................
2025-02-06 19:08:10,917:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:10,918:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:08:10,918:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7935
2025-02-06 19:08:10,918:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:08:10,918:INFO:choose_better completed
2025-02-06 19:08:10,922:INFO:_master_model_container: 5
2025-02-06 19:08:10,922:INFO:_display_container: 4
2025-02-06 19:08:10,922:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:10,922:INFO:tune_model() successfully completed......................................
2025-02-06 19:08:10,998:INFO:Initializing create_model()
2025-02-06 19:08:10,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:10,998:INFO:Checking exceptions
2025-02-06 19:08:11,005:INFO:Importing libraries
2025-02-06 19:08:11,005:INFO:Copying training dataset
2025-02-06 19:08:11,010:INFO:Defining folds
2025-02-06 19:08:11,010:INFO:Declaring metric variables
2025-02-06 19:08:11,013:INFO:Importing untrained model
2025-02-06 19:08:11,015:INFO:Logistic Regression Imported successfully
2025-02-06 19:08:11,017:INFO:Starting cross validation
2025-02-06 19:08:11,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:11,084:INFO:Calculating mean and std
2025-02-06 19:08:11,084:INFO:Creating metrics dataframe
2025-02-06 19:08:11,086:INFO:Finalizing model
2025-02-06 19:08:11,116:INFO:Uploading results into container
2025-02-06 19:08:11,117:INFO:Uploading model into container now
2025-02-06 19:08:11,122:INFO:_master_model_container: 6
2025-02-06 19:08:11,123:INFO:_display_container: 5
2025-02-06 19:08:11,123:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:11,123:INFO:create_model() successfully completed......................................
2025-02-06 19:08:11,218:INFO:Initializing tune_model()
2025-02-06 19:08:11,218:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:08:11,218:INFO:Checking exceptions
2025-02-06 19:08:11,226:INFO:Copying training dataset
2025-02-06 19:08:11,233:INFO:Checking base model
2025-02-06 19:08:11,233:INFO:Base model : Logistic Regression
2025-02-06 19:08:11,236:INFO:Declaring metric variables
2025-02-06 19:08:11,238:INFO:Defining Hyperparameters
2025-02-06 19:08:11,346:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:08:11,346:INFO:Tuning with n_jobs=-1
2025-02-06 19:08:11,346:INFO:Initializing RandomizedSearchCV
2025-02-06 19:08:11,709:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:08:11,709:INFO:Hyperparameter search completed
2025-02-06 19:08:11,709:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:11,709:INFO:Initializing create_model()
2025-02-06 19:08:11,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021937984CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:08:11,709:INFO:Checking exceptions
2025-02-06 19:08:11,709:INFO:Importing libraries
2025-02-06 19:08:11,709:INFO:Copying training dataset
2025-02-06 19:08:11,717:INFO:Defining folds
2025-02-06 19:08:11,717:INFO:Declaring metric variables
2025-02-06 19:08:11,718:INFO:Importing untrained model
2025-02-06 19:08:11,719:INFO:Declaring custom model
2025-02-06 19:08:11,720:INFO:Logistic Regression Imported successfully
2025-02-06 19:08:11,724:INFO:Starting cross validation
2025-02-06 19:08:11,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:11,782:INFO:Calculating mean and std
2025-02-06 19:08:11,782:INFO:Creating metrics dataframe
2025-02-06 19:08:11,785:INFO:Finalizing model
2025-02-06 19:08:11,812:INFO:Uploading results into container
2025-02-06 19:08:11,812:INFO:Uploading model into container now
2025-02-06 19:08:11,813:INFO:_master_model_container: 7
2025-02-06 19:08:11,813:INFO:_display_container: 6
2025-02-06 19:08:11,813:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:11,813:INFO:create_model() successfully completed......................................
2025-02-06 19:08:11,910:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:11,910:INFO:choose_better activated
2025-02-06 19:08:11,912:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:11,912:INFO:Initializing create_model()
2025-02-06 19:08:11,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:11,913:INFO:Checking exceptions
2025-02-06 19:08:11,914:INFO:Importing libraries
2025-02-06 19:08:11,914:INFO:Copying training dataset
2025-02-06 19:08:11,920:INFO:Defining folds
2025-02-06 19:08:11,920:INFO:Declaring metric variables
2025-02-06 19:08:11,920:INFO:Importing untrained model
2025-02-06 19:08:11,920:INFO:Declaring custom model
2025-02-06 19:08:11,921:INFO:Logistic Regression Imported successfully
2025-02-06 19:08:11,921:INFO:Starting cross validation
2025-02-06 19:08:11,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:11,989:INFO:Calculating mean and std
2025-02-06 19:08:11,989:INFO:Creating metrics dataframe
2025-02-06 19:08:11,990:INFO:Finalizing model
2025-02-06 19:08:12,020:INFO:Uploading results into container
2025-02-06 19:08:12,020:INFO:Uploading model into container now
2025-02-06 19:08:12,020:INFO:_master_model_container: 8
2025-02-06 19:08:12,020:INFO:_display_container: 7
2025-02-06 19:08:12,020:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:12,020:INFO:create_model() successfully completed......................................
2025-02-06 19:08:12,122:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:12,122:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:08:12,122:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:08:12,123:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:08:12,123:INFO:choose_better completed
2025-02-06 19:08:12,128:INFO:_master_model_container: 8
2025-02-06 19:08:12,128:INFO:_display_container: 6
2025-02-06 19:08:12,128:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:12,128:INFO:tune_model() successfully completed......................................
2025-02-06 19:08:12,210:INFO:Initializing compare_models()
2025-02-06 19:08:12,210:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:08:12,210:INFO:Checking exceptions
2025-02-06 19:08:12,213:INFO:Preparing display monitor
2025-02-06 19:08:12,225:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:08:12,226:INFO:Total runtime is 0.0 minutes
2025-02-06 19:08:12,227:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:12,228:INFO:Initializing create_model()
2025-02-06 19:08:12,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193799C050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:12,228:INFO:Checking exceptions
2025-02-06 19:08:12,228:INFO:Importing libraries
2025-02-06 19:08:12,228:INFO:Copying training dataset
2025-02-06 19:08:12,234:INFO:Defining folds
2025-02-06 19:08:12,234:INFO:Declaring metric variables
2025-02-06 19:08:12,236:INFO:Importing untrained model
2025-02-06 19:08:12,236:INFO:Declaring custom model
2025-02-06 19:08:12,238:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:12,240:INFO:Starting cross validation
2025-02-06 19:08:12,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:12,638:INFO:Calculating mean and std
2025-02-06 19:08:12,638:INFO:Creating metrics dataframe
2025-02-06 19:08:12,640:INFO:Uploading results into container
2025-02-06 19:08:12,640:INFO:Uploading model into container now
2025-02-06 19:08:12,640:INFO:_master_model_container: 9
2025-02-06 19:08:12,640:INFO:_display_container: 7
2025-02-06 19:08:12,640:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:12,640:INFO:create_model() successfully completed......................................
2025-02-06 19:08:12,760:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:12,760:INFO:Creating metrics dataframe
2025-02-06 19:08:12,763:INFO:Initializing custom model Logistic Regression
2025-02-06 19:08:12,763:INFO:Total runtime is 0.008979626496632894 minutes
2025-02-06 19:08:12,766:INFO:SubProcess create_model() called ==================================
2025-02-06 19:08:12,766:INFO:Initializing create_model()
2025-02-06 19:08:12,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193799C050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:12,767:INFO:Checking exceptions
2025-02-06 19:08:12,767:INFO:Importing libraries
2025-02-06 19:08:12,767:INFO:Copying training dataset
2025-02-06 19:08:12,772:INFO:Defining folds
2025-02-06 19:08:12,772:INFO:Declaring metric variables
2025-02-06 19:08:12,774:INFO:Importing untrained model
2025-02-06 19:08:12,774:INFO:Declaring custom model
2025-02-06 19:08:12,776:INFO:Logistic Regression Imported successfully
2025-02-06 19:08:12,779:INFO:Starting cross validation
2025-02-06 19:08:12,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:08:12,837:INFO:Calculating mean and std
2025-02-06 19:08:12,837:INFO:Creating metrics dataframe
2025-02-06 19:08:12,837:INFO:Uploading results into container
2025-02-06 19:08:12,838:INFO:Uploading model into container now
2025-02-06 19:08:12,838:INFO:_master_model_container: 10
2025-02-06 19:08:12,838:INFO:_display_container: 7
2025-02-06 19:08:12,838:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:08:12,838:INFO:create_model() successfully completed......................................
2025-02-06 19:08:12,936:INFO:SubProcess create_model() end ==================================
2025-02-06 19:08:12,936:INFO:Creating metrics dataframe
2025-02-06 19:08:12,938:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:08:12,943:INFO:Initializing create_model()
2025-02-06 19:08:12,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:08:12,943:INFO:Checking exceptions
2025-02-06 19:08:12,944:INFO:Importing libraries
2025-02-06 19:08:12,944:INFO:Copying training dataset
2025-02-06 19:08:12,951:INFO:Defining folds
2025-02-06 19:08:12,951:INFO:Declaring metric variables
2025-02-06 19:08:12,951:INFO:Importing untrained model
2025-02-06 19:08:12,951:INFO:Declaring custom model
2025-02-06 19:08:12,951:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:08:12,951:INFO:Cross validation set to False
2025-02-06 19:08:12,952:INFO:Fitting Model
2025-02-06 19:08:12,966:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:08:12,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
2025-02-06 19:08:12,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:08:12,966:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:08:12,966:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:08:12,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:08:12,967:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:08:12,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:08:13,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:13,011:INFO:create_model() successfully completed......................................
2025-02-06 19:08:13,129:INFO:_master_model_container: 10
2025-02-06 19:08:13,129:INFO:_display_container: 7
2025-02-06 19:08:13,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:08:13,129:INFO:compare_models() successfully completed......................................
2025-02-06 19:08:13,130:INFO:Initializing predict_model()
2025-02-06 19:08:13,130:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81940>)
2025-02-06 19:08:13,130:INFO:Checking exceptions
2025-02-06 19:08:13,130:INFO:Preloading libraries
2025-02-06 19:08:13,131:INFO:Set up data.
2025-02-06 19:08:13,137:INFO:Set up index.
2025-02-06 19:08:13,285:INFO:Initializing predict_model()
2025-02-06 19:08:13,285:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC82AC0>)
2025-02-06 19:08:13,285:INFO:Checking exceptions
2025-02-06 19:08:13,285:INFO:Preloading libraries
2025-02-06 19:08:13,286:INFO:Set up data.
2025-02-06 19:08:13,291:INFO:Set up index.
2025-02-06 19:08:13,425:INFO:Initializing predict_model()
2025-02-06 19:08:13,425:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC82AC0>)
2025-02-06 19:08:13,425:INFO:Checking exceptions
2025-02-06 19:08:13,425:INFO:Preloading libraries
2025-02-06 19:08:13,426:INFO:Set up data.
2025-02-06 19:08:13,433:INFO:Set up index.
2025-02-06 19:08:13,561:INFO:Initializing predict_model()
2025-02-06 19:08:13,561:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219401FAD90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193CC82AC0>)
2025-02-06 19:08:13,562:INFO:Checking exceptions
2025-02-06 19:08:13,562:INFO:Preloading libraries
2025-02-06 19:08:13,564:INFO:Set up data.
2025-02-06 19:08:13,568:INFO:Set up index.
2025-02-06 19:10:19,596:INFO:PyCaret ClassificationExperiment
2025-02-06 19:10:19,596:INFO:Logging name: clf-default-name
2025-02-06 19:10:19,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:10:19,596:INFO:version 3.3.2
2025-02-06 19:10:19,596:INFO:Initializing setup()
2025-02-06 19:10:19,596:INFO:self.USI: 7280
2025-02-06 19:10:19,596:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:10:19,596:INFO:Checking environment
2025-02-06 19:10:19,596:INFO:python_version: 3.11.9
2025-02-06 19:10:19,596:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:10:19,596:INFO:machine: AMD64
2025-02-06 19:10:19,596:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:10:19,600:INFO:Memory: svmem(total=67771465728, available=45747118080, percent=32.5, used=22024347648, free=45747118080)
2025-02-06 19:10:19,600:INFO:Physical Core: 8
2025-02-06 19:10:19,600:INFO:Logical Core: 16
2025-02-06 19:10:19,600:INFO:Checking libraries
2025-02-06 19:10:19,600:INFO:System:
2025-02-06 19:10:19,600:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:10:19,600:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:10:19,600:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:10:19,600:INFO:PyCaret required dependencies:
2025-02-06 19:10:19,600:INFO:                 pip: 25.0
2025-02-06 19:10:19,600:INFO:          setuptools: 65.5.0
2025-02-06 19:10:19,600:INFO:             pycaret: 3.3.2
2025-02-06 19:10:19,600:INFO:             IPython: 8.32.0
2025-02-06 19:10:19,600:INFO:          ipywidgets: 8.1.5
2025-02-06 19:10:19,600:INFO:                tqdm: 4.67.1
2025-02-06 19:10:19,600:INFO:               numpy: 1.26.4
2025-02-06 19:10:19,600:INFO:              pandas: 2.1.4
2025-02-06 19:10:19,600:INFO:              jinja2: 3.1.5
2025-02-06 19:10:19,600:INFO:               scipy: 1.11.4
2025-02-06 19:10:19,600:INFO:              joblib: 1.3.2
2025-02-06 19:10:19,600:INFO:             sklearn: 1.4.2
2025-02-06 19:10:19,600:INFO:                pyod: 2.0.3
2025-02-06 19:10:19,600:INFO:            imblearn: 0.13.0
2025-02-06 19:10:19,600:INFO:   category_encoders: 2.7.0
2025-02-06 19:10:19,600:INFO:            lightgbm: 4.5.0
2025-02-06 19:10:19,600:INFO:               numba: 0.61.0
2025-02-06 19:10:19,600:INFO:            requests: 2.32.3
2025-02-06 19:10:19,600:INFO:          matplotlib: 3.7.5
2025-02-06 19:10:19,600:INFO:          scikitplot: 0.3.7
2025-02-06 19:10:19,600:INFO:         yellowbrick: 1.5
2025-02-06 19:10:19,600:INFO:              plotly: 5.24.1
2025-02-06 19:10:19,600:INFO:    plotly-resampler: Not installed
2025-02-06 19:10:19,600:INFO:             kaleido: 0.2.1
2025-02-06 19:10:19,600:INFO:           schemdraw: 0.15
2025-02-06 19:10:19,600:INFO:         statsmodels: 0.14.4
2025-02-06 19:10:19,600:INFO:              sktime: 0.26.0
2025-02-06 19:10:19,600:INFO:               tbats: 1.1.3
2025-02-06 19:10:19,600:INFO:            pmdarima: 2.0.4
2025-02-06 19:10:19,600:INFO:              psutil: 6.1.1
2025-02-06 19:10:19,600:INFO:          markupsafe: 3.0.2
2025-02-06 19:10:19,600:INFO:             pickle5: Not installed
2025-02-06 19:10:19,600:INFO:         cloudpickle: 3.1.1
2025-02-06 19:10:19,600:INFO:         deprecation: 2.1.0
2025-02-06 19:10:19,600:INFO:              xxhash: 3.5.0
2025-02-06 19:10:19,600:INFO:           wurlitzer: Not installed
2025-02-06 19:10:19,600:INFO:PyCaret optional dependencies:
2025-02-06 19:10:19,600:INFO:                shap: Not installed
2025-02-06 19:10:19,600:INFO:           interpret: Not installed
2025-02-06 19:10:19,600:INFO:                umap: Not installed
2025-02-06 19:10:19,600:INFO:     ydata_profiling: Not installed
2025-02-06 19:10:19,600:INFO:  explainerdashboard: Not installed
2025-02-06 19:10:19,600:INFO:             autoviz: Not installed
2025-02-06 19:10:19,600:INFO:           fairlearn: Not installed
2025-02-06 19:10:19,600:INFO:          deepchecks: Not installed
2025-02-06 19:10:19,600:INFO:             xgboost: Not installed
2025-02-06 19:10:19,600:INFO:            catboost: Not installed
2025-02-06 19:10:19,600:INFO:              kmodes: Not installed
2025-02-06 19:10:19,600:INFO:             mlxtend: Not installed
2025-02-06 19:10:19,600:INFO:       statsforecast: Not installed
2025-02-06 19:10:19,600:INFO:        tune_sklearn: Not installed
2025-02-06 19:10:19,600:INFO:                 ray: Not installed
2025-02-06 19:10:19,600:INFO:            hyperopt: Not installed
2025-02-06 19:10:19,600:INFO:              optuna: Not installed
2025-02-06 19:10:19,600:INFO:               skopt: Not installed
2025-02-06 19:10:19,600:INFO:              mlflow: Not installed
2025-02-06 19:10:19,600:INFO:              gradio: Not installed
2025-02-06 19:10:19,600:INFO:             fastapi: Not installed
2025-02-06 19:10:19,600:INFO:             uvicorn: Not installed
2025-02-06 19:10:19,600:INFO:              m2cgen: Not installed
2025-02-06 19:10:19,600:INFO:           evidently: Not installed
2025-02-06 19:10:19,600:INFO:               fugue: Not installed
2025-02-06 19:10:19,600:INFO:           streamlit: Not installed
2025-02-06 19:10:19,600:INFO:             prophet: Not installed
2025-02-06 19:10:19,600:INFO:None
2025-02-06 19:10:19,600:INFO:Set up data.
2025-02-06 19:10:19,607:INFO:Set up folding strategy.
2025-02-06 19:10:19,607:INFO:Set up train/test split.
2025-02-06 19:10:19,612:INFO:Set up index.
2025-02-06 19:10:19,612:INFO:Assigning column types.
2025-02-06 19:10:19,618:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:10:19,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,698:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:10:19,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:10:19,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,775:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:10:19,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:19,854:INFO:Preparing preprocessing pipeline...
2025-02-06 19:10:19,855:INFO:Set up simple imputation.
2025-02-06 19:10:19,856:INFO:Set up feature normalization.
2025-02-06 19:10:19,880:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:10:19,882:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:10:19,882:INFO:Creating final display dataframe.
2025-02-06 19:10:19,965:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              7280
2025-02-06 19:10:20,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:20,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:20,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:20,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:10:20,043:INFO:setup() successfully completed in 0.45s...............
2025-02-06 19:10:20,043:INFO:Initializing compare_models()
2025-02-06 19:10:20,043:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:10:20,043:INFO:Checking exceptions
2025-02-06 19:10:20,047:INFO:Preparing display monitor
2025-02-06 19:10:20,057:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:10:20,057:INFO:Total runtime is 0.0 minutes
2025-02-06 19:10:20,058:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:20,058:INFO:Initializing create_model()
2025-02-06 19:10:20,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219402DBE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:20,058:INFO:Checking exceptions
2025-02-06 19:10:20,058:INFO:Importing libraries
2025-02-06 19:10:20,058:INFO:Copying training dataset
2025-02-06 19:10:20,065:INFO:Defining folds
2025-02-06 19:10:20,065:INFO:Declaring metric variables
2025-02-06 19:10:20,066:INFO:Importing untrained model
2025-02-06 19:10:20,068:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:20,071:INFO:Starting cross validation
2025-02-06 19:10:20,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:20,808:INFO:Calculating mean and std
2025-02-06 19:10:20,808:INFO:Creating metrics dataframe
2025-02-06 19:10:20,810:INFO:Uploading results into container
2025-02-06 19:10:20,810:INFO:Uploading model into container now
2025-02-06 19:10:20,810:INFO:_master_model_container: 1
2025-02-06 19:10:20,810:INFO:_display_container: 2
2025-02-06 19:10:20,810:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:20,810:INFO:create_model() successfully completed......................................
2025-02-06 19:10:20,958:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:20,958:INFO:Creating metrics dataframe
2025-02-06 19:10:20,961:INFO:Initializing Logistic Regression
2025-02-06 19:10:20,961:INFO:Total runtime is 0.015058664480845134 minutes
2025-02-06 19:10:20,963:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:20,963:INFO:Initializing create_model()
2025-02-06 19:10:20,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219402DBE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:20,963:INFO:Checking exceptions
2025-02-06 19:10:20,963:INFO:Importing libraries
2025-02-06 19:10:20,963:INFO:Copying training dataset
2025-02-06 19:10:20,969:INFO:Defining folds
2025-02-06 19:10:20,969:INFO:Declaring metric variables
2025-02-06 19:10:20,970:INFO:Importing untrained model
2025-02-06 19:10:20,972:INFO:Logistic Regression Imported successfully
2025-02-06 19:10:20,975:INFO:Starting cross validation
2025-02-06 19:10:20,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:21,032:INFO:Calculating mean and std
2025-02-06 19:10:21,032:INFO:Creating metrics dataframe
2025-02-06 19:10:21,033:INFO:Uploading results into container
2025-02-06 19:10:21,034:INFO:Uploading model into container now
2025-02-06 19:10:21,034:INFO:_master_model_container: 2
2025-02-06 19:10:21,034:INFO:_display_container: 2
2025-02-06 19:10:21,034:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:21,034:INFO:create_model() successfully completed......................................
2025-02-06 19:10:21,135:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:21,135:INFO:Creating metrics dataframe
2025-02-06 19:10:21,138:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:10:21,142:INFO:Initializing create_model()
2025-02-06 19:10:21,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:21,142:INFO:Checking exceptions
2025-02-06 19:10:21,143:INFO:Importing libraries
2025-02-06 19:10:21,143:INFO:Copying training dataset
2025-02-06 19:10:21,149:INFO:Defining folds
2025-02-06 19:10:21,149:INFO:Declaring metric variables
2025-02-06 19:10:21,149:INFO:Importing untrained model
2025-02-06 19:10:21,149:INFO:Declaring custom model
2025-02-06 19:10:21,149:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:21,150:INFO:Cross validation set to False
2025-02-06 19:10:21,150:INFO:Fitting Model
2025-02-06 19:10:21,163:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:10:21,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-02-06 19:10:21,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:10:21,164:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:10:21,164:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:10:21,164:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:10:21,164:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:10:21,225:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:21,225:INFO:create_model() successfully completed......................................
2025-02-06 19:10:21,351:INFO:_master_model_container: 2
2025-02-06 19:10:21,351:INFO:_display_container: 2
2025-02-06 19:10:21,352:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:21,352:INFO:compare_models() successfully completed......................................
2025-02-06 19:10:21,352:INFO:Initializing create_model()
2025-02-06 19:10:21,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:21,352:INFO:Checking exceptions
2025-02-06 19:10:21,358:INFO:Importing libraries
2025-02-06 19:10:21,358:INFO:Copying training dataset
2025-02-06 19:10:21,364:INFO:Defining folds
2025-02-06 19:10:21,364:INFO:Declaring metric variables
2025-02-06 19:10:21,367:INFO:Importing untrained model
2025-02-06 19:10:21,368:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:21,371:INFO:Starting cross validation
2025-02-06 19:10:21,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:22,151:INFO:Calculating mean and std
2025-02-06 19:10:22,151:INFO:Creating metrics dataframe
2025-02-06 19:10:22,155:INFO:Finalizing model
2025-02-06 19:10:22,173:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:10:22,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
2025-02-06 19:10:22,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:10:22,174:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:10:22,174:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:10:22,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:10:22,175:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:10:22,298:INFO:Uploading results into container
2025-02-06 19:10:22,299:INFO:Uploading model into container now
2025-02-06 19:10:22,305:INFO:_master_model_container: 3
2025-02-06 19:10:22,305:INFO:_display_container: 3
2025-02-06 19:10:22,306:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:22,306:INFO:create_model() successfully completed......................................
2025-02-06 19:10:22,430:INFO:Initializing tune_model()
2025-02-06 19:10:22,430:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:10:22,430:INFO:Checking exceptions
2025-02-06 19:10:22,439:INFO:Copying training dataset
2025-02-06 19:10:22,443:INFO:Checking base model
2025-02-06 19:10:22,443:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:10:22,445:INFO:Declaring metric variables
2025-02-06 19:10:22,447:INFO:Defining Hyperparameters
2025-02-06 19:10:22,533:INFO:custom_grid: {'actual_estimator__num_leaves': [10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:10:22,533:INFO:Tuning with n_jobs=-1
2025-02-06 19:10:22,533:INFO:Initializing RandomizedSearchCV
2025-02-06 19:10:27,168:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.6}
2025-02-06 19:10:27,169:INFO:Hyperparameter search completed
2025-02-06 19:10:27,169:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:27,169:INFO:Initializing create_model()
2025-02-06 19:10:27,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193F8E7C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.6})
2025-02-06 19:10:27,169:INFO:Checking exceptions
2025-02-06 19:10:27,169:INFO:Importing libraries
2025-02-06 19:10:27,170:INFO:Copying training dataset
2025-02-06 19:10:27,178:INFO:Defining folds
2025-02-06 19:10:27,178:INFO:Declaring metric variables
2025-02-06 19:10:27,181:INFO:Importing untrained model
2025-02-06 19:10:27,181:INFO:Declaring custom model
2025-02-06 19:10:27,183:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:27,187:INFO:Starting cross validation
2025-02-06 19:10:27,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:27,494:INFO:Calculating mean and std
2025-02-06 19:10:27,495:INFO:Creating metrics dataframe
2025-02-06 19:10:27,499:INFO:Finalizing model
2025-02-06 19:10:27,519:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:10:27,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.
2025-02-06 19:10:27,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:10:27,519:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:10:27,520:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:10:27,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:10:27,520:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:10:27,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:27,578:INFO:Uploading results into container
2025-02-06 19:10:27,578:INFO:Uploading model into container now
2025-02-06 19:10:27,578:INFO:_master_model_container: 4
2025-02-06 19:10:27,578:INFO:_display_container: 4
2025-02-06 19:10:27,579:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:27,579:INFO:create_model() successfully completed......................................
2025-02-06 19:10:27,710:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:27,710:INFO:choose_better activated
2025-02-06 19:10:27,713:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:27,713:INFO:Initializing create_model()
2025-02-06 19:10:27,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:27,713:INFO:Checking exceptions
2025-02-06 19:10:27,714:INFO:Importing libraries
2025-02-06 19:10:27,714:INFO:Copying training dataset
2025-02-06 19:10:27,720:INFO:Defining folds
2025-02-06 19:10:27,720:INFO:Declaring metric variables
2025-02-06 19:10:27,720:INFO:Importing untrained model
2025-02-06 19:10:27,720:INFO:Declaring custom model
2025-02-06 19:10:27,720:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:27,720:INFO:Starting cross validation
2025-02-06 19:10:27,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:28,390:INFO:Calculating mean and std
2025-02-06 19:10:28,391:INFO:Creating metrics dataframe
2025-02-06 19:10:28,393:INFO:Finalizing model
2025-02-06 19:10:28,411:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:10:28,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
2025-02-06 19:10:28,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:10:28,412:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:10:28,413:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:10:28,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:10:28,413:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:10:28,513:INFO:Uploading results into container
2025-02-06 19:10:28,513:INFO:Uploading model into container now
2025-02-06 19:10:28,513:INFO:_master_model_container: 5
2025-02-06 19:10:28,513:INFO:_display_container: 5
2025-02-06 19:10:28,515:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:28,515:INFO:create_model() successfully completed......................................
2025-02-06 19:10:28,633:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:28,633:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:10:28,633:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7924
2025-02-06 19:10:28,633:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:10:28,633:INFO:choose_better completed
2025-02-06 19:10:28,638:INFO:_master_model_container: 5
2025-02-06 19:10:28,638:INFO:_display_container: 4
2025-02-06 19:10:28,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:28,639:INFO:tune_model() successfully completed......................................
2025-02-06 19:10:28,727:INFO:Initializing create_model()
2025-02-06 19:10:28,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:28,727:INFO:Checking exceptions
2025-02-06 19:10:28,734:INFO:Importing libraries
2025-02-06 19:10:28,734:INFO:Copying training dataset
2025-02-06 19:10:28,740:INFO:Defining folds
2025-02-06 19:10:28,740:INFO:Declaring metric variables
2025-02-06 19:10:28,741:INFO:Importing untrained model
2025-02-06 19:10:28,743:INFO:Logistic Regression Imported successfully
2025-02-06 19:10:28,746:INFO:Starting cross validation
2025-02-06 19:10:28,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:28,814:INFO:Calculating mean and std
2025-02-06 19:10:28,814:INFO:Creating metrics dataframe
2025-02-06 19:10:28,817:INFO:Finalizing model
2025-02-06 19:10:28,847:INFO:Uploading results into container
2025-02-06 19:10:28,847:INFO:Uploading model into container now
2025-02-06 19:10:28,852:INFO:_master_model_container: 6
2025-02-06 19:10:28,852:INFO:_display_container: 5
2025-02-06 19:10:28,853:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:28,853:INFO:create_model() successfully completed......................................
2025-02-06 19:10:28,949:INFO:Initializing tune_model()
2025-02-06 19:10:28,949:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:10:28,949:INFO:Checking exceptions
2025-02-06 19:10:28,958:INFO:Copying training dataset
2025-02-06 19:10:28,962:INFO:Checking base model
2025-02-06 19:10:28,962:INFO:Base model : Logistic Regression
2025-02-06 19:10:28,963:INFO:Declaring metric variables
2025-02-06 19:10:28,965:INFO:Defining Hyperparameters
2025-02-06 19:10:29,049:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:10:29,049:INFO:Tuning with n_jobs=-1
2025-02-06 19:10:29,049:INFO:Initializing RandomizedSearchCV
2025-02-06 19:10:29,415:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:10:29,415:INFO:Hyperparameter search completed
2025-02-06 19:10:29,415:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:29,415:INFO:Initializing create_model()
2025-02-06 19:10:29,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002193CDDD790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:10:29,415:INFO:Checking exceptions
2025-02-06 19:10:29,415:INFO:Importing libraries
2025-02-06 19:10:29,415:INFO:Copying training dataset
2025-02-06 19:10:29,421:INFO:Defining folds
2025-02-06 19:10:29,422:INFO:Declaring metric variables
2025-02-06 19:10:29,423:INFO:Importing untrained model
2025-02-06 19:10:29,423:INFO:Declaring custom model
2025-02-06 19:10:29,425:INFO:Logistic Regression Imported successfully
2025-02-06 19:10:29,428:INFO:Starting cross validation
2025-02-06 19:10:29,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:29,486:INFO:Calculating mean and std
2025-02-06 19:10:29,486:INFO:Creating metrics dataframe
2025-02-06 19:10:29,489:INFO:Finalizing model
2025-02-06 19:10:29,513:INFO:Uploading results into container
2025-02-06 19:10:29,513:INFO:Uploading model into container now
2025-02-06 19:10:29,513:INFO:_master_model_container: 7
2025-02-06 19:10:29,513:INFO:_display_container: 6
2025-02-06 19:10:29,513:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:29,513:INFO:create_model() successfully completed......................................
2025-02-06 19:10:29,614:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:29,614:INFO:choose_better activated
2025-02-06 19:10:29,617:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:29,617:INFO:Initializing create_model()
2025-02-06 19:10:29,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:29,617:INFO:Checking exceptions
2025-02-06 19:10:29,618:INFO:Importing libraries
2025-02-06 19:10:29,618:INFO:Copying training dataset
2025-02-06 19:10:29,624:INFO:Defining folds
2025-02-06 19:10:29,624:INFO:Declaring metric variables
2025-02-06 19:10:29,624:INFO:Importing untrained model
2025-02-06 19:10:29,624:INFO:Declaring custom model
2025-02-06 19:10:29,625:INFO:Logistic Regression Imported successfully
2025-02-06 19:10:29,625:INFO:Starting cross validation
2025-02-06 19:10:29,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:29,693:INFO:Calculating mean and std
2025-02-06 19:10:29,693:INFO:Creating metrics dataframe
2025-02-06 19:10:29,693:INFO:Finalizing model
2025-02-06 19:10:29,723:INFO:Uploading results into container
2025-02-06 19:10:29,724:INFO:Uploading model into container now
2025-02-06 19:10:29,724:INFO:_master_model_container: 8
2025-02-06 19:10:29,724:INFO:_display_container: 7
2025-02-06 19:10:29,724:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:29,724:INFO:create_model() successfully completed......................................
2025-02-06 19:10:29,827:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:29,828:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:10:29,828:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:10:29,828:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:10:29,828:INFO:choose_better completed
2025-02-06 19:10:29,832:INFO:_master_model_container: 8
2025-02-06 19:10:29,833:INFO:_display_container: 6
2025-02-06 19:10:29,833:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:29,833:INFO:tune_model() successfully completed......................................
2025-02-06 19:10:29,923:INFO:Initializing compare_models()
2025-02-06 19:10:29,925:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:10:29,925:INFO:Checking exceptions
2025-02-06 19:10:29,927:INFO:Preparing display monitor
2025-02-06 19:10:29,936:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:10:29,936:INFO:Total runtime is 0.0 minutes
2025-02-06 19:10:29,938:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:29,938:INFO:Initializing create_model()
2025-02-06 19:10:29,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940459AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:29,938:INFO:Checking exceptions
2025-02-06 19:10:29,938:INFO:Importing libraries
2025-02-06 19:10:29,938:INFO:Copying training dataset
2025-02-06 19:10:29,944:INFO:Defining folds
2025-02-06 19:10:29,944:INFO:Declaring metric variables
2025-02-06 19:10:29,945:INFO:Importing untrained model
2025-02-06 19:10:29,945:INFO:Declaring custom model
2025-02-06 19:10:29,947:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:29,951:INFO:Starting cross validation
2025-02-06 19:10:29,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:30,192:INFO:Calculating mean and std
2025-02-06 19:10:30,192:INFO:Creating metrics dataframe
2025-02-06 19:10:30,194:INFO:Uploading results into container
2025-02-06 19:10:30,194:INFO:Uploading model into container now
2025-02-06 19:10:30,194:INFO:_master_model_container: 9
2025-02-06 19:10:30,194:INFO:_display_container: 7
2025-02-06 19:10:30,195:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:30,195:INFO:create_model() successfully completed......................................
2025-02-06 19:10:30,313:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:30,313:INFO:Creating metrics dataframe
2025-02-06 19:10:30,316:INFO:Initializing custom model Logistic Regression
2025-02-06 19:10:30,316:INFO:Total runtime is 0.006341850757598877 minutes
2025-02-06 19:10:30,317:INFO:SubProcess create_model() called ==================================
2025-02-06 19:10:30,317:INFO:Initializing create_model()
2025-02-06 19:10:30,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021940459AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:30,317:INFO:Checking exceptions
2025-02-06 19:10:30,317:INFO:Importing libraries
2025-02-06 19:10:30,317:INFO:Copying training dataset
2025-02-06 19:10:30,324:INFO:Defining folds
2025-02-06 19:10:30,324:INFO:Declaring metric variables
2025-02-06 19:10:30,325:INFO:Importing untrained model
2025-02-06 19:10:30,325:INFO:Declaring custom model
2025-02-06 19:10:30,327:INFO:Logistic Regression Imported successfully
2025-02-06 19:10:30,330:INFO:Starting cross validation
2025-02-06 19:10:30,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:10:30,387:INFO:Calculating mean and std
2025-02-06 19:10:30,387:INFO:Creating metrics dataframe
2025-02-06 19:10:30,388:INFO:Uploading results into container
2025-02-06 19:10:30,388:INFO:Uploading model into container now
2025-02-06 19:10:30,388:INFO:_master_model_container: 10
2025-02-06 19:10:30,388:INFO:_display_container: 7
2025-02-06 19:10:30,389:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:10:30,389:INFO:create_model() successfully completed......................................
2025-02-06 19:10:30,485:INFO:SubProcess create_model() end ==================================
2025-02-06 19:10:30,486:INFO:Creating metrics dataframe
2025-02-06 19:10:30,489:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:10:30,493:INFO:Initializing create_model()
2025-02-06 19:10:30,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:10:30,493:INFO:Checking exceptions
2025-02-06 19:10:30,493:INFO:Importing libraries
2025-02-06 19:10:30,493:INFO:Copying training dataset
2025-02-06 19:10:30,500:INFO:Defining folds
2025-02-06 19:10:30,500:INFO:Declaring metric variables
2025-02-06 19:10:30,500:INFO:Importing untrained model
2025-02-06 19:10:30,500:INFO:Declaring custom model
2025-02-06 19:10:30,501:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:10:30,501:INFO:Cross validation set to False
2025-02-06 19:10:30,501:INFO:Fitting Model
2025-02-06 19:10:30,515:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:10:30,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-02-06 19:10:30,516:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:10:30,516:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:10:30,516:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:10:30,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:10:30,516:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:10:30,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:10:30,538:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:30,538:INFO:create_model() successfully completed......................................
2025-02-06 19:10:30,651:INFO:_master_model_container: 10
2025-02-06 19:10:30,651:INFO:_display_container: 7
2025-02-06 19:10:30,651:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:10:30,651:INFO:compare_models() successfully completed......................................
2025-02-06 19:10:30,652:INFO:Initializing predict_model()
2025-02-06 19:10:30,652:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81D00>)
2025-02-06 19:10:30,652:INFO:Checking exceptions
2025-02-06 19:10:30,652:INFO:Preloading libraries
2025-02-06 19:10:30,653:INFO:Set up data.
2025-02-06 19:10:30,659:INFO:Set up index.
2025-02-06 19:10:30,801:INFO:Initializing predict_model()
2025-02-06 19:10:30,801:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81D00>)
2025-02-06 19:10:30,801:INFO:Checking exceptions
2025-02-06 19:10:30,801:INFO:Preloading libraries
2025-02-06 19:10:30,802:INFO:Set up data.
2025-02-06 19:10:30,807:INFO:Set up index.
2025-02-06 19:10:30,934:INFO:Initializing predict_model()
2025-02-06 19:10:30,934:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935D81D00>)
2025-02-06 19:10:30,934:INFO:Checking exceptions
2025-02-06 19:10:30,934:INFO:Preloading libraries
2025-02-06 19:10:30,935:INFO:Set up data.
2025-02-06 19:10:30,941:INFO:Set up index.
2025-02-06 19:10:31,080:INFO:Initializing predict_model()
2025-02-06 19:10:31,080:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021940888ED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002193807A340>)
2025-02-06 19:10:31,080:INFO:Checking exceptions
2025-02-06 19:10:31,080:INFO:Preloading libraries
2025-02-06 19:10:31,081:INFO:Set up data.
2025-02-06 19:10:31,086:INFO:Set up index.
2025-02-06 19:11:07,369:INFO:PyCaret ClassificationExperiment
2025-02-06 19:11:07,369:INFO:Logging name: clf-default-name
2025-02-06 19:11:07,369:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:11:07,369:INFO:version 3.3.2
2025-02-06 19:11:07,369:INFO:Initializing setup()
2025-02-06 19:11:07,369:INFO:self.USI: ae2b
2025-02-06 19:11:07,369:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'html_param', 'target_param', 'exp_name_log', 'y', 'USI', 'log_plots_param', 'seed', 'fold_shuffle_param', 'pipeline', 'X_test', 'y_test', '_available_plots', 'fix_imbalance', 'n_jobs_param', 'data', 'idx', 'memory', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X_train'}
2025-02-06 19:11:07,369:INFO:Checking environment
2025-02-06 19:11:07,369:INFO:python_version: 3.11.9
2025-02-06 19:11:07,369:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:11:07,369:INFO:machine: AMD64
2025-02-06 19:11:07,369:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:11:07,375:INFO:Memory: svmem(total=67771465728, available=45815402496, percent=32.4, used=21956063232, free=45815402496)
2025-02-06 19:11:07,375:INFO:Physical Core: 8
2025-02-06 19:11:07,375:INFO:Logical Core: 16
2025-02-06 19:11:07,375:INFO:Checking libraries
2025-02-06 19:11:07,375:INFO:System:
2025-02-06 19:11:07,375:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:11:07,375:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:11:07,375:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:11:07,375:INFO:PyCaret required dependencies:
2025-02-06 19:11:07,375:INFO:                 pip: 25.0
2025-02-06 19:11:07,375:INFO:          setuptools: 65.5.0
2025-02-06 19:11:07,375:INFO:             pycaret: 3.3.2
2025-02-06 19:11:07,376:INFO:             IPython: 8.32.0
2025-02-06 19:11:07,376:INFO:          ipywidgets: 8.1.5
2025-02-06 19:11:07,376:INFO:                tqdm: 4.67.1
2025-02-06 19:11:07,376:INFO:               numpy: 1.26.4
2025-02-06 19:11:07,376:INFO:              pandas: 2.1.4
2025-02-06 19:11:07,376:INFO:              jinja2: 3.1.5
2025-02-06 19:11:07,376:INFO:               scipy: 1.11.4
2025-02-06 19:11:07,376:INFO:              joblib: 1.3.2
2025-02-06 19:11:07,376:INFO:             sklearn: 1.4.2
2025-02-06 19:11:07,376:INFO:                pyod: 2.0.3
2025-02-06 19:11:07,376:INFO:            imblearn: 0.13.0
2025-02-06 19:11:07,376:INFO:   category_encoders: 2.7.0
2025-02-06 19:11:07,376:INFO:            lightgbm: 4.5.0
2025-02-06 19:11:07,376:INFO:               numba: 0.61.0
2025-02-06 19:11:07,376:INFO:            requests: 2.32.3
2025-02-06 19:11:07,376:INFO:          matplotlib: 3.7.5
2025-02-06 19:11:07,376:INFO:          scikitplot: 0.3.7
2025-02-06 19:11:07,376:INFO:         yellowbrick: 1.5
2025-02-06 19:11:07,376:INFO:              plotly: 5.24.1
2025-02-06 19:11:07,376:INFO:    plotly-resampler: Not installed
2025-02-06 19:11:07,376:INFO:             kaleido: 0.2.1
2025-02-06 19:11:07,376:INFO:           schemdraw: 0.15
2025-02-06 19:11:07,376:INFO:         statsmodels: 0.14.4
2025-02-06 19:11:07,376:INFO:              sktime: 0.26.0
2025-02-06 19:11:07,376:INFO:               tbats: 1.1.3
2025-02-06 19:11:07,376:INFO:            pmdarima: 2.0.4
2025-02-06 19:11:07,376:INFO:              psutil: 6.1.1
2025-02-06 19:11:07,376:INFO:          markupsafe: 3.0.2
2025-02-06 19:11:07,376:INFO:             pickle5: Not installed
2025-02-06 19:11:07,376:INFO:         cloudpickle: 3.1.1
2025-02-06 19:11:07,376:INFO:         deprecation: 2.1.0
2025-02-06 19:11:07,376:INFO:              xxhash: 3.5.0
2025-02-06 19:11:07,376:INFO:           wurlitzer: Not installed
2025-02-06 19:11:07,376:INFO:PyCaret optional dependencies:
2025-02-06 19:11:07,376:INFO:                shap: Not installed
2025-02-06 19:11:07,376:INFO:           interpret: Not installed
2025-02-06 19:11:07,376:INFO:                umap: Not installed
2025-02-06 19:11:07,376:INFO:     ydata_profiling: Not installed
2025-02-06 19:11:07,376:INFO:  explainerdashboard: Not installed
2025-02-06 19:11:07,376:INFO:             autoviz: Not installed
2025-02-06 19:11:07,376:INFO:           fairlearn: Not installed
2025-02-06 19:11:07,376:INFO:          deepchecks: Not installed
2025-02-06 19:11:07,376:INFO:             xgboost: Not installed
2025-02-06 19:11:07,376:INFO:            catboost: Not installed
2025-02-06 19:11:07,376:INFO:              kmodes: Not installed
2025-02-06 19:11:07,376:INFO:             mlxtend: Not installed
2025-02-06 19:11:07,376:INFO:       statsforecast: Not installed
2025-02-06 19:11:07,376:INFO:        tune_sklearn: Not installed
2025-02-06 19:11:07,376:INFO:                 ray: Not installed
2025-02-06 19:11:07,376:INFO:            hyperopt: Not installed
2025-02-06 19:11:07,376:INFO:              optuna: Not installed
2025-02-06 19:11:07,376:INFO:               skopt: Not installed
2025-02-06 19:11:07,376:INFO:              mlflow: Not installed
2025-02-06 19:11:07,376:INFO:              gradio: Not installed
2025-02-06 19:11:07,376:INFO:             fastapi: Not installed
2025-02-06 19:11:07,376:INFO:             uvicorn: Not installed
2025-02-06 19:11:07,376:INFO:              m2cgen: Not installed
2025-02-06 19:11:07,376:INFO:           evidently: Not installed
2025-02-06 19:11:07,376:INFO:               fugue: Not installed
2025-02-06 19:11:07,377:INFO:           streamlit: Not installed
2025-02-06 19:11:07,377:INFO:             prophet: Not installed
2025-02-06 19:11:07,377:INFO:None
2025-02-06 19:11:07,377:INFO:Set up data.
2025-02-06 19:11:07,386:INFO:Set up folding strategy.
2025-02-06 19:11:07,386:INFO:Set up train/test split.
2025-02-06 19:11:07,394:INFO:Set up index.
2025-02-06 19:11:07,394:INFO:Assigning column types.
2025-02-06 19:11:07,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:11:07,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,485:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:11:07,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,548:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:11:07,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,562:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:11:07,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,640:INFO:Preparing preprocessing pipeline...
2025-02-06 19:11:07,641:INFO:Set up simple imputation.
2025-02-06 19:11:07,641:INFO:Set up feature normalization.
2025-02-06 19:11:07,665:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:11:07,667:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:11:07,667:INFO:Creating final display dataframe.
2025-02-06 19:11:07,740:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ae2b
2025-02-06 19:11:07,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:11:07,818:INFO:setup() successfully completed in 0.45s...............
2025-02-06 19:11:07,818:INFO:Initializing compare_models()
2025-02-06 19:11:07,818:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:11:07,818:INFO:Checking exceptions
2025-02-06 19:11:07,822:INFO:Preparing display monitor
2025-02-06 19:11:07,831:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:11:07,832:INFO:Total runtime is 1.705487569173177e-05 minutes
2025-02-06 19:11:07,833:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:07,833:INFO:Initializing create_model()
2025-02-06 19:11:07,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219402483D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:07,833:INFO:Checking exceptions
2025-02-06 19:11:07,833:INFO:Importing libraries
2025-02-06 19:11:07,833:INFO:Copying training dataset
2025-02-06 19:11:07,839:INFO:Defining folds
2025-02-06 19:11:07,839:INFO:Declaring metric variables
2025-02-06 19:11:07,840:INFO:Importing untrained model
2025-02-06 19:11:07,842:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:07,845:INFO:Starting cross validation
2025-02-06 19:11:07,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:08,525:INFO:Calculating mean and std
2025-02-06 19:11:08,525:INFO:Creating metrics dataframe
2025-02-06 19:11:08,526:INFO:Uploading results into container
2025-02-06 19:11:08,527:INFO:Uploading model into container now
2025-02-06 19:11:08,527:INFO:_master_model_container: 1
2025-02-06 19:11:08,527:INFO:_display_container: 2
2025-02-06 19:11:08,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:08,527:INFO:create_model() successfully completed......................................
2025-02-06 19:11:08,664:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:08,664:INFO:Creating metrics dataframe
2025-02-06 19:11:08,668:INFO:Initializing Logistic Regression
2025-02-06 19:11:08,668:INFO:Total runtime is 0.013938228289286295 minutes
2025-02-06 19:11:08,670:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:08,670:INFO:Initializing create_model()
2025-02-06 19:11:08,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219402483D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:08,670:INFO:Checking exceptions
2025-02-06 19:11:08,670:INFO:Importing libraries
2025-02-06 19:11:08,670:INFO:Copying training dataset
2025-02-06 19:11:08,676:INFO:Defining folds
2025-02-06 19:11:08,676:INFO:Declaring metric variables
2025-02-06 19:11:08,677:INFO:Importing untrained model
2025-02-06 19:11:08,679:INFO:Logistic Regression Imported successfully
2025-02-06 19:11:08,681:INFO:Starting cross validation
2025-02-06 19:11:08,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:08,738:INFO:Calculating mean and std
2025-02-06 19:11:08,738:INFO:Creating metrics dataframe
2025-02-06 19:11:08,739:INFO:Uploading results into container
2025-02-06 19:11:08,739:INFO:Uploading model into container now
2025-02-06 19:11:08,739:INFO:_master_model_container: 2
2025-02-06 19:11:08,739:INFO:_display_container: 2
2025-02-06 19:11:08,740:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:08,740:INFO:create_model() successfully completed......................................
2025-02-06 19:11:08,841:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:08,841:INFO:Creating metrics dataframe
2025-02-06 19:11:08,845:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:11:08,850:INFO:Initializing create_model()
2025-02-06 19:11:08,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:08,850:INFO:Checking exceptions
2025-02-06 19:11:08,850:INFO:Importing libraries
2025-02-06 19:11:08,850:INFO:Copying training dataset
2025-02-06 19:11:08,856:INFO:Defining folds
2025-02-06 19:11:08,856:INFO:Declaring metric variables
2025-02-06 19:11:08,856:INFO:Importing untrained model
2025-02-06 19:11:08,856:INFO:Declaring custom model
2025-02-06 19:11:08,856:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:08,857:INFO:Cross validation set to False
2025-02-06 19:11:08,857:INFO:Fitting Model
2025-02-06 19:11:08,870:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:11:08,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
2025-02-06 19:11:08,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:11:08,871:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:11:08,871:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:11:08,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:11:08,871:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:11:08,929:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:08,929:INFO:create_model() successfully completed......................................
2025-02-06 19:11:09,046:INFO:_master_model_container: 2
2025-02-06 19:11:09,047:INFO:_display_container: 2
2025-02-06 19:11:09,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:09,047:INFO:compare_models() successfully completed......................................
2025-02-06 19:11:09,047:INFO:Initializing create_model()
2025-02-06 19:11:09,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:09,047:INFO:Checking exceptions
2025-02-06 19:11:09,055:INFO:Importing libraries
2025-02-06 19:11:09,055:INFO:Copying training dataset
2025-02-06 19:11:09,060:INFO:Defining folds
2025-02-06 19:11:09,060:INFO:Declaring metric variables
2025-02-06 19:11:09,062:INFO:Importing untrained model
2025-02-06 19:11:09,064:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:09,067:INFO:Starting cross validation
2025-02-06 19:11:09,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:09,825:INFO:Calculating mean and std
2025-02-06 19:11:09,826:INFO:Creating metrics dataframe
2025-02-06 19:11:09,830:INFO:Finalizing model
2025-02-06 19:11:09,851:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:11:09,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.
2025-02-06 19:11:09,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:11:09,852:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:11:09,852:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:11:09,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:11:09,853:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:11:09,948:INFO:Uploading results into container
2025-02-06 19:11:09,948:INFO:Uploading model into container now
2025-02-06 19:11:09,955:INFO:_master_model_container: 3
2025-02-06 19:11:09,955:INFO:_display_container: 3
2025-02-06 19:11:09,955:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:09,955:INFO:create_model() successfully completed......................................
2025-02-06 19:11:10,081:INFO:Initializing tune_model()
2025-02-06 19:11:10,081:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:11:10,081:INFO:Checking exceptions
2025-02-06 19:11:10,090:INFO:Copying training dataset
2025-02-06 19:11:10,094:INFO:Checking base model
2025-02-06 19:11:10,094:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:11:10,096:INFO:Declaring metric variables
2025-02-06 19:11:10,098:INFO:Defining Hyperparameters
2025-02-06 19:11:10,186:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:11:10,186:INFO:Tuning with n_jobs=-1
2025-02-06 19:11:10,186:INFO:Initializing RandomizedSearchCV
2025-02-06 19:11:13,704:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 19:11:13,705:INFO:Hyperparameter search completed
2025-02-06 19:11:13,705:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:13,706:INFO:Initializing create_model()
2025-02-06 19:11:13,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219422F2B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 19:11:13,706:INFO:Checking exceptions
2025-02-06 19:11:13,706:INFO:Importing libraries
2025-02-06 19:11:13,706:INFO:Copying training dataset
2025-02-06 19:11:13,716:INFO:Defining folds
2025-02-06 19:11:13,716:INFO:Declaring metric variables
2025-02-06 19:11:13,718:INFO:Importing untrained model
2025-02-06 19:11:13,718:INFO:Declaring custom model
2025-02-06 19:11:13,720:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:13,724:INFO:Starting cross validation
2025-02-06 19:11:13,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:14,025:INFO:Calculating mean and std
2025-02-06 19:11:14,027:INFO:Creating metrics dataframe
2025-02-06 19:11:14,030:INFO:Finalizing model
2025-02-06 19:11:14,048:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:11:14,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
2025-02-06 19:11:14,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:11:14,049:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:11:14,049:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:11:14,050:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:11:14,050:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:11:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:14,118:INFO:Uploading results into container
2025-02-06 19:11:14,119:INFO:Uploading model into container now
2025-02-06 19:11:14,119:INFO:_master_model_container: 4
2025-02-06 19:11:14,119:INFO:_display_container: 4
2025-02-06 19:11:14,120:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:14,120:INFO:create_model() successfully completed......................................
2025-02-06 19:11:14,247:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:14,248:INFO:choose_better activated
2025-02-06 19:11:14,249:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:14,250:INFO:Initializing create_model()
2025-02-06 19:11:14,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:14,250:INFO:Checking exceptions
2025-02-06 19:11:14,251:INFO:Importing libraries
2025-02-06 19:11:14,251:INFO:Copying training dataset
2025-02-06 19:11:14,258:INFO:Defining folds
2025-02-06 19:11:14,258:INFO:Declaring metric variables
2025-02-06 19:11:14,258:INFO:Importing untrained model
2025-02-06 19:11:14,258:INFO:Declaring custom model
2025-02-06 19:11:14,258:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:14,259:INFO:Starting cross validation
2025-02-06 19:11:14,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:14,961:INFO:Calculating mean and std
2025-02-06 19:11:14,961:INFO:Creating metrics dataframe
2025-02-06 19:11:14,962:INFO:Finalizing model
2025-02-06 19:11:14,980:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:11:14,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
2025-02-06 19:11:14,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:11:14,981:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:11:14,981:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:11:14,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:11:14,982:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:11:15,083:INFO:Uploading results into container
2025-02-06 19:11:15,083:INFO:Uploading model into container now
2025-02-06 19:11:15,083:INFO:_master_model_container: 5
2025-02-06 19:11:15,083:INFO:_display_container: 5
2025-02-06 19:11:15,084:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:15,084:INFO:create_model() successfully completed......................................
2025-02-06 19:11:15,199:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:15,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:11:15,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7913
2025-02-06 19:11:15,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:11:15,200:INFO:choose_better completed
2025-02-06 19:11:15,204:INFO:_master_model_container: 5
2025-02-06 19:11:15,204:INFO:_display_container: 4
2025-02-06 19:11:15,204:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:15,204:INFO:tune_model() successfully completed......................................
2025-02-06 19:11:15,280:INFO:Initializing create_model()
2025-02-06 19:11:15,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:15,280:INFO:Checking exceptions
2025-02-06 19:11:15,289:INFO:Importing libraries
2025-02-06 19:11:15,289:INFO:Copying training dataset
2025-02-06 19:11:15,298:INFO:Defining folds
2025-02-06 19:11:15,298:INFO:Declaring metric variables
2025-02-06 19:11:15,300:INFO:Importing untrained model
2025-02-06 19:11:15,302:INFO:Logistic Regression Imported successfully
2025-02-06 19:11:15,304:INFO:Starting cross validation
2025-02-06 19:11:15,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:15,361:INFO:Calculating mean and std
2025-02-06 19:11:15,361:INFO:Creating metrics dataframe
2025-02-06 19:11:15,364:INFO:Finalizing model
2025-02-06 19:11:15,396:INFO:Uploading results into container
2025-02-06 19:11:15,396:INFO:Uploading model into container now
2025-02-06 19:11:15,400:INFO:_master_model_container: 6
2025-02-06 19:11:15,400:INFO:_display_container: 5
2025-02-06 19:11:15,400:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:15,400:INFO:create_model() successfully completed......................................
2025-02-06 19:11:15,501:INFO:Initializing tune_model()
2025-02-06 19:11:15,501:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:11:15,501:INFO:Checking exceptions
2025-02-06 19:11:15,510:INFO:Copying training dataset
2025-02-06 19:11:15,514:INFO:Checking base model
2025-02-06 19:11:15,514:INFO:Base model : Logistic Regression
2025-02-06 19:11:15,515:INFO:Declaring metric variables
2025-02-06 19:11:15,517:INFO:Defining Hyperparameters
2025-02-06 19:11:15,607:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:11:15,607:INFO:Tuning with n_jobs=-1
2025-02-06 19:11:15,607:INFO:Initializing RandomizedSearchCV
2025-02-06 19:11:15,969:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:11:15,969:INFO:Hyperparameter search completed
2025-02-06 19:11:15,969:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:15,970:INFO:Initializing create_model()
2025-02-06 19:11:15,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002194090BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:11:15,970:INFO:Checking exceptions
2025-02-06 19:11:15,970:INFO:Importing libraries
2025-02-06 19:11:15,970:INFO:Copying training dataset
2025-02-06 19:11:15,976:INFO:Defining folds
2025-02-06 19:11:15,976:INFO:Declaring metric variables
2025-02-06 19:11:15,978:INFO:Importing untrained model
2025-02-06 19:11:15,978:INFO:Declaring custom model
2025-02-06 19:11:15,980:INFO:Logistic Regression Imported successfully
2025-02-06 19:11:15,983:INFO:Starting cross validation
2025-02-06 19:11:15,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:16,041:INFO:Calculating mean and std
2025-02-06 19:11:16,042:INFO:Creating metrics dataframe
2025-02-06 19:11:16,044:INFO:Finalizing model
2025-02-06 19:11:16,068:INFO:Uploading results into container
2025-02-06 19:11:16,068:INFO:Uploading model into container now
2025-02-06 19:11:16,068:INFO:_master_model_container: 7
2025-02-06 19:11:16,069:INFO:_display_container: 6
2025-02-06 19:11:16,069:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:16,069:INFO:create_model() successfully completed......................................
2025-02-06 19:11:16,164:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:16,164:INFO:choose_better activated
2025-02-06 19:11:16,167:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:16,167:INFO:Initializing create_model()
2025-02-06 19:11:16,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:16,167:INFO:Checking exceptions
2025-02-06 19:11:16,168:INFO:Importing libraries
2025-02-06 19:11:16,168:INFO:Copying training dataset
2025-02-06 19:11:16,174:INFO:Defining folds
2025-02-06 19:11:16,174:INFO:Declaring metric variables
2025-02-06 19:11:16,174:INFO:Importing untrained model
2025-02-06 19:11:16,174:INFO:Declaring custom model
2025-02-06 19:11:16,174:INFO:Logistic Regression Imported successfully
2025-02-06 19:11:16,174:INFO:Starting cross validation
2025-02-06 19:11:16,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:16,232:INFO:Calculating mean and std
2025-02-06 19:11:16,232:INFO:Creating metrics dataframe
2025-02-06 19:11:16,233:INFO:Finalizing model
2025-02-06 19:11:16,260:INFO:Uploading results into container
2025-02-06 19:11:16,261:INFO:Uploading model into container now
2025-02-06 19:11:16,261:INFO:_master_model_container: 8
2025-02-06 19:11:16,261:INFO:_display_container: 7
2025-02-06 19:11:16,261:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:16,261:INFO:create_model() successfully completed......................................
2025-02-06 19:11:16,362:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:16,362:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:11:16,362:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:11:16,363:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:11:16,363:INFO:choose_better completed
2025-02-06 19:11:16,367:INFO:_master_model_container: 8
2025-02-06 19:11:16,367:INFO:_display_container: 6
2025-02-06 19:11:16,368:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:16,368:INFO:tune_model() successfully completed......................................
2025-02-06 19:11:16,455:INFO:Initializing compare_models()
2025-02-06 19:11:16,455:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:11:16,455:INFO:Checking exceptions
2025-02-06 19:11:16,458:INFO:Preparing display monitor
2025-02-06 19:11:16,468:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:11:16,469:INFO:Total runtime is 1.6657511393229165e-05 minutes
2025-02-06 19:11:16,470:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:16,471:INFO:Initializing create_model()
2025-02-06 19:11:16,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219404586D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:16,471:INFO:Checking exceptions
2025-02-06 19:11:16,471:INFO:Importing libraries
2025-02-06 19:11:16,471:INFO:Copying training dataset
2025-02-06 19:11:16,476:INFO:Defining folds
2025-02-06 19:11:16,477:INFO:Declaring metric variables
2025-02-06 19:11:16,479:INFO:Importing untrained model
2025-02-06 19:11:16,479:INFO:Declaring custom model
2025-02-06 19:11:16,481:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:16,484:INFO:Starting cross validation
2025-02-06 19:11:16,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:16,751:INFO:Calculating mean and std
2025-02-06 19:11:16,752:INFO:Creating metrics dataframe
2025-02-06 19:11:16,753:INFO:Uploading results into container
2025-02-06 19:11:16,753:INFO:Uploading model into container now
2025-02-06 19:11:16,754:INFO:_master_model_container: 9
2025-02-06 19:11:16,754:INFO:_display_container: 7
2025-02-06 19:11:16,754:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:16,754:INFO:create_model() successfully completed......................................
2025-02-06 19:11:16,876:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:16,876:INFO:Creating metrics dataframe
2025-02-06 19:11:16,879:INFO:Initializing custom model Logistic Regression
2025-02-06 19:11:16,880:INFO:Total runtime is 0.006865584850311279 minutes
2025-02-06 19:11:16,881:INFO:SubProcess create_model() called ==================================
2025-02-06 19:11:16,881:INFO:Initializing create_model()
2025-02-06 19:11:16,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219404586D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:16,881:INFO:Checking exceptions
2025-02-06 19:11:16,881:INFO:Importing libraries
2025-02-06 19:11:16,881:INFO:Copying training dataset
2025-02-06 19:11:16,887:INFO:Defining folds
2025-02-06 19:11:16,887:INFO:Declaring metric variables
2025-02-06 19:11:16,889:INFO:Importing untrained model
2025-02-06 19:11:16,889:INFO:Declaring custom model
2025-02-06 19:11:16,890:INFO:Logistic Regression Imported successfully
2025-02-06 19:11:16,893:INFO:Starting cross validation
2025-02-06 19:11:16,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:11:16,952:INFO:Calculating mean and std
2025-02-06 19:11:16,952:INFO:Creating metrics dataframe
2025-02-06 19:11:16,953:INFO:Uploading results into container
2025-02-06 19:11:16,953:INFO:Uploading model into container now
2025-02-06 19:11:16,953:INFO:_master_model_container: 10
2025-02-06 19:11:16,953:INFO:_display_container: 7
2025-02-06 19:11:16,953:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:11:16,954:INFO:create_model() successfully completed......................................
2025-02-06 19:11:17,051:INFO:SubProcess create_model() end ==================================
2025-02-06 19:11:17,051:INFO:Creating metrics dataframe
2025-02-06 19:11:17,054:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:11:17,058:INFO:Initializing create_model()
2025-02-06 19:11:17,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:11:17,058:INFO:Checking exceptions
2025-02-06 19:11:17,059:INFO:Importing libraries
2025-02-06 19:11:17,059:INFO:Copying training dataset
2025-02-06 19:11:17,066:INFO:Defining folds
2025-02-06 19:11:17,066:INFO:Declaring metric variables
2025-02-06 19:11:17,066:INFO:Importing untrained model
2025-02-06 19:11:17,066:INFO:Declaring custom model
2025-02-06 19:11:17,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:11:17,066:INFO:Cross validation set to False
2025-02-06 19:11:17,067:INFO:Fitting Model
2025-02-06 19:11:17,080:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:11:17,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
2025-02-06 19:11:17,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:11:17,081:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:11:17,081:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:11:17,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:11:17,081:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:11:17,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:17,104:INFO:create_model() successfully completed......................................
2025-02-06 19:11:17,216:INFO:_master_model_container: 10
2025-02-06 19:11:17,216:INFO:_display_container: 7
2025-02-06 19:11:17,216:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:11:17,216:INFO:compare_models() successfully completed......................................
2025-02-06 19:11:17,217:INFO:Initializing predict_model()
2025-02-06 19:11:17,217:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000219404C3560>)
2025-02-06 19:11:17,217:INFO:Checking exceptions
2025-02-06 19:11:17,217:INFO:Preloading libraries
2025-02-06 19:11:17,218:INFO:Set up data.
2025-02-06 19:11:17,223:INFO:Set up index.
2025-02-06 19:11:17,367:INFO:Initializing predict_model()
2025-02-06 19:11:17,368:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935BA3B00>)
2025-02-06 19:11:17,368:INFO:Checking exceptions
2025-02-06 19:11:17,368:INFO:Preloading libraries
2025-02-06 19:11:17,369:INFO:Set up data.
2025-02-06 19:11:17,372:INFO:Set up index.
2025-02-06 19:11:17,502:INFO:Initializing predict_model()
2025-02-06 19:11:17,502:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935BA3B00>)
2025-02-06 19:11:17,502:INFO:Checking exceptions
2025-02-06 19:11:17,502:INFO:Preloading libraries
2025-02-06 19:11:17,502:INFO:Set up data.
2025-02-06 19:11:17,508:INFO:Set up index.
2025-02-06 19:11:17,626:INFO:Initializing predict_model()
2025-02-06 19:11:17,626:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219424FFC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021935BA3B00>)
2025-02-06 19:11:17,626:INFO:Checking exceptions
2025-02-06 19:11:17,626:INFO:Preloading libraries
2025-02-06 19:11:17,627:INFO:Set up data.
2025-02-06 19:11:17,631:INFO:Set up index.
2025-02-06 19:19:19,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:19:19,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:19:19,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:19:19,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:20:24,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:20:24,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:20:24,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:20:24,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 19:20:26,260:INFO:PyCaret ClassificationExperiment
2025-02-06 19:20:26,260:INFO:Logging name: clf-default-name
2025-02-06 19:20:26,260:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 19:20:26,260:INFO:version 3.3.2
2025-02-06 19:20:26,260:INFO:Initializing setup()
2025-02-06 19:20:26,260:INFO:self.USI: 52f1
2025-02-06 19:20:26,260:INFO:self._variable_keys: {'html_param', 'X_train', 'logging_param', 'log_plots_param', 'USI', 'fold_groups_param', 'gpu_param', '_ml_usecase', 'exp_id', 'memory', 'data', 'y_test', 'X', 'seed', 'pipeline', 'exp_name_log', 'is_multiclass', 'idx', 'X_test', 'fold_shuffle_param', 'n_jobs_param', 'y', 'y_train', 'gpu_n_jobs_param', 'fold_generator', 'fix_imbalance', '_available_plots', 'target_param'}
2025-02-06 19:20:26,260:INFO:Checking environment
2025-02-06 19:20:26,260:INFO:python_version: 3.11.9
2025-02-06 19:20:26,260:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 19:20:26,260:INFO:machine: AMD64
2025-02-06 19:20:26,260:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 19:20:26,264:INFO:Memory: svmem(total=67771465728, available=48576692224, percent=28.3, used=19194773504, free=48576692224)
2025-02-06 19:20:26,264:INFO:Physical Core: 8
2025-02-06 19:20:26,264:INFO:Logical Core: 16
2025-02-06 19:20:26,264:INFO:Checking libraries
2025-02-06 19:20:26,264:INFO:System:
2025-02-06 19:20:26,264:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 19:20:26,265:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 19:20:26,265:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 19:20:26,265:INFO:PyCaret required dependencies:
2025-02-06 19:20:26,280:INFO:                 pip: 25.0
2025-02-06 19:20:26,280:INFO:          setuptools: 65.5.0
2025-02-06 19:20:26,280:INFO:             pycaret: 3.3.2
2025-02-06 19:20:26,280:INFO:             IPython: 8.32.0
2025-02-06 19:20:26,280:INFO:          ipywidgets: 8.1.5
2025-02-06 19:20:26,280:INFO:                tqdm: 4.67.1
2025-02-06 19:20:26,280:INFO:               numpy: 1.26.4
2025-02-06 19:20:26,280:INFO:              pandas: 2.1.4
2025-02-06 19:20:26,280:INFO:              jinja2: 3.1.5
2025-02-06 19:20:26,280:INFO:               scipy: 1.11.4
2025-02-06 19:20:26,280:INFO:              joblib: 1.3.2
2025-02-06 19:20:26,280:INFO:             sklearn: 1.4.2
2025-02-06 19:20:26,280:INFO:                pyod: 2.0.3
2025-02-06 19:20:26,280:INFO:            imblearn: 0.13.0
2025-02-06 19:20:26,280:INFO:   category_encoders: 2.7.0
2025-02-06 19:20:26,280:INFO:            lightgbm: 4.5.0
2025-02-06 19:20:26,280:INFO:               numba: 0.61.0
2025-02-06 19:20:26,280:INFO:            requests: 2.32.3
2025-02-06 19:20:26,280:INFO:          matplotlib: 3.7.5
2025-02-06 19:20:26,280:INFO:          scikitplot: 0.3.7
2025-02-06 19:20:26,280:INFO:         yellowbrick: 1.5
2025-02-06 19:20:26,280:INFO:              plotly: 5.24.1
2025-02-06 19:20:26,280:INFO:    plotly-resampler: Not installed
2025-02-06 19:20:26,280:INFO:             kaleido: 0.2.1
2025-02-06 19:20:26,280:INFO:           schemdraw: 0.15
2025-02-06 19:20:26,280:INFO:         statsmodels: 0.14.4
2025-02-06 19:20:26,280:INFO:              sktime: 0.26.0
2025-02-06 19:20:26,280:INFO:               tbats: 1.1.3
2025-02-06 19:20:26,280:INFO:            pmdarima: 2.0.4
2025-02-06 19:20:26,280:INFO:              psutil: 6.1.1
2025-02-06 19:20:26,280:INFO:          markupsafe: 3.0.2
2025-02-06 19:20:26,280:INFO:             pickle5: Not installed
2025-02-06 19:20:26,280:INFO:         cloudpickle: 3.1.1
2025-02-06 19:20:26,280:INFO:         deprecation: 2.1.0
2025-02-06 19:20:26,280:INFO:              xxhash: 3.5.0
2025-02-06 19:20:26,280:INFO:           wurlitzer: Not installed
2025-02-06 19:20:26,280:INFO:PyCaret optional dependencies:
2025-02-06 19:20:26,287:INFO:                shap: Not installed
2025-02-06 19:20:26,287:INFO:           interpret: Not installed
2025-02-06 19:20:26,287:INFO:                umap: Not installed
2025-02-06 19:20:26,287:INFO:     ydata_profiling: Not installed
2025-02-06 19:20:26,287:INFO:  explainerdashboard: Not installed
2025-02-06 19:20:26,287:INFO:             autoviz: Not installed
2025-02-06 19:20:26,287:INFO:           fairlearn: Not installed
2025-02-06 19:20:26,287:INFO:          deepchecks: Not installed
2025-02-06 19:20:26,288:INFO:             xgboost: Not installed
2025-02-06 19:20:26,288:INFO:            catboost: Not installed
2025-02-06 19:20:26,288:INFO:              kmodes: Not installed
2025-02-06 19:20:26,288:INFO:             mlxtend: Not installed
2025-02-06 19:20:26,288:INFO:       statsforecast: Not installed
2025-02-06 19:20:26,288:INFO:        tune_sklearn: Not installed
2025-02-06 19:20:26,288:INFO:                 ray: Not installed
2025-02-06 19:20:26,288:INFO:            hyperopt: Not installed
2025-02-06 19:20:26,288:INFO:              optuna: Not installed
2025-02-06 19:20:26,288:INFO:               skopt: Not installed
2025-02-06 19:20:26,288:INFO:              mlflow: Not installed
2025-02-06 19:20:26,288:INFO:              gradio: Not installed
2025-02-06 19:20:26,288:INFO:             fastapi: Not installed
2025-02-06 19:20:26,288:INFO:             uvicorn: Not installed
2025-02-06 19:20:26,288:INFO:              m2cgen: Not installed
2025-02-06 19:20:26,288:INFO:           evidently: Not installed
2025-02-06 19:20:26,288:INFO:               fugue: Not installed
2025-02-06 19:20:26,288:INFO:           streamlit: Not installed
2025-02-06 19:20:26,288:INFO:             prophet: Not installed
2025-02-06 19:20:26,288:INFO:None
2025-02-06 19:20:26,288:INFO:Set up data.
2025-02-06 19:20:26,296:INFO:Set up folding strategy.
2025-02-06 19:20:26,296:INFO:Set up train/test split.
2025-02-06 19:20:26,302:INFO:Set up index.
2025-02-06 19:20:26,302:INFO:Assigning column types.
2025-02-06 19:20:26,307:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 19:20:26,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,390:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 19:20:26,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,453:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 19:20:26,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,467:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 19:20:26,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,549:INFO:Preparing preprocessing pipeline...
2025-02-06 19:20:26,550:INFO:Set up simple imputation.
2025-02-06 19:20:26,550:INFO:Set up feature normalization.
2025-02-06 19:20:26,574:INFO:Finished creating preprocessing pipeline.
2025-02-06 19:20:26,577:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 19:20:26,577:INFO:Creating final display dataframe.
2025-02-06 19:20:26,656:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8      Rows with missing values             94.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              52f1
2025-02-06 19:20:26,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 19:20:26,736:INFO:setup() successfully completed in 0.48s...............
2025-02-06 19:20:26,736:INFO:Initializing compare_models()
2025-02-06 19:20:26,736:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:20:26,736:INFO:Checking exceptions
2025-02-06 19:20:26,741:INFO:Preparing display monitor
2025-02-06 19:20:26,752:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 19:20:26,752:INFO:Total runtime is 0.0 minutes
2025-02-06 19:20:26,754:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:26,754:INFO:Initializing create_model()
2025-02-06 19:20:26,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3DDD7090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:26,754:INFO:Checking exceptions
2025-02-06 19:20:26,754:INFO:Importing libraries
2025-02-06 19:20:26,754:INFO:Copying training dataset
2025-02-06 19:20:26,760:INFO:Defining folds
2025-02-06 19:20:26,760:INFO:Declaring metric variables
2025-02-06 19:20:26,761:INFO:Importing untrained model
2025-02-06 19:20:26,763:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:26,766:INFO:Starting cross validation
2025-02-06 19:20:26,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:29,640:INFO:Calculating mean and std
2025-02-06 19:20:29,642:INFO:Creating metrics dataframe
2025-02-06 19:20:29,643:INFO:Uploading results into container
2025-02-06 19:20:29,643:INFO:Uploading model into container now
2025-02-06 19:20:29,644:INFO:_master_model_container: 1
2025-02-06 19:20:29,644:INFO:_display_container: 2
2025-02-06 19:20:29,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:29,644:INFO:create_model() successfully completed......................................
2025-02-06 19:20:29,717:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:29,717:INFO:Creating metrics dataframe
2025-02-06 19:20:29,721:INFO:Initializing Logistic Regression
2025-02-06 19:20:29,721:INFO:Total runtime is 0.049485957622528075 minutes
2025-02-06 19:20:29,722:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:29,722:INFO:Initializing create_model()
2025-02-06 19:20:29,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3DDD7090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:29,724:INFO:Checking exceptions
2025-02-06 19:20:29,724:INFO:Importing libraries
2025-02-06 19:20:29,724:INFO:Copying training dataset
2025-02-06 19:20:29,731:INFO:Defining folds
2025-02-06 19:20:29,731:INFO:Declaring metric variables
2025-02-06 19:20:29,732:INFO:Importing untrained model
2025-02-06 19:20:29,735:INFO:Logistic Regression Imported successfully
2025-02-06 19:20:29,738:INFO:Starting cross validation
2025-02-06 19:20:29,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:31,200:INFO:Calculating mean and std
2025-02-06 19:20:31,201:INFO:Creating metrics dataframe
2025-02-06 19:20:31,202:INFO:Uploading results into container
2025-02-06 19:20:31,203:INFO:Uploading model into container now
2025-02-06 19:20:31,203:INFO:_master_model_container: 2
2025-02-06 19:20:31,203:INFO:_display_container: 2
2025-02-06 19:20:31,203:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:31,203:INFO:create_model() successfully completed......................................
2025-02-06 19:20:31,263:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:31,263:INFO:Creating metrics dataframe
2025-02-06 19:20:31,267:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:20:31,270:INFO:Initializing create_model()
2025-02-06 19:20:31,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:31,271:INFO:Checking exceptions
2025-02-06 19:20:31,271:INFO:Importing libraries
2025-02-06 19:20:31,271:INFO:Copying training dataset
2025-02-06 19:20:31,277:INFO:Defining folds
2025-02-06 19:20:31,277:INFO:Declaring metric variables
2025-02-06 19:20:31,277:INFO:Importing untrained model
2025-02-06 19:20:31,277:INFO:Declaring custom model
2025-02-06 19:20:31,277:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:31,278:INFO:Cross validation set to False
2025-02-06 19:20:31,278:INFO:Fitting Model
2025-02-06 19:20:31,292:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:20:31,293:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000581 seconds.
2025-02-06 19:20:31,293:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:20:31,293:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:20:31,293:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:20:31,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:20:31,294:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:20:31,356:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:31,357:INFO:create_model() successfully completed......................................
2025-02-06 19:20:31,416:INFO:_master_model_container: 2
2025-02-06 19:20:31,417:INFO:_display_container: 2
2025-02-06 19:20:31,417:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:31,417:INFO:compare_models() successfully completed......................................
2025-02-06 19:20:31,417:INFO:Initializing create_model()
2025-02-06 19:20:31,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:31,417:INFO:Checking exceptions
2025-02-06 19:20:31,427:INFO:Importing libraries
2025-02-06 19:20:31,428:INFO:Copying training dataset
2025-02-06 19:20:31,436:INFO:Defining folds
2025-02-06 19:20:31,436:INFO:Declaring metric variables
2025-02-06 19:20:31,438:INFO:Importing untrained model
2025-02-06 19:20:31,440:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:31,444:INFO:Starting cross validation
2025-02-06 19:20:31,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:32,430:INFO:Calculating mean and std
2025-02-06 19:20:32,432:INFO:Creating metrics dataframe
2025-02-06 19:20:32,435:INFO:Finalizing model
2025-02-06 19:20:32,454:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:20:32,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
2025-02-06 19:20:32,455:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:20:32,455:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:20:32,455:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:20:32,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:20:32,456:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:20:32,555:INFO:Uploading results into container
2025-02-06 19:20:32,556:INFO:Uploading model into container now
2025-02-06 19:20:32,563:INFO:_master_model_container: 3
2025-02-06 19:20:32,563:INFO:_display_container: 3
2025-02-06 19:20:32,563:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:32,563:INFO:create_model() successfully completed......................................
2025-02-06 19:20:32,621:INFO:Initializing tune_model()
2025-02-06 19:20:32,621:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:20:32,621:INFO:Checking exceptions
2025-02-06 19:20:32,632:INFO:Copying training dataset
2025-02-06 19:20:32,639:INFO:Checking base model
2025-02-06 19:20:32,639:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 19:20:32,641:INFO:Declaring metric variables
2025-02-06 19:20:32,644:INFO:Defining Hyperparameters
2025-02-06 19:20:32,684:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 19:20:32,684:INFO:Tuning with n_jobs=-1
2025-02-06 19:20:32,684:INFO:Initializing RandomizedSearchCV
2025-02-06 19:20:36,391:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 19:20:36,392:INFO:Hyperparameter search completed
2025-02-06 19:20:36,392:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:36,393:INFO:Initializing create_model()
2025-02-06 19:20:36,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3C83C790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 19:20:36,393:INFO:Checking exceptions
2025-02-06 19:20:36,393:INFO:Importing libraries
2025-02-06 19:20:36,393:INFO:Copying training dataset
2025-02-06 19:20:36,402:INFO:Defining folds
2025-02-06 19:20:36,402:INFO:Declaring metric variables
2025-02-06 19:20:36,404:INFO:Importing untrained model
2025-02-06 19:20:36,404:INFO:Declaring custom model
2025-02-06 19:20:36,407:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:36,410:INFO:Starting cross validation
2025-02-06 19:20:36,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:36,740:INFO:Calculating mean and std
2025-02-06 19:20:36,742:INFO:Creating metrics dataframe
2025-02-06 19:20:36,745:INFO:Finalizing model
2025-02-06 19:20:36,764:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:20:36,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.
2025-02-06 19:20:36,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:20:36,765:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:20:36,766:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:20:36,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:20:36,766:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:20:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:36,829:INFO:Uploading results into container
2025-02-06 19:20:36,830:INFO:Uploading model into container now
2025-02-06 19:20:36,830:INFO:_master_model_container: 4
2025-02-06 19:20:36,830:INFO:_display_container: 4
2025-02-06 19:20:36,831:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:36,831:INFO:create_model() successfully completed......................................
2025-02-06 19:20:36,894:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:36,894:INFO:choose_better activated
2025-02-06 19:20:36,897:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:36,898:INFO:Initializing create_model()
2025-02-06 19:20:36,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:36,898:INFO:Checking exceptions
2025-02-06 19:20:36,898:INFO:Importing libraries
2025-02-06 19:20:36,898:INFO:Copying training dataset
2025-02-06 19:20:36,907:INFO:Defining folds
2025-02-06 19:20:36,907:INFO:Declaring metric variables
2025-02-06 19:20:36,907:INFO:Importing untrained model
2025-02-06 19:20:36,907:INFO:Declaring custom model
2025-02-06 19:20:36,907:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:36,907:INFO:Starting cross validation
2025-02-06 19:20:36,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:37,724:INFO:Calculating mean and std
2025-02-06 19:20:37,724:INFO:Creating metrics dataframe
2025-02-06 19:20:37,725:INFO:Finalizing model
2025-02-06 19:20:37,745:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:20:37,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000626 seconds.
2025-02-06 19:20:37,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:20:37,746:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:20:37,746:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:20:37,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:20:37,746:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:20:37,843:INFO:Uploading results into container
2025-02-06 19:20:37,843:INFO:Uploading model into container now
2025-02-06 19:20:37,843:INFO:_master_model_container: 5
2025-02-06 19:20:37,843:INFO:_display_container: 5
2025-02-06 19:20:37,844:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:37,844:INFO:create_model() successfully completed......................................
2025-02-06 19:20:37,918:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:37,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7852
2025-02-06 19:20:37,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7913
2025-02-06 19:20:37,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 19:20:37,919:INFO:choose_better completed
2025-02-06 19:20:37,926:INFO:_master_model_container: 5
2025-02-06 19:20:37,926:INFO:_display_container: 4
2025-02-06 19:20:37,926:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:37,926:INFO:tune_model() successfully completed......................................
2025-02-06 19:20:37,970:INFO:Initializing create_model()
2025-02-06 19:20:37,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:37,970:INFO:Checking exceptions
2025-02-06 19:20:37,976:INFO:Importing libraries
2025-02-06 19:20:37,977:INFO:Copying training dataset
2025-02-06 19:20:37,983:INFO:Defining folds
2025-02-06 19:20:37,983:INFO:Declaring metric variables
2025-02-06 19:20:37,984:INFO:Importing untrained model
2025-02-06 19:20:37,985:INFO:Logistic Regression Imported successfully
2025-02-06 19:20:37,990:INFO:Starting cross validation
2025-02-06 19:20:37,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:38,059:INFO:Calculating mean and std
2025-02-06 19:20:38,059:INFO:Creating metrics dataframe
2025-02-06 19:20:38,062:INFO:Finalizing model
2025-02-06 19:20:38,098:INFO:Uploading results into container
2025-02-06 19:20:38,099:INFO:Uploading model into container now
2025-02-06 19:20:38,105:INFO:_master_model_container: 6
2025-02-06 19:20:38,105:INFO:_display_container: 5
2025-02-06 19:20:38,106:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:38,106:INFO:create_model() successfully completed......................................
2025-02-06 19:20:38,166:INFO:Initializing tune_model()
2025-02-06 19:20:38,166:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 19:20:38,166:INFO:Checking exceptions
2025-02-06 19:20:38,175:INFO:Copying training dataset
2025-02-06 19:20:38,180:INFO:Checking base model
2025-02-06 19:20:38,180:INFO:Base model : Logistic Regression
2025-02-06 19:20:38,181:INFO:Declaring metric variables
2025-02-06 19:20:38,183:INFO:Defining Hyperparameters
2025-02-06 19:20:38,217:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 19:20:38,217:INFO:Tuning with n_jobs=-1
2025-02-06 19:20:38,217:INFO:Initializing RandomizedSearchCV
2025-02-06 19:20:38,586:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 19:20:38,586:INFO:Hyperparameter search completed
2025-02-06 19:20:38,586:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:38,587:INFO:Initializing create_model()
2025-02-06 19:20:38,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3CC95590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'max_iter': 100, 'C': 0.1})
2025-02-06 19:20:38,587:INFO:Checking exceptions
2025-02-06 19:20:38,587:INFO:Importing libraries
2025-02-06 19:20:38,587:INFO:Copying training dataset
2025-02-06 19:20:38,592:INFO:Defining folds
2025-02-06 19:20:38,592:INFO:Declaring metric variables
2025-02-06 19:20:38,595:INFO:Importing untrained model
2025-02-06 19:20:38,595:INFO:Declaring custom model
2025-02-06 19:20:38,597:INFO:Logistic Regression Imported successfully
2025-02-06 19:20:38,599:INFO:Starting cross validation
2025-02-06 19:20:38,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:38,657:INFO:Calculating mean and std
2025-02-06 19:20:38,657:INFO:Creating metrics dataframe
2025-02-06 19:20:38,660:INFO:Finalizing model
2025-02-06 19:20:38,683:INFO:Uploading results into container
2025-02-06 19:20:38,683:INFO:Uploading model into container now
2025-02-06 19:20:38,684:INFO:_master_model_container: 7
2025-02-06 19:20:38,684:INFO:_display_container: 6
2025-02-06 19:20:38,684:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:38,684:INFO:create_model() successfully completed......................................
2025-02-06 19:20:38,727:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:38,727:INFO:choose_better activated
2025-02-06 19:20:38,728:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:38,728:INFO:Initializing create_model()
2025-02-06 19:20:38,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:38,728:INFO:Checking exceptions
2025-02-06 19:20:38,730:INFO:Importing libraries
2025-02-06 19:20:38,730:INFO:Copying training dataset
2025-02-06 19:20:38,736:INFO:Defining folds
2025-02-06 19:20:38,736:INFO:Declaring metric variables
2025-02-06 19:20:38,736:INFO:Importing untrained model
2025-02-06 19:20:38,736:INFO:Declaring custom model
2025-02-06 19:20:38,736:INFO:Logistic Regression Imported successfully
2025-02-06 19:20:38,736:INFO:Starting cross validation
2025-02-06 19:20:38,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:38,803:INFO:Calculating mean and std
2025-02-06 19:20:38,803:INFO:Creating metrics dataframe
2025-02-06 19:20:38,804:INFO:Finalizing model
2025-02-06 19:20:38,832:INFO:Uploading results into container
2025-02-06 19:20:38,832:INFO:Uploading model into container now
2025-02-06 19:20:38,832:INFO:_master_model_container: 8
2025-02-06 19:20:38,832:INFO:_display_container: 7
2025-02-06 19:20:38,832:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:38,832:INFO:create_model() successfully completed......................................
2025-02-06 19:20:38,876:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:38,877:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7829
2025-02-06 19:20:38,877:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.783
2025-02-06 19:20:38,877:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 19:20:38,877:INFO:choose_better completed
2025-02-06 19:20:38,881:INFO:_master_model_container: 8
2025-02-06 19:20:38,881:INFO:_display_container: 6
2025-02-06 19:20:38,881:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:38,881:INFO:tune_model() successfully completed......................................
2025-02-06 19:20:38,922:INFO:Initializing compare_models()
2025-02-06 19:20:38,922:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 19:20:38,922:INFO:Checking exceptions
2025-02-06 19:20:38,925:INFO:Preparing display monitor
2025-02-06 19:20:38,935:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 19:20:38,935:INFO:Total runtime is 0.0 minutes
2025-02-06 19:20:38,936:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:38,936:INFO:Initializing create_model()
2025-02-06 19:20:38,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3DE74410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:38,937:INFO:Checking exceptions
2025-02-06 19:20:38,937:INFO:Importing libraries
2025-02-06 19:20:38,937:INFO:Copying training dataset
2025-02-06 19:20:38,942:INFO:Defining folds
2025-02-06 19:20:38,942:INFO:Declaring metric variables
2025-02-06 19:20:38,944:INFO:Importing untrained model
2025-02-06 19:20:38,944:INFO:Declaring custom model
2025-02-06 19:20:38,946:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:38,948:INFO:Starting cross validation
2025-02-06 19:20:38,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:39,268:INFO:Calculating mean and std
2025-02-06 19:20:39,268:INFO:Creating metrics dataframe
2025-02-06 19:20:39,270:INFO:Uploading results into container
2025-02-06 19:20:39,270:INFO:Uploading model into container now
2025-02-06 19:20:39,271:INFO:_master_model_container: 9
2025-02-06 19:20:39,271:INFO:_display_container: 7
2025-02-06 19:20:39,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:39,271:INFO:create_model() successfully completed......................................
2025-02-06 19:20:39,338:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:39,338:INFO:Creating metrics dataframe
2025-02-06 19:20:39,342:INFO:Initializing custom model Logistic Regression
2025-02-06 19:20:39,342:INFO:Total runtime is 0.006787403424580892 minutes
2025-02-06 19:20:39,345:INFO:SubProcess create_model() called ==================================
2025-02-06 19:20:39,345:INFO:Initializing create_model()
2025-02-06 19:20:39,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D3DE74410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:39,346:INFO:Checking exceptions
2025-02-06 19:20:39,346:INFO:Importing libraries
2025-02-06 19:20:39,346:INFO:Copying training dataset
2025-02-06 19:20:39,354:INFO:Defining folds
2025-02-06 19:20:39,354:INFO:Declaring metric variables
2025-02-06 19:20:39,356:INFO:Importing untrained model
2025-02-06 19:20:39,356:INFO:Declaring custom model
2025-02-06 19:20:39,357:INFO:Logistic Regression Imported successfully
2025-02-06 19:20:39,360:INFO:Starting cross validation
2025-02-06 19:20:39,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 19:20:39,418:INFO:Calculating mean and std
2025-02-06 19:20:39,418:INFO:Creating metrics dataframe
2025-02-06 19:20:39,419:INFO:Uploading results into container
2025-02-06 19:20:39,420:INFO:Uploading model into container now
2025-02-06 19:20:39,420:INFO:_master_model_container: 10
2025-02-06 19:20:39,420:INFO:_display_container: 7
2025-02-06 19:20:39,420:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 19:20:39,420:INFO:create_model() successfully completed......................................
2025-02-06 19:20:39,465:INFO:SubProcess create_model() end ==================================
2025-02-06 19:20:39,466:INFO:Creating metrics dataframe
2025-02-06 19:20:39,469:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 19:20:39,472:INFO:Initializing create_model()
2025-02-06 19:20:39,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 19:20:39,472:INFO:Checking exceptions
2025-02-06 19:20:39,473:INFO:Importing libraries
2025-02-06 19:20:39,473:INFO:Copying training dataset
2025-02-06 19:20:39,479:INFO:Defining folds
2025-02-06 19:20:39,479:INFO:Declaring metric variables
2025-02-06 19:20:39,479:INFO:Importing untrained model
2025-02-06 19:20:39,479:INFO:Declaring custom model
2025-02-06 19:20:39,480:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 19:20:39,480:INFO:Cross validation set to False
2025-02-06 19:20:39,480:INFO:Fitting Model
2025-02-06 19:20:39,496:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 19:20:39,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.
2025-02-06 19:20:39,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 19:20:39,496:INFO:[LightGBM] [Info] Total Bins 6550
2025-02-06 19:20:39,497:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 19:20:39,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 19:20:39,497:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 19:20:39,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:39,524:INFO:create_model() successfully completed......................................
2025-02-06 19:20:39,589:INFO:_master_model_container: 10
2025-02-06 19:20:39,589:INFO:_display_container: 7
2025-02-06 19:20:39,589:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 19:20:39,589:INFO:compare_models() successfully completed......................................
2025-02-06 19:20:39,590:INFO:Initializing predict_model()
2025-02-06 19:20:39,590:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020D3DB6DB20>)
2025-02-06 19:20:39,591:INFO:Checking exceptions
2025-02-06 19:20:39,591:INFO:Preloading libraries
2025-02-06 19:20:39,592:INFO:Set up data.
2025-02-06 19:20:39,599:INFO:Set up index.
2025-02-06 19:20:39,704:INFO:Initializing predict_model()
2025-02-06 19:20:39,704:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020D3D4E6340>)
2025-02-06 19:20:39,704:INFO:Checking exceptions
2025-02-06 19:20:39,704:INFO:Preloading libraries
2025-02-06 19:20:39,705:INFO:Set up data.
2025-02-06 19:20:39,712:INFO:Set up index.
2025-02-06 19:20:39,797:INFO:Initializing predict_model()
2025-02-06 19:20:39,797:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020D3D4E6340>)
2025-02-06 19:20:39,797:INFO:Checking exceptions
2025-02-06 19:20:39,797:INFO:Preloading libraries
2025-02-06 19:20:39,798:INFO:Set up data.
2025-02-06 19:20:39,808:INFO:Set up index.
2025-02-06 19:20:39,895:INFO:Initializing predict_model()
2025-02-06 19:20:39,895:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D3D3E6210>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020D3D4E6340>)
2025-02-06 19:20:39,895:INFO:Checking exceptions
2025-02-06 19:20:39,895:INFO:Preloading libraries
2025-02-06 19:20:39,896:INFO:Set up data.
2025-02-06 19:20:39,900:INFO:Set up index.
2025-02-06 20:17:38,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:17:38,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:17:38,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:17:38,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:17:38,970:INFO:PyCaret ClassificationExperiment
2025-02-06 20:17:38,970:INFO:Logging name: clf-default-name
2025-02-06 20:17:38,970:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 20:17:38,970:INFO:version 3.3.2
2025-02-06 20:17:38,970:INFO:Initializing setup()
2025-02-06 20:17:38,970:INFO:self.USI: df9e
2025-02-06 20:17:38,970:INFO:self._variable_keys: {'y', 'target_param', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass', 'fold_generator', 'USI', 'memory', 'idx', 'exp_id', 'seed', 'log_plots_param', 'fix_imbalance', 'fold_groups_param', 'data', 'fold_shuffle_param', 'exp_name_log', 'X_test', '_ml_usecase', 'gpu_param', 'X', 'html_param', '_available_plots', 'n_jobs_param', 'X_train', 'y_train', 'y_test', 'pipeline'}
2025-02-06 20:17:38,970:INFO:Checking environment
2025-02-06 20:17:38,970:INFO:python_version: 3.11.9
2025-02-06 20:17:38,970:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 20:17:38,970:INFO:machine: AMD64
2025-02-06 20:17:38,970:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 20:17:38,975:INFO:Memory: svmem(total=67771465728, available=48256884736, percent=28.8, used=19514580992, free=48256884736)
2025-02-06 20:17:38,975:INFO:Physical Core: 8
2025-02-06 20:17:38,975:INFO:Logical Core: 16
2025-02-06 20:17:38,975:INFO:Checking libraries
2025-02-06 20:17:38,975:INFO:System:
2025-02-06 20:17:38,975:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 20:17:38,975:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 20:17:38,975:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 20:17:38,975:INFO:PyCaret required dependencies:
2025-02-06 20:17:38,988:INFO:                 pip: 25.0
2025-02-06 20:17:38,988:INFO:          setuptools: 65.5.0
2025-02-06 20:17:38,988:INFO:             pycaret: 3.3.2
2025-02-06 20:17:38,988:INFO:             IPython: 8.32.0
2025-02-06 20:17:38,988:INFO:          ipywidgets: 8.1.5
2025-02-06 20:17:38,988:INFO:                tqdm: 4.67.1
2025-02-06 20:17:38,988:INFO:               numpy: 1.26.4
2025-02-06 20:17:38,988:INFO:              pandas: 2.1.4
2025-02-06 20:17:38,988:INFO:              jinja2: 3.1.5
2025-02-06 20:17:38,988:INFO:               scipy: 1.11.4
2025-02-06 20:17:38,988:INFO:              joblib: 1.3.2
2025-02-06 20:17:38,988:INFO:             sklearn: 1.4.2
2025-02-06 20:17:38,988:INFO:                pyod: 2.0.3
2025-02-06 20:17:38,988:INFO:            imblearn: 0.13.0
2025-02-06 20:17:38,988:INFO:   category_encoders: 2.7.0
2025-02-06 20:17:38,988:INFO:            lightgbm: 4.5.0
2025-02-06 20:17:38,988:INFO:               numba: 0.61.0
2025-02-06 20:17:38,988:INFO:            requests: 2.32.3
2025-02-06 20:17:38,988:INFO:          matplotlib: 3.7.5
2025-02-06 20:17:38,988:INFO:          scikitplot: 0.3.7
2025-02-06 20:17:38,988:INFO:         yellowbrick: 1.5
2025-02-06 20:17:38,988:INFO:              plotly: 5.24.1
2025-02-06 20:17:38,988:INFO:    plotly-resampler: Not installed
2025-02-06 20:17:38,988:INFO:             kaleido: 0.2.1
2025-02-06 20:17:38,988:INFO:           schemdraw: 0.15
2025-02-06 20:17:38,988:INFO:         statsmodels: 0.14.4
2025-02-06 20:17:38,988:INFO:              sktime: 0.26.0
2025-02-06 20:17:38,988:INFO:               tbats: 1.1.3
2025-02-06 20:17:38,988:INFO:            pmdarima: 2.0.4
2025-02-06 20:17:38,988:INFO:              psutil: 6.1.1
2025-02-06 20:17:38,988:INFO:          markupsafe: 3.0.2
2025-02-06 20:17:38,988:INFO:             pickle5: Not installed
2025-02-06 20:17:38,988:INFO:         cloudpickle: 3.1.1
2025-02-06 20:17:38,988:INFO:         deprecation: 2.1.0
2025-02-06 20:17:38,988:INFO:              xxhash: 3.5.0
2025-02-06 20:17:38,988:INFO:           wurlitzer: Not installed
2025-02-06 20:17:38,988:INFO:PyCaret optional dependencies:
2025-02-06 20:17:38,994:INFO:                shap: Not installed
2025-02-06 20:17:38,994:INFO:           interpret: Not installed
2025-02-06 20:17:38,994:INFO:                umap: Not installed
2025-02-06 20:17:38,994:INFO:     ydata_profiling: Not installed
2025-02-06 20:17:38,994:INFO:  explainerdashboard: Not installed
2025-02-06 20:17:38,994:INFO:             autoviz: Not installed
2025-02-06 20:17:38,994:INFO:           fairlearn: Not installed
2025-02-06 20:17:38,994:INFO:          deepchecks: Not installed
2025-02-06 20:17:38,994:INFO:             xgboost: Not installed
2025-02-06 20:17:38,994:INFO:            catboost: Not installed
2025-02-06 20:17:38,994:INFO:              kmodes: Not installed
2025-02-06 20:17:38,994:INFO:             mlxtend: Not installed
2025-02-06 20:17:38,994:INFO:       statsforecast: Not installed
2025-02-06 20:17:38,994:INFO:        tune_sklearn: Not installed
2025-02-06 20:17:38,994:INFO:                 ray: Not installed
2025-02-06 20:17:38,994:INFO:            hyperopt: Not installed
2025-02-06 20:17:38,994:INFO:              optuna: Not installed
2025-02-06 20:17:38,994:INFO:               skopt: Not installed
2025-02-06 20:17:38,994:INFO:              mlflow: Not installed
2025-02-06 20:17:38,994:INFO:              gradio: Not installed
2025-02-06 20:17:38,994:INFO:             fastapi: Not installed
2025-02-06 20:17:38,994:INFO:             uvicorn: Not installed
2025-02-06 20:17:38,994:INFO:              m2cgen: Not installed
2025-02-06 20:17:38,994:INFO:           evidently: Not installed
2025-02-06 20:17:38,994:INFO:               fugue: Not installed
2025-02-06 20:17:38,994:INFO:           streamlit: Not installed
2025-02-06 20:17:38,994:INFO:             prophet: Not installed
2025-02-06 20:17:38,994:INFO:None
2025-02-06 20:17:38,994:INFO:Set up data.
2025-02-06 20:17:39,000:INFO:Set up folding strategy.
2025-02-06 20:17:39,000:INFO:Set up train/test split.
2025-02-06 20:17:39,005:INFO:Set up index.
2025-02-06 20:17:39,006:INFO:Assigning column types.
2025-02-06 20:17:39,011:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 20:17:39,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,093:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 20:17:39,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:17:39,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,171:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 20:17:39,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,251:INFO:Preparing preprocessing pipeline...
2025-02-06 20:17:39,252:INFO:Set up simple imputation.
2025-02-06 20:17:39,252:INFO:Set up feature normalization.
2025-02-06 20:17:39,275:INFO:Finished creating preprocessing pipeline.
2025-02-06 20:17:39,277:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 20:17:39,277:INFO:Creating final display dataframe.
2025-02-06 20:17:39,346:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              df9e
2025-02-06 20:17:39,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:17:39,425:INFO:setup() successfully completed in 0.46s...............
2025-02-06 20:17:39,425:INFO:Initializing compare_models()
2025-02-06 20:17:39,426:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 20:17:39,426:INFO:Checking exceptions
2025-02-06 20:17:39,429:INFO:Preparing display monitor
2025-02-06 20:17:39,439:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 20:17:39,439:INFO:Total runtime is 0.0 minutes
2025-02-06 20:17:39,442:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:39,442:INFO:Initializing create_model()
2025-02-06 20:17:39,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002688C103110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:39,442:INFO:Checking exceptions
2025-02-06 20:17:39,442:INFO:Importing libraries
2025-02-06 20:17:39,442:INFO:Copying training dataset
2025-02-06 20:17:39,449:INFO:Defining folds
2025-02-06 20:17:39,449:INFO:Declaring metric variables
2025-02-06 20:17:39,451:INFO:Importing untrained model
2025-02-06 20:17:39,452:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:39,455:INFO:Starting cross validation
2025-02-06 20:17:39,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:42,420:INFO:Calculating mean and std
2025-02-06 20:17:42,422:INFO:Creating metrics dataframe
2025-02-06 20:17:42,423:INFO:Uploading results into container
2025-02-06 20:17:42,424:INFO:Uploading model into container now
2025-02-06 20:17:42,424:INFO:_master_model_container: 1
2025-02-06 20:17:42,424:INFO:_display_container: 2
2025-02-06 20:17:42,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:42,425:INFO:create_model() successfully completed......................................
2025-02-06 20:17:42,492:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:42,492:INFO:Creating metrics dataframe
2025-02-06 20:17:42,497:INFO:Initializing Logistic Regression
2025-02-06 20:17:42,497:INFO:Total runtime is 0.05096547206242879 minutes
2025-02-06 20:17:42,499:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:42,499:INFO:Initializing create_model()
2025-02-06 20:17:42,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002688C103110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:42,499:INFO:Checking exceptions
2025-02-06 20:17:42,499:INFO:Importing libraries
2025-02-06 20:17:42,499:INFO:Copying training dataset
2025-02-06 20:17:42,508:INFO:Defining folds
2025-02-06 20:17:42,508:INFO:Declaring metric variables
2025-02-06 20:17:42,509:INFO:Importing untrained model
2025-02-06 20:17:42,512:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:42,514:INFO:Starting cross validation
2025-02-06 20:17:42,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:43,917:INFO:Calculating mean and std
2025-02-06 20:17:43,918:INFO:Creating metrics dataframe
2025-02-06 20:17:43,919:INFO:Uploading results into container
2025-02-06 20:17:43,920:INFO:Uploading model into container now
2025-02-06 20:17:43,920:INFO:_master_model_container: 2
2025-02-06 20:17:43,921:INFO:_display_container: 2
2025-02-06 20:17:43,921:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:43,921:INFO:create_model() successfully completed......................................
2025-02-06 20:17:43,991:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:43,991:INFO:Creating metrics dataframe
2025-02-06 20:17:43,995:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 20:17:43,999:INFO:Initializing create_model()
2025-02-06 20:17:43,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:43,999:INFO:Checking exceptions
2025-02-06 20:17:44,000:INFO:Importing libraries
2025-02-06 20:17:44,000:INFO:Copying training dataset
2025-02-06 20:17:44,006:INFO:Defining folds
2025-02-06 20:17:44,006:INFO:Declaring metric variables
2025-02-06 20:17:44,006:INFO:Importing untrained model
2025-02-06 20:17:44,006:INFO:Declaring custom model
2025-02-06 20:17:44,007:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:44,007:INFO:Cross validation set to False
2025-02-06 20:17:44,007:INFO:Fitting Model
2025-02-06 20:17:44,035:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:44,035:INFO:create_model() successfully completed......................................
2025-02-06 20:17:44,085:INFO:_master_model_container: 2
2025-02-06 20:17:44,085:INFO:_display_container: 2
2025-02-06 20:17:44,085:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:44,085:INFO:compare_models() successfully completed......................................
2025-02-06 20:17:44,085:INFO:Initializing create_model()
2025-02-06 20:17:44,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:44,085:INFO:Checking exceptions
2025-02-06 20:17:44,092:INFO:Importing libraries
2025-02-06 20:17:44,092:INFO:Copying training dataset
2025-02-06 20:17:44,098:INFO:Defining folds
2025-02-06 20:17:44,098:INFO:Declaring metric variables
2025-02-06 20:17:44,100:INFO:Importing untrained model
2025-02-06 20:17:44,101:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:44,104:INFO:Starting cross validation
2025-02-06 20:17:44,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:44,950:INFO:Calculating mean and std
2025-02-06 20:17:44,950:INFO:Creating metrics dataframe
2025-02-06 20:17:44,953:INFO:Finalizing model
2025-02-06 20:17:44,973:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 20:17:44,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
2025-02-06 20:17:44,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 20:17:44,974:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 20:17:44,974:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 20:17:44,975:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 20:17:44,975:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 20:17:45,092:INFO:Uploading results into container
2025-02-06 20:17:45,092:INFO:Uploading model into container now
2025-02-06 20:17:45,099:INFO:_master_model_container: 3
2025-02-06 20:17:45,100:INFO:_display_container: 3
2025-02-06 20:17:45,100:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:45,100:INFO:create_model() successfully completed......................................
2025-02-06 20:17:45,175:INFO:Initializing tune_model()
2025-02-06 20:17:45,175:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 20:17:45,175:INFO:Checking exceptions
2025-02-06 20:17:45,187:INFO:Copying training dataset
2025-02-06 20:17:45,193:INFO:Checking base model
2025-02-06 20:17:45,193:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 20:17:45,195:INFO:Declaring metric variables
2025-02-06 20:17:45,197:INFO:Defining Hyperparameters
2025-02-06 20:17:45,241:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 20:17:45,241:INFO:Tuning with n_jobs=-1
2025-02-06 20:17:45,241:INFO:Initializing RandomizedSearchCV
2025-02-06 20:17:48,651:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 20:17:48,651:INFO:Hyperparameter search completed
2025-02-06 20:17:48,651:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:48,652:INFO:Initializing create_model()
2025-02-06 20:17:48,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002688AF82290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 20:17:48,652:INFO:Checking exceptions
2025-02-06 20:17:48,652:INFO:Importing libraries
2025-02-06 20:17:48,652:INFO:Copying training dataset
2025-02-06 20:17:48,661:INFO:Defining folds
2025-02-06 20:17:48,661:INFO:Declaring metric variables
2025-02-06 20:17:48,663:INFO:Importing untrained model
2025-02-06 20:17:48,663:INFO:Declaring custom model
2025-02-06 20:17:48,665:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:48,670:INFO:Starting cross validation
2025-02-06 20:17:48,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:48,987:INFO:Calculating mean and std
2025-02-06 20:17:48,988:INFO:Creating metrics dataframe
2025-02-06 20:17:48,991:INFO:Finalizing model
2025-02-06 20:17:49,008:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 20:17:49,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.
2025-02-06 20:17:49,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 20:17:49,009:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 20:17:49,009:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 20:17:49,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 20:17:49,009:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 20:17:49,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:49,078:INFO:Uploading results into container
2025-02-06 20:17:49,079:INFO:Uploading model into container now
2025-02-06 20:17:49,079:INFO:_master_model_container: 4
2025-02-06 20:17:49,079:INFO:_display_container: 4
2025-02-06 20:17:49,079:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:49,079:INFO:create_model() successfully completed......................................
2025-02-06 20:17:49,138:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:49,139:INFO:choose_better activated
2025-02-06 20:17:49,140:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:49,140:INFO:Initializing create_model()
2025-02-06 20:17:49,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:49,141:INFO:Checking exceptions
2025-02-06 20:17:49,142:INFO:Importing libraries
2025-02-06 20:17:49,142:INFO:Copying training dataset
2025-02-06 20:17:49,150:INFO:Defining folds
2025-02-06 20:17:49,150:INFO:Declaring metric variables
2025-02-06 20:17:49,150:INFO:Importing untrained model
2025-02-06 20:17:49,150:INFO:Declaring custom model
2025-02-06 20:17:49,150:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:49,150:INFO:Starting cross validation
2025-02-06 20:17:49,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:49,837:INFO:Calculating mean and std
2025-02-06 20:17:49,837:INFO:Creating metrics dataframe
2025-02-06 20:17:49,839:INFO:Finalizing model
2025-02-06 20:17:49,857:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 20:17:49,858:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
2025-02-06 20:17:49,858:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 20:17:49,858:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 20:17:49,858:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 20:17:49,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 20:17:49,859:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 20:17:49,971:INFO:Uploading results into container
2025-02-06 20:17:49,972:INFO:Uploading model into container now
2025-02-06 20:17:49,972:INFO:_master_model_container: 5
2025-02-06 20:17:49,972:INFO:_display_container: 5
2025-02-06 20:17:49,972:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:49,972:INFO:create_model() successfully completed......................................
2025-02-06 20:17:50,042:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:50,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 20:17:50,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 20:17:50,043:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 20:17:50,043:INFO:choose_better completed
2025-02-06 20:17:50,049:INFO:_master_model_container: 5
2025-02-06 20:17:50,049:INFO:_display_container: 4
2025-02-06 20:17:50,049:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:50,049:INFO:tune_model() successfully completed......................................
2025-02-06 20:17:50,095:INFO:Initializing create_model()
2025-02-06 20:17:50,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:50,095:INFO:Checking exceptions
2025-02-06 20:17:50,102:INFO:Importing libraries
2025-02-06 20:17:50,102:INFO:Copying training dataset
2025-02-06 20:17:50,109:INFO:Defining folds
2025-02-06 20:17:50,109:INFO:Declaring metric variables
2025-02-06 20:17:50,111:INFO:Importing untrained model
2025-02-06 20:17:50,112:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:50,115:INFO:Starting cross validation
2025-02-06 20:17:50,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:50,184:INFO:Calculating mean and std
2025-02-06 20:17:50,184:INFO:Creating metrics dataframe
2025-02-06 20:17:50,188:INFO:Finalizing model
2025-02-06 20:17:50,218:INFO:Uploading results into container
2025-02-06 20:17:50,218:INFO:Uploading model into container now
2025-02-06 20:17:50,224:INFO:_master_model_container: 6
2025-02-06 20:17:50,224:INFO:_display_container: 5
2025-02-06 20:17:50,224:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:50,224:INFO:create_model() successfully completed......................................
2025-02-06 20:17:50,290:INFO:Initializing tune_model()
2025-02-06 20:17:50,290:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 20:17:50,290:INFO:Checking exceptions
2025-02-06 20:17:50,299:INFO:Copying training dataset
2025-02-06 20:17:50,304:INFO:Checking base model
2025-02-06 20:17:50,304:INFO:Base model : Logistic Regression
2025-02-06 20:17:50,305:INFO:Declaring metric variables
2025-02-06 20:17:50,306:INFO:Defining Hyperparameters
2025-02-06 20:17:50,352:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 20:17:50,352:INFO:Tuning with n_jobs=-1
2025-02-06 20:17:50,352:INFO:Initializing RandomizedSearchCV
2025-02-06 20:17:50,750:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 20:17:50,750:INFO:Hyperparameter search completed
2025-02-06 20:17:50,750:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:50,750:INFO:Initializing create_model()
2025-02-06 20:17:50,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000268C7952F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 20:17:50,750:INFO:Checking exceptions
2025-02-06 20:17:50,750:INFO:Importing libraries
2025-02-06 20:17:50,750:INFO:Copying training dataset
2025-02-06 20:17:50,756:INFO:Defining folds
2025-02-06 20:17:50,756:INFO:Declaring metric variables
2025-02-06 20:17:50,758:INFO:Importing untrained model
2025-02-06 20:17:50,758:INFO:Declaring custom model
2025-02-06 20:17:50,759:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:50,762:INFO:Starting cross validation
2025-02-06 20:17:50,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:50,840:INFO:Calculating mean and std
2025-02-06 20:17:50,840:INFO:Creating metrics dataframe
2025-02-06 20:17:50,842:INFO:Finalizing model
2025-02-06 20:17:50,868:INFO:Uploading results into container
2025-02-06 20:17:50,870:INFO:Uploading model into container now
2025-02-06 20:17:50,870:INFO:_master_model_container: 7
2025-02-06 20:17:50,870:INFO:_display_container: 6
2025-02-06 20:17:50,870:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:50,870:INFO:create_model() successfully completed......................................
2025-02-06 20:17:50,916:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:50,916:INFO:choose_better activated
2025-02-06 20:17:50,918:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:50,918:INFO:Initializing create_model()
2025-02-06 20:17:50,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:50,918:INFO:Checking exceptions
2025-02-06 20:17:50,920:INFO:Importing libraries
2025-02-06 20:17:50,920:INFO:Copying training dataset
2025-02-06 20:17:50,925:INFO:Defining folds
2025-02-06 20:17:50,925:INFO:Declaring metric variables
2025-02-06 20:17:50,925:INFO:Importing untrained model
2025-02-06 20:17:50,925:INFO:Declaring custom model
2025-02-06 20:17:50,925:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:50,925:INFO:Starting cross validation
2025-02-06 20:17:50,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:50,982:INFO:Calculating mean and std
2025-02-06 20:17:50,982:INFO:Creating metrics dataframe
2025-02-06 20:17:50,983:INFO:Finalizing model
2025-02-06 20:17:51,009:INFO:Uploading results into container
2025-02-06 20:17:51,009:INFO:Uploading model into container now
2025-02-06 20:17:51,009:INFO:_master_model_container: 8
2025-02-06 20:17:51,009:INFO:_display_container: 7
2025-02-06 20:17:51,011:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:51,011:INFO:create_model() successfully completed......................................
2025-02-06 20:17:51,058:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:51,059:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 20:17:51,059:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 20:17:51,059:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 20:17:51,059:INFO:choose_better completed
2025-02-06 20:17:51,064:INFO:_master_model_container: 8
2025-02-06 20:17:51,064:INFO:_display_container: 6
2025-02-06 20:17:51,064:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:51,064:INFO:tune_model() successfully completed......................................
2025-02-06 20:17:51,097:INFO:Initializing compare_models()
2025-02-06 20:17:51,097:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 20:17:51,098:INFO:Checking exceptions
2025-02-06 20:17:51,100:INFO:Preparing display monitor
2025-02-06 20:17:51,109:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 20:17:51,109:INFO:Total runtime is 0.0 minutes
2025-02-06 20:17:51,111:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:51,111:INFO:Initializing create_model()
2025-02-06 20:17:51,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002688BA67290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:51,111:INFO:Checking exceptions
2025-02-06 20:17:51,111:INFO:Importing libraries
2025-02-06 20:17:51,111:INFO:Copying training dataset
2025-02-06 20:17:51,117:INFO:Defining folds
2025-02-06 20:17:51,117:INFO:Declaring metric variables
2025-02-06 20:17:51,118:INFO:Importing untrained model
2025-02-06 20:17:51,118:INFO:Declaring custom model
2025-02-06 20:17:51,121:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:51,124:INFO:Starting cross validation
2025-02-06 20:17:51,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:51,407:INFO:Calculating mean and std
2025-02-06 20:17:51,408:INFO:Creating metrics dataframe
2025-02-06 20:17:51,409:INFO:Uploading results into container
2025-02-06 20:17:51,410:INFO:Uploading model into container now
2025-02-06 20:17:51,410:INFO:_master_model_container: 9
2025-02-06 20:17:51,410:INFO:_display_container: 7
2025-02-06 20:17:51,410:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:51,410:INFO:create_model() successfully completed......................................
2025-02-06 20:17:51,470:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:51,470:INFO:Creating metrics dataframe
2025-02-06 20:17:51,474:INFO:Initializing custom model Logistic Regression
2025-02-06 20:17:51,474:INFO:Total runtime is 0.0060831109682718916 minutes
2025-02-06 20:17:51,476:INFO:SubProcess create_model() called ==================================
2025-02-06 20:17:51,476:INFO:Initializing create_model()
2025-02-06 20:17:51,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002688BA67290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:51,476:INFO:Checking exceptions
2025-02-06 20:17:51,476:INFO:Importing libraries
2025-02-06 20:17:51,476:INFO:Copying training dataset
2025-02-06 20:17:51,484:INFO:Defining folds
2025-02-06 20:17:51,484:INFO:Declaring metric variables
2025-02-06 20:17:51,487:INFO:Importing untrained model
2025-02-06 20:17:51,487:INFO:Declaring custom model
2025-02-06 20:17:51,489:INFO:Logistic Regression Imported successfully
2025-02-06 20:17:51,494:INFO:Starting cross validation
2025-02-06 20:17:51,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:17:51,572:INFO:Calculating mean and std
2025-02-06 20:17:51,572:INFO:Creating metrics dataframe
2025-02-06 20:17:51,573:INFO:Uploading results into container
2025-02-06 20:17:51,574:INFO:Uploading model into container now
2025-02-06 20:17:51,574:INFO:_master_model_container: 10
2025-02-06 20:17:51,574:INFO:_display_container: 7
2025-02-06 20:17:51,574:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 20:17:51,574:INFO:create_model() successfully completed......................................
2025-02-06 20:17:51,630:INFO:SubProcess create_model() end ==================================
2025-02-06 20:17:51,630:INFO:Creating metrics dataframe
2025-02-06 20:17:51,634:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 20:17:51,638:INFO:Initializing create_model()
2025-02-06 20:17:51,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 20:17:51,638:INFO:Checking exceptions
2025-02-06 20:17:51,639:INFO:Importing libraries
2025-02-06 20:17:51,639:INFO:Copying training dataset
2025-02-06 20:17:51,644:INFO:Defining folds
2025-02-06 20:17:51,644:INFO:Declaring metric variables
2025-02-06 20:17:51,644:INFO:Importing untrained model
2025-02-06 20:17:51,644:INFO:Declaring custom model
2025-02-06 20:17:51,644:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:17:51,646:INFO:Cross validation set to False
2025-02-06 20:17:51,646:INFO:Fitting Model
2025-02-06 20:17:51,659:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 20:17:51,659:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.
2025-02-06 20:17:51,660:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 20:17:51,660:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 20:17:51,660:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 20:17:51,660:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 20:17:51,660:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 20:17:51,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:17:51,685:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:51,685:INFO:create_model() successfully completed......................................
2025-02-06 20:17:51,755:INFO:_master_model_container: 10
2025-02-06 20:17:51,756:INFO:_display_container: 7
2025-02-06 20:17:51,756:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:17:51,756:INFO:compare_models() successfully completed......................................
2025-02-06 20:17:51,757:INFO:Initializing predict_model()
2025-02-06 20:17:51,757:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000268C46F22A0>)
2025-02-06 20:17:51,757:INFO:Checking exceptions
2025-02-06 20:17:51,757:INFO:Preloading libraries
2025-02-06 20:17:51,758:INFO:Set up data.
2025-02-06 20:17:51,767:INFO:Set up index.
2025-02-06 20:17:51,889:INFO:Initializing predict_model()
2025-02-06 20:17:51,889:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002688BA787D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000268C46F22A0>)
2025-02-06 20:17:51,889:INFO:Checking exceptions
2025-02-06 20:17:51,889:INFO:Preloading libraries
2025-02-06 20:45:56,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:45:56,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:45:56,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:45:56,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 20:46:29,612:INFO:PyCaret ClassificationExperiment
2025-02-06 20:46:29,612:INFO:Logging name: clf-default-name
2025-02-06 20:46:29,612:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 20:46:29,612:INFO:version 3.3.2
2025-02-06 20:46:29,612:INFO:Initializing setup()
2025-02-06 20:46:29,612:INFO:self.USI: 9b24
2025-02-06 20:46:29,612:INFO:self._variable_keys: {'gpu_param', 'data', 'X_train', 'is_multiclass', 'log_plots_param', 'fold_generator', 'X', 'pipeline', 'logging_param', 'seed', 'y_train', 'y_test', 'html_param', '_available_plots', 'fold_groups_param', 'fold_shuffle_param', 'exp_id', '_ml_usecase', 'y', 'exp_name_log', 'idx', 'X_test', 'memory', 'USI', 'n_jobs_param', 'fix_imbalance', 'target_param', 'gpu_n_jobs_param'}
2025-02-06 20:46:29,612:INFO:Checking environment
2025-02-06 20:46:29,612:INFO:python_version: 3.11.9
2025-02-06 20:46:29,612:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 20:46:29,612:INFO:machine: AMD64
2025-02-06 20:46:29,612:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 20:46:29,617:INFO:Memory: svmem(total=67771465728, available=48176353280, percent=28.9, used=19595112448, free=48176353280)
2025-02-06 20:46:29,617:INFO:Physical Core: 8
2025-02-06 20:46:29,617:INFO:Logical Core: 16
2025-02-06 20:46:29,617:INFO:Checking libraries
2025-02-06 20:46:29,617:INFO:System:
2025-02-06 20:46:29,617:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 20:46:29,617:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 20:46:29,617:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 20:46:29,617:INFO:PyCaret required dependencies:
2025-02-06 20:46:29,631:INFO:                 pip: 25.0
2025-02-06 20:46:29,631:INFO:          setuptools: 65.5.0
2025-02-06 20:46:29,631:INFO:             pycaret: 3.3.2
2025-02-06 20:46:29,631:INFO:             IPython: 8.32.0
2025-02-06 20:46:29,631:INFO:          ipywidgets: 8.1.5
2025-02-06 20:46:29,631:INFO:                tqdm: 4.67.1
2025-02-06 20:46:29,631:INFO:               numpy: 1.26.4
2025-02-06 20:46:29,631:INFO:              pandas: 2.1.4
2025-02-06 20:46:29,631:INFO:              jinja2: 3.1.5
2025-02-06 20:46:29,631:INFO:               scipy: 1.11.4
2025-02-06 20:46:29,631:INFO:              joblib: 1.3.2
2025-02-06 20:46:29,631:INFO:             sklearn: 1.4.2
2025-02-06 20:46:29,631:INFO:                pyod: 2.0.3
2025-02-06 20:46:29,631:INFO:            imblearn: 0.13.0
2025-02-06 20:46:29,631:INFO:   category_encoders: 2.7.0
2025-02-06 20:46:29,631:INFO:            lightgbm: 4.5.0
2025-02-06 20:46:29,631:INFO:               numba: 0.61.0
2025-02-06 20:46:29,631:INFO:            requests: 2.32.3
2025-02-06 20:46:29,631:INFO:          matplotlib: 3.7.5
2025-02-06 20:46:29,631:INFO:          scikitplot: 0.3.7
2025-02-06 20:46:29,631:INFO:         yellowbrick: 1.5
2025-02-06 20:46:29,631:INFO:              plotly: 5.24.1
2025-02-06 20:46:29,631:INFO:    plotly-resampler: Not installed
2025-02-06 20:46:29,631:INFO:             kaleido: 0.2.1
2025-02-06 20:46:29,631:INFO:           schemdraw: 0.15
2025-02-06 20:46:29,631:INFO:         statsmodels: 0.14.4
2025-02-06 20:46:29,631:INFO:              sktime: 0.26.0
2025-02-06 20:46:29,631:INFO:               tbats: 1.1.3
2025-02-06 20:46:29,631:INFO:            pmdarima: 2.0.4
2025-02-06 20:46:29,631:INFO:              psutil: 6.1.1
2025-02-06 20:46:29,631:INFO:          markupsafe: 3.0.2
2025-02-06 20:46:29,631:INFO:             pickle5: Not installed
2025-02-06 20:46:29,631:INFO:         cloudpickle: 3.1.1
2025-02-06 20:46:29,631:INFO:         deprecation: 2.1.0
2025-02-06 20:46:29,631:INFO:              xxhash: 3.5.0
2025-02-06 20:46:29,631:INFO:           wurlitzer: Not installed
2025-02-06 20:46:29,631:INFO:PyCaret optional dependencies:
2025-02-06 20:46:29,637:INFO:                shap: Not installed
2025-02-06 20:46:29,638:INFO:           interpret: Not installed
2025-02-06 20:46:29,638:INFO:                umap: Not installed
2025-02-06 20:46:29,638:INFO:     ydata_profiling: Not installed
2025-02-06 20:46:29,638:INFO:  explainerdashboard: Not installed
2025-02-06 20:46:29,638:INFO:             autoviz: Not installed
2025-02-06 20:46:29,638:INFO:           fairlearn: Not installed
2025-02-06 20:46:29,638:INFO:          deepchecks: Not installed
2025-02-06 20:46:29,638:INFO:             xgboost: Not installed
2025-02-06 20:46:29,638:INFO:            catboost: Not installed
2025-02-06 20:46:29,638:INFO:              kmodes: Not installed
2025-02-06 20:46:29,638:INFO:             mlxtend: Not installed
2025-02-06 20:46:29,638:INFO:       statsforecast: Not installed
2025-02-06 20:46:29,638:INFO:        tune_sklearn: Not installed
2025-02-06 20:46:29,638:INFO:                 ray: Not installed
2025-02-06 20:46:29,638:INFO:            hyperopt: Not installed
2025-02-06 20:46:29,638:INFO:              optuna: Not installed
2025-02-06 20:46:29,638:INFO:               skopt: Not installed
2025-02-06 20:46:29,638:INFO:              mlflow: Not installed
2025-02-06 20:46:29,638:INFO:              gradio: Not installed
2025-02-06 20:46:29,638:INFO:             fastapi: Not installed
2025-02-06 20:46:29,638:INFO:             uvicorn: Not installed
2025-02-06 20:46:29,638:INFO:              m2cgen: Not installed
2025-02-06 20:46:29,638:INFO:           evidently: Not installed
2025-02-06 20:46:29,638:INFO:               fugue: Not installed
2025-02-06 20:46:29,638:INFO:           streamlit: Not installed
2025-02-06 20:46:29,638:INFO:             prophet: Not installed
2025-02-06 20:46:29,638:INFO:None
2025-02-06 20:46:29,638:INFO:Set up data.
2025-02-06 20:46:29,646:INFO:Set up folding strategy.
2025-02-06 20:46:29,646:INFO:Set up train/test split.
2025-02-06 20:46:29,653:INFO:Set up index.
2025-02-06 20:46:29,654:INFO:Assigning column types.
2025-02-06 20:46:29,658:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 20:46:29,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,742:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 20:46:29,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,805:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 20:46:29,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,820:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 20:46:29,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,899:INFO:Preparing preprocessing pipeline...
2025-02-06 20:46:29,900:INFO:Set up simple imputation.
2025-02-06 20:46:29,911:INFO:Finished creating preprocessing pipeline.
2025-02-06 20:46:29,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 20:46:29,914:INFO:Creating final display dataframe.
2025-02-06 20:46:29,951:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              9b24
2025-02-06 20:46:29,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:29,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:30,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:30,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 20:46:30,030:INFO:setup() successfully completed in 0.42s...............
2025-02-06 20:46:30,030:INFO:Initializing create_model()
2025-02-06 20:46:30,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000163A9994150>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 20:46:30,030:INFO:Checking exceptions
2025-02-06 20:46:30,031:INFO:Importing libraries
2025-02-06 20:46:30,031:INFO:Copying training dataset
2025-02-06 20:46:30,033:INFO:Defining folds
2025-02-06 20:46:30,034:INFO:Declaring metric variables
2025-02-06 20:46:30,034:INFO:Importing untrained model
2025-02-06 20:46:30,034:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 20:46:30,034:INFO:Starting cross validation
2025-02-06 20:46:30,034:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 20:46:33,299:INFO:Calculating mean and std
2025-02-06 20:46:33,300:INFO:Creating metrics dataframe
2025-02-06 20:46:33,302:INFO:Finalizing model
2025-02-06 20:46:33,320:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 20:46:33,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
2025-02-06 20:46:33,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 20:46:33,322:INFO:[LightGBM] [Info] Total Bins 6715
2025-02-06 20:46:33,322:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 20:46:33,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 20:46:33,322:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 20:46:33,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 20:46:33,746:INFO:Uploading results into container
2025-02-06 20:46:33,746:INFO:Uploading model into container now
2025-02-06 20:46:33,747:INFO:_master_model_container: 1
2025-02-06 20:46:33,747:INFO:_display_container: 2
2025-02-06 20:46:33,747:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1234, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 20:46:33,748:INFO:create_model() successfully completed......................................
2025-02-06 21:11:55,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:11:55,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:11:55,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:11:55,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:12:19,387:INFO:PyCaret ClassificationExperiment
2025-02-06 21:12:19,387:INFO:Logging name: clf-default-name
2025-02-06 21:12:19,387:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:12:19,387:INFO:version 3.3.2
2025-02-06 21:12:19,387:INFO:Initializing setup()
2025-02-06 21:12:19,387:INFO:self.USI: a079
2025-02-06 21:12:19,388:INFO:self._variable_keys: {'html_param', '_available_plots', 'fix_imbalance', 'X_test', 'data', 'exp_id', 'fold_shuffle_param', 'exp_name_log', 'fold_generator', 'X_train', 'USI', '_ml_usecase', 'idx', 'seed', 'y', 'fold_groups_param', 'pipeline', 'gpu_param', 'y_train', 'log_plots_param', 'n_jobs_param', 'y_test', 'target_param', 'gpu_n_jobs_param', 'logging_param', 'memory', 'X', 'is_multiclass'}
2025-02-06 21:12:19,388:INFO:Checking environment
2025-02-06 21:12:19,388:INFO:python_version: 3.11.9
2025-02-06 21:12:19,388:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:12:19,388:INFO:machine: AMD64
2025-02-06 21:12:19,388:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:12:19,393:INFO:Memory: svmem(total=67771465728, available=48238387200, percent=28.8, used=19533078528, free=48238387200)
2025-02-06 21:12:19,393:INFO:Physical Core: 8
2025-02-06 21:12:19,393:INFO:Logical Core: 16
2025-02-06 21:12:19,393:INFO:Checking libraries
2025-02-06 21:12:19,393:INFO:System:
2025-02-06 21:12:19,393:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:12:19,393:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:12:19,393:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:12:19,393:INFO:PyCaret required dependencies:
2025-02-06 21:12:19,404:INFO:                 pip: 25.0
2025-02-06 21:12:19,404:INFO:          setuptools: 65.5.0
2025-02-06 21:12:19,404:INFO:             pycaret: 3.3.2
2025-02-06 21:12:19,404:INFO:             IPython: 8.32.0
2025-02-06 21:12:19,404:INFO:          ipywidgets: 8.1.5
2025-02-06 21:12:19,404:INFO:                tqdm: 4.67.1
2025-02-06 21:12:19,404:INFO:               numpy: 1.26.4
2025-02-06 21:12:19,404:INFO:              pandas: 2.1.4
2025-02-06 21:12:19,404:INFO:              jinja2: 3.1.5
2025-02-06 21:12:19,404:INFO:               scipy: 1.11.4
2025-02-06 21:12:19,404:INFO:              joblib: 1.3.2
2025-02-06 21:12:19,404:INFO:             sklearn: 1.4.2
2025-02-06 21:12:19,404:INFO:                pyod: 2.0.3
2025-02-06 21:12:19,404:INFO:            imblearn: 0.13.0
2025-02-06 21:12:19,404:INFO:   category_encoders: 2.7.0
2025-02-06 21:12:19,404:INFO:            lightgbm: 4.5.0
2025-02-06 21:12:19,404:INFO:               numba: 0.61.0
2025-02-06 21:12:19,406:INFO:            requests: 2.32.3
2025-02-06 21:12:19,406:INFO:          matplotlib: 3.7.5
2025-02-06 21:12:19,406:INFO:          scikitplot: 0.3.7
2025-02-06 21:12:19,406:INFO:         yellowbrick: 1.5
2025-02-06 21:12:19,406:INFO:              plotly: 5.24.1
2025-02-06 21:12:19,406:INFO:    plotly-resampler: Not installed
2025-02-06 21:12:19,406:INFO:             kaleido: 0.2.1
2025-02-06 21:12:19,406:INFO:           schemdraw: 0.15
2025-02-06 21:12:19,406:INFO:         statsmodels: 0.14.4
2025-02-06 21:12:19,406:INFO:              sktime: 0.26.0
2025-02-06 21:12:19,406:INFO:               tbats: 1.1.3
2025-02-06 21:12:19,406:INFO:            pmdarima: 2.0.4
2025-02-06 21:12:19,406:INFO:              psutil: 6.1.1
2025-02-06 21:12:19,406:INFO:          markupsafe: 3.0.2
2025-02-06 21:12:19,406:INFO:             pickle5: Not installed
2025-02-06 21:12:19,406:INFO:         cloudpickle: 3.1.1
2025-02-06 21:12:19,406:INFO:         deprecation: 2.1.0
2025-02-06 21:12:19,406:INFO:              xxhash: 3.5.0
2025-02-06 21:12:19,406:INFO:           wurlitzer: Not installed
2025-02-06 21:12:19,406:INFO:PyCaret optional dependencies:
2025-02-06 21:12:19,411:INFO:                shap: Not installed
2025-02-06 21:12:19,411:INFO:           interpret: Not installed
2025-02-06 21:12:19,411:INFO:                umap: Not installed
2025-02-06 21:12:19,411:INFO:     ydata_profiling: Not installed
2025-02-06 21:12:19,411:INFO:  explainerdashboard: Not installed
2025-02-06 21:12:19,411:INFO:             autoviz: Not installed
2025-02-06 21:12:19,411:INFO:           fairlearn: Not installed
2025-02-06 21:12:19,411:INFO:          deepchecks: Not installed
2025-02-06 21:12:19,411:INFO:             xgboost: Not installed
2025-02-06 21:12:19,411:INFO:            catboost: Not installed
2025-02-06 21:12:19,411:INFO:              kmodes: Not installed
2025-02-06 21:12:19,411:INFO:             mlxtend: Not installed
2025-02-06 21:12:19,411:INFO:       statsforecast: Not installed
2025-02-06 21:12:19,411:INFO:        tune_sklearn: Not installed
2025-02-06 21:12:19,411:INFO:                 ray: Not installed
2025-02-06 21:12:19,411:INFO:            hyperopt: Not installed
2025-02-06 21:12:19,411:INFO:              optuna: Not installed
2025-02-06 21:12:19,411:INFO:               skopt: Not installed
2025-02-06 21:12:19,411:INFO:              mlflow: Not installed
2025-02-06 21:12:19,411:INFO:              gradio: Not installed
2025-02-06 21:12:19,411:INFO:             fastapi: Not installed
2025-02-06 21:12:19,411:INFO:             uvicorn: Not installed
2025-02-06 21:12:19,411:INFO:              m2cgen: Not installed
2025-02-06 21:12:19,411:INFO:           evidently: Not installed
2025-02-06 21:12:19,411:INFO:               fugue: Not installed
2025-02-06 21:12:19,411:INFO:           streamlit: Not installed
2025-02-06 21:12:19,411:INFO:             prophet: Not installed
2025-02-06 21:12:19,411:INFO:None
2025-02-06 21:12:19,411:INFO:Set up data.
2025-02-06 21:12:19,421:INFO:Set up folding strategy.
2025-02-06 21:12:19,421:INFO:Set up train/test split.
2025-02-06 21:12:19,428:INFO:Set up index.
2025-02-06 21:12:19,429:INFO:Assigning column types.
2025-02-06 21:12:19,432:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:12:19,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,457:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,515:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:12:19,539:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:12:19,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,593:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:12:19,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,672:INFO:Preparing preprocessing pipeline...
2025-02-06 21:12:19,673:INFO:Set up simple imputation.
2025-02-06 21:12:19,686:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:12:19,689:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_2', 'VAR_3', 'VAR_4',
                                             'VAR_5', 'VAR_6', 'VAR_7', 'VAR_8',
                                             'VAR_9', 'VAR_11', 'VAR_13',
                                             'VAR_15', 'VAR_17', 'VAR_19',
                                             'VAR_20', 'VAR_22', 'VAR_24',
                                             'VAR_25', 'VAR_28', 'VAR_30',
                                             'VAR_32', 'VAR_33', 'VAR_34',
                                             'V...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-02-06 21:12:19,689:INFO:Creating final display dataframe.
2025-02-06 21:12:19,728:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 42)
4        Transformed data shape        (8211, 41)
5   Transformed train set shape        (5747, 41)
6    Transformed test set shape        (2464, 41)
7               Ignore features                 1
8              Numeric features                40
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              a079
2025-02-06 21:12:19,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:12:19,806:INFO:setup() successfully completed in 0.42s...............
2025-02-06 21:12:19,806:INFO:Initializing create_model()
2025-02-06 21:12:19,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000229ABAD7590>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 31, 'max_depth': 6, 'n_estimators': 500, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_lambda': 1, 'reg_alpha': 0.1})
2025-02-06 21:12:19,806:INFO:Checking exceptions
2025-02-06 21:12:19,807:INFO:Importing libraries
2025-02-06 21:12:19,807:INFO:Copying training dataset
2025-02-06 21:12:19,811:INFO:Defining folds
2025-02-06 21:12:19,811:INFO:Declaring metric variables
2025-02-06 21:12:19,811:INFO:Importing untrained model
2025-02-06 21:12:19,811:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:12:19,811:INFO:Starting cross validation
2025-02-06 21:12:19,811:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:12:23,133:INFO:Calculating mean and std
2025-02-06 21:12:23,133:INFO:Creating metrics dataframe
2025-02-06 21:12:23,135:INFO:Finalizing model
2025-02-06 21:12:23,151:INFO:[LightGBM] [Info] Number of positive: 1621, number of negative: 4126
2025-02-06 21:12:23,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001039 seconds.
2025-02-06 21:12:23,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:12:23,153:INFO:[LightGBM] [Info] Total Bins 6715
2025-02-06 21:12:23,153:INFO:[LightGBM] [Info] Number of data points in the train set: 5747, number of used features: 40
2025-02-06 21:12:23,154:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282060 -> initscore=-0.934265
2025-02-06 21:12:23,154:INFO:[LightGBM] [Info] Start training from score -0.934265
2025-02-06 21:12:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:12:23,535:INFO:Uploading results into container
2025-02-06 21:12:23,535:INFO:Uploading model into container now
2025-02-06 21:12:23,535:INFO:_master_model_container: 1
2025-02-06 21:12:23,535:INFO:_display_container: 2
2025-02-06 21:12:23,536:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=6,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1234, reg_alpha=0.1, reg_lambda=1, subsample=0.8,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:12:23,536:INFO:create_model() successfully completed......................................
2025-02-06 21:16:57,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:16:57,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:16:57,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:16:57,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:18:33,013:INFO:PyCaret ClassificationExperiment
2025-02-06 21:18:33,013:INFO:Logging name: clf-default-name
2025-02-06 21:18:33,013:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:18:33,013:INFO:version 3.3.2
2025-02-06 21:18:33,013:INFO:Initializing setup()
2025-02-06 21:18:33,013:INFO:self.USI: 83e3
2025-02-06 21:18:33,013:INFO:self._variable_keys: {'memory', 'html_param', 'y_test', 'seed', '_available_plots', 'X_train', 'data', 'y_train', 'is_multiclass', 'fold_shuffle_param', '_ml_usecase', 'logging_param', 'X', 'fold_generator', 'log_plots_param', 'target_param', 'X_test', 'fix_imbalance', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'fold_groups_param', 'exp_id', 'idx', 'pipeline', 'y', 'gpu_param'}
2025-02-06 21:18:33,013:INFO:Checking environment
2025-02-06 21:18:33,013:INFO:python_version: 3.11.9
2025-02-06 21:18:33,013:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:18:33,013:INFO:machine: AMD64
2025-02-06 21:18:33,013:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:18:33,018:INFO:Memory: svmem(total=67771465728, available=49945264128, percent=26.3, used=17826201600, free=49945264128)
2025-02-06 21:18:33,018:INFO:Physical Core: 8
2025-02-06 21:18:33,018:INFO:Logical Core: 16
2025-02-06 21:18:33,018:INFO:Checking libraries
2025-02-06 21:18:33,018:INFO:System:
2025-02-06 21:18:33,018:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:18:33,018:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:18:33,018:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:18:33,018:INFO:PyCaret required dependencies:
2025-02-06 21:18:33,033:INFO:                 pip: 25.0
2025-02-06 21:18:33,033:INFO:          setuptools: 65.5.0
2025-02-06 21:18:33,033:INFO:             pycaret: 3.3.2
2025-02-06 21:18:33,033:INFO:             IPython: 8.32.0
2025-02-06 21:18:33,033:INFO:          ipywidgets: 8.1.5
2025-02-06 21:18:33,033:INFO:                tqdm: 4.67.1
2025-02-06 21:18:33,033:INFO:               numpy: 1.26.4
2025-02-06 21:18:33,033:INFO:              pandas: 2.1.4
2025-02-06 21:18:33,033:INFO:              jinja2: 3.1.5
2025-02-06 21:18:33,033:INFO:               scipy: 1.11.4
2025-02-06 21:18:33,033:INFO:              joblib: 1.3.2
2025-02-06 21:18:33,033:INFO:             sklearn: 1.4.2
2025-02-06 21:18:33,033:INFO:                pyod: 2.0.3
2025-02-06 21:18:33,033:INFO:            imblearn: 0.13.0
2025-02-06 21:18:33,033:INFO:   category_encoders: 2.7.0
2025-02-06 21:18:33,033:INFO:            lightgbm: 4.5.0
2025-02-06 21:18:33,033:INFO:               numba: 0.61.0
2025-02-06 21:18:33,033:INFO:            requests: 2.32.3
2025-02-06 21:18:33,033:INFO:          matplotlib: 3.7.5
2025-02-06 21:18:33,033:INFO:          scikitplot: 0.3.7
2025-02-06 21:18:33,034:INFO:         yellowbrick: 1.5
2025-02-06 21:18:33,034:INFO:              plotly: 5.24.1
2025-02-06 21:18:33,034:INFO:    plotly-resampler: Not installed
2025-02-06 21:18:33,034:INFO:             kaleido: 0.2.1
2025-02-06 21:18:33,034:INFO:           schemdraw: 0.15
2025-02-06 21:18:33,034:INFO:         statsmodels: 0.14.4
2025-02-06 21:18:33,034:INFO:              sktime: 0.26.0
2025-02-06 21:18:33,034:INFO:               tbats: 1.1.3
2025-02-06 21:18:33,034:INFO:            pmdarima: 2.0.4
2025-02-06 21:18:33,034:INFO:              psutil: 6.1.1
2025-02-06 21:18:33,034:INFO:          markupsafe: 3.0.2
2025-02-06 21:18:33,034:INFO:             pickle5: Not installed
2025-02-06 21:18:33,034:INFO:         cloudpickle: 3.1.1
2025-02-06 21:18:33,034:INFO:         deprecation: 2.1.0
2025-02-06 21:18:33,034:INFO:              xxhash: 3.5.0
2025-02-06 21:18:33,034:INFO:           wurlitzer: Not installed
2025-02-06 21:18:33,034:INFO:PyCaret optional dependencies:
2025-02-06 21:18:33,039:INFO:                shap: Not installed
2025-02-06 21:18:33,039:INFO:           interpret: Not installed
2025-02-06 21:18:33,039:INFO:                umap: Not installed
2025-02-06 21:18:33,039:INFO:     ydata_profiling: Not installed
2025-02-06 21:18:33,039:INFO:  explainerdashboard: Not installed
2025-02-06 21:18:33,039:INFO:             autoviz: Not installed
2025-02-06 21:18:33,039:INFO:           fairlearn: Not installed
2025-02-06 21:18:33,039:INFO:          deepchecks: Not installed
2025-02-06 21:18:33,039:INFO:             xgboost: Not installed
2025-02-06 21:18:33,039:INFO:            catboost: Not installed
2025-02-06 21:18:33,039:INFO:              kmodes: Not installed
2025-02-06 21:18:33,039:INFO:             mlxtend: Not installed
2025-02-06 21:18:33,039:INFO:       statsforecast: Not installed
2025-02-06 21:18:33,039:INFO:        tune_sklearn: Not installed
2025-02-06 21:18:33,039:INFO:                 ray: Not installed
2025-02-06 21:18:33,039:INFO:            hyperopt: Not installed
2025-02-06 21:18:33,039:INFO:              optuna: Not installed
2025-02-06 21:18:33,039:INFO:               skopt: Not installed
2025-02-06 21:18:33,039:INFO:              mlflow: Not installed
2025-02-06 21:18:33,039:INFO:              gradio: Not installed
2025-02-06 21:18:33,039:INFO:             fastapi: Not installed
2025-02-06 21:18:33,039:INFO:             uvicorn: Not installed
2025-02-06 21:18:33,039:INFO:              m2cgen: Not installed
2025-02-06 21:18:33,039:INFO:           evidently: Not installed
2025-02-06 21:18:33,039:INFO:               fugue: Not installed
2025-02-06 21:18:33,039:INFO:           streamlit: Not installed
2025-02-06 21:18:33,039:INFO:             prophet: Not installed
2025-02-06 21:18:33,039:INFO:None
2025-02-06 21:18:33,039:INFO:Set up data.
2025-02-06 21:18:33,046:INFO:Set up folding strategy.
2025-02-06 21:18:33,046:INFO:Set up train/test split.
2025-02-06 21:18:33,052:INFO:Set up index.
2025-02-06 21:18:33,052:INFO:Assigning column types.
2025-02-06 21:18:33,057:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:18:33,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,082:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,125:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,140:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:18:33,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:18:33,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,220:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:18:33,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,301:INFO:Preparing preprocessing pipeline...
2025-02-06 21:18:33,303:INFO:Set up simple imputation.
2025-02-06 21:18:33,303:INFO:Set up feature normalization.
2025-02-06 21:18:33,325:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:18:33,327:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:18:33,327:INFO:Creating final display dataframe.
2025-02-06 21:18:33,399:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              83e3
2025-02-06 21:18:33,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:18:33,479:INFO:setup() successfully completed in 0.47s...............
2025-02-06 21:18:33,479:INFO:Initializing compare_models()
2025-02-06 21:18:33,479:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:18:33,479:INFO:Checking exceptions
2025-02-06 21:18:33,483:INFO:Preparing display monitor
2025-02-06 21:18:33,496:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:18:33,496:INFO:Total runtime is 0.0 minutes
2025-02-06 21:18:33,498:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:33,498:INFO:Initializing create_model()
2025-02-06 21:18:33,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010FD487CF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:33,498:INFO:Checking exceptions
2025-02-06 21:18:33,498:INFO:Importing libraries
2025-02-06 21:18:33,498:INFO:Copying training dataset
2025-02-06 21:18:33,503:INFO:Defining folds
2025-02-06 21:18:33,503:INFO:Declaring metric variables
2025-02-06 21:18:33,505:INFO:Importing untrained model
2025-02-06 21:18:33,506:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:33,510:INFO:Starting cross validation
2025-02-06 21:18:33,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:36,561:INFO:Calculating mean and std
2025-02-06 21:18:36,562:INFO:Creating metrics dataframe
2025-02-06 21:18:36,564:INFO:Uploading results into container
2025-02-06 21:18:36,565:INFO:Uploading model into container now
2025-02-06 21:18:36,565:INFO:_master_model_container: 1
2025-02-06 21:18:36,565:INFO:_display_container: 2
2025-02-06 21:18:36,566:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:36,566:INFO:create_model() successfully completed......................................
2025-02-06 21:18:36,635:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:36,635:INFO:Creating metrics dataframe
2025-02-06 21:18:36,640:INFO:Initializing Logistic Regression
2025-02-06 21:18:36,640:INFO:Total runtime is 0.05239627758661906 minutes
2025-02-06 21:18:36,642:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:36,642:INFO:Initializing create_model()
2025-02-06 21:18:36,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010FD487CF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:36,642:INFO:Checking exceptions
2025-02-06 21:18:36,643:INFO:Importing libraries
2025-02-06 21:18:36,643:INFO:Copying training dataset
2025-02-06 21:18:36,650:INFO:Defining folds
2025-02-06 21:18:36,650:INFO:Declaring metric variables
2025-02-06 21:18:36,652:INFO:Importing untrained model
2025-02-06 21:18:36,653:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:36,656:INFO:Starting cross validation
2025-02-06 21:18:36,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:38,115:INFO:Calculating mean and std
2025-02-06 21:18:38,116:INFO:Creating metrics dataframe
2025-02-06 21:18:38,117:INFO:Uploading results into container
2025-02-06 21:18:38,118:INFO:Uploading model into container now
2025-02-06 21:18:38,118:INFO:_master_model_container: 2
2025-02-06 21:18:38,118:INFO:_display_container: 2
2025-02-06 21:18:38,118:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:38,118:INFO:create_model() successfully completed......................................
2025-02-06 21:18:38,193:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:38,193:INFO:Creating metrics dataframe
2025-02-06 21:18:38,197:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:18:38,201:INFO:Initializing create_model()
2025-02-06 21:18:38,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:38,201:INFO:Checking exceptions
2025-02-06 21:18:38,203:INFO:Importing libraries
2025-02-06 21:18:38,203:INFO:Copying training dataset
2025-02-06 21:18:38,210:INFO:Defining folds
2025-02-06 21:18:38,211:INFO:Declaring metric variables
2025-02-06 21:18:38,211:INFO:Importing untrained model
2025-02-06 21:18:38,211:INFO:Declaring custom model
2025-02-06 21:18:38,211:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:38,211:INFO:Cross validation set to False
2025-02-06 21:18:38,211:INFO:Fitting Model
2025-02-06 21:18:38,242:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:38,242:INFO:create_model() successfully completed......................................
2025-02-06 21:18:38,294:INFO:_master_model_container: 2
2025-02-06 21:18:38,294:INFO:_display_container: 2
2025-02-06 21:18:38,294:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:38,294:INFO:compare_models() successfully completed......................................
2025-02-06 21:18:38,294:INFO:Initializing create_model()
2025-02-06 21:18:38,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:38,294:INFO:Checking exceptions
2025-02-06 21:18:38,300:INFO:Importing libraries
2025-02-06 21:18:38,300:INFO:Copying training dataset
2025-02-06 21:18:38,306:INFO:Defining folds
2025-02-06 21:18:38,306:INFO:Declaring metric variables
2025-02-06 21:18:38,308:INFO:Importing untrained model
2025-02-06 21:18:38,310:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:38,312:INFO:Starting cross validation
2025-02-06 21:18:38,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:39,094:INFO:Calculating mean and std
2025-02-06 21:18:39,095:INFO:Creating metrics dataframe
2025-02-06 21:18:39,100:INFO:Finalizing model
2025-02-06 21:18:39,119:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:18:39,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.
2025-02-06 21:18:39,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:18:39,121:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:18:39,121:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:18:39,121:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:18:39,121:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:18:39,234:INFO:Uploading results into container
2025-02-06 21:18:39,234:INFO:Uploading model into container now
2025-02-06 21:18:39,241:INFO:_master_model_container: 3
2025-02-06 21:18:39,241:INFO:_display_container: 3
2025-02-06 21:18:39,242:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:39,242:INFO:create_model() successfully completed......................................
2025-02-06 21:18:39,317:INFO:Initializing tune_model()
2025-02-06 21:18:39,317:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:18:39,317:INFO:Checking exceptions
2025-02-06 21:18:39,329:INFO:Copying training dataset
2025-02-06 21:18:39,339:INFO:Checking base model
2025-02-06 21:18:39,339:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:18:39,342:INFO:Declaring metric variables
2025-02-06 21:18:39,344:INFO:Defining Hyperparameters
2025-02-06 21:18:39,413:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:18:39,413:INFO:Tuning with n_jobs=-1
2025-02-06 21:18:39,413:INFO:Initializing RandomizedSearchCV
2025-02-06 21:18:42,913:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:18:42,914:INFO:Hyperparameter search completed
2025-02-06 21:18:42,914:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:42,916:INFO:Initializing create_model()
2025-02-06 21:18:42,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010F906BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:18:42,916:INFO:Checking exceptions
2025-02-06 21:18:42,916:INFO:Importing libraries
2025-02-06 21:18:42,916:INFO:Copying training dataset
2025-02-06 21:18:42,925:INFO:Defining folds
2025-02-06 21:18:42,925:INFO:Declaring metric variables
2025-02-06 21:18:42,927:INFO:Importing untrained model
2025-02-06 21:18:42,927:INFO:Declaring custom model
2025-02-06 21:18:42,929:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:42,933:INFO:Starting cross validation
2025-02-06 21:18:42,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:43,348:INFO:Calculating mean and std
2025-02-06 21:18:43,349:INFO:Creating metrics dataframe
2025-02-06 21:18:43,353:INFO:Finalizing model
2025-02-06 21:18:43,370:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:18:43,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.
2025-02-06 21:18:43,371:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:18:43,372:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:18:43,372:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:18:43,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:18:43,372:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:18:43,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:43,437:INFO:Uploading results into container
2025-02-06 21:18:43,438:INFO:Uploading model into container now
2025-02-06 21:18:43,438:INFO:_master_model_container: 4
2025-02-06 21:18:43,438:INFO:_display_container: 4
2025-02-06 21:18:43,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:43,438:INFO:create_model() successfully completed......................................
2025-02-06 21:18:43,509:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:43,509:INFO:choose_better activated
2025-02-06 21:18:43,512:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:43,512:INFO:Initializing create_model()
2025-02-06 21:18:43,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:43,513:INFO:Checking exceptions
2025-02-06 21:18:43,514:INFO:Importing libraries
2025-02-06 21:18:43,514:INFO:Copying training dataset
2025-02-06 21:18:43,523:INFO:Defining folds
2025-02-06 21:18:43,523:INFO:Declaring metric variables
2025-02-06 21:18:43,523:INFO:Importing untrained model
2025-02-06 21:18:43,523:INFO:Declaring custom model
2025-02-06 21:18:43,524:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:43,525:INFO:Starting cross validation
2025-02-06 21:18:43,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:44,351:INFO:Calculating mean and std
2025-02-06 21:18:44,351:INFO:Creating metrics dataframe
2025-02-06 21:18:44,352:INFO:Finalizing model
2025-02-06 21:18:44,369:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:18:44,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
2025-02-06 21:18:44,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:18:44,370:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:18:44,370:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:18:44,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:18:44,370:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:18:44,473:INFO:Uploading results into container
2025-02-06 21:18:44,474:INFO:Uploading model into container now
2025-02-06 21:18:44,474:INFO:_master_model_container: 5
2025-02-06 21:18:44,474:INFO:_display_container: 5
2025-02-06 21:18:44,475:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:44,475:INFO:create_model() successfully completed......................................
2025-02-06 21:18:44,545:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:44,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:18:44,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:18:44,546:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:18:44,546:INFO:choose_better completed
2025-02-06 21:18:44,553:INFO:_master_model_container: 5
2025-02-06 21:18:44,553:INFO:_display_container: 4
2025-02-06 21:18:44,553:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:44,553:INFO:tune_model() successfully completed......................................
2025-02-06 21:18:44,614:INFO:Initializing create_model()
2025-02-06 21:18:44,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:44,614:INFO:Checking exceptions
2025-02-06 21:18:44,622:INFO:Importing libraries
2025-02-06 21:18:44,622:INFO:Copying training dataset
2025-02-06 21:18:44,628:INFO:Defining folds
2025-02-06 21:18:44,628:INFO:Declaring metric variables
2025-02-06 21:18:44,629:INFO:Importing untrained model
2025-02-06 21:18:44,631:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:44,635:INFO:Starting cross validation
2025-02-06 21:18:44,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:44,701:INFO:Calculating mean and std
2025-02-06 21:18:44,702:INFO:Creating metrics dataframe
2025-02-06 21:18:44,705:INFO:Finalizing model
2025-02-06 21:18:44,735:INFO:Uploading results into container
2025-02-06 21:18:44,735:INFO:Uploading model into container now
2025-02-06 21:18:44,739:INFO:_master_model_container: 6
2025-02-06 21:18:44,739:INFO:_display_container: 5
2025-02-06 21:18:44,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:44,739:INFO:create_model() successfully completed......................................
2025-02-06 21:18:44,790:INFO:Initializing tune_model()
2025-02-06 21:18:44,791:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:18:44,791:INFO:Checking exceptions
2025-02-06 21:18:44,800:INFO:Copying training dataset
2025-02-06 21:18:44,804:INFO:Checking base model
2025-02-06 21:18:44,804:INFO:Base model : Logistic Regression
2025-02-06 21:18:44,807:INFO:Declaring metric variables
2025-02-06 21:18:44,808:INFO:Defining Hyperparameters
2025-02-06 21:18:44,872:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:18:44,872:INFO:Tuning with n_jobs=-1
2025-02-06 21:18:44,872:INFO:Initializing RandomizedSearchCV
2025-02-06 21:18:45,266:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:18:45,266:INFO:Hyperparameter search completed
2025-02-06 21:18:45,266:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:45,266:INFO:Initializing create_model()
2025-02-06 21:18:45,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010FD3F6F810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:18:45,266:INFO:Checking exceptions
2025-02-06 21:18:45,266:INFO:Importing libraries
2025-02-06 21:18:45,266:INFO:Copying training dataset
2025-02-06 21:18:45,272:INFO:Defining folds
2025-02-06 21:18:45,272:INFO:Declaring metric variables
2025-02-06 21:18:45,274:INFO:Importing untrained model
2025-02-06 21:18:45,274:INFO:Declaring custom model
2025-02-06 21:18:45,276:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:45,279:INFO:Starting cross validation
2025-02-06 21:18:45,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:45,356:INFO:Calculating mean and std
2025-02-06 21:18:45,356:INFO:Creating metrics dataframe
2025-02-06 21:18:45,359:INFO:Finalizing model
2025-02-06 21:18:45,388:INFO:Uploading results into container
2025-02-06 21:18:45,388:INFO:Uploading model into container now
2025-02-06 21:18:45,388:INFO:_master_model_container: 7
2025-02-06 21:18:45,388:INFO:_display_container: 6
2025-02-06 21:18:45,389:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:45,389:INFO:create_model() successfully completed......................................
2025-02-06 21:18:45,443:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:45,443:INFO:choose_better activated
2025-02-06 21:18:45,445:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:45,446:INFO:Initializing create_model()
2025-02-06 21:18:45,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:45,446:INFO:Checking exceptions
2025-02-06 21:18:45,447:INFO:Importing libraries
2025-02-06 21:18:45,447:INFO:Copying training dataset
2025-02-06 21:18:45,452:INFO:Defining folds
2025-02-06 21:18:45,452:INFO:Declaring metric variables
2025-02-06 21:18:45,452:INFO:Importing untrained model
2025-02-06 21:18:45,452:INFO:Declaring custom model
2025-02-06 21:18:45,453:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:45,453:INFO:Starting cross validation
2025-02-06 21:18:45,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:45,511:INFO:Calculating mean and std
2025-02-06 21:18:45,511:INFO:Creating metrics dataframe
2025-02-06 21:18:45,512:INFO:Finalizing model
2025-02-06 21:18:45,540:INFO:Uploading results into container
2025-02-06 21:18:45,540:INFO:Uploading model into container now
2025-02-06 21:18:45,540:INFO:_master_model_container: 8
2025-02-06 21:18:45,540:INFO:_display_container: 7
2025-02-06 21:18:45,540:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:45,540:INFO:create_model() successfully completed......................................
2025-02-06 21:18:45,597:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:45,597:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:18:45,597:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:18:45,598:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:18:45,598:INFO:choose_better completed
2025-02-06 21:18:45,602:INFO:_master_model_container: 8
2025-02-06 21:18:45,603:INFO:_display_container: 6
2025-02-06 21:18:45,603:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:45,603:INFO:tune_model() successfully completed......................................
2025-02-06 21:18:45,640:INFO:Initializing compare_models()
2025-02-06 21:18:45,640:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:18:45,640:INFO:Checking exceptions
2025-02-06 21:18:45,643:INFO:Preparing display monitor
2025-02-06 21:18:45,652:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:18:45,653:INFO:Total runtime is 2.5057792663574217e-05 minutes
2025-02-06 21:18:45,654:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:45,654:INFO:Initializing create_model()
2025-02-06 21:18:45,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010FD47230D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:45,655:INFO:Checking exceptions
2025-02-06 21:18:45,655:INFO:Importing libraries
2025-02-06 21:18:45,655:INFO:Copying training dataset
2025-02-06 21:18:45,660:INFO:Defining folds
2025-02-06 21:18:45,661:INFO:Declaring metric variables
2025-02-06 21:18:45,662:INFO:Importing untrained model
2025-02-06 21:18:45,662:INFO:Declaring custom model
2025-02-06 21:18:45,663:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:45,667:INFO:Starting cross validation
2025-02-06 21:18:45,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:45,986:INFO:Calculating mean and std
2025-02-06 21:18:45,986:INFO:Creating metrics dataframe
2025-02-06 21:18:45,987:INFO:Uploading results into container
2025-02-06 21:18:45,988:INFO:Uploading model into container now
2025-02-06 21:18:45,988:INFO:_master_model_container: 9
2025-02-06 21:18:45,988:INFO:_display_container: 7
2025-02-06 21:18:45,988:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:45,988:INFO:create_model() successfully completed......................................
2025-02-06 21:18:46,046:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:46,046:INFO:Creating metrics dataframe
2025-02-06 21:18:46,050:INFO:Initializing custom model Logistic Regression
2025-02-06 21:18:46,050:INFO:Total runtime is 0.006635332107543945 minutes
2025-02-06 21:18:46,052:INFO:SubProcess create_model() called ==================================
2025-02-06 21:18:46,053:INFO:Initializing create_model()
2025-02-06 21:18:46,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010FD47230D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:46,053:INFO:Checking exceptions
2025-02-06 21:18:46,053:INFO:Importing libraries
2025-02-06 21:18:46,053:INFO:Copying training dataset
2025-02-06 21:18:46,063:INFO:Defining folds
2025-02-06 21:18:46,063:INFO:Declaring metric variables
2025-02-06 21:18:46,066:INFO:Importing untrained model
2025-02-06 21:18:46,066:INFO:Declaring custom model
2025-02-06 21:18:46,068:INFO:Logistic Regression Imported successfully
2025-02-06 21:18:46,073:INFO:Starting cross validation
2025-02-06 21:18:46,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:18:46,142:INFO:Calculating mean and std
2025-02-06 21:18:46,142:INFO:Creating metrics dataframe
2025-02-06 21:18:46,142:INFO:Uploading results into container
2025-02-06 21:18:46,143:INFO:Uploading model into container now
2025-02-06 21:18:46,143:INFO:_master_model_container: 10
2025-02-06 21:18:46,143:INFO:_display_container: 7
2025-02-06 21:18:46,143:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:18:46,143:INFO:create_model() successfully completed......................................
2025-02-06 21:18:46,195:INFO:SubProcess create_model() end ==================================
2025-02-06 21:18:46,195:INFO:Creating metrics dataframe
2025-02-06 21:18:46,198:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:18:46,202:INFO:Initializing create_model()
2025-02-06 21:18:46,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:18:46,202:INFO:Checking exceptions
2025-02-06 21:18:46,203:INFO:Importing libraries
2025-02-06 21:18:46,203:INFO:Copying training dataset
2025-02-06 21:18:46,208:INFO:Defining folds
2025-02-06 21:18:46,208:INFO:Declaring metric variables
2025-02-06 21:18:46,208:INFO:Importing untrained model
2025-02-06 21:18:46,208:INFO:Declaring custom model
2025-02-06 21:18:46,208:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:18:46,209:INFO:Cross validation set to False
2025-02-06 21:18:46,209:INFO:Fitting Model
2025-02-06 21:18:46,222:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:18:46,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
2025-02-06 21:18:46,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:18:46,223:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:18:46,223:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:18:46,223:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:18:46,223:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:18:46,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:18:46,249:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:46,249:INFO:create_model() successfully completed......................................
2025-02-06 21:18:46,314:INFO:_master_model_container: 10
2025-02-06 21:18:46,314:INFO:_display_container: 7
2025-02-06 21:18:46,314:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:18:46,314:INFO:compare_models() successfully completed......................................
2025-02-06 21:18:46,315:INFO:Initializing predict_model()
2025-02-06 21:18:46,315:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010FD4637560>)
2025-02-06 21:18:46,315:INFO:Checking exceptions
2025-02-06 21:18:46,315:INFO:Preloading libraries
2025-02-06 21:18:46,316:INFO:Set up data.
2025-02-06 21:18:46,325:INFO:Set up index.
2025-02-06 21:18:46,423:INFO:Initializing predict_model()
2025-02-06 21:18:46,423:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010FD4637560>)
2025-02-06 21:18:46,423:INFO:Checking exceptions
2025-02-06 21:18:46,423:INFO:Preloading libraries
2025-02-06 21:18:46,424:INFO:Set up data.
2025-02-06 21:18:46,430:INFO:Set up index.
2025-02-06 21:18:46,512:INFO:Initializing predict_model()
2025-02-06 21:18:46,512:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010FD4637560>)
2025-02-06 21:18:46,512:INFO:Checking exceptions
2025-02-06 21:18:46,512:INFO:Preloading libraries
2025-02-06 21:18:46,513:INFO:Set up data.
2025-02-06 21:18:46,521:INFO:Set up index.
2025-02-06 21:18:46,612:INFO:Initializing predict_model()
2025-02-06 21:18:46,612:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010FD46FA850>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010FD4637560>)
2025-02-06 21:18:46,612:INFO:Checking exceptions
2025-02-06 21:18:46,612:INFO:Preloading libraries
2025-02-06 21:18:46,613:INFO:Set up data.
2025-02-06 21:18:46,618:INFO:Set up index.
2025-02-06 21:40:58,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:40:58,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:40:58,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:40:58,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:40:59,492:INFO:PyCaret ClassificationExperiment
2025-02-06 21:40:59,492:INFO:Logging name: clf-default-name
2025-02-06 21:40:59,492:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:40:59,492:INFO:version 3.3.2
2025-02-06 21:40:59,492:INFO:Initializing setup()
2025-02-06 21:40:59,492:INFO:self.USI: 77d6
2025-02-06 21:40:59,492:INFO:self._variable_keys: {'seed', 'html_param', 'y_train', 'USI', 'fold_generator', 'pipeline', 'X_train', 'target_param', 'y_test', 'idx', '_ml_usecase', 'is_multiclass', 'fold_shuffle_param', 'logging_param', 'y', 'X_test', 'fold_groups_param', 'data', 'n_jobs_param', '_available_plots', 'gpu_param', 'exp_id', 'X', 'fix_imbalance', 'gpu_n_jobs_param', 'exp_name_log', 'memory', 'log_plots_param'}
2025-02-06 21:40:59,492:INFO:Checking environment
2025-02-06 21:40:59,492:INFO:python_version: 3.11.9
2025-02-06 21:40:59,492:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:40:59,492:INFO:machine: AMD64
2025-02-06 21:40:59,492:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:40:59,496:INFO:Memory: svmem(total=67771465728, available=49449230336, percent=27.0, used=18322235392, free=49449230336)
2025-02-06 21:40:59,497:INFO:Physical Core: 8
2025-02-06 21:40:59,497:INFO:Logical Core: 16
2025-02-06 21:40:59,497:INFO:Checking libraries
2025-02-06 21:40:59,497:INFO:System:
2025-02-06 21:40:59,497:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:40:59,497:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:40:59,497:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:40:59,497:INFO:PyCaret required dependencies:
2025-02-06 21:40:59,511:INFO:                 pip: 25.0
2025-02-06 21:40:59,511:INFO:          setuptools: 65.5.0
2025-02-06 21:40:59,511:INFO:             pycaret: 3.3.2
2025-02-06 21:40:59,511:INFO:             IPython: 8.32.0
2025-02-06 21:40:59,512:INFO:          ipywidgets: 8.1.5
2025-02-06 21:40:59,512:INFO:                tqdm: 4.67.1
2025-02-06 21:40:59,512:INFO:               numpy: 1.26.4
2025-02-06 21:40:59,512:INFO:              pandas: 2.1.4
2025-02-06 21:40:59,512:INFO:              jinja2: 3.1.5
2025-02-06 21:40:59,512:INFO:               scipy: 1.11.4
2025-02-06 21:40:59,512:INFO:              joblib: 1.3.2
2025-02-06 21:40:59,512:INFO:             sklearn: 1.4.2
2025-02-06 21:40:59,512:INFO:                pyod: 2.0.3
2025-02-06 21:40:59,512:INFO:            imblearn: 0.13.0
2025-02-06 21:40:59,512:INFO:   category_encoders: 2.7.0
2025-02-06 21:40:59,512:INFO:            lightgbm: 4.5.0
2025-02-06 21:40:59,512:INFO:               numba: 0.61.0
2025-02-06 21:40:59,512:INFO:            requests: 2.32.3
2025-02-06 21:40:59,512:INFO:          matplotlib: 3.7.5
2025-02-06 21:40:59,512:INFO:          scikitplot: 0.3.7
2025-02-06 21:40:59,512:INFO:         yellowbrick: 1.5
2025-02-06 21:40:59,512:INFO:              plotly: 5.24.1
2025-02-06 21:40:59,512:INFO:    plotly-resampler: Not installed
2025-02-06 21:40:59,512:INFO:             kaleido: 0.2.1
2025-02-06 21:40:59,512:INFO:           schemdraw: 0.15
2025-02-06 21:40:59,512:INFO:         statsmodels: 0.14.4
2025-02-06 21:40:59,512:INFO:              sktime: 0.26.0
2025-02-06 21:40:59,512:INFO:               tbats: 1.1.3
2025-02-06 21:40:59,512:INFO:            pmdarima: 2.0.4
2025-02-06 21:40:59,512:INFO:              psutil: 6.1.1
2025-02-06 21:40:59,512:INFO:          markupsafe: 3.0.2
2025-02-06 21:40:59,512:INFO:             pickle5: Not installed
2025-02-06 21:40:59,512:INFO:         cloudpickle: 3.1.1
2025-02-06 21:40:59,512:INFO:         deprecation: 2.1.0
2025-02-06 21:40:59,512:INFO:              xxhash: 3.5.0
2025-02-06 21:40:59,512:INFO:           wurlitzer: Not installed
2025-02-06 21:40:59,512:INFO:PyCaret optional dependencies:
2025-02-06 21:40:59,520:INFO:                shap: Not installed
2025-02-06 21:40:59,520:INFO:           interpret: Not installed
2025-02-06 21:40:59,520:INFO:                umap: Not installed
2025-02-06 21:40:59,520:INFO:     ydata_profiling: Not installed
2025-02-06 21:40:59,520:INFO:  explainerdashboard: Not installed
2025-02-06 21:40:59,520:INFO:             autoviz: Not installed
2025-02-06 21:40:59,520:INFO:           fairlearn: Not installed
2025-02-06 21:40:59,520:INFO:          deepchecks: Not installed
2025-02-06 21:40:59,520:INFO:             xgboost: Not installed
2025-02-06 21:40:59,520:INFO:            catboost: Not installed
2025-02-06 21:40:59,520:INFO:              kmodes: Not installed
2025-02-06 21:40:59,520:INFO:             mlxtend: Not installed
2025-02-06 21:40:59,520:INFO:       statsforecast: Not installed
2025-02-06 21:40:59,520:INFO:        tune_sklearn: Not installed
2025-02-06 21:40:59,520:INFO:                 ray: Not installed
2025-02-06 21:40:59,520:INFO:            hyperopt: Not installed
2025-02-06 21:40:59,520:INFO:              optuna: Not installed
2025-02-06 21:40:59,520:INFO:               skopt: Not installed
2025-02-06 21:40:59,520:INFO:              mlflow: Not installed
2025-02-06 21:40:59,520:INFO:              gradio: Not installed
2025-02-06 21:40:59,521:INFO:             fastapi: Not installed
2025-02-06 21:40:59,521:INFO:             uvicorn: Not installed
2025-02-06 21:40:59,521:INFO:              m2cgen: Not installed
2025-02-06 21:40:59,521:INFO:           evidently: Not installed
2025-02-06 21:40:59,521:INFO:               fugue: Not installed
2025-02-06 21:40:59,521:INFO:           streamlit: Not installed
2025-02-06 21:40:59,521:INFO:             prophet: Not installed
2025-02-06 21:40:59,521:INFO:None
2025-02-06 21:40:59,521:INFO:Set up data.
2025-02-06 21:40:59,530:INFO:Set up folding strategy.
2025-02-06 21:40:59,530:INFO:Set up train/test split.
2025-02-06 21:40:59,536:INFO:Set up index.
2025-02-06 21:40:59,536:INFO:Assigning column types.
2025-02-06 21:40:59,542:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:40:59,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,568:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,627:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:40:59,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:40:59,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,707:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:40:59,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,787:INFO:Preparing preprocessing pipeline...
2025-02-06 21:40:59,788:INFO:Set up simple imputation.
2025-02-06 21:40:59,788:INFO:Set up feature normalization.
2025-02-06 21:40:59,812:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:40:59,814:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:40:59,814:INFO:Creating final display dataframe.
2025-02-06 21:40:59,886:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              77d6
2025-02-06 21:40:59,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:40:59,966:INFO:setup() successfully completed in 0.47s...............
2025-02-06 21:40:59,966:INFO:Initializing compare_models()
2025-02-06 21:40:59,966:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:40:59,966:INFO:Checking exceptions
2025-02-06 21:40:59,970:INFO:Preparing display monitor
2025-02-06 21:40:59,983:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:40:59,983:INFO:Total runtime is 0.0 minutes
2025-02-06 21:40:59,985:INFO:SubProcess create_model() called ==================================
2025-02-06 21:40:59,985:INFO:Initializing create_model()
2025-02-06 21:40:59,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EF03A8090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:40:59,985:INFO:Checking exceptions
2025-02-06 21:40:59,985:INFO:Importing libraries
2025-02-06 21:40:59,985:INFO:Copying training dataset
2025-02-06 21:40:59,990:INFO:Defining folds
2025-02-06 21:40:59,990:INFO:Declaring metric variables
2025-02-06 21:40:59,991:INFO:Importing untrained model
2025-02-06 21:40:59,993:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:40:59,996:INFO:Starting cross validation
2025-02-06 21:40:59,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:03,042:INFO:Calculating mean and std
2025-02-06 21:41:03,043:INFO:Creating metrics dataframe
2025-02-06 21:41:03,046:INFO:Uploading results into container
2025-02-06 21:41:03,046:INFO:Uploading model into container now
2025-02-06 21:41:03,046:INFO:_master_model_container: 1
2025-02-06 21:41:03,046:INFO:_display_container: 2
2025-02-06 21:41:03,046:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:03,046:INFO:create_model() successfully completed......................................
2025-02-06 21:41:03,119:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:03,119:INFO:Creating metrics dataframe
2025-02-06 21:41:03,124:INFO:Initializing Logistic Regression
2025-02-06 21:41:03,124:INFO:Total runtime is 0.05234572490056356 minutes
2025-02-06 21:41:03,126:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:03,126:INFO:Initializing create_model()
2025-02-06 21:41:03,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EF03A8090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:03,126:INFO:Checking exceptions
2025-02-06 21:41:03,126:INFO:Importing libraries
2025-02-06 21:41:03,126:INFO:Copying training dataset
2025-02-06 21:41:03,135:INFO:Defining folds
2025-02-06 21:41:03,135:INFO:Declaring metric variables
2025-02-06 21:41:03,136:INFO:Importing untrained model
2025-02-06 21:41:03,138:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:03,141:INFO:Starting cross validation
2025-02-06 21:41:03,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:04,591:INFO:Calculating mean and std
2025-02-06 21:41:04,591:INFO:Creating metrics dataframe
2025-02-06 21:41:04,594:INFO:Uploading results into container
2025-02-06 21:41:04,594:INFO:Uploading model into container now
2025-02-06 21:41:04,595:INFO:_master_model_container: 2
2025-02-06 21:41:04,595:INFO:_display_container: 2
2025-02-06 21:41:04,595:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:04,595:INFO:create_model() successfully completed......................................
2025-02-06 21:41:04,669:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:04,669:INFO:Creating metrics dataframe
2025-02-06 21:41:04,673:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:41:04,677:INFO:Initializing create_model()
2025-02-06 21:41:04,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:04,678:INFO:Checking exceptions
2025-02-06 21:41:04,678:INFO:Importing libraries
2025-02-06 21:41:04,678:INFO:Copying training dataset
2025-02-06 21:41:04,684:INFO:Defining folds
2025-02-06 21:41:04,684:INFO:Declaring metric variables
2025-02-06 21:41:04,684:INFO:Importing untrained model
2025-02-06 21:41:04,684:INFO:Declaring custom model
2025-02-06 21:41:04,684:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:04,685:INFO:Cross validation set to False
2025-02-06 21:41:04,685:INFO:Fitting Model
2025-02-06 21:41:04,712:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:04,713:INFO:create_model() successfully completed......................................
2025-02-06 21:41:04,768:INFO:_master_model_container: 2
2025-02-06 21:41:04,768:INFO:_display_container: 2
2025-02-06 21:41:04,769:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:04,769:INFO:compare_models() successfully completed......................................
2025-02-06 21:41:04,769:INFO:Initializing create_model()
2025-02-06 21:41:04,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:04,769:INFO:Checking exceptions
2025-02-06 21:41:04,776:INFO:Importing libraries
2025-02-06 21:41:04,776:INFO:Copying training dataset
2025-02-06 21:41:04,783:INFO:Defining folds
2025-02-06 21:41:04,783:INFO:Declaring metric variables
2025-02-06 21:41:04,785:INFO:Importing untrained model
2025-02-06 21:41:04,787:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:41:04,790:INFO:Starting cross validation
2025-02-06 21:41:04,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:05,529:INFO:Calculating mean and std
2025-02-06 21:41:05,529:INFO:Creating metrics dataframe
2025-02-06 21:41:05,532:INFO:Finalizing model
2025-02-06 21:41:05,553:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:41:05,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.
2025-02-06 21:41:05,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:41:05,555:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:41:05,555:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:41:05,555:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:41:05,555:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:41:05,664:INFO:Uploading results into container
2025-02-06 21:41:05,665:INFO:Uploading model into container now
2025-02-06 21:41:05,671:INFO:_master_model_container: 3
2025-02-06 21:41:05,671:INFO:_display_container: 3
2025-02-06 21:41:05,672:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:05,672:INFO:create_model() successfully completed......................................
2025-02-06 21:41:05,732:INFO:Initializing tune_model()
2025-02-06 21:41:05,732:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:41:05,732:INFO:Checking exceptions
2025-02-06 21:41:05,743:INFO:Copying training dataset
2025-02-06 21:41:05,749:INFO:Checking base model
2025-02-06 21:41:05,749:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:41:05,751:INFO:Declaring metric variables
2025-02-06 21:41:05,753:INFO:Defining Hyperparameters
2025-02-06 21:41:05,799:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:41:05,799:INFO:Tuning with n_jobs=-1
2025-02-06 21:41:05,799:INFO:Initializing RandomizedSearchCV
2025-02-06 21:41:09,132:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:41:09,134:INFO:Hyperparameter search completed
2025-02-06 21:41:09,134:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:09,135:INFO:Initializing create_model()
2025-02-06 21:41:09,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EEF27E7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:41:09,135:INFO:Checking exceptions
2025-02-06 21:41:09,135:INFO:Importing libraries
2025-02-06 21:41:09,136:INFO:Copying training dataset
2025-02-06 21:41:09,145:INFO:Defining folds
2025-02-06 21:41:09,145:INFO:Declaring metric variables
2025-02-06 21:41:09,146:INFO:Importing untrained model
2025-02-06 21:41:09,146:INFO:Declaring custom model
2025-02-06 21:41:09,149:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:41:09,153:INFO:Starting cross validation
2025-02-06 21:41:09,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:09,466:INFO:Calculating mean and std
2025-02-06 21:41:09,467:INFO:Creating metrics dataframe
2025-02-06 21:41:09,471:INFO:Finalizing model
2025-02-06 21:41:09,490:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:41:09,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000718 seconds.
2025-02-06 21:41:09,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:41:09,491:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:41:09,492:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:41:09,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:41:09,492:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:41:09,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:09,557:INFO:Uploading results into container
2025-02-06 21:41:09,557:INFO:Uploading model into container now
2025-02-06 21:41:09,558:INFO:_master_model_container: 4
2025-02-06 21:41:09,558:INFO:_display_container: 4
2025-02-06 21:41:09,559:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:09,559:INFO:create_model() successfully completed......................................
2025-02-06 21:41:09,624:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:09,624:INFO:choose_better activated
2025-02-06 21:41:09,627:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:09,627:INFO:Initializing create_model()
2025-02-06 21:41:09,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:09,627:INFO:Checking exceptions
2025-02-06 21:41:09,628:INFO:Importing libraries
2025-02-06 21:41:09,628:INFO:Copying training dataset
2025-02-06 21:41:09,635:INFO:Defining folds
2025-02-06 21:41:09,635:INFO:Declaring metric variables
2025-02-06 21:41:09,635:INFO:Importing untrained model
2025-02-06 21:41:09,636:INFO:Declaring custom model
2025-02-06 21:41:09,636:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:41:09,637:INFO:Starting cross validation
2025-02-06 21:41:09,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:10,381:INFO:Calculating mean and std
2025-02-06 21:41:10,381:INFO:Creating metrics dataframe
2025-02-06 21:41:10,383:INFO:Finalizing model
2025-02-06 21:41:10,399:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:41:10,401:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.
2025-02-06 21:41:10,401:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:41:10,401:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:41:10,401:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:41:10,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:41:10,401:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:41:10,525:INFO:Uploading results into container
2025-02-06 21:41:10,526:INFO:Uploading model into container now
2025-02-06 21:41:10,526:INFO:_master_model_container: 5
2025-02-06 21:41:10,526:INFO:_display_container: 5
2025-02-06 21:41:10,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:10,527:INFO:create_model() successfully completed......................................
2025-02-06 21:41:10,583:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:10,584:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:41:10,584:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:41:10,584:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:41:10,584:INFO:choose_better completed
2025-02-06 21:41:10,590:INFO:_master_model_container: 5
2025-02-06 21:41:10,590:INFO:_display_container: 4
2025-02-06 21:41:10,590:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:10,590:INFO:tune_model() successfully completed......................................
2025-02-06 21:41:10,632:INFO:Initializing create_model()
2025-02-06 21:41:10,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:10,632:INFO:Checking exceptions
2025-02-06 21:41:10,638:INFO:Importing libraries
2025-02-06 21:41:10,639:INFO:Copying training dataset
2025-02-06 21:41:10,644:INFO:Defining folds
2025-02-06 21:41:10,644:INFO:Declaring metric variables
2025-02-06 21:41:10,647:INFO:Importing untrained model
2025-02-06 21:41:10,649:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:10,651:INFO:Starting cross validation
2025-02-06 21:41:10,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:10,720:INFO:Calculating mean and std
2025-02-06 21:41:10,721:INFO:Creating metrics dataframe
2025-02-06 21:41:10,725:INFO:Finalizing model
2025-02-06 21:41:10,762:INFO:Uploading results into container
2025-02-06 21:41:10,763:INFO:Uploading model into container now
2025-02-06 21:41:10,767:INFO:_master_model_container: 6
2025-02-06 21:41:10,767:INFO:_display_container: 5
2025-02-06 21:41:10,767:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:10,767:INFO:create_model() successfully completed......................................
2025-02-06 21:41:10,825:INFO:Initializing tune_model()
2025-02-06 21:41:10,825:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:41:10,825:INFO:Checking exceptions
2025-02-06 21:41:10,835:INFO:Copying training dataset
2025-02-06 21:41:10,838:INFO:Checking base model
2025-02-06 21:41:10,838:INFO:Base model : Logistic Regression
2025-02-06 21:41:10,840:INFO:Declaring metric variables
2025-02-06 21:41:10,841:INFO:Defining Hyperparameters
2025-02-06 21:41:10,880:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:41:10,880:INFO:Tuning with n_jobs=-1
2025-02-06 21:41:10,880:INFO:Initializing RandomizedSearchCV
2025-02-06 21:41:11,285:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:41:11,285:INFO:Hyperparameter search completed
2025-02-06 21:41:11,285:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:11,286:INFO:Initializing create_model()
2025-02-06 21:41:11,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EEF9DE750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:41:11,286:INFO:Checking exceptions
2025-02-06 21:41:11,286:INFO:Importing libraries
2025-02-06 21:41:11,286:INFO:Copying training dataset
2025-02-06 21:41:11,292:INFO:Defining folds
2025-02-06 21:41:11,292:INFO:Declaring metric variables
2025-02-06 21:41:11,293:INFO:Importing untrained model
2025-02-06 21:41:11,293:INFO:Declaring custom model
2025-02-06 21:41:11,295:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:11,297:INFO:Starting cross validation
2025-02-06 21:41:11,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:11,386:INFO:Calculating mean and std
2025-02-06 21:41:11,386:INFO:Creating metrics dataframe
2025-02-06 21:41:11,388:INFO:Finalizing model
2025-02-06 21:41:11,415:INFO:Uploading results into container
2025-02-06 21:41:11,417:INFO:Uploading model into container now
2025-02-06 21:41:11,417:INFO:_master_model_container: 7
2025-02-06 21:41:11,417:INFO:_display_container: 6
2025-02-06 21:41:11,417:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:11,417:INFO:create_model() successfully completed......................................
2025-02-06 21:41:11,472:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:11,472:INFO:choose_better activated
2025-02-06 21:41:11,473:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:11,474:INFO:Initializing create_model()
2025-02-06 21:41:11,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:11,474:INFO:Checking exceptions
2025-02-06 21:41:11,474:INFO:Importing libraries
2025-02-06 21:41:11,474:INFO:Copying training dataset
2025-02-06 21:41:11,480:INFO:Defining folds
2025-02-06 21:41:11,480:INFO:Declaring metric variables
2025-02-06 21:41:11,480:INFO:Importing untrained model
2025-02-06 21:41:11,480:INFO:Declaring custom model
2025-02-06 21:41:11,481:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:11,481:INFO:Starting cross validation
2025-02-06 21:41:11,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:11,536:INFO:Calculating mean and std
2025-02-06 21:41:11,536:INFO:Creating metrics dataframe
2025-02-06 21:41:11,537:INFO:Finalizing model
2025-02-06 21:41:11,564:INFO:Uploading results into container
2025-02-06 21:41:11,564:INFO:Uploading model into container now
2025-02-06 21:41:11,564:INFO:_master_model_container: 8
2025-02-06 21:41:11,564:INFO:_display_container: 7
2025-02-06 21:41:11,566:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:11,566:INFO:create_model() successfully completed......................................
2025-02-06 21:41:11,624:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:11,624:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:41:11,625:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:41:11,625:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:41:11,625:INFO:choose_better completed
2025-02-06 21:41:11,629:INFO:_master_model_container: 8
2025-02-06 21:41:11,629:INFO:_display_container: 6
2025-02-06 21:41:11,630:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:11,630:INFO:tune_model() successfully completed......................................
2025-02-06 21:41:11,695:INFO:Initializing compare_models()
2025-02-06 21:41:11,695:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:41:11,695:INFO:Checking exceptions
2025-02-06 21:41:11,698:INFO:Preparing display monitor
2025-02-06 21:41:11,708:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:41:11,708:INFO:Total runtime is 0.0 minutes
2025-02-06 21:41:11,709:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:11,710:INFO:Initializing create_model()
2025-02-06 21:41:11,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EEE07C510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:11,710:INFO:Checking exceptions
2025-02-06 21:41:11,710:INFO:Importing libraries
2025-02-06 21:41:11,710:INFO:Copying training dataset
2025-02-06 21:41:11,714:INFO:Defining folds
2025-02-06 21:41:11,714:INFO:Declaring metric variables
2025-02-06 21:41:11,717:INFO:Importing untrained model
2025-02-06 21:41:11,717:INFO:Declaring custom model
2025-02-06 21:41:11,719:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:41:11,721:INFO:Starting cross validation
2025-02-06 21:41:11,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:12,022:INFO:Calculating mean and std
2025-02-06 21:41:12,022:INFO:Creating metrics dataframe
2025-02-06 21:41:12,023:INFO:Uploading results into container
2025-02-06 21:41:12,024:INFO:Uploading model into container now
2025-02-06 21:41:12,024:INFO:_master_model_container: 9
2025-02-06 21:41:12,024:INFO:_display_container: 7
2025-02-06 21:41:12,025:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:12,025:INFO:create_model() successfully completed......................................
2025-02-06 21:41:12,093:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:12,093:INFO:Creating metrics dataframe
2025-02-06 21:41:12,098:INFO:Initializing custom model Logistic Regression
2025-02-06 21:41:12,098:INFO:Total runtime is 0.006501968701680501 minutes
2025-02-06 21:41:12,100:INFO:SubProcess create_model() called ==================================
2025-02-06 21:41:12,100:INFO:Initializing create_model()
2025-02-06 21:41:12,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022EEE07C510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:12,100:INFO:Checking exceptions
2025-02-06 21:41:12,100:INFO:Importing libraries
2025-02-06 21:41:12,100:INFO:Copying training dataset
2025-02-06 21:41:12,108:INFO:Defining folds
2025-02-06 21:41:12,108:INFO:Declaring metric variables
2025-02-06 21:41:12,109:INFO:Importing untrained model
2025-02-06 21:41:12,109:INFO:Declaring custom model
2025-02-06 21:41:12,111:INFO:Logistic Regression Imported successfully
2025-02-06 21:41:12,115:INFO:Starting cross validation
2025-02-06 21:41:12,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:41:12,208:INFO:Calculating mean and std
2025-02-06 21:41:12,208:INFO:Creating metrics dataframe
2025-02-06 21:41:12,210:INFO:Uploading results into container
2025-02-06 21:41:12,210:INFO:Uploading model into container now
2025-02-06 21:41:12,210:INFO:_master_model_container: 10
2025-02-06 21:41:12,210:INFO:_display_container: 7
2025-02-06 21:41:12,210:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:41:12,210:INFO:create_model() successfully completed......................................
2025-02-06 21:41:12,261:INFO:SubProcess create_model() end ==================================
2025-02-06 21:41:12,261:INFO:Creating metrics dataframe
2025-02-06 21:41:12,263:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:41:12,267:INFO:Initializing create_model()
2025-02-06 21:41:12,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:41:12,267:INFO:Checking exceptions
2025-02-06 21:41:12,268:INFO:Importing libraries
2025-02-06 21:41:12,268:INFO:Copying training dataset
2025-02-06 21:41:12,273:INFO:Defining folds
2025-02-06 21:41:12,274:INFO:Declaring metric variables
2025-02-06 21:41:12,274:INFO:Importing untrained model
2025-02-06 21:41:12,274:INFO:Declaring custom model
2025-02-06 21:41:12,274:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:41:12,274:INFO:Cross validation set to False
2025-02-06 21:41:12,274:INFO:Fitting Model
2025-02-06 21:41:12,293:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:41:12,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
2025-02-06 21:41:12,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:41:12,295:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:41:12,295:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:41:12,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:41:12,295:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:41:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:41:12,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:12,320:INFO:create_model() successfully completed......................................
2025-02-06 21:41:12,387:INFO:_master_model_container: 10
2025-02-06 21:41:12,387:INFO:_display_container: 7
2025-02-06 21:41:12,387:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:41:12,387:INFO:compare_models() successfully completed......................................
2025-02-06 21:41:12,388:INFO:Initializing predict_model()
2025-02-06 21:41:12,388:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022EF1803E20>)
2025-02-06 21:41:12,388:INFO:Checking exceptions
2025-02-06 21:41:12,388:INFO:Preloading libraries
2025-02-06 21:41:12,390:INFO:Set up data.
2025-02-06 21:41:12,399:INFO:Set up index.
2025-02-06 21:41:12,502:INFO:Initializing predict_model()
2025-02-06 21:41:12,502:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022EF00C7380>)
2025-02-06 21:41:12,503:INFO:Checking exceptions
2025-02-06 21:41:12,503:INFO:Preloading libraries
2025-02-06 21:41:12,505:INFO:Set up data.
2025-02-06 21:41:12,510:INFO:Set up index.
2025-02-06 21:41:12,601:INFO:Initializing predict_model()
2025-02-06 21:41:12,601:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022EF00C7380>)
2025-02-06 21:41:12,601:INFO:Checking exceptions
2025-02-06 21:41:12,601:INFO:Preloading libraries
2025-02-06 21:41:12,603:INFO:Set up data.
2025-02-06 21:41:12,612:INFO:Set up index.
2025-02-06 21:41:12,705:INFO:Initializing predict_model()
2025-02-06 21:41:12,705:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022EF00C7380>)
2025-02-06 21:41:12,705:INFO:Checking exceptions
2025-02-06 21:41:12,705:INFO:Preloading libraries
2025-02-06 21:41:12,706:INFO:Set up data.
2025-02-06 21:41:12,710:INFO:Set up index.
2025-02-06 21:41:12,795:INFO:Initializing get_config()
2025-02-06 21:41:12,796:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022EEFD4AC10>, variable=X_train)
2025-02-06 21:41:12,796:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-02-06 21:41:12,796:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-02-06 21:41:12,803:INFO:Variable:  returned as       VAR_1  VAR_72       VAR_53       VAR_65   VAR_6       VAR_17  \
954    59.0     6.0   484.519989  6828.040039  4211.0  1600.000000   
6679    0.0    11.0   598.630005   301.320007   105.0  1600.000000   
6356   99.0    55.0   500.000000  1308.660034  2744.0  3500.000000   
2694    7.0   233.0  1400.000000   750.000000   341.0   450.000000   
6488   29.0   147.0  1669.030029  1060.380005   939.0  3000.000000   
...     ...     ...          ...          ...     ...          ...   
3390    0.0     2.0  2955.000000  8122.180176  3829.0  6930.560059   
7190   48.0     1.0  1565.920044   251.110001   427.0  1000.000000   
5937   18.0   867.0  2200.000000   750.000000  1175.0  1100.000000   
5094   28.0   158.0   700.000000  1312.650024  2070.0  1200.000000   
4058    0.0   250.0  2700.000000   750.000000   595.0  1600.000000   

           VAR_30  VAR_57        VAR_9       VAR_54  ...  VAR_58  VAR_39  \
954    484.519989      49   484.519989   484.519989  ...  1047.0  1421.0   
6679   598.630005      36   598.630005  1202.140015  ...   262.0   257.0   
6356  2000.000000      28  2000.000000  2000.000000  ...  1186.0   257.0   
2694   450.000000      48   450.000000   500.000000  ...   262.0   257.0   
6488  4669.029785      58  1669.030029  4669.029785  ...   262.0    55.0   
...           ...     ...          ...          ...  ...     ...     ...   
3390  2955.000000      50  2955.000000  2955.000000  ...  1327.0   923.0   
7190  1000.000000      46  1000.000000  1000.000000  ...   274.0   257.0   
5937  1400.000000      47   800.000000  1500.000000  ...   262.0   257.0   
5094  1544.250000      46   700.000000   700.000000  ...   236.0    29.0   
4058  1000.000000      55  1000.000000  5000.000000  ...   262.0    69.0   

      VAR_20  VAR_40  VAR_44  VAR_25    VAR_60  VAR_2  VAR_28  VAR_19  
954        3     8.0    12.0     5.0  0.079926    0.0     6.0    28.0  
6679       8     0.0     0.0     0.0 -0.231735    0.0     0.0     0.0  
6356      12     0.0     1.0     4.0 -0.411787    1.0     4.0    11.0  
2694      12     0.0     0.0     0.0  0.079926    0.0     0.0     0.0  
6488      12     6.0     7.0     0.0  0.357324    0.0     0.0     0.0  
...      ...     ...     ...     ...       ...    ...     ...     ...  
3390      12    11.0    12.0    11.0  0.156301    0.0    12.0    45.0  
7190      12     0.0     0.0     0.0 -0.016209    0.0     0.0     0.0  
5937      12     5.0     6.0     2.0  0.079926    0.0     3.0     0.0  
5094      12     4.0     4.0     4.0 -0.016209    0.0     8.0    10.0  
4058      12     0.0     0.0     0.0  0.219380    0.0     0.0     0.0  

[5254 rows x 34 columns]
2025-02-06 21:41:12,803:INFO:get_config() successfully completed......................................
2025-02-06 21:43:52,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:43:52,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:43:52,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:43:52,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:43:53,313:INFO:PyCaret ClassificationExperiment
2025-02-06 21:43:53,313:INFO:Logging name: clf-default-name
2025-02-06 21:43:53,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:43:53,313:INFO:version 3.3.2
2025-02-06 21:43:53,313:INFO:Initializing setup()
2025-02-06 21:43:53,313:INFO:self.USI: 943c
2025-02-06 21:43:53,313:INFO:self._variable_keys: {'_ml_usecase', 'target_param', 'exp_id', 'data', 'X', 'memory', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'X_test', 'y', 'logging_param', '_available_plots', 'seed', 'gpu_param', 'html_param', 'fix_imbalance', 'y_train', 'fold_groups_param', 'y_test', 'log_plots_param', 'USI', 'n_jobs_param', 'exp_name_log', 'X_train', 'idx'}
2025-02-06 21:43:53,313:INFO:Checking environment
2025-02-06 21:43:53,313:INFO:python_version: 3.11.9
2025-02-06 21:43:53,313:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:43:53,313:INFO:machine: AMD64
2025-02-06 21:43:53,313:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:43:53,318:INFO:Memory: svmem(total=67771465728, available=49610866688, percent=26.8, used=18160599040, free=49610866688)
2025-02-06 21:43:53,318:INFO:Physical Core: 8
2025-02-06 21:43:53,318:INFO:Logical Core: 16
2025-02-06 21:43:53,318:INFO:Checking libraries
2025-02-06 21:43:53,318:INFO:System:
2025-02-06 21:43:53,318:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:43:53,318:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:43:53,318:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:43:53,318:INFO:PyCaret required dependencies:
2025-02-06 21:43:53,333:INFO:                 pip: 25.0
2025-02-06 21:43:53,333:INFO:          setuptools: 65.5.0
2025-02-06 21:43:53,333:INFO:             pycaret: 3.3.2
2025-02-06 21:43:53,333:INFO:             IPython: 8.32.0
2025-02-06 21:43:53,333:INFO:          ipywidgets: 8.1.5
2025-02-06 21:43:53,333:INFO:                tqdm: 4.67.1
2025-02-06 21:43:53,333:INFO:               numpy: 1.26.4
2025-02-06 21:43:53,333:INFO:              pandas: 2.1.4
2025-02-06 21:43:53,333:INFO:              jinja2: 3.1.5
2025-02-06 21:43:53,334:INFO:               scipy: 1.11.4
2025-02-06 21:43:53,334:INFO:              joblib: 1.3.2
2025-02-06 21:43:53,334:INFO:             sklearn: 1.4.2
2025-02-06 21:43:53,334:INFO:                pyod: 2.0.3
2025-02-06 21:43:53,334:INFO:            imblearn: 0.13.0
2025-02-06 21:43:53,334:INFO:   category_encoders: 2.7.0
2025-02-06 21:43:53,334:INFO:            lightgbm: 4.5.0
2025-02-06 21:43:53,334:INFO:               numba: 0.61.0
2025-02-06 21:43:53,334:INFO:            requests: 2.32.3
2025-02-06 21:43:53,334:INFO:          matplotlib: 3.7.5
2025-02-06 21:43:53,334:INFO:          scikitplot: 0.3.7
2025-02-06 21:43:53,334:INFO:         yellowbrick: 1.5
2025-02-06 21:43:53,334:INFO:              plotly: 5.24.1
2025-02-06 21:43:53,334:INFO:    plotly-resampler: Not installed
2025-02-06 21:43:53,334:INFO:             kaleido: 0.2.1
2025-02-06 21:43:53,334:INFO:           schemdraw: 0.15
2025-02-06 21:43:53,334:INFO:         statsmodels: 0.14.4
2025-02-06 21:43:53,334:INFO:              sktime: 0.26.0
2025-02-06 21:43:53,334:INFO:               tbats: 1.1.3
2025-02-06 21:43:53,334:INFO:            pmdarima: 2.0.4
2025-02-06 21:43:53,334:INFO:              psutil: 6.1.1
2025-02-06 21:43:53,334:INFO:          markupsafe: 3.0.2
2025-02-06 21:43:53,334:INFO:             pickle5: Not installed
2025-02-06 21:43:53,334:INFO:         cloudpickle: 3.1.1
2025-02-06 21:43:53,334:INFO:         deprecation: 2.1.0
2025-02-06 21:43:53,334:INFO:              xxhash: 3.5.0
2025-02-06 21:43:53,334:INFO:           wurlitzer: Not installed
2025-02-06 21:43:53,334:INFO:PyCaret optional dependencies:
2025-02-06 21:43:53,341:INFO:                shap: Not installed
2025-02-06 21:43:53,341:INFO:           interpret: Not installed
2025-02-06 21:43:53,341:INFO:                umap: Not installed
2025-02-06 21:43:53,341:INFO:     ydata_profiling: Not installed
2025-02-06 21:43:53,341:INFO:  explainerdashboard: Not installed
2025-02-06 21:43:53,341:INFO:             autoviz: Not installed
2025-02-06 21:43:53,341:INFO:           fairlearn: Not installed
2025-02-06 21:43:53,341:INFO:          deepchecks: Not installed
2025-02-06 21:43:53,341:INFO:             xgboost: Not installed
2025-02-06 21:43:53,341:INFO:            catboost: Not installed
2025-02-06 21:43:53,341:INFO:              kmodes: Not installed
2025-02-06 21:43:53,341:INFO:             mlxtend: Not installed
2025-02-06 21:43:53,341:INFO:       statsforecast: Not installed
2025-02-06 21:43:53,341:INFO:        tune_sklearn: Not installed
2025-02-06 21:43:53,341:INFO:                 ray: Not installed
2025-02-06 21:43:53,341:INFO:            hyperopt: Not installed
2025-02-06 21:43:53,341:INFO:              optuna: Not installed
2025-02-06 21:43:53,341:INFO:               skopt: Not installed
2025-02-06 21:43:53,341:INFO:              mlflow: Not installed
2025-02-06 21:43:53,341:INFO:              gradio: Not installed
2025-02-06 21:43:53,341:INFO:             fastapi: Not installed
2025-02-06 21:43:53,341:INFO:             uvicorn: Not installed
2025-02-06 21:43:53,341:INFO:              m2cgen: Not installed
2025-02-06 21:43:53,342:INFO:           evidently: Not installed
2025-02-06 21:43:53,342:INFO:               fugue: Not installed
2025-02-06 21:43:53,342:INFO:           streamlit: Not installed
2025-02-06 21:43:53,342:INFO:             prophet: Not installed
2025-02-06 21:43:53,342:INFO:None
2025-02-06 21:43:53,342:INFO:Set up data.
2025-02-06 21:43:53,350:INFO:Set up folding strategy.
2025-02-06 21:43:53,350:INFO:Set up train/test split.
2025-02-06 21:43:53,358:INFO:Set up index.
2025-02-06 21:43:53,358:INFO:Assigning column types.
2025-02-06 21:43:53,363:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:43:53,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,450:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:43:53,473:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,512:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:43:53,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,528:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:43:53,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,607:INFO:Preparing preprocessing pipeline...
2025-02-06 21:43:53,608:INFO:Set up simple imputation.
2025-02-06 21:43:53,608:INFO:Set up feature normalization.
2025-02-06 21:43:53,631:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:43:53,633:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:43:53,633:INFO:Creating final display dataframe.
2025-02-06 21:43:53,705:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              943c
2025-02-06 21:43:53,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:43:53,784:INFO:setup() successfully completed in 0.47s...............
2025-02-06 21:43:53,784:INFO:Initializing compare_models()
2025-02-06 21:43:53,784:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:43:53,784:INFO:Checking exceptions
2025-02-06 21:43:53,788:INFO:Preparing display monitor
2025-02-06 21:43:53,800:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:43:53,800:INFO:Total runtime is 0.0 minutes
2025-02-06 21:43:53,802:INFO:SubProcess create_model() called ==================================
2025-02-06 21:43:53,802:INFO:Initializing create_model()
2025-02-06 21:43:53,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA226070D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:43:53,802:INFO:Checking exceptions
2025-02-06 21:43:53,802:INFO:Importing libraries
2025-02-06 21:43:53,802:INFO:Copying training dataset
2025-02-06 21:43:53,808:INFO:Defining folds
2025-02-06 21:43:53,808:INFO:Declaring metric variables
2025-02-06 21:43:53,810:INFO:Importing untrained model
2025-02-06 21:43:53,811:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:43:53,814:INFO:Starting cross validation
2025-02-06 21:43:53,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:43:56,762:INFO:Calculating mean and std
2025-02-06 21:43:56,763:INFO:Creating metrics dataframe
2025-02-06 21:43:56,764:INFO:Uploading results into container
2025-02-06 21:43:56,765:INFO:Uploading model into container now
2025-02-06 21:43:56,765:INFO:_master_model_container: 1
2025-02-06 21:43:56,765:INFO:_display_container: 2
2025-02-06 21:43:56,766:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:43:56,766:INFO:create_model() successfully completed......................................
2025-02-06 21:43:56,831:INFO:SubProcess create_model() end ==================================
2025-02-06 21:43:56,831:INFO:Creating metrics dataframe
2025-02-06 21:43:56,835:INFO:Initializing Logistic Regression
2025-02-06 21:43:56,835:INFO:Total runtime is 0.05058368444442749 minutes
2025-02-06 21:43:56,838:INFO:SubProcess create_model() called ==================================
2025-02-06 21:43:56,838:INFO:Initializing create_model()
2025-02-06 21:43:56,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA226070D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:43:56,838:INFO:Checking exceptions
2025-02-06 21:43:56,838:INFO:Importing libraries
2025-02-06 21:43:56,838:INFO:Copying training dataset
2025-02-06 21:43:56,845:INFO:Defining folds
2025-02-06 21:43:56,845:INFO:Declaring metric variables
2025-02-06 21:43:56,848:INFO:Importing untrained model
2025-02-06 21:43:56,850:INFO:Logistic Regression Imported successfully
2025-02-06 21:43:56,854:INFO:Starting cross validation
2025-02-06 21:43:56,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:43:58,305:INFO:Calculating mean and std
2025-02-06 21:43:58,307:INFO:Creating metrics dataframe
2025-02-06 21:43:58,308:INFO:Uploading results into container
2025-02-06 21:43:58,308:INFO:Uploading model into container now
2025-02-06 21:43:58,309:INFO:_master_model_container: 2
2025-02-06 21:43:58,309:INFO:_display_container: 2
2025-02-06 21:43:58,309:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:43:58,309:INFO:create_model() successfully completed......................................
2025-02-06 21:43:58,381:INFO:SubProcess create_model() end ==================================
2025-02-06 21:43:58,381:INFO:Creating metrics dataframe
2025-02-06 21:43:58,386:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:43:58,388:INFO:Initializing create_model()
2025-02-06 21:43:58,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:43:58,389:INFO:Checking exceptions
2025-02-06 21:43:58,390:INFO:Importing libraries
2025-02-06 21:43:58,390:INFO:Copying training dataset
2025-02-06 21:43:58,395:INFO:Defining folds
2025-02-06 21:43:58,395:INFO:Declaring metric variables
2025-02-06 21:43:58,396:INFO:Importing untrained model
2025-02-06 21:43:58,396:INFO:Declaring custom model
2025-02-06 21:43:58,396:INFO:Logistic Regression Imported successfully
2025-02-06 21:43:58,396:INFO:Cross validation set to False
2025-02-06 21:43:58,396:INFO:Fitting Model
2025-02-06 21:43:58,425:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:43:58,425:INFO:create_model() successfully completed......................................
2025-02-06 21:43:58,477:INFO:_master_model_container: 2
2025-02-06 21:43:58,477:INFO:_display_container: 2
2025-02-06 21:43:58,477:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:43:58,477:INFO:compare_models() successfully completed......................................
2025-02-06 21:43:58,477:INFO:Initializing create_model()
2025-02-06 21:43:58,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:43:58,477:INFO:Checking exceptions
2025-02-06 21:43:58,485:INFO:Importing libraries
2025-02-06 21:43:58,485:INFO:Copying training dataset
2025-02-06 21:43:58,491:INFO:Defining folds
2025-02-06 21:43:58,491:INFO:Declaring metric variables
2025-02-06 21:43:58,492:INFO:Importing untrained model
2025-02-06 21:43:58,494:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:43:58,497:INFO:Starting cross validation
2025-02-06 21:43:58,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:43:59,300:INFO:Calculating mean and std
2025-02-06 21:43:59,300:INFO:Creating metrics dataframe
2025-02-06 21:43:59,304:INFO:Finalizing model
2025-02-06 21:43:59,323:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:43:59,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
2025-02-06 21:43:59,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:43:59,324:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:43:59,324:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:43:59,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:43:59,325:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:43:59,423:INFO:Uploading results into container
2025-02-06 21:43:59,424:INFO:Uploading model into container now
2025-02-06 21:43:59,429:INFO:_master_model_container: 3
2025-02-06 21:43:59,429:INFO:_display_container: 3
2025-02-06 21:43:59,431:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:43:59,431:INFO:create_model() successfully completed......................................
2025-02-06 21:43:59,499:INFO:Initializing tune_model()
2025-02-06 21:43:59,499:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:43:59,499:INFO:Checking exceptions
2025-02-06 21:43:59,510:INFO:Copying training dataset
2025-02-06 21:43:59,517:INFO:Checking base model
2025-02-06 21:43:59,517:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:43:59,519:INFO:Declaring metric variables
2025-02-06 21:43:59,520:INFO:Defining Hyperparameters
2025-02-06 21:43:59,563:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:43:59,563:INFO:Tuning with n_jobs=-1
2025-02-06 21:43:59,563:INFO:Initializing RandomizedSearchCV
2025-02-06 21:44:02,810:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:44:02,811:INFO:Hyperparameter search completed
2025-02-06 21:44:02,811:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:02,812:INFO:Initializing create_model()
2025-02-06 21:44:02,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA203913D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:44:02,812:INFO:Checking exceptions
2025-02-06 21:44:02,812:INFO:Importing libraries
2025-02-06 21:44:02,812:INFO:Copying training dataset
2025-02-06 21:44:02,821:INFO:Defining folds
2025-02-06 21:44:02,821:INFO:Declaring metric variables
2025-02-06 21:44:02,823:INFO:Importing untrained model
2025-02-06 21:44:02,823:INFO:Declaring custom model
2025-02-06 21:44:02,826:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:44:02,830:INFO:Starting cross validation
2025-02-06 21:44:02,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:03,177:INFO:Calculating mean and std
2025-02-06 21:44:03,178:INFO:Creating metrics dataframe
2025-02-06 21:44:03,183:INFO:Finalizing model
2025-02-06 21:44:03,200:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:44:03,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
2025-02-06 21:44:03,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:44:03,201:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:44:03,201:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:44:03,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:44:03,201:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:44:03,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:03,257:INFO:Uploading results into container
2025-02-06 21:44:03,258:INFO:Uploading model into container now
2025-02-06 21:44:03,258:INFO:_master_model_container: 4
2025-02-06 21:44:03,258:INFO:_display_container: 4
2025-02-06 21:44:03,258:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:03,258:INFO:create_model() successfully completed......................................
2025-02-06 21:44:03,316:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:03,316:INFO:choose_better activated
2025-02-06 21:44:03,318:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:03,318:INFO:Initializing create_model()
2025-02-06 21:44:03,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:03,319:INFO:Checking exceptions
2025-02-06 21:44:03,320:INFO:Importing libraries
2025-02-06 21:44:03,320:INFO:Copying training dataset
2025-02-06 21:44:03,328:INFO:Defining folds
2025-02-06 21:44:03,328:INFO:Declaring metric variables
2025-02-06 21:44:03,328:INFO:Importing untrained model
2025-02-06 21:44:03,328:INFO:Declaring custom model
2025-02-06 21:44:03,329:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:44:03,329:INFO:Starting cross validation
2025-02-06 21:44:03,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:04,065:INFO:Calculating mean and std
2025-02-06 21:44:04,066:INFO:Creating metrics dataframe
2025-02-06 21:44:04,068:INFO:Finalizing model
2025-02-06 21:44:04,087:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:44:04,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.
2025-02-06 21:44:04,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:44:04,088:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:44:04,088:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:44:04,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:44:04,089:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:44:04,191:INFO:Uploading results into container
2025-02-06 21:44:04,191:INFO:Uploading model into container now
2025-02-06 21:44:04,191:INFO:_master_model_container: 5
2025-02-06 21:44:04,191:INFO:_display_container: 5
2025-02-06 21:44:04,191:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:04,191:INFO:create_model() successfully completed......................................
2025-02-06 21:44:04,246:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:04,247:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:44:04,248:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:44:04,248:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:44:04,248:INFO:choose_better completed
2025-02-06 21:44:04,253:INFO:_master_model_container: 5
2025-02-06 21:44:04,253:INFO:_display_container: 4
2025-02-06 21:44:04,254:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:04,254:INFO:tune_model() successfully completed......................................
2025-02-06 21:44:04,306:INFO:Initializing create_model()
2025-02-06 21:44:04,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:04,306:INFO:Checking exceptions
2025-02-06 21:44:04,312:INFO:Importing libraries
2025-02-06 21:44:04,312:INFO:Copying training dataset
2025-02-06 21:44:04,318:INFO:Defining folds
2025-02-06 21:44:04,319:INFO:Declaring metric variables
2025-02-06 21:44:04,320:INFO:Importing untrained model
2025-02-06 21:44:04,322:INFO:Logistic Regression Imported successfully
2025-02-06 21:44:04,325:INFO:Starting cross validation
2025-02-06 21:44:04,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:04,394:INFO:Calculating mean and std
2025-02-06 21:44:04,394:INFO:Creating metrics dataframe
2025-02-06 21:44:04,397:INFO:Finalizing model
2025-02-06 21:44:04,427:INFO:Uploading results into container
2025-02-06 21:44:04,427:INFO:Uploading model into container now
2025-02-06 21:44:04,431:INFO:_master_model_container: 6
2025-02-06 21:44:04,432:INFO:_display_container: 5
2025-02-06 21:44:04,432:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:44:04,432:INFO:create_model() successfully completed......................................
2025-02-06 21:44:04,493:INFO:Initializing tune_model()
2025-02-06 21:44:04,494:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:44:04,494:INFO:Checking exceptions
2025-02-06 21:44:04,501:INFO:Copying training dataset
2025-02-06 21:44:04,505:INFO:Checking base model
2025-02-06 21:44:04,505:INFO:Base model : Logistic Regression
2025-02-06 21:44:04,507:INFO:Declaring metric variables
2025-02-06 21:44:04,508:INFO:Defining Hyperparameters
2025-02-06 21:44:04,575:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:44:04,575:INFO:Tuning with n_jobs=-1
2025-02-06 21:44:04,575:INFO:Initializing RandomizedSearchCV
2025-02-06 21:44:04,964:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:44:04,964:INFO:Hyperparameter search completed
2025-02-06 21:44:04,964:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:04,964:INFO:Initializing create_model()
2025-02-06 21:44:04,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA5CCF1D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:44:04,964:INFO:Checking exceptions
2025-02-06 21:44:04,965:INFO:Importing libraries
2025-02-06 21:44:04,965:INFO:Copying training dataset
2025-02-06 21:44:04,971:INFO:Defining folds
2025-02-06 21:44:04,971:INFO:Declaring metric variables
2025-02-06 21:44:04,973:INFO:Importing untrained model
2025-02-06 21:44:04,973:INFO:Declaring custom model
2025-02-06 21:44:04,974:INFO:Logistic Regression Imported successfully
2025-02-06 21:44:04,977:INFO:Starting cross validation
2025-02-06 21:44:04,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:05,077:INFO:Calculating mean and std
2025-02-06 21:44:05,077:INFO:Creating metrics dataframe
2025-02-06 21:44:05,079:INFO:Finalizing model
2025-02-06 21:44:05,110:INFO:Uploading results into container
2025-02-06 21:44:05,110:INFO:Uploading model into container now
2025-02-06 21:44:05,111:INFO:_master_model_container: 7
2025-02-06 21:44:05,111:INFO:_display_container: 6
2025-02-06 21:44:05,111:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:44:05,111:INFO:create_model() successfully completed......................................
2025-02-06 21:44:05,160:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:05,160:INFO:choose_better activated
2025-02-06 21:44:05,161:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:05,162:INFO:Initializing create_model()
2025-02-06 21:44:05,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:05,162:INFO:Checking exceptions
2025-02-06 21:44:05,162:INFO:Importing libraries
2025-02-06 21:44:05,163:INFO:Copying training dataset
2025-02-06 21:44:05,169:INFO:Defining folds
2025-02-06 21:44:05,169:INFO:Declaring metric variables
2025-02-06 21:44:05,169:INFO:Importing untrained model
2025-02-06 21:44:05,169:INFO:Declaring custom model
2025-02-06 21:44:05,169:INFO:Logistic Regression Imported successfully
2025-02-06 21:44:05,169:INFO:Starting cross validation
2025-02-06 21:44:05,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:05,225:INFO:Calculating mean and std
2025-02-06 21:44:05,225:INFO:Creating metrics dataframe
2025-02-06 21:44:05,226:INFO:Finalizing model
2025-02-06 21:44:05,252:INFO:Uploading results into container
2025-02-06 21:44:05,253:INFO:Uploading model into container now
2025-02-06 21:44:05,253:INFO:_master_model_container: 8
2025-02-06 21:44:05,253:INFO:_display_container: 7
2025-02-06 21:44:05,253:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:44:05,253:INFO:create_model() successfully completed......................................
2025-02-06 21:44:05,306:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:05,306:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:44:05,307:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:44:05,307:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:44:05,307:INFO:choose_better completed
2025-02-06 21:44:05,311:INFO:_master_model_container: 8
2025-02-06 21:44:05,311:INFO:_display_container: 6
2025-02-06 21:44:05,311:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:44:05,311:INFO:tune_model() successfully completed......................................
2025-02-06 21:44:05,350:INFO:Initializing compare_models()
2025-02-06 21:44:05,350:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:44:05,350:INFO:Checking exceptions
2025-02-06 21:44:05,353:INFO:Preparing display monitor
2025-02-06 21:44:05,364:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:44:05,364:INFO:Total runtime is 0.0 minutes
2025-02-06 21:44:05,365:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:05,365:INFO:Initializing create_model()
2025-02-06 21:44:05,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA206215D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:05,365:INFO:Checking exceptions
2025-02-06 21:44:05,365:INFO:Importing libraries
2025-02-06 21:44:05,365:INFO:Copying training dataset
2025-02-06 21:44:05,371:INFO:Defining folds
2025-02-06 21:44:05,371:INFO:Declaring metric variables
2025-02-06 21:44:05,372:INFO:Importing untrained model
2025-02-06 21:44:05,373:INFO:Declaring custom model
2025-02-06 21:44:05,374:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:44:05,377:INFO:Starting cross validation
2025-02-06 21:44:05,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:05,701:INFO:Calculating mean and std
2025-02-06 21:44:05,702:INFO:Creating metrics dataframe
2025-02-06 21:44:05,704:INFO:Uploading results into container
2025-02-06 21:44:05,704:INFO:Uploading model into container now
2025-02-06 21:44:05,705:INFO:_master_model_container: 9
2025-02-06 21:44:05,705:INFO:_display_container: 7
2025-02-06 21:44:05,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:05,706:INFO:create_model() successfully completed......................................
2025-02-06 21:44:05,767:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:05,767:INFO:Creating metrics dataframe
2025-02-06 21:44:05,771:INFO:Initializing custom model Logistic Regression
2025-02-06 21:44:05,772:INFO:Total runtime is 0.006809715429941813 minutes
2025-02-06 21:44:05,774:INFO:SubProcess create_model() called ==================================
2025-02-06 21:44:05,774:INFO:Initializing create_model()
2025-02-06 21:44:05,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA206215D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:05,775:INFO:Checking exceptions
2025-02-06 21:44:05,775:INFO:Importing libraries
2025-02-06 21:44:05,775:INFO:Copying training dataset
2025-02-06 21:44:05,783:INFO:Defining folds
2025-02-06 21:44:05,783:INFO:Declaring metric variables
2025-02-06 21:44:05,785:INFO:Importing untrained model
2025-02-06 21:44:05,785:INFO:Declaring custom model
2025-02-06 21:44:05,787:INFO:Logistic Regression Imported successfully
2025-02-06 21:44:05,791:INFO:Starting cross validation
2025-02-06 21:44:05,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:44:05,880:INFO:Calculating mean and std
2025-02-06 21:44:05,880:INFO:Creating metrics dataframe
2025-02-06 21:44:05,881:INFO:Uploading results into container
2025-02-06 21:44:05,881:INFO:Uploading model into container now
2025-02-06 21:44:05,881:INFO:_master_model_container: 10
2025-02-06 21:44:05,881:INFO:_display_container: 7
2025-02-06 21:44:05,882:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:44:05,882:INFO:create_model() successfully completed......................................
2025-02-06 21:44:05,931:INFO:SubProcess create_model() end ==================================
2025-02-06 21:44:05,931:INFO:Creating metrics dataframe
2025-02-06 21:44:05,934:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:44:05,939:INFO:Initializing create_model()
2025-02-06 21:44:05,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:44:05,939:INFO:Checking exceptions
2025-02-06 21:44:05,940:INFO:Importing libraries
2025-02-06 21:44:05,940:INFO:Copying training dataset
2025-02-06 21:44:05,946:INFO:Defining folds
2025-02-06 21:44:05,946:INFO:Declaring metric variables
2025-02-06 21:44:05,946:INFO:Importing untrained model
2025-02-06 21:44:05,946:INFO:Declaring custom model
2025-02-06 21:44:05,946:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:44:05,947:INFO:Cross validation set to False
2025-02-06 21:44:05,947:INFO:Fitting Model
2025-02-06 21:44:05,962:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:44:05,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
2025-02-06 21:44:05,963:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:44:05,963:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:44:05,963:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:44:05,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:44:05,963:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:44:05,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:44:05,988:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:05,988:INFO:create_model() successfully completed......................................
2025-02-06 21:44:06,062:INFO:_master_model_container: 10
2025-02-06 21:44:06,062:INFO:_display_container: 7
2025-02-06 21:44:06,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:44:06,063:INFO:compare_models() successfully completed......................................
2025-02-06 21:44:06,064:INFO:Initializing predict_model()
2025-02-06 21:44:06,064:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CA226B6980>)
2025-02-06 21:44:06,064:INFO:Checking exceptions
2025-02-06 21:44:06,064:INFO:Preloading libraries
2025-02-06 21:44:06,066:INFO:Set up data.
2025-02-06 21:44:06,075:INFO:Set up index.
2025-02-06 21:44:06,183:INFO:Initializing predict_model()
2025-02-06 21:44:06,183:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CA226B6980>)
2025-02-06 21:44:06,183:INFO:Checking exceptions
2025-02-06 21:44:06,183:INFO:Preloading libraries
2025-02-06 21:44:06,184:INFO:Set up data.
2025-02-06 21:44:06,192:INFO:Set up index.
2025-02-06 21:44:06,280:INFO:Initializing predict_model()
2025-02-06 21:44:06,280:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CA226B6980>)
2025-02-06 21:44:06,280:INFO:Checking exceptions
2025-02-06 21:44:06,280:INFO:Preloading libraries
2025-02-06 21:44:06,280:INFO:Set up data.
2025-02-06 21:44:06,288:INFO:Set up index.
2025-02-06 21:44:06,373:INFO:Initializing predict_model()
2025-02-06 21:44:06,373:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CA226B6980>)
2025-02-06 21:44:06,373:INFO:Checking exceptions
2025-02-06 21:44:06,373:INFO:Preloading libraries
2025-02-06 21:44:06,374:INFO:Set up data.
2025-02-06 21:44:06,378:INFO:Set up index.
2025-02-06 21:44:06,444:INFO:Initializing get_config()
2025-02-06 21:44:06,444:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CA207C8C90>, variable=train_pred)
2025-02-06 21:45:21,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:21,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:21,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:21,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:22,246:INFO:PyCaret ClassificationExperiment
2025-02-06 21:45:22,246:INFO:Logging name: clf-default-name
2025-02-06 21:45:22,246:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:45:22,246:INFO:version 3.3.2
2025-02-06 21:45:22,246:INFO:Initializing setup()
2025-02-06 21:45:22,246:INFO:self.USI: 8e3b
2025-02-06 21:45:22,246:INFO:self._variable_keys: {'memory', 'X_train', 'idx', 'X', 'n_jobs_param', 'y_test', 'exp_id', '_available_plots', 'y_train', 'fold_groups_param', 'seed', 'data', 'y', 'X_test', 'fix_imbalance', 'html_param', 'target_param', 'logging_param', 'is_multiclass', 'log_plots_param', '_ml_usecase', 'gpu_n_jobs_param', 'USI', 'pipeline', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'exp_name_log'}
2025-02-06 21:45:22,246:INFO:Checking environment
2025-02-06 21:45:22,246:INFO:python_version: 3.11.9
2025-02-06 21:45:22,246:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:45:22,246:INFO:machine: AMD64
2025-02-06 21:45:22,246:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:45:22,251:INFO:Memory: svmem(total=67771465728, available=49609142272, percent=26.8, used=18162323456, free=49609142272)
2025-02-06 21:45:22,251:INFO:Physical Core: 8
2025-02-06 21:45:22,251:INFO:Logical Core: 16
2025-02-06 21:45:22,251:INFO:Checking libraries
2025-02-06 21:45:22,251:INFO:System:
2025-02-06 21:45:22,253:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:45:22,253:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:45:22,253:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:45:22,253:INFO:PyCaret required dependencies:
2025-02-06 21:45:22,267:INFO:                 pip: 25.0
2025-02-06 21:45:22,269:INFO:          setuptools: 65.5.0
2025-02-06 21:45:22,269:INFO:             pycaret: 3.3.2
2025-02-06 21:45:22,269:INFO:             IPython: 8.32.0
2025-02-06 21:45:22,269:INFO:          ipywidgets: 8.1.5
2025-02-06 21:45:22,269:INFO:                tqdm: 4.67.1
2025-02-06 21:45:22,269:INFO:               numpy: 1.26.4
2025-02-06 21:45:22,269:INFO:              pandas: 2.1.4
2025-02-06 21:45:22,269:INFO:              jinja2: 3.1.5
2025-02-06 21:45:22,269:INFO:               scipy: 1.11.4
2025-02-06 21:45:22,269:INFO:              joblib: 1.3.2
2025-02-06 21:45:22,269:INFO:             sklearn: 1.4.2
2025-02-06 21:45:22,269:INFO:                pyod: 2.0.3
2025-02-06 21:45:22,269:INFO:            imblearn: 0.13.0
2025-02-06 21:45:22,269:INFO:   category_encoders: 2.7.0
2025-02-06 21:45:22,269:INFO:            lightgbm: 4.5.0
2025-02-06 21:45:22,269:INFO:               numba: 0.61.0
2025-02-06 21:45:22,269:INFO:            requests: 2.32.3
2025-02-06 21:45:22,269:INFO:          matplotlib: 3.7.5
2025-02-06 21:45:22,269:INFO:          scikitplot: 0.3.7
2025-02-06 21:45:22,269:INFO:         yellowbrick: 1.5
2025-02-06 21:45:22,269:INFO:              plotly: 5.24.1
2025-02-06 21:45:22,269:INFO:    plotly-resampler: Not installed
2025-02-06 21:45:22,269:INFO:             kaleido: 0.2.1
2025-02-06 21:45:22,269:INFO:           schemdraw: 0.15
2025-02-06 21:45:22,269:INFO:         statsmodels: 0.14.4
2025-02-06 21:45:22,269:INFO:              sktime: 0.26.0
2025-02-06 21:45:22,269:INFO:               tbats: 1.1.3
2025-02-06 21:45:22,269:INFO:            pmdarima: 2.0.4
2025-02-06 21:45:22,269:INFO:              psutil: 6.1.1
2025-02-06 21:45:22,269:INFO:          markupsafe: 3.0.2
2025-02-06 21:45:22,269:INFO:             pickle5: Not installed
2025-02-06 21:45:22,269:INFO:         cloudpickle: 3.1.1
2025-02-06 21:45:22,269:INFO:         deprecation: 2.1.0
2025-02-06 21:45:22,269:INFO:              xxhash: 3.5.0
2025-02-06 21:45:22,269:INFO:           wurlitzer: Not installed
2025-02-06 21:45:22,269:INFO:PyCaret optional dependencies:
2025-02-06 21:45:22,276:INFO:                shap: Not installed
2025-02-06 21:45:22,276:INFO:           interpret: Not installed
2025-02-06 21:45:22,276:INFO:                umap: Not installed
2025-02-06 21:45:22,276:INFO:     ydata_profiling: Not installed
2025-02-06 21:45:22,276:INFO:  explainerdashboard: Not installed
2025-02-06 21:45:22,276:INFO:             autoviz: Not installed
2025-02-06 21:45:22,276:INFO:           fairlearn: Not installed
2025-02-06 21:45:22,276:INFO:          deepchecks: Not installed
2025-02-06 21:45:22,276:INFO:             xgboost: Not installed
2025-02-06 21:45:22,276:INFO:            catboost: Not installed
2025-02-06 21:45:22,276:INFO:              kmodes: Not installed
2025-02-06 21:45:22,276:INFO:             mlxtend: Not installed
2025-02-06 21:45:22,276:INFO:       statsforecast: Not installed
2025-02-06 21:45:22,276:INFO:        tune_sklearn: Not installed
2025-02-06 21:45:22,276:INFO:                 ray: Not installed
2025-02-06 21:45:22,276:INFO:            hyperopt: Not installed
2025-02-06 21:45:22,276:INFO:              optuna: Not installed
2025-02-06 21:45:22,276:INFO:               skopt: Not installed
2025-02-06 21:45:22,276:INFO:              mlflow: Not installed
2025-02-06 21:45:22,276:INFO:              gradio: Not installed
2025-02-06 21:45:22,276:INFO:             fastapi: Not installed
2025-02-06 21:45:22,276:INFO:             uvicorn: Not installed
2025-02-06 21:45:22,276:INFO:              m2cgen: Not installed
2025-02-06 21:45:22,276:INFO:           evidently: Not installed
2025-02-06 21:45:22,276:INFO:               fugue: Not installed
2025-02-06 21:45:22,276:INFO:           streamlit: Not installed
2025-02-06 21:45:22,276:INFO:             prophet: Not installed
2025-02-06 21:45:22,276:INFO:None
2025-02-06 21:45:22,276:INFO:Set up data.
2025-02-06 21:45:22,283:INFO:Set up folding strategy.
2025-02-06 21:45:22,283:INFO:Set up train/test split.
2025-02-06 21:45:22,289:INFO:Set up index.
2025-02-06 21:45:22,289:INFO:Assigning column types.
2025-02-06 21:45:22,294:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:45:22,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,321:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,364:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,379:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:45:22,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:22,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,456:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:45:22,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,535:INFO:Preparing preprocessing pipeline...
2025-02-06 21:45:22,536:INFO:Set up simple imputation.
2025-02-06 21:45:22,536:INFO:Set up feature normalization.
2025-02-06 21:45:22,559:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:45:22,561:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:45:22,561:INFO:Creating final display dataframe.
2025-02-06 21:45:22,632:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              8e3b
2025-02-06 21:45:22,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:22,713:INFO:setup() successfully completed in 0.47s...............
2025-02-06 21:45:22,713:INFO:Initializing compare_models()
2025-02-06 21:45:22,713:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:45:22,713:INFO:Checking exceptions
2025-02-06 21:45:22,717:INFO:Preparing display monitor
2025-02-06 21:45:22,729:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:45:22,729:INFO:Total runtime is 0.0 minutes
2025-02-06 21:45:22,730:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:22,730:INFO:Initializing create_model()
2025-02-06 21:45:22,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011696F62B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:22,731:INFO:Checking exceptions
2025-02-06 21:45:22,731:INFO:Importing libraries
2025-02-06 21:45:22,731:INFO:Copying training dataset
2025-02-06 21:45:22,736:INFO:Defining folds
2025-02-06 21:45:22,736:INFO:Declaring metric variables
2025-02-06 21:45:22,738:INFO:Importing untrained model
2025-02-06 21:45:22,740:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:22,743:INFO:Starting cross validation
2025-02-06 21:45:22,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:25,647:INFO:Calculating mean and std
2025-02-06 21:45:25,649:INFO:Creating metrics dataframe
2025-02-06 21:45:25,650:INFO:Uploading results into container
2025-02-06 21:45:25,651:INFO:Uploading model into container now
2025-02-06 21:45:25,651:INFO:_master_model_container: 1
2025-02-06 21:45:25,651:INFO:_display_container: 2
2025-02-06 21:45:25,651:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:25,651:INFO:create_model() successfully completed......................................
2025-02-06 21:45:25,733:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:25,733:INFO:Creating metrics dataframe
2025-02-06 21:45:25,738:INFO:Initializing Logistic Regression
2025-02-06 21:45:25,738:INFO:Total runtime is 0.05014426708221435 minutes
2025-02-06 21:45:25,740:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:25,740:INFO:Initializing create_model()
2025-02-06 21:45:25,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011696F62B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:25,741:INFO:Checking exceptions
2025-02-06 21:45:25,741:INFO:Importing libraries
2025-02-06 21:45:25,741:INFO:Copying training dataset
2025-02-06 21:45:25,750:INFO:Defining folds
2025-02-06 21:45:25,750:INFO:Declaring metric variables
2025-02-06 21:45:25,752:INFO:Importing untrained model
2025-02-06 21:45:25,754:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:25,757:INFO:Starting cross validation
2025-02-06 21:45:25,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:27,213:INFO:Calculating mean and std
2025-02-06 21:45:27,214:INFO:Creating metrics dataframe
2025-02-06 21:45:27,216:INFO:Uploading results into container
2025-02-06 21:45:27,216:INFO:Uploading model into container now
2025-02-06 21:45:27,217:INFO:_master_model_container: 2
2025-02-06 21:45:27,217:INFO:_display_container: 2
2025-02-06 21:45:27,217:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:27,217:INFO:create_model() successfully completed......................................
2025-02-06 21:45:27,287:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:27,288:INFO:Creating metrics dataframe
2025-02-06 21:45:27,292:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:45:27,295:INFO:Initializing create_model()
2025-02-06 21:45:27,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:27,295:INFO:Checking exceptions
2025-02-06 21:45:27,296:INFO:Importing libraries
2025-02-06 21:45:27,296:INFO:Copying training dataset
2025-02-06 21:45:27,301:INFO:Defining folds
2025-02-06 21:45:27,303:INFO:Declaring metric variables
2025-02-06 21:45:27,303:INFO:Importing untrained model
2025-02-06 21:45:27,303:INFO:Declaring custom model
2025-02-06 21:45:27,303:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:27,303:INFO:Cross validation set to False
2025-02-06 21:45:27,303:INFO:Fitting Model
2025-02-06 21:45:27,330:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:27,330:INFO:create_model() successfully completed......................................
2025-02-06 21:45:27,379:INFO:_master_model_container: 2
2025-02-06 21:45:27,379:INFO:_display_container: 2
2025-02-06 21:45:27,380:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:27,380:INFO:compare_models() successfully completed......................................
2025-02-06 21:45:27,380:INFO:Initializing create_model()
2025-02-06 21:45:27,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:27,380:INFO:Checking exceptions
2025-02-06 21:45:27,387:INFO:Importing libraries
2025-02-06 21:45:27,387:INFO:Copying training dataset
2025-02-06 21:45:27,395:INFO:Defining folds
2025-02-06 21:45:27,395:INFO:Declaring metric variables
2025-02-06 21:45:27,396:INFO:Importing untrained model
2025-02-06 21:45:27,398:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:27,401:INFO:Starting cross validation
2025-02-06 21:45:27,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:28,157:INFO:Calculating mean and std
2025-02-06 21:45:28,157:INFO:Creating metrics dataframe
2025-02-06 21:45:28,161:INFO:Finalizing model
2025-02-06 21:45:28,181:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:45:28,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
2025-02-06 21:45:28,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:45:28,181:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:45:28,181:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:45:28,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:45:28,182:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:45:28,289:INFO:Uploading results into container
2025-02-06 21:45:28,289:INFO:Uploading model into container now
2025-02-06 21:45:28,296:INFO:_master_model_container: 3
2025-02-06 21:45:28,296:INFO:_display_container: 3
2025-02-06 21:45:28,297:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:28,297:INFO:create_model() successfully completed......................................
2025-02-06 21:45:28,376:INFO:Initializing tune_model()
2025-02-06 21:45:28,377:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:45:28,377:INFO:Checking exceptions
2025-02-06 21:45:28,389:INFO:Copying training dataset
2025-02-06 21:45:28,393:INFO:Checking base model
2025-02-06 21:45:28,393:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:45:28,394:INFO:Declaring metric variables
2025-02-06 21:45:28,395:INFO:Defining Hyperparameters
2025-02-06 21:45:28,437:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:45:28,437:INFO:Tuning with n_jobs=-1
2025-02-06 21:45:28,437:INFO:Initializing RandomizedSearchCV
2025-02-06 21:45:31,650:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:45:31,651:INFO:Hyperparameter search completed
2025-02-06 21:45:31,651:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:31,652:INFO:Initializing create_model()
2025-02-06 21:45:31,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001169515E750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:45:31,652:INFO:Checking exceptions
2025-02-06 21:45:31,652:INFO:Importing libraries
2025-02-06 21:45:31,652:INFO:Copying training dataset
2025-02-06 21:45:31,662:INFO:Defining folds
2025-02-06 21:45:31,662:INFO:Declaring metric variables
2025-02-06 21:45:31,663:INFO:Importing untrained model
2025-02-06 21:45:31,663:INFO:Declaring custom model
2025-02-06 21:45:31,666:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:31,669:INFO:Starting cross validation
2025-02-06 21:45:31,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:32,022:INFO:Calculating mean and std
2025-02-06 21:45:32,023:INFO:Creating metrics dataframe
2025-02-06 21:45:32,029:INFO:Finalizing model
2025-02-06 21:45:32,050:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:45:32,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.
2025-02-06 21:45:32,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:45:32,051:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:45:32,051:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:45:32,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:45:32,052:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:45:32,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:32,116:INFO:Uploading results into container
2025-02-06 21:45:32,117:INFO:Uploading model into container now
2025-02-06 21:45:32,117:INFO:_master_model_container: 4
2025-02-06 21:45:32,117:INFO:_display_container: 4
2025-02-06 21:45:32,117:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:32,117:INFO:create_model() successfully completed......................................
2025-02-06 21:45:32,180:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:32,180:INFO:choose_better activated
2025-02-06 21:45:32,182:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:32,183:INFO:Initializing create_model()
2025-02-06 21:45:32,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:32,183:INFO:Checking exceptions
2025-02-06 21:45:32,184:INFO:Importing libraries
2025-02-06 21:45:32,184:INFO:Copying training dataset
2025-02-06 21:45:32,193:INFO:Defining folds
2025-02-06 21:45:32,193:INFO:Declaring metric variables
2025-02-06 21:45:32,193:INFO:Importing untrained model
2025-02-06 21:45:32,193:INFO:Declaring custom model
2025-02-06 21:45:32,193:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:32,193:INFO:Starting cross validation
2025-02-06 21:45:32,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:32,857:INFO:Calculating mean and std
2025-02-06 21:45:32,857:INFO:Creating metrics dataframe
2025-02-06 21:45:32,859:INFO:Finalizing model
2025-02-06 21:45:32,877:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:45:32,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.
2025-02-06 21:45:32,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:45:32,878:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:45:32,878:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:45:32,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:45:32,878:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:45:32,986:INFO:Uploading results into container
2025-02-06 21:45:32,987:INFO:Uploading model into container now
2025-02-06 21:45:32,987:INFO:_master_model_container: 5
2025-02-06 21:45:32,987:INFO:_display_container: 5
2025-02-06 21:45:32,987:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:32,988:INFO:create_model() successfully completed......................................
2025-02-06 21:45:33,045:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:33,045:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:45:33,046:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:45:33,046:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:45:33,046:INFO:choose_better completed
2025-02-06 21:45:33,052:INFO:_master_model_container: 5
2025-02-06 21:45:33,052:INFO:_display_container: 4
2025-02-06 21:45:33,053:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:33,053:INFO:tune_model() successfully completed......................................
2025-02-06 21:45:33,097:INFO:Initializing create_model()
2025-02-06 21:45:33,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:33,098:INFO:Checking exceptions
2025-02-06 21:45:33,104:INFO:Importing libraries
2025-02-06 21:45:33,104:INFO:Copying training dataset
2025-02-06 21:45:33,112:INFO:Defining folds
2025-02-06 21:45:33,112:INFO:Declaring metric variables
2025-02-06 21:45:33,114:INFO:Importing untrained model
2025-02-06 21:45:33,116:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:33,119:INFO:Starting cross validation
2025-02-06 21:45:33,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:33,186:INFO:Calculating mean and std
2025-02-06 21:45:33,187:INFO:Creating metrics dataframe
2025-02-06 21:45:33,189:INFO:Finalizing model
2025-02-06 21:45:33,219:INFO:Uploading results into container
2025-02-06 21:45:33,219:INFO:Uploading model into container now
2025-02-06 21:45:33,224:INFO:_master_model_container: 6
2025-02-06 21:45:33,224:INFO:_display_container: 5
2025-02-06 21:45:33,224:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:33,224:INFO:create_model() successfully completed......................................
2025-02-06 21:45:33,278:INFO:Initializing tune_model()
2025-02-06 21:45:33,278:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:45:33,278:INFO:Checking exceptions
2025-02-06 21:45:33,286:INFO:Copying training dataset
2025-02-06 21:45:33,290:INFO:Checking base model
2025-02-06 21:45:33,290:INFO:Base model : Logistic Regression
2025-02-06 21:45:33,293:INFO:Declaring metric variables
2025-02-06 21:45:33,295:INFO:Defining Hyperparameters
2025-02-06 21:45:33,357:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:45:33,358:INFO:Tuning with n_jobs=-1
2025-02-06 21:45:33,358:INFO:Initializing RandomizedSearchCV
2025-02-06 21:45:33,742:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:45:33,742:INFO:Hyperparameter search completed
2025-02-06 21:45:33,742:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:33,743:INFO:Initializing create_model()
2025-02-06 21:45:33,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011695980C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:45:33,743:INFO:Checking exceptions
2025-02-06 21:45:33,743:INFO:Importing libraries
2025-02-06 21:45:33,743:INFO:Copying training dataset
2025-02-06 21:45:33,748:INFO:Defining folds
2025-02-06 21:45:33,748:INFO:Declaring metric variables
2025-02-06 21:45:33,750:INFO:Importing untrained model
2025-02-06 21:45:33,750:INFO:Declaring custom model
2025-02-06 21:45:33,752:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:33,755:INFO:Starting cross validation
2025-02-06 21:45:33,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:33,832:INFO:Calculating mean and std
2025-02-06 21:45:33,832:INFO:Creating metrics dataframe
2025-02-06 21:45:33,835:INFO:Finalizing model
2025-02-06 21:45:33,867:INFO:Uploading results into container
2025-02-06 21:45:33,867:INFO:Uploading model into container now
2025-02-06 21:45:33,868:INFO:_master_model_container: 7
2025-02-06 21:45:33,868:INFO:_display_container: 6
2025-02-06 21:45:33,868:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:33,868:INFO:create_model() successfully completed......................................
2025-02-06 21:45:33,917:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:33,917:INFO:choose_better activated
2025-02-06 21:45:33,918:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:33,919:INFO:Initializing create_model()
2025-02-06 21:45:33,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:33,919:INFO:Checking exceptions
2025-02-06 21:45:33,919:INFO:Importing libraries
2025-02-06 21:45:33,919:INFO:Copying training dataset
2025-02-06 21:45:33,925:INFO:Defining folds
2025-02-06 21:45:33,925:INFO:Declaring metric variables
2025-02-06 21:45:33,925:INFO:Importing untrained model
2025-02-06 21:45:33,925:INFO:Declaring custom model
2025-02-06 21:45:33,925:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:33,925:INFO:Starting cross validation
2025-02-06 21:45:33,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:33,982:INFO:Calculating mean and std
2025-02-06 21:45:33,982:INFO:Creating metrics dataframe
2025-02-06 21:45:33,983:INFO:Finalizing model
2025-02-06 21:45:34,010:INFO:Uploading results into container
2025-02-06 21:45:34,011:INFO:Uploading model into container now
2025-02-06 21:45:34,011:INFO:_master_model_container: 8
2025-02-06 21:45:34,011:INFO:_display_container: 7
2025-02-06 21:45:34,011:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:34,011:INFO:create_model() successfully completed......................................
2025-02-06 21:45:34,057:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:34,057:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:45:34,058:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:45:34,058:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:45:34,058:INFO:choose_better completed
2025-02-06 21:45:34,063:INFO:_master_model_container: 8
2025-02-06 21:45:34,063:INFO:_display_container: 6
2025-02-06 21:45:34,063:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:34,063:INFO:tune_model() successfully completed......................................
2025-02-06 21:45:34,103:INFO:Initializing compare_models()
2025-02-06 21:45:34,103:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:45:34,103:INFO:Checking exceptions
2025-02-06 21:45:34,105:INFO:Preparing display monitor
2025-02-06 21:45:34,115:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:45:34,115:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-02-06 21:45:34,117:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:34,117:INFO:Initializing create_model()
2025-02-06 21:45:34,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000116958E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:34,118:INFO:Checking exceptions
2025-02-06 21:45:34,118:INFO:Importing libraries
2025-02-06 21:45:34,118:INFO:Copying training dataset
2025-02-06 21:45:34,122:INFO:Defining folds
2025-02-06 21:45:34,122:INFO:Declaring metric variables
2025-02-06 21:45:34,125:INFO:Importing untrained model
2025-02-06 21:45:34,125:INFO:Declaring custom model
2025-02-06 21:45:34,126:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:34,129:INFO:Starting cross validation
2025-02-06 21:45:34,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:34,458:INFO:Calculating mean and std
2025-02-06 21:45:34,458:INFO:Creating metrics dataframe
2025-02-06 21:45:34,460:INFO:Uploading results into container
2025-02-06 21:45:34,461:INFO:Uploading model into container now
2025-02-06 21:45:34,461:INFO:_master_model_container: 9
2025-02-06 21:45:34,461:INFO:_display_container: 7
2025-02-06 21:45:34,461:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:34,461:INFO:create_model() successfully completed......................................
2025-02-06 21:45:34,530:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:34,530:INFO:Creating metrics dataframe
2025-02-06 21:45:34,534:INFO:Initializing custom model Logistic Regression
2025-02-06 21:45:34,534:INFO:Total runtime is 0.0069989323616027836 minutes
2025-02-06 21:45:34,536:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:34,536:INFO:Initializing create_model()
2025-02-06 21:45:34,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000116958E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:34,537:INFO:Checking exceptions
2025-02-06 21:45:34,537:INFO:Importing libraries
2025-02-06 21:45:34,537:INFO:Copying training dataset
2025-02-06 21:45:34,544:INFO:Defining folds
2025-02-06 21:45:34,544:INFO:Declaring metric variables
2025-02-06 21:45:34,545:INFO:Importing untrained model
2025-02-06 21:45:34,545:INFO:Declaring custom model
2025-02-06 21:45:34,547:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:34,550:INFO:Starting cross validation
2025-02-06 21:45:34,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:34,632:INFO:Calculating mean and std
2025-02-06 21:45:34,632:INFO:Creating metrics dataframe
2025-02-06 21:45:34,632:INFO:Uploading results into container
2025-02-06 21:45:34,633:INFO:Uploading model into container now
2025-02-06 21:45:34,633:INFO:_master_model_container: 10
2025-02-06 21:45:34,633:INFO:_display_container: 7
2025-02-06 21:45:34,633:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:45:34,633:INFO:create_model() successfully completed......................................
2025-02-06 21:45:34,682:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:34,682:INFO:Creating metrics dataframe
2025-02-06 21:45:34,685:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:45:34,689:INFO:Initializing create_model()
2025-02-06 21:45:34,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:34,689:INFO:Checking exceptions
2025-02-06 21:45:34,690:INFO:Importing libraries
2025-02-06 21:45:34,690:INFO:Copying training dataset
2025-02-06 21:45:34,695:INFO:Defining folds
2025-02-06 21:45:34,695:INFO:Declaring metric variables
2025-02-06 21:45:34,695:INFO:Importing untrained model
2025-02-06 21:45:34,695:INFO:Declaring custom model
2025-02-06 21:45:34,696:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:34,696:INFO:Cross validation set to False
2025-02-06 21:45:34,696:INFO:Fitting Model
2025-02-06 21:45:34,710:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:45:34,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
2025-02-06 21:45:34,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:45:34,711:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:45:34,711:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:45:34,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:45:34,712:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:45:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:45:34,759:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:34,759:INFO:create_model() successfully completed......................................
2025-02-06 21:45:34,861:INFO:_master_model_container: 10
2025-02-06 21:45:34,861:INFO:_display_container: 7
2025-02-06 21:45:34,861:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:34,861:INFO:compare_models() successfully completed......................................
2025-02-06 21:45:34,862:INFO:Initializing predict_model()
2025-02-06 21:45:34,862:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000011695A89580>)
2025-02-06 21:45:34,862:INFO:Checking exceptions
2025-02-06 21:45:34,862:INFO:Preloading libraries
2025-02-06 21:45:34,863:INFO:Set up data.
2025-02-06 21:45:34,869:INFO:Set up index.
2025-02-06 21:45:34,977:INFO:Initializing predict_model()
2025-02-06 21:45:34,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000116958434C0>)
2025-02-06 21:45:34,977:INFO:Checking exceptions
2025-02-06 21:45:34,977:INFO:Preloading libraries
2025-02-06 21:45:34,979:INFO:Set up data.
2025-02-06 21:45:34,984:INFO:Set up index.
2025-02-06 21:45:35,075:INFO:Initializing predict_model()
2025-02-06 21:45:35,076:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000116958434C0>)
2025-02-06 21:45:35,076:INFO:Checking exceptions
2025-02-06 21:45:35,076:INFO:Preloading libraries
2025-02-06 21:45:35,077:INFO:Set up data.
2025-02-06 21:45:35,087:INFO:Set up index.
2025-02-06 21:45:35,177:INFO:Initializing predict_model()
2025-02-06 21:45:35,177:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000116958434C0>)
2025-02-06 21:45:35,177:INFO:Checking exceptions
2025-02-06 21:45:35,177:INFO:Preloading libraries
2025-02-06 21:45:35,177:INFO:Set up data.
2025-02-06 21:45:35,182:INFO:Set up index.
2025-02-06 21:45:35,249:INFO:Initializing get_config()
2025-02-06 21:45:35,249:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011694C4F3D0>, variable=train_pred)
2025-02-06 21:45:55,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:55,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:55,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:55,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:45:56,132:INFO:PyCaret ClassificationExperiment
2025-02-06 21:45:56,132:INFO:Logging name: clf-default-name
2025-02-06 21:45:56,132:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:45:56,132:INFO:version 3.3.2
2025-02-06 21:45:56,132:INFO:Initializing setup()
2025-02-06 21:45:56,132:INFO:self.USI: e783
2025-02-06 21:45:56,132:INFO:self._variable_keys: {'fold_shuffle_param', '_ml_usecase', 'exp_name_log', 'X_test', 'X', 'gpu_n_jobs_param', 'X_train', 'y', 'html_param', 'seed', 'y_test', 'fold_groups_param', 'data', 'is_multiclass', 'idx', 'logging_param', 'target_param', 'log_plots_param', 'USI', '_available_plots', 'pipeline', 'y_train', 'n_jobs_param', 'memory', 'gpu_param', 'fix_imbalance', 'fold_generator', 'exp_id'}
2025-02-06 21:45:56,132:INFO:Checking environment
2025-02-06 21:45:56,132:INFO:python_version: 3.11.9
2025-02-06 21:45:56,132:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:45:56,132:INFO:machine: AMD64
2025-02-06 21:45:56,132:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:45:56,138:INFO:Memory: svmem(total=67771465728, available=49555279872, percent=26.9, used=18216185856, free=49555279872)
2025-02-06 21:45:56,138:INFO:Physical Core: 8
2025-02-06 21:45:56,138:INFO:Logical Core: 16
2025-02-06 21:45:56,138:INFO:Checking libraries
2025-02-06 21:45:56,138:INFO:System:
2025-02-06 21:45:56,138:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:45:56,138:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:45:56,138:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:45:56,138:INFO:PyCaret required dependencies:
2025-02-06 21:45:56,152:INFO:                 pip: 25.0
2025-02-06 21:45:56,152:INFO:          setuptools: 65.5.0
2025-02-06 21:45:56,152:INFO:             pycaret: 3.3.2
2025-02-06 21:45:56,152:INFO:             IPython: 8.32.0
2025-02-06 21:45:56,152:INFO:          ipywidgets: 8.1.5
2025-02-06 21:45:56,152:INFO:                tqdm: 4.67.1
2025-02-06 21:45:56,152:INFO:               numpy: 1.26.4
2025-02-06 21:45:56,152:INFO:              pandas: 2.1.4
2025-02-06 21:45:56,152:INFO:              jinja2: 3.1.5
2025-02-06 21:45:56,152:INFO:               scipy: 1.11.4
2025-02-06 21:45:56,152:INFO:              joblib: 1.3.2
2025-02-06 21:45:56,152:INFO:             sklearn: 1.4.2
2025-02-06 21:45:56,152:INFO:                pyod: 2.0.3
2025-02-06 21:45:56,152:INFO:            imblearn: 0.13.0
2025-02-06 21:45:56,152:INFO:   category_encoders: 2.7.0
2025-02-06 21:45:56,153:INFO:            lightgbm: 4.5.0
2025-02-06 21:45:56,153:INFO:               numba: 0.61.0
2025-02-06 21:45:56,153:INFO:            requests: 2.32.3
2025-02-06 21:45:56,153:INFO:          matplotlib: 3.7.5
2025-02-06 21:45:56,153:INFO:          scikitplot: 0.3.7
2025-02-06 21:45:56,153:INFO:         yellowbrick: 1.5
2025-02-06 21:45:56,153:INFO:              plotly: 5.24.1
2025-02-06 21:45:56,153:INFO:    plotly-resampler: Not installed
2025-02-06 21:45:56,153:INFO:             kaleido: 0.2.1
2025-02-06 21:45:56,153:INFO:           schemdraw: 0.15
2025-02-06 21:45:56,153:INFO:         statsmodels: 0.14.4
2025-02-06 21:45:56,153:INFO:              sktime: 0.26.0
2025-02-06 21:45:56,153:INFO:               tbats: 1.1.3
2025-02-06 21:45:56,153:INFO:            pmdarima: 2.0.4
2025-02-06 21:45:56,153:INFO:              psutil: 6.1.1
2025-02-06 21:45:56,153:INFO:          markupsafe: 3.0.2
2025-02-06 21:45:56,153:INFO:             pickle5: Not installed
2025-02-06 21:45:56,153:INFO:         cloudpickle: 3.1.1
2025-02-06 21:45:56,153:INFO:         deprecation: 2.1.0
2025-02-06 21:45:56,153:INFO:              xxhash: 3.5.0
2025-02-06 21:45:56,153:INFO:           wurlitzer: Not installed
2025-02-06 21:45:56,153:INFO:PyCaret optional dependencies:
2025-02-06 21:45:56,158:INFO:                shap: Not installed
2025-02-06 21:45:56,159:INFO:           interpret: Not installed
2025-02-06 21:45:56,159:INFO:                umap: Not installed
2025-02-06 21:45:56,159:INFO:     ydata_profiling: Not installed
2025-02-06 21:45:56,159:INFO:  explainerdashboard: Not installed
2025-02-06 21:45:56,159:INFO:             autoviz: Not installed
2025-02-06 21:45:56,159:INFO:           fairlearn: Not installed
2025-02-06 21:45:56,159:INFO:          deepchecks: Not installed
2025-02-06 21:45:56,159:INFO:             xgboost: Not installed
2025-02-06 21:45:56,159:INFO:            catboost: Not installed
2025-02-06 21:45:56,159:INFO:              kmodes: Not installed
2025-02-06 21:45:56,159:INFO:             mlxtend: Not installed
2025-02-06 21:45:56,159:INFO:       statsforecast: Not installed
2025-02-06 21:45:56,159:INFO:        tune_sklearn: Not installed
2025-02-06 21:45:56,159:INFO:                 ray: Not installed
2025-02-06 21:45:56,159:INFO:            hyperopt: Not installed
2025-02-06 21:45:56,159:INFO:              optuna: Not installed
2025-02-06 21:45:56,159:INFO:               skopt: Not installed
2025-02-06 21:45:56,159:INFO:              mlflow: Not installed
2025-02-06 21:45:56,159:INFO:              gradio: Not installed
2025-02-06 21:45:56,159:INFO:             fastapi: Not installed
2025-02-06 21:45:56,159:INFO:             uvicorn: Not installed
2025-02-06 21:45:56,159:INFO:              m2cgen: Not installed
2025-02-06 21:45:56,159:INFO:           evidently: Not installed
2025-02-06 21:45:56,159:INFO:               fugue: Not installed
2025-02-06 21:45:56,159:INFO:           streamlit: Not installed
2025-02-06 21:45:56,159:INFO:             prophet: Not installed
2025-02-06 21:45:56,159:INFO:None
2025-02-06 21:45:56,159:INFO:Set up data.
2025-02-06 21:45:56,166:INFO:Set up folding strategy.
2025-02-06 21:45:56,166:INFO:Set up train/test split.
2025-02-06 21:45:56,172:INFO:Set up index.
2025-02-06 21:45:56,172:INFO:Assigning column types.
2025-02-06 21:45:56,177:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:45:56,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,245:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:45:56,282:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:45:56,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,337:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:45:56,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,416:INFO:Preparing preprocessing pipeline...
2025-02-06 21:45:56,418:INFO:Set up simple imputation.
2025-02-06 21:45:56,418:INFO:Set up feature normalization.
2025-02-06 21:45:56,440:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:45:56,443:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:45:56,443:INFO:Creating final display dataframe.
2025-02-06 21:45:56,513:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e783
2025-02-06 21:45:56,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:45:56,591:INFO:setup() successfully completed in 0.46s...............
2025-02-06 21:45:56,591:INFO:Initializing compare_models()
2025-02-06 21:45:56,591:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:45:56,591:INFO:Checking exceptions
2025-02-06 21:45:56,595:INFO:Preparing display monitor
2025-02-06 21:45:56,609:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:45:56,609:INFO:Total runtime is 0.0 minutes
2025-02-06 21:45:56,611:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:56,611:INFO:Initializing create_model()
2025-02-06 21:45:56,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A212A5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:56,611:INFO:Checking exceptions
2025-02-06 21:45:56,611:INFO:Importing libraries
2025-02-06 21:45:56,611:INFO:Copying training dataset
2025-02-06 21:45:56,617:INFO:Defining folds
2025-02-06 21:45:56,617:INFO:Declaring metric variables
2025-02-06 21:45:56,618:INFO:Importing untrained model
2025-02-06 21:45:56,620:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:45:56,624:INFO:Starting cross validation
2025-02-06 21:45:56,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:45:59,868:INFO:Calculating mean and std
2025-02-06 21:45:59,869:INFO:Creating metrics dataframe
2025-02-06 21:45:59,870:INFO:Uploading results into container
2025-02-06 21:45:59,870:INFO:Uploading model into container now
2025-02-06 21:45:59,871:INFO:_master_model_container: 1
2025-02-06 21:45:59,871:INFO:_display_container: 2
2025-02-06 21:45:59,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:45:59,871:INFO:create_model() successfully completed......................................
2025-02-06 21:45:59,948:INFO:SubProcess create_model() end ==================================
2025-02-06 21:45:59,948:INFO:Creating metrics dataframe
2025-02-06 21:45:59,952:INFO:Initializing Logistic Regression
2025-02-06 21:45:59,953:INFO:Total runtime is 0.055734248956044515 minutes
2025-02-06 21:45:59,955:INFO:SubProcess create_model() called ==================================
2025-02-06 21:45:59,955:INFO:Initializing create_model()
2025-02-06 21:45:59,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A212A5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:45:59,955:INFO:Checking exceptions
2025-02-06 21:45:59,955:INFO:Importing libraries
2025-02-06 21:45:59,955:INFO:Copying training dataset
2025-02-06 21:45:59,964:INFO:Defining folds
2025-02-06 21:45:59,964:INFO:Declaring metric variables
2025-02-06 21:45:59,965:INFO:Importing untrained model
2025-02-06 21:45:59,967:INFO:Logistic Regression Imported successfully
2025-02-06 21:45:59,970:INFO:Starting cross validation
2025-02-06 21:45:59,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:01,448:INFO:Calculating mean and std
2025-02-06 21:46:01,449:INFO:Creating metrics dataframe
2025-02-06 21:46:01,450:INFO:Uploading results into container
2025-02-06 21:46:01,451:INFO:Uploading model into container now
2025-02-06 21:46:01,451:INFO:_master_model_container: 2
2025-02-06 21:46:01,451:INFO:_display_container: 2
2025-02-06 21:46:01,452:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:01,452:INFO:create_model() successfully completed......................................
2025-02-06 21:46:01,524:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:01,524:INFO:Creating metrics dataframe
2025-02-06 21:46:01,527:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:46:01,532:INFO:Initializing create_model()
2025-02-06 21:46:01,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:01,532:INFO:Checking exceptions
2025-02-06 21:46:01,532:INFO:Importing libraries
2025-02-06 21:46:01,532:INFO:Copying training dataset
2025-02-06 21:46:01,538:INFO:Defining folds
2025-02-06 21:46:01,538:INFO:Declaring metric variables
2025-02-06 21:46:01,538:INFO:Importing untrained model
2025-02-06 21:46:01,538:INFO:Declaring custom model
2025-02-06 21:46:01,538:INFO:Logistic Regression Imported successfully
2025-02-06 21:46:01,539:INFO:Cross validation set to False
2025-02-06 21:46:01,539:INFO:Fitting Model
2025-02-06 21:46:01,567:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:01,567:INFO:create_model() successfully completed......................................
2025-02-06 21:46:01,630:INFO:_master_model_container: 2
2025-02-06 21:46:01,630:INFO:_display_container: 2
2025-02-06 21:46:01,630:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:01,630:INFO:compare_models() successfully completed......................................
2025-02-06 21:46:01,630:INFO:Initializing create_model()
2025-02-06 21:46:01,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:01,630:INFO:Checking exceptions
2025-02-06 21:46:01,638:INFO:Importing libraries
2025-02-06 21:46:01,639:INFO:Copying training dataset
2025-02-06 21:46:01,647:INFO:Defining folds
2025-02-06 21:46:01,647:INFO:Declaring metric variables
2025-02-06 21:46:01,650:INFO:Importing untrained model
2025-02-06 21:46:01,652:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:46:01,655:INFO:Starting cross validation
2025-02-06 21:46:01,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:02,412:INFO:Calculating mean and std
2025-02-06 21:46:02,412:INFO:Creating metrics dataframe
2025-02-06 21:46:02,417:INFO:Finalizing model
2025-02-06 21:46:02,437:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:46:02,437:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.
2025-02-06 21:46:02,437:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:46:02,438:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:46:02,438:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:46:02,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:46:02,438:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:46:02,550:INFO:Uploading results into container
2025-02-06 21:46:02,550:INFO:Uploading model into container now
2025-02-06 21:46:02,558:INFO:_master_model_container: 3
2025-02-06 21:46:02,558:INFO:_display_container: 3
2025-02-06 21:46:02,558:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:02,558:INFO:create_model() successfully completed......................................
2025-02-06 21:46:02,630:INFO:Initializing tune_model()
2025-02-06 21:46:02,630:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:46:02,630:INFO:Checking exceptions
2025-02-06 21:46:02,643:INFO:Copying training dataset
2025-02-06 21:46:02,652:INFO:Checking base model
2025-02-06 21:46:02,652:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:46:02,655:INFO:Declaring metric variables
2025-02-06 21:46:02,658:INFO:Defining Hyperparameters
2025-02-06 21:46:02,733:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:46:02,733:INFO:Tuning with n_jobs=-1
2025-02-06 21:46:02,733:INFO:Initializing RandomizedSearchCV
2025-02-06 21:46:05,979:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:46:05,979:INFO:Hyperparameter search completed
2025-02-06 21:46:05,979:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:05,980:INFO:Initializing create_model()
2025-02-06 21:46:05,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A1EA16250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:46:05,980:INFO:Checking exceptions
2025-02-06 21:46:05,980:INFO:Importing libraries
2025-02-06 21:46:05,980:INFO:Copying training dataset
2025-02-06 21:46:05,988:INFO:Defining folds
2025-02-06 21:46:05,990:INFO:Declaring metric variables
2025-02-06 21:46:05,992:INFO:Importing untrained model
2025-02-06 21:46:05,992:INFO:Declaring custom model
2025-02-06 21:46:05,994:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:46:05,997:INFO:Starting cross validation
2025-02-06 21:46:05,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:06,303:INFO:Calculating mean and std
2025-02-06 21:46:06,304:INFO:Creating metrics dataframe
2025-02-06 21:46:06,307:INFO:Finalizing model
2025-02-06 21:46:06,325:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:46:06,326:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
2025-02-06 21:46:06,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:46:06,326:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:46:06,326:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:46:06,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:46:06,326:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:46:06,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:06,391:INFO:Uploading results into container
2025-02-06 21:46:06,391:INFO:Uploading model into container now
2025-02-06 21:46:06,392:INFO:_master_model_container: 4
2025-02-06 21:46:06,392:INFO:_display_container: 4
2025-02-06 21:46:06,392:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:06,392:INFO:create_model() successfully completed......................................
2025-02-06 21:46:06,452:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:06,452:INFO:choose_better activated
2025-02-06 21:46:06,454:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:06,455:INFO:Initializing create_model()
2025-02-06 21:46:06,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:06,455:INFO:Checking exceptions
2025-02-06 21:46:06,456:INFO:Importing libraries
2025-02-06 21:46:06,456:INFO:Copying training dataset
2025-02-06 21:46:06,463:INFO:Defining folds
2025-02-06 21:46:06,463:INFO:Declaring metric variables
2025-02-06 21:46:06,463:INFO:Importing untrained model
2025-02-06 21:46:06,463:INFO:Declaring custom model
2025-02-06 21:46:06,464:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:46:06,464:INFO:Starting cross validation
2025-02-06 21:46:06,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:07,157:INFO:Calculating mean and std
2025-02-06 21:46:07,157:INFO:Creating metrics dataframe
2025-02-06 21:46:07,158:INFO:Finalizing model
2025-02-06 21:46:07,174:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:46:07,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-02-06 21:46:07,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:46:07,175:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:46:07,176:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:46:07,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:46:07,176:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:46:07,277:INFO:Uploading results into container
2025-02-06 21:46:07,277:INFO:Uploading model into container now
2025-02-06 21:46:07,277:INFO:_master_model_container: 5
2025-02-06 21:46:07,277:INFO:_display_container: 5
2025-02-06 21:46:07,278:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:07,278:INFO:create_model() successfully completed......................................
2025-02-06 21:46:07,333:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:07,334:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:46:07,334:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:46:07,334:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:46:07,334:INFO:choose_better completed
2025-02-06 21:46:07,340:INFO:_master_model_container: 5
2025-02-06 21:46:07,340:INFO:_display_container: 4
2025-02-06 21:46:07,341:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:07,341:INFO:tune_model() successfully completed......................................
2025-02-06 21:46:07,386:INFO:Initializing create_model()
2025-02-06 21:46:07,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:07,386:INFO:Checking exceptions
2025-02-06 21:46:07,393:INFO:Importing libraries
2025-02-06 21:46:07,394:INFO:Copying training dataset
2025-02-06 21:46:07,400:INFO:Defining folds
2025-02-06 21:46:07,400:INFO:Declaring metric variables
2025-02-06 21:46:07,401:INFO:Importing untrained model
2025-02-06 21:46:07,403:INFO:Logistic Regression Imported successfully
2025-02-06 21:46:07,406:INFO:Starting cross validation
2025-02-06 21:46:07,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:07,473:INFO:Calculating mean and std
2025-02-06 21:46:07,473:INFO:Creating metrics dataframe
2025-02-06 21:46:07,476:INFO:Finalizing model
2025-02-06 21:46:07,510:INFO:Uploading results into container
2025-02-06 21:46:07,511:INFO:Uploading model into container now
2025-02-06 21:46:07,516:INFO:_master_model_container: 6
2025-02-06 21:46:07,516:INFO:_display_container: 5
2025-02-06 21:46:07,517:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:07,517:INFO:create_model() successfully completed......................................
2025-02-06 21:46:07,594:INFO:Initializing tune_model()
2025-02-06 21:46:07,594:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:46:07,594:INFO:Checking exceptions
2025-02-06 21:46:07,603:INFO:Copying training dataset
2025-02-06 21:46:07,607:INFO:Checking base model
2025-02-06 21:46:07,607:INFO:Base model : Logistic Regression
2025-02-06 21:46:07,608:INFO:Declaring metric variables
2025-02-06 21:46:07,610:INFO:Defining Hyperparameters
2025-02-06 21:46:07,653:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:46:07,653:INFO:Tuning with n_jobs=-1
2025-02-06 21:46:07,653:INFO:Initializing RandomizedSearchCV
2025-02-06 21:46:08,051:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:46:08,051:INFO:Hyperparameter search completed
2025-02-06 21:46:08,051:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:08,052:INFO:Initializing create_model()
2025-02-06 21:46:08,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A20B19F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:46:08,052:INFO:Checking exceptions
2025-02-06 21:46:08,052:INFO:Importing libraries
2025-02-06 21:46:08,052:INFO:Copying training dataset
2025-02-06 21:46:08,058:INFO:Defining folds
2025-02-06 21:46:08,058:INFO:Declaring metric variables
2025-02-06 21:46:08,060:INFO:Importing untrained model
2025-02-06 21:46:08,060:INFO:Declaring custom model
2025-02-06 21:46:08,062:INFO:Logistic Regression Imported successfully
2025-02-06 21:46:08,064:INFO:Starting cross validation
2025-02-06 21:46:08,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:08,132:INFO:Calculating mean and std
2025-02-06 21:46:08,132:INFO:Creating metrics dataframe
2025-02-06 21:46:08,135:INFO:Finalizing model
2025-02-06 21:46:08,167:INFO:Uploading results into container
2025-02-06 21:46:08,167:INFO:Uploading model into container now
2025-02-06 21:46:08,168:INFO:_master_model_container: 7
2025-02-06 21:46:08,168:INFO:_display_container: 6
2025-02-06 21:46:08,168:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:08,168:INFO:create_model() successfully completed......................................
2025-02-06 21:46:08,223:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:08,223:INFO:choose_better activated
2025-02-06 21:46:08,225:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:08,225:INFO:Initializing create_model()
2025-02-06 21:46:08,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:08,226:INFO:Checking exceptions
2025-02-06 21:46:08,226:INFO:Importing libraries
2025-02-06 21:46:08,226:INFO:Copying training dataset
2025-02-06 21:46:08,231:INFO:Defining folds
2025-02-06 21:46:08,231:INFO:Declaring metric variables
2025-02-06 21:46:08,232:INFO:Importing untrained model
2025-02-06 21:46:08,232:INFO:Declaring custom model
2025-02-06 21:46:08,232:INFO:Logistic Regression Imported successfully
2025-02-06 21:46:08,232:INFO:Starting cross validation
2025-02-06 21:46:08,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:08,289:INFO:Calculating mean and std
2025-02-06 21:46:08,289:INFO:Creating metrics dataframe
2025-02-06 21:46:08,290:INFO:Finalizing model
2025-02-06 21:46:08,318:INFO:Uploading results into container
2025-02-06 21:46:08,319:INFO:Uploading model into container now
2025-02-06 21:46:08,319:INFO:_master_model_container: 8
2025-02-06 21:46:08,319:INFO:_display_container: 7
2025-02-06 21:46:08,319:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:08,319:INFO:create_model() successfully completed......................................
2025-02-06 21:46:08,373:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:08,374:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:46:08,374:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:46:08,374:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:46:08,374:INFO:choose_better completed
2025-02-06 21:46:08,378:INFO:_master_model_container: 8
2025-02-06 21:46:08,380:INFO:_display_container: 6
2025-02-06 21:46:08,380:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:08,380:INFO:tune_model() successfully completed......................................
2025-02-06 21:46:08,418:INFO:Initializing compare_models()
2025-02-06 21:46:08,418:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:46:08,418:INFO:Checking exceptions
2025-02-06 21:46:08,421:INFO:Preparing display monitor
2025-02-06 21:46:08,431:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:46:08,431:INFO:Total runtime is 0.0 minutes
2025-02-06 21:46:08,432:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:08,432:INFO:Initializing create_model()
2025-02-06 21:46:08,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A20D7DAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:08,432:INFO:Checking exceptions
2025-02-06 21:46:08,432:INFO:Importing libraries
2025-02-06 21:46:08,432:INFO:Copying training dataset
2025-02-06 21:46:08,440:INFO:Defining folds
2025-02-06 21:46:08,440:INFO:Declaring metric variables
2025-02-06 21:46:08,441:INFO:Importing untrained model
2025-02-06 21:46:08,441:INFO:Declaring custom model
2025-02-06 21:46:08,444:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:46:08,447:INFO:Starting cross validation
2025-02-06 21:46:08,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:08,752:INFO:Calculating mean and std
2025-02-06 21:46:08,753:INFO:Creating metrics dataframe
2025-02-06 21:46:08,754:INFO:Uploading results into container
2025-02-06 21:46:08,754:INFO:Uploading model into container now
2025-02-06 21:46:08,755:INFO:_master_model_container: 9
2025-02-06 21:46:08,755:INFO:_display_container: 7
2025-02-06 21:46:08,755:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:08,755:INFO:create_model() successfully completed......................................
2025-02-06 21:46:08,815:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:08,815:INFO:Creating metrics dataframe
2025-02-06 21:46:08,820:INFO:Initializing custom model Logistic Regression
2025-02-06 21:46:08,820:INFO:Total runtime is 0.006484611829121908 minutes
2025-02-06 21:46:08,822:INFO:SubProcess create_model() called ==================================
2025-02-06 21:46:08,822:INFO:Initializing create_model()
2025-02-06 21:46:08,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A20D7DAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:08,822:INFO:Checking exceptions
2025-02-06 21:46:08,823:INFO:Importing libraries
2025-02-06 21:46:08,823:INFO:Copying training dataset
2025-02-06 21:46:08,830:INFO:Defining folds
2025-02-06 21:46:08,830:INFO:Declaring metric variables
2025-02-06 21:46:08,832:INFO:Importing untrained model
2025-02-06 21:46:08,832:INFO:Declaring custom model
2025-02-06 21:46:08,835:INFO:Logistic Regression Imported successfully
2025-02-06 21:46:08,838:INFO:Starting cross validation
2025-02-06 21:46:08,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:46:08,916:INFO:Calculating mean and std
2025-02-06 21:46:08,916:INFO:Creating metrics dataframe
2025-02-06 21:46:08,917:INFO:Uploading results into container
2025-02-06 21:46:08,917:INFO:Uploading model into container now
2025-02-06 21:46:08,917:INFO:_master_model_container: 10
2025-02-06 21:46:08,917:INFO:_display_container: 7
2025-02-06 21:46:08,917:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:46:08,917:INFO:create_model() successfully completed......................................
2025-02-06 21:46:08,960:INFO:SubProcess create_model() end ==================================
2025-02-06 21:46:08,960:INFO:Creating metrics dataframe
2025-02-06 21:46:08,964:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:46:08,968:INFO:Initializing create_model()
2025-02-06 21:46:08,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:46:08,968:INFO:Checking exceptions
2025-02-06 21:46:08,968:INFO:Importing libraries
2025-02-06 21:46:08,968:INFO:Copying training dataset
2025-02-06 21:46:08,975:INFO:Defining folds
2025-02-06 21:46:08,975:INFO:Declaring metric variables
2025-02-06 21:46:08,976:INFO:Importing untrained model
2025-02-06 21:46:08,976:INFO:Declaring custom model
2025-02-06 21:46:08,976:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:46:08,976:INFO:Cross validation set to False
2025-02-06 21:46:08,976:INFO:Fitting Model
2025-02-06 21:46:08,990:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:46:08,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.
2025-02-06 21:46:08,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:46:08,991:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:46:08,991:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:46:08,992:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:46:08,992:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:46:08,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:08,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:46:09,020:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:09,020:INFO:create_model() successfully completed......................................
2025-02-06 21:46:09,093:INFO:_master_model_container: 10
2025-02-06 21:46:09,093:INFO:_display_container: 7
2025-02-06 21:46:09,094:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:46:09,094:INFO:compare_models() successfully completed......................................
2025-02-06 21:46:09,095:INFO:Initializing predict_model()
2025-02-06 21:46:09,095:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A212A3CE0>)
2025-02-06 21:46:09,095:INFO:Checking exceptions
2025-02-06 21:46:09,096:INFO:Preloading libraries
2025-02-06 21:46:09,098:INFO:Set up data.
2025-02-06 21:46:09,106:INFO:Set up index.
2025-02-06 21:46:09,213:INFO:Initializing predict_model()
2025-02-06 21:46:09,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A20CB7BA0>)
2025-02-06 21:46:09,213:INFO:Checking exceptions
2025-02-06 21:46:09,213:INFO:Preloading libraries
2025-02-06 21:46:09,215:INFO:Set up data.
2025-02-06 21:46:09,221:INFO:Set up index.
2025-02-06 21:46:09,319:INFO:Initializing predict_model()
2025-02-06 21:46:09,319:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A20CB7BA0>)
2025-02-06 21:46:09,319:INFO:Checking exceptions
2025-02-06 21:46:09,319:INFO:Preloading libraries
2025-02-06 21:46:09,320:INFO:Set up data.
2025-02-06 21:46:09,328:INFO:Set up index.
2025-02-06 21:46:09,419:INFO:Initializing predict_model()
2025-02-06 21:46:09,420:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A201FE390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A20CB7BA0>)
2025-02-06 21:46:09,420:INFO:Checking exceptions
2025-02-06 21:46:09,420:INFO:Preloading libraries
2025-02-06 21:46:09,420:INFO:Set up data.
2025-02-06 21:46:09,424:INFO:Set up index.
2025-02-06 21:50:01,364:INFO:PyCaret ClassificationExperiment
2025-02-06 21:50:01,364:INFO:Logging name: clf-default-name
2025-02-06 21:50:01,364:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:50:01,364:INFO:version 3.3.2
2025-02-06 21:50:01,364:INFO:Initializing setup()
2025-02-06 21:50:01,364:INFO:self.USI: eeac
2025-02-06 21:50:01,364:INFO:self._variable_keys: {'fold_shuffle_param', '_ml_usecase', 'exp_name_log', 'X_test', 'X', 'gpu_n_jobs_param', 'X_train', 'y', 'html_param', 'seed', 'y_test', 'fold_groups_param', 'data', 'is_multiclass', 'idx', 'logging_param', 'target_param', 'log_plots_param', 'USI', '_available_plots', 'pipeline', 'y_train', 'n_jobs_param', 'memory', 'gpu_param', 'fix_imbalance', 'fold_generator', 'exp_id'}
2025-02-06 21:50:01,364:INFO:Checking environment
2025-02-06 21:50:01,364:INFO:python_version: 3.11.9
2025-02-06 21:50:01,364:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:50:01,364:INFO:machine: AMD64
2025-02-06 21:50:01,364:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:50:01,369:INFO:Memory: svmem(total=67771465728, available=47179264000, percent=30.4, used=20592201728, free=47179264000)
2025-02-06 21:50:01,369:INFO:Physical Core: 8
2025-02-06 21:50:01,369:INFO:Logical Core: 16
2025-02-06 21:50:01,369:INFO:Checking libraries
2025-02-06 21:50:01,369:INFO:System:
2025-02-06 21:50:01,369:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:50:01,369:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:50:01,369:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:50:01,369:INFO:PyCaret required dependencies:
2025-02-06 21:50:01,369:INFO:                 pip: 25.0
2025-02-06 21:50:01,369:INFO:          setuptools: 65.5.0
2025-02-06 21:50:01,369:INFO:             pycaret: 3.3.2
2025-02-06 21:50:01,369:INFO:             IPython: 8.32.0
2025-02-06 21:50:01,369:INFO:          ipywidgets: 8.1.5
2025-02-06 21:50:01,369:INFO:                tqdm: 4.67.1
2025-02-06 21:50:01,369:INFO:               numpy: 1.26.4
2025-02-06 21:50:01,369:INFO:              pandas: 2.1.4
2025-02-06 21:50:01,369:INFO:              jinja2: 3.1.5
2025-02-06 21:50:01,369:INFO:               scipy: 1.11.4
2025-02-06 21:50:01,370:INFO:              joblib: 1.3.2
2025-02-06 21:50:01,370:INFO:             sklearn: 1.4.2
2025-02-06 21:50:01,370:INFO:                pyod: 2.0.3
2025-02-06 21:50:01,370:INFO:            imblearn: 0.13.0
2025-02-06 21:50:01,370:INFO:   category_encoders: 2.7.0
2025-02-06 21:50:01,370:INFO:            lightgbm: 4.5.0
2025-02-06 21:50:01,370:INFO:               numba: 0.61.0
2025-02-06 21:50:01,370:INFO:            requests: 2.32.3
2025-02-06 21:50:01,370:INFO:          matplotlib: 3.7.5
2025-02-06 21:50:01,370:INFO:          scikitplot: 0.3.7
2025-02-06 21:50:01,370:INFO:         yellowbrick: 1.5
2025-02-06 21:50:01,370:INFO:              plotly: 5.24.1
2025-02-06 21:50:01,370:INFO:    plotly-resampler: Not installed
2025-02-06 21:50:01,370:INFO:             kaleido: 0.2.1
2025-02-06 21:50:01,370:INFO:           schemdraw: 0.15
2025-02-06 21:50:01,370:INFO:         statsmodels: 0.14.4
2025-02-06 21:50:01,370:INFO:              sktime: 0.26.0
2025-02-06 21:50:01,370:INFO:               tbats: 1.1.3
2025-02-06 21:50:01,370:INFO:            pmdarima: 2.0.4
2025-02-06 21:50:01,370:INFO:              psutil: 6.1.1
2025-02-06 21:50:01,370:INFO:          markupsafe: 3.0.2
2025-02-06 21:50:01,370:INFO:             pickle5: Not installed
2025-02-06 21:50:01,370:INFO:         cloudpickle: 3.1.1
2025-02-06 21:50:01,370:INFO:         deprecation: 2.1.0
2025-02-06 21:50:01,370:INFO:              xxhash: 3.5.0
2025-02-06 21:50:01,370:INFO:           wurlitzer: Not installed
2025-02-06 21:50:01,370:INFO:PyCaret optional dependencies:
2025-02-06 21:50:01,370:INFO:                shap: Not installed
2025-02-06 21:50:01,370:INFO:           interpret: Not installed
2025-02-06 21:50:01,370:INFO:                umap: Not installed
2025-02-06 21:50:01,370:INFO:     ydata_profiling: Not installed
2025-02-06 21:50:01,370:INFO:  explainerdashboard: Not installed
2025-02-06 21:50:01,370:INFO:             autoviz: Not installed
2025-02-06 21:50:01,370:INFO:           fairlearn: Not installed
2025-02-06 21:50:01,370:INFO:          deepchecks: Not installed
2025-02-06 21:50:01,370:INFO:             xgboost: Not installed
2025-02-06 21:50:01,370:INFO:            catboost: Not installed
2025-02-06 21:50:01,370:INFO:              kmodes: Not installed
2025-02-06 21:50:01,370:INFO:             mlxtend: Not installed
2025-02-06 21:50:01,370:INFO:       statsforecast: Not installed
2025-02-06 21:50:01,370:INFO:        tune_sklearn: Not installed
2025-02-06 21:50:01,370:INFO:                 ray: Not installed
2025-02-06 21:50:01,370:INFO:            hyperopt: Not installed
2025-02-06 21:50:01,370:INFO:              optuna: Not installed
2025-02-06 21:50:01,370:INFO:               skopt: Not installed
2025-02-06 21:50:01,370:INFO:              mlflow: Not installed
2025-02-06 21:50:01,370:INFO:              gradio: Not installed
2025-02-06 21:50:01,370:INFO:             fastapi: Not installed
2025-02-06 21:50:01,370:INFO:             uvicorn: Not installed
2025-02-06 21:50:01,370:INFO:              m2cgen: Not installed
2025-02-06 21:50:01,370:INFO:           evidently: Not installed
2025-02-06 21:50:01,370:INFO:               fugue: Not installed
2025-02-06 21:50:01,370:INFO:           streamlit: Not installed
2025-02-06 21:50:01,370:INFO:             prophet: Not installed
2025-02-06 21:50:01,370:INFO:None
2025-02-06 21:50:01,370:INFO:Set up data.
2025-02-06 21:50:01,376:INFO:Set up folding strategy.
2025-02-06 21:50:01,376:INFO:Set up train/test split.
2025-02-06 21:50:01,382:INFO:Set up index.
2025-02-06 21:50:01,382:INFO:Assigning column types.
2025-02-06 21:50:01,387:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:50:01,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,411:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,468:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:50:01,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:01,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,548:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:50:01,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,626:INFO:Preparing preprocessing pipeline...
2025-02-06 21:50:01,627:INFO:Set up simple imputation.
2025-02-06 21:50:01,627:INFO:Set up feature normalization.
2025-02-06 21:50:01,650:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:50:01,652:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:50:01,652:INFO:Creating final display dataframe.
2025-02-06 21:50:01,722:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              eeac
2025-02-06 21:50:01,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:01,801:INFO:setup() successfully completed in 0.44s...............
2025-02-06 21:50:01,801:INFO:Initializing compare_models()
2025-02-06 21:50:01,801:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:50:01,801:INFO:Checking exceptions
2025-02-06 21:50:01,805:INFO:Preparing display monitor
2025-02-06 21:50:01,814:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:50:01,814:INFO:Total runtime is 0.0 minutes
2025-02-06 21:50:01,816:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:01,816:INFO:Initializing create_model()
2025-02-06 21:50:01,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A2141F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:01,816:INFO:Checking exceptions
2025-02-06 21:50:01,816:INFO:Importing libraries
2025-02-06 21:50:01,816:INFO:Copying training dataset
2025-02-06 21:50:01,822:INFO:Defining folds
2025-02-06 21:50:01,822:INFO:Declaring metric variables
2025-02-06 21:50:01,823:INFO:Importing untrained model
2025-02-06 21:50:01,825:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:01,828:INFO:Starting cross validation
2025-02-06 21:50:01,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:02,596:INFO:Calculating mean and std
2025-02-06 21:50:02,596:INFO:Creating metrics dataframe
2025-02-06 21:50:02,597:INFO:Uploading results into container
2025-02-06 21:50:02,597:INFO:Uploading model into container now
2025-02-06 21:50:02,597:INFO:_master_model_container: 1
2025-02-06 21:50:02,597:INFO:_display_container: 2
2025-02-06 21:50:02,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:02,599:INFO:create_model() successfully completed......................................
2025-02-06 21:50:02,664:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:02,664:INFO:Creating metrics dataframe
2025-02-06 21:50:02,683:INFO:Initializing Logistic Regression
2025-02-06 21:50:02,683:INFO:Total runtime is 0.014476160208384195 minutes
2025-02-06 21:50:02,686:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:02,686:INFO:Initializing create_model()
2025-02-06 21:50:02,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A2141F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:02,686:INFO:Checking exceptions
2025-02-06 21:50:02,686:INFO:Importing libraries
2025-02-06 21:50:02,686:INFO:Copying training dataset
2025-02-06 21:50:02,695:INFO:Defining folds
2025-02-06 21:50:02,695:INFO:Declaring metric variables
2025-02-06 21:50:02,697:INFO:Importing untrained model
2025-02-06 21:50:02,699:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:02,703:INFO:Starting cross validation
2025-02-06 21:50:02,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:02,771:INFO:Calculating mean and std
2025-02-06 21:50:02,771:INFO:Creating metrics dataframe
2025-02-06 21:50:02,772:INFO:Uploading results into container
2025-02-06 21:50:02,772:INFO:Uploading model into container now
2025-02-06 21:50:02,772:INFO:_master_model_container: 2
2025-02-06 21:50:02,772:INFO:_display_container: 2
2025-02-06 21:50:02,773:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:02,773:INFO:create_model() successfully completed......................................
2025-02-06 21:50:02,841:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:02,841:INFO:Creating metrics dataframe
2025-02-06 21:50:02,845:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:50:02,849:INFO:Initializing create_model()
2025-02-06 21:50:02,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:02,849:INFO:Checking exceptions
2025-02-06 21:50:02,850:INFO:Importing libraries
2025-02-06 21:50:02,850:INFO:Copying training dataset
2025-02-06 21:50:02,856:INFO:Defining folds
2025-02-06 21:50:02,856:INFO:Declaring metric variables
2025-02-06 21:50:02,856:INFO:Importing untrained model
2025-02-06 21:50:02,856:INFO:Declaring custom model
2025-02-06 21:50:02,856:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:02,857:INFO:Cross validation set to False
2025-02-06 21:50:02,857:INFO:Fitting Model
2025-02-06 21:50:02,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:02,883:INFO:create_model() successfully completed......................................
2025-02-06 21:50:02,941:INFO:_master_model_container: 2
2025-02-06 21:50:02,941:INFO:_display_container: 2
2025-02-06 21:50:02,941:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:02,941:INFO:compare_models() successfully completed......................................
2025-02-06 21:50:02,941:INFO:Initializing create_model()
2025-02-06 21:50:02,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:02,941:INFO:Checking exceptions
2025-02-06 21:50:02,948:INFO:Importing libraries
2025-02-06 21:50:02,948:INFO:Copying training dataset
2025-02-06 21:50:02,954:INFO:Defining folds
2025-02-06 21:50:02,954:INFO:Declaring metric variables
2025-02-06 21:50:02,956:INFO:Importing untrained model
2025-02-06 21:50:02,957:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:02,961:INFO:Starting cross validation
2025-02-06 21:50:02,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:03,838:INFO:Calculating mean and std
2025-02-06 21:50:03,839:INFO:Creating metrics dataframe
2025-02-06 21:50:03,842:INFO:Finalizing model
2025-02-06 21:50:03,859:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:03,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
2025-02-06 21:50:03,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:03,860:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:03,861:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:03,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:03,861:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:03,962:INFO:Uploading results into container
2025-02-06 21:50:03,962:INFO:Uploading model into container now
2025-02-06 21:50:03,968:INFO:_master_model_container: 3
2025-02-06 21:50:03,968:INFO:_display_container: 3
2025-02-06 21:50:03,969:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:03,969:INFO:create_model() successfully completed......................................
2025-02-06 21:50:04,034:INFO:Initializing tune_model()
2025-02-06 21:50:04,035:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:50:04,035:INFO:Checking exceptions
2025-02-06 21:50:04,046:INFO:Copying training dataset
2025-02-06 21:50:04,053:INFO:Checking base model
2025-02-06 21:50:04,053:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:50:04,055:INFO:Declaring metric variables
2025-02-06 21:50:04,056:INFO:Defining Hyperparameters
2025-02-06 21:50:04,105:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:50:04,105:INFO:Tuning with n_jobs=-1
2025-02-06 21:50:04,105:INFO:Initializing RandomizedSearchCV
2025-02-06 21:50:07,338:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:50:07,338:INFO:Hyperparameter search completed
2025-02-06 21:50:07,339:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:07,339:INFO:Initializing create_model()
2025-02-06 21:50:07,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A2095F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:50:07,339:INFO:Checking exceptions
2025-02-06 21:50:07,339:INFO:Importing libraries
2025-02-06 21:50:07,340:INFO:Copying training dataset
2025-02-06 21:50:07,349:INFO:Defining folds
2025-02-06 21:50:07,349:INFO:Declaring metric variables
2025-02-06 21:50:07,350:INFO:Importing untrained model
2025-02-06 21:50:07,350:INFO:Declaring custom model
2025-02-06 21:50:07,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:07,357:INFO:Starting cross validation
2025-02-06 21:50:07,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:07,667:INFO:Calculating mean and std
2025-02-06 21:50:07,668:INFO:Creating metrics dataframe
2025-02-06 21:50:07,672:INFO:Finalizing model
2025-02-06 21:50:07,689:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:07,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000721 seconds.
2025-02-06 21:50:07,690:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:07,690:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:07,691:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:07,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:07,691:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:07,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:07,756:INFO:Uploading results into container
2025-02-06 21:50:07,757:INFO:Uploading model into container now
2025-02-06 21:50:07,757:INFO:_master_model_container: 4
2025-02-06 21:50:07,757:INFO:_display_container: 4
2025-02-06 21:50:07,758:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:07,758:INFO:create_model() successfully completed......................................
2025-02-06 21:50:07,820:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:07,820:INFO:choose_better activated
2025-02-06 21:50:07,823:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:07,823:INFO:Initializing create_model()
2025-02-06 21:50:07,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:07,823:INFO:Checking exceptions
2025-02-06 21:50:07,824:INFO:Importing libraries
2025-02-06 21:50:07,824:INFO:Copying training dataset
2025-02-06 21:50:07,833:INFO:Defining folds
2025-02-06 21:50:07,833:INFO:Declaring metric variables
2025-02-06 21:50:07,833:INFO:Importing untrained model
2025-02-06 21:50:07,833:INFO:Declaring custom model
2025-02-06 21:50:07,833:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:07,834:INFO:Starting cross validation
2025-02-06 21:50:07,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:08,543:INFO:Calculating mean and std
2025-02-06 21:50:08,544:INFO:Creating metrics dataframe
2025-02-06 21:50:08,545:INFO:Finalizing model
2025-02-06 21:50:08,563:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:08,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.
2025-02-06 21:50:08,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:08,564:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:08,564:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:08,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:08,564:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:08,666:INFO:Uploading results into container
2025-02-06 21:50:08,667:INFO:Uploading model into container now
2025-02-06 21:50:08,667:INFO:_master_model_container: 5
2025-02-06 21:50:08,667:INFO:_display_container: 5
2025-02-06 21:50:08,667:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:08,667:INFO:create_model() successfully completed......................................
2025-02-06 21:50:08,727:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:08,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:50:08,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:50:08,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:50:08,728:INFO:choose_better completed
2025-02-06 21:50:08,734:INFO:_master_model_container: 5
2025-02-06 21:50:08,734:INFO:_display_container: 4
2025-02-06 21:50:08,734:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:08,735:INFO:tune_model() successfully completed......................................
2025-02-06 21:50:08,793:INFO:Initializing create_model()
2025-02-06 21:50:08,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:08,793:INFO:Checking exceptions
2025-02-06 21:50:08,800:INFO:Importing libraries
2025-02-06 21:50:08,801:INFO:Copying training dataset
2025-02-06 21:50:08,807:INFO:Defining folds
2025-02-06 21:50:08,807:INFO:Declaring metric variables
2025-02-06 21:50:08,809:INFO:Importing untrained model
2025-02-06 21:50:08,811:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:08,814:INFO:Starting cross validation
2025-02-06 21:50:08,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:08,882:INFO:Calculating mean and std
2025-02-06 21:50:08,882:INFO:Creating metrics dataframe
2025-02-06 21:50:08,885:INFO:Finalizing model
2025-02-06 21:50:08,916:INFO:Uploading results into container
2025-02-06 21:50:08,917:INFO:Uploading model into container now
2025-02-06 21:50:08,921:INFO:_master_model_container: 6
2025-02-06 21:50:08,921:INFO:_display_container: 5
2025-02-06 21:50:08,921:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:08,921:INFO:create_model() successfully completed......................................
2025-02-06 21:50:08,980:INFO:Initializing tune_model()
2025-02-06 21:50:08,980:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:50:08,980:INFO:Checking exceptions
2025-02-06 21:50:08,988:INFO:Copying training dataset
2025-02-06 21:50:08,992:INFO:Checking base model
2025-02-06 21:50:08,992:INFO:Base model : Logistic Regression
2025-02-06 21:50:08,993:INFO:Declaring metric variables
2025-02-06 21:50:08,995:INFO:Defining Hyperparameters
2025-02-06 21:50:09,070:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:50:09,071:INFO:Tuning with n_jobs=-1
2025-02-06 21:50:09,071:INFO:Initializing RandomizedSearchCV
2025-02-06 21:50:09,485:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:50:09,485:INFO:Hyperparameter search completed
2025-02-06 21:50:09,485:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:09,486:INFO:Initializing create_model()
2025-02-06 21:50:09,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A1FFDF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:50:09,486:INFO:Checking exceptions
2025-02-06 21:50:09,486:INFO:Importing libraries
2025-02-06 21:50:09,486:INFO:Copying training dataset
2025-02-06 21:50:09,492:INFO:Defining folds
2025-02-06 21:50:09,492:INFO:Declaring metric variables
2025-02-06 21:50:09,494:INFO:Importing untrained model
2025-02-06 21:50:09,494:INFO:Declaring custom model
2025-02-06 21:50:09,496:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:09,499:INFO:Starting cross validation
2025-02-06 21:50:09,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:09,576:INFO:Calculating mean and std
2025-02-06 21:50:09,576:INFO:Creating metrics dataframe
2025-02-06 21:50:09,578:INFO:Finalizing model
2025-02-06 21:50:09,612:INFO:Uploading results into container
2025-02-06 21:50:09,612:INFO:Uploading model into container now
2025-02-06 21:50:09,613:INFO:_master_model_container: 7
2025-02-06 21:50:09,613:INFO:_display_container: 6
2025-02-06 21:50:09,613:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:09,613:INFO:create_model() successfully completed......................................
2025-02-06 21:50:09,666:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:09,666:INFO:choose_better activated
2025-02-06 21:50:09,668:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:09,669:INFO:Initializing create_model()
2025-02-06 21:50:09,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:09,669:INFO:Checking exceptions
2025-02-06 21:50:09,670:INFO:Importing libraries
2025-02-06 21:50:09,670:INFO:Copying training dataset
2025-02-06 21:50:09,675:INFO:Defining folds
2025-02-06 21:50:09,675:INFO:Declaring metric variables
2025-02-06 21:50:09,675:INFO:Importing untrained model
2025-02-06 21:50:09,675:INFO:Declaring custom model
2025-02-06 21:50:09,675:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:09,675:INFO:Starting cross validation
2025-02-06 21:50:09,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:09,743:INFO:Calculating mean and std
2025-02-06 21:50:09,743:INFO:Creating metrics dataframe
2025-02-06 21:50:09,743:INFO:Finalizing model
2025-02-06 21:50:09,772:INFO:Uploading results into container
2025-02-06 21:50:09,772:INFO:Uploading model into container now
2025-02-06 21:50:09,772:INFO:_master_model_container: 8
2025-02-06 21:50:09,772:INFO:_display_container: 7
2025-02-06 21:50:09,773:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:09,773:INFO:create_model() successfully completed......................................
2025-02-06 21:50:09,826:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:09,826:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:50:09,826:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:50:09,827:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:50:09,827:INFO:choose_better completed
2025-02-06 21:50:09,831:INFO:_master_model_container: 8
2025-02-06 21:50:09,831:INFO:_display_container: 6
2025-02-06 21:50:09,831:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:09,831:INFO:tune_model() successfully completed......................................
2025-02-06 21:50:09,872:INFO:Initializing compare_models()
2025-02-06 21:50:09,872:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:50:09,872:INFO:Checking exceptions
2025-02-06 21:50:09,875:INFO:Preparing display monitor
2025-02-06 21:50:09,884:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:50:09,884:INFO:Total runtime is 0.0 minutes
2025-02-06 21:50:09,885:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:09,885:INFO:Initializing create_model()
2025-02-06 21:50:09,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A20A96E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:09,885:INFO:Checking exceptions
2025-02-06 21:50:09,885:INFO:Importing libraries
2025-02-06 21:50:09,886:INFO:Copying training dataset
2025-02-06 21:50:09,892:INFO:Defining folds
2025-02-06 21:50:09,892:INFO:Declaring metric variables
2025-02-06 21:50:09,893:INFO:Importing untrained model
2025-02-06 21:50:09,893:INFO:Declaring custom model
2025-02-06 21:50:09,895:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:09,897:INFO:Starting cross validation
2025-02-06 21:50:09,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:10,199:INFO:Calculating mean and std
2025-02-06 21:50:10,199:INFO:Creating metrics dataframe
2025-02-06 21:50:10,201:INFO:Uploading results into container
2025-02-06 21:50:10,202:INFO:Uploading model into container now
2025-02-06 21:50:10,202:INFO:_master_model_container: 9
2025-02-06 21:50:10,202:INFO:_display_container: 7
2025-02-06 21:50:10,202:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:10,202:INFO:create_model() successfully completed......................................
2025-02-06 21:50:10,265:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:10,266:INFO:Creating metrics dataframe
2025-02-06 21:50:10,270:INFO:Initializing custom model Logistic Regression
2025-02-06 21:50:10,270:INFO:Total runtime is 0.006429032484690348 minutes
2025-02-06 21:50:10,272:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:10,273:INFO:Initializing create_model()
2025-02-06 21:50:10,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A20A96E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:10,273:INFO:Checking exceptions
2025-02-06 21:50:10,273:INFO:Importing libraries
2025-02-06 21:50:10,273:INFO:Copying training dataset
2025-02-06 21:50:10,281:INFO:Defining folds
2025-02-06 21:50:10,281:INFO:Declaring metric variables
2025-02-06 21:50:10,283:INFO:Importing untrained model
2025-02-06 21:50:10,283:INFO:Declaring custom model
2025-02-06 21:50:10,287:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:10,291:INFO:Starting cross validation
2025-02-06 21:50:10,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:10,371:INFO:Calculating mean and std
2025-02-06 21:50:10,371:INFO:Creating metrics dataframe
2025-02-06 21:50:10,372:INFO:Uploading results into container
2025-02-06 21:50:10,372:INFO:Uploading model into container now
2025-02-06 21:50:10,372:INFO:_master_model_container: 10
2025-02-06 21:50:10,372:INFO:_display_container: 7
2025-02-06 21:50:10,373:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:10,373:INFO:create_model() successfully completed......................................
2025-02-06 21:50:10,418:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:10,418:INFO:Creating metrics dataframe
2025-02-06 21:50:10,421:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:50:10,425:INFO:Initializing create_model()
2025-02-06 21:50:10,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:10,425:INFO:Checking exceptions
2025-02-06 21:50:10,427:INFO:Importing libraries
2025-02-06 21:50:10,427:INFO:Copying training dataset
2025-02-06 21:50:10,433:INFO:Defining folds
2025-02-06 21:50:10,433:INFO:Declaring metric variables
2025-02-06 21:50:10,433:INFO:Importing untrained model
2025-02-06 21:50:10,433:INFO:Declaring custom model
2025-02-06 21:50:10,433:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:10,434:INFO:Cross validation set to False
2025-02-06 21:50:10,434:INFO:Fitting Model
2025-02-06 21:50:10,453:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:10,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.
2025-02-06 21:50:10,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-02-06 21:50:10,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-02-06 21:50:10,455:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:10,455:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:10,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:10,455:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:10,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:10,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:10,506:INFO:create_model() successfully completed......................................
2025-02-06 21:50:10,576:INFO:_master_model_container: 10
2025-02-06 21:50:10,576:INFO:_display_container: 7
2025-02-06 21:50:10,577:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:10,577:INFO:compare_models() successfully completed......................................
2025-02-06 21:50:10,578:INFO:Initializing predict_model()
2025-02-06 21:50:10,578:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A5974C7C0>)
2025-02-06 21:50:10,578:INFO:Checking exceptions
2025-02-06 21:50:10,578:INFO:Preloading libraries
2025-02-06 21:50:10,580:INFO:Set up data.
2025-02-06 21:50:10,588:INFO:Set up index.
2025-02-06 21:50:10,692:INFO:Initializing predict_model()
2025-02-06 21:50:10,692:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A5974C7C0>)
2025-02-06 21:50:10,692:INFO:Checking exceptions
2025-02-06 21:50:10,692:INFO:Preloading libraries
2025-02-06 21:50:10,693:INFO:Set up data.
2025-02-06 21:50:10,699:INFO:Set up index.
2025-02-06 21:50:10,784:INFO:Initializing predict_model()
2025-02-06 21:50:10,784:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A5974C7C0>)
2025-02-06 21:50:10,784:INFO:Checking exceptions
2025-02-06 21:50:10,784:INFO:Preloading libraries
2025-02-06 21:50:10,786:INFO:Set up data.
2025-02-06 21:50:10,795:INFO:Set up index.
2025-02-06 21:50:10,883:INFO:Initializing predict_model()
2025-02-06 21:50:10,883:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A212A7310>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A5974C7C0>)
2025-02-06 21:50:10,883:INFO:Checking exceptions
2025-02-06 21:50:10,883:INFO:Preloading libraries
2025-02-06 21:50:10,884:INFO:Set up data.
2025-02-06 21:50:10,888:INFO:Set up index.
2025-02-06 21:50:23,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:50:23,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:50:23,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:50:23,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 21:50:23,650:INFO:PyCaret ClassificationExperiment
2025-02-06 21:50:23,650:INFO:Logging name: clf-default-name
2025-02-06 21:50:23,650:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 21:50:23,650:INFO:version 3.3.2
2025-02-06 21:50:23,650:INFO:Initializing setup()
2025-02-06 21:50:23,650:INFO:self.USI: e942
2025-02-06 21:50:23,650:INFO:self._variable_keys: {'data', 'X_test', 'logging_param', 'gpu_param', 'idx', 'seed', 'y', 'log_plots_param', 'fold_generator', 'fold_shuffle_param', 'exp_id', '_available_plots', 'X_train', 'X', 'exp_name_log', 'is_multiclass', 'fold_groups_param', 'fix_imbalance', 'html_param', 'target_param', 'y_train', 'pipeline', 'y_test', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'USI'}
2025-02-06 21:50:23,650:INFO:Checking environment
2025-02-06 21:50:23,650:INFO:python_version: 3.11.9
2025-02-06 21:50:23,650:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 21:50:23,650:INFO:machine: AMD64
2025-02-06 21:50:23,650:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 21:50:23,654:INFO:Memory: svmem(total=67771465728, available=49607966720, percent=26.8, used=18163499008, free=49607966720)
2025-02-06 21:50:23,654:INFO:Physical Core: 8
2025-02-06 21:50:23,654:INFO:Logical Core: 16
2025-02-06 21:50:23,654:INFO:Checking libraries
2025-02-06 21:50:23,654:INFO:System:
2025-02-06 21:50:23,654:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 21:50:23,654:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 21:50:23,654:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 21:50:23,654:INFO:PyCaret required dependencies:
2025-02-06 21:50:23,668:INFO:                 pip: 25.0
2025-02-06 21:50:23,668:INFO:          setuptools: 65.5.0
2025-02-06 21:50:23,668:INFO:             pycaret: 3.3.2
2025-02-06 21:50:23,668:INFO:             IPython: 8.32.0
2025-02-06 21:50:23,668:INFO:          ipywidgets: 8.1.5
2025-02-06 21:50:23,668:INFO:                tqdm: 4.67.1
2025-02-06 21:50:23,668:INFO:               numpy: 1.26.4
2025-02-06 21:50:23,668:INFO:              pandas: 2.1.4
2025-02-06 21:50:23,668:INFO:              jinja2: 3.1.5
2025-02-06 21:50:23,668:INFO:               scipy: 1.11.4
2025-02-06 21:50:23,668:INFO:              joblib: 1.3.2
2025-02-06 21:50:23,668:INFO:             sklearn: 1.4.2
2025-02-06 21:50:23,668:INFO:                pyod: 2.0.3
2025-02-06 21:50:23,668:INFO:            imblearn: 0.13.0
2025-02-06 21:50:23,668:INFO:   category_encoders: 2.7.0
2025-02-06 21:50:23,668:INFO:            lightgbm: 4.5.0
2025-02-06 21:50:23,668:INFO:               numba: 0.61.0
2025-02-06 21:50:23,668:INFO:            requests: 2.32.3
2025-02-06 21:50:23,668:INFO:          matplotlib: 3.7.5
2025-02-06 21:50:23,668:INFO:          scikitplot: 0.3.7
2025-02-06 21:50:23,669:INFO:         yellowbrick: 1.5
2025-02-06 21:50:23,669:INFO:              plotly: 5.24.1
2025-02-06 21:50:23,669:INFO:    plotly-resampler: Not installed
2025-02-06 21:50:23,669:INFO:             kaleido: 0.2.1
2025-02-06 21:50:23,669:INFO:           schemdraw: 0.15
2025-02-06 21:50:23,669:INFO:         statsmodels: 0.14.4
2025-02-06 21:50:23,669:INFO:              sktime: 0.26.0
2025-02-06 21:50:23,669:INFO:               tbats: 1.1.3
2025-02-06 21:50:23,669:INFO:            pmdarima: 2.0.4
2025-02-06 21:50:23,669:INFO:              psutil: 6.1.1
2025-02-06 21:50:23,669:INFO:          markupsafe: 3.0.2
2025-02-06 21:50:23,669:INFO:             pickle5: Not installed
2025-02-06 21:50:23,669:INFO:         cloudpickle: 3.1.1
2025-02-06 21:50:23,669:INFO:         deprecation: 2.1.0
2025-02-06 21:50:23,669:INFO:              xxhash: 3.5.0
2025-02-06 21:50:23,669:INFO:           wurlitzer: Not installed
2025-02-06 21:50:23,669:INFO:PyCaret optional dependencies:
2025-02-06 21:50:23,674:INFO:                shap: Not installed
2025-02-06 21:50:23,674:INFO:           interpret: Not installed
2025-02-06 21:50:23,674:INFO:                umap: Not installed
2025-02-06 21:50:23,674:INFO:     ydata_profiling: Not installed
2025-02-06 21:50:23,674:INFO:  explainerdashboard: Not installed
2025-02-06 21:50:23,674:INFO:             autoviz: Not installed
2025-02-06 21:50:23,674:INFO:           fairlearn: Not installed
2025-02-06 21:50:23,674:INFO:          deepchecks: Not installed
2025-02-06 21:50:23,674:INFO:             xgboost: Not installed
2025-02-06 21:50:23,674:INFO:            catboost: Not installed
2025-02-06 21:50:23,674:INFO:              kmodes: Not installed
2025-02-06 21:50:23,674:INFO:             mlxtend: Not installed
2025-02-06 21:50:23,674:INFO:       statsforecast: Not installed
2025-02-06 21:50:23,674:INFO:        tune_sklearn: Not installed
2025-02-06 21:50:23,674:INFO:                 ray: Not installed
2025-02-06 21:50:23,674:INFO:            hyperopt: Not installed
2025-02-06 21:50:23,674:INFO:              optuna: Not installed
2025-02-06 21:50:23,674:INFO:               skopt: Not installed
2025-02-06 21:50:23,674:INFO:              mlflow: Not installed
2025-02-06 21:50:23,674:INFO:              gradio: Not installed
2025-02-06 21:50:23,674:INFO:             fastapi: Not installed
2025-02-06 21:50:23,674:INFO:             uvicorn: Not installed
2025-02-06 21:50:23,674:INFO:              m2cgen: Not installed
2025-02-06 21:50:23,674:INFO:           evidently: Not installed
2025-02-06 21:50:23,674:INFO:               fugue: Not installed
2025-02-06 21:50:23,675:INFO:           streamlit: Not installed
2025-02-06 21:50:23,675:INFO:             prophet: Not installed
2025-02-06 21:50:23,675:INFO:None
2025-02-06 21:50:23,675:INFO:Set up data.
2025-02-06 21:50:23,681:INFO:Set up folding strategy.
2025-02-06 21:50:23,681:INFO:Set up train/test split.
2025-02-06 21:50:23,687:INFO:Set up index.
2025-02-06 21:50:23,687:INFO:Assigning column types.
2025-02-06 21:50:23,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 21:50:23,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,761:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,776:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 21:50:23,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 21:50:23,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,860:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 21:50:23,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:23,946:INFO:Preparing preprocessing pipeline...
2025-02-06 21:50:23,948:INFO:Set up simple imputation.
2025-02-06 21:50:23,948:INFO:Set up feature normalization.
2025-02-06 21:50:23,973:INFO:Finished creating preprocessing pipeline.
2025-02-06 21:50:23,975:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 21:50:23,975:INFO:Creating final display dataframe.
2025-02-06 21:50:24,048:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e942
2025-02-06 21:50:24,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:24,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:24,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:24,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 21:50:24,129:INFO:setup() successfully completed in 0.48s...............
2025-02-06 21:50:24,129:INFO:Initializing compare_models()
2025-02-06 21:50:24,129:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:50:24,129:INFO:Checking exceptions
2025-02-06 21:50:24,133:INFO:Preparing display monitor
2025-02-06 21:50:24,145:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 21:50:24,145:INFO:Total runtime is 0.0 minutes
2025-02-06 21:50:24,146:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:24,146:INFO:Initializing create_model()
2025-02-06 21:50:24,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C1E36E710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:24,146:INFO:Checking exceptions
2025-02-06 21:50:24,146:INFO:Importing libraries
2025-02-06 21:50:24,146:INFO:Copying training dataset
2025-02-06 21:50:24,154:INFO:Defining folds
2025-02-06 21:50:24,154:INFO:Declaring metric variables
2025-02-06 21:50:24,155:INFO:Importing untrained model
2025-02-06 21:50:24,157:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:24,160:INFO:Starting cross validation
2025-02-06 21:50:24,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:27,187:INFO:Calculating mean and std
2025-02-06 21:50:27,188:INFO:Creating metrics dataframe
2025-02-06 21:50:27,190:INFO:Uploading results into container
2025-02-06 21:50:27,190:INFO:Uploading model into container now
2025-02-06 21:50:27,190:INFO:_master_model_container: 1
2025-02-06 21:50:27,190:INFO:_display_container: 2
2025-02-06 21:50:27,191:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:27,191:INFO:create_model() successfully completed......................................
2025-02-06 21:50:27,274:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:27,274:INFO:Creating metrics dataframe
2025-02-06 21:50:27,278:INFO:Initializing Logistic Regression
2025-02-06 21:50:27,278:INFO:Total runtime is 0.052215711275736494 minutes
2025-02-06 21:50:27,279:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:27,279:INFO:Initializing create_model()
2025-02-06 21:50:27,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C1E36E710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:27,280:INFO:Checking exceptions
2025-02-06 21:50:27,280:INFO:Importing libraries
2025-02-06 21:50:27,280:INFO:Copying training dataset
2025-02-06 21:50:27,286:INFO:Defining folds
2025-02-06 21:50:27,286:INFO:Declaring metric variables
2025-02-06 21:50:27,287:INFO:Importing untrained model
2025-02-06 21:50:27,289:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:27,292:INFO:Starting cross validation
2025-02-06 21:50:27,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:28,735:INFO:Calculating mean and std
2025-02-06 21:50:28,735:INFO:Creating metrics dataframe
2025-02-06 21:50:28,737:INFO:Uploading results into container
2025-02-06 21:50:28,737:INFO:Uploading model into container now
2025-02-06 21:50:28,738:INFO:_master_model_container: 2
2025-02-06 21:50:28,738:INFO:_display_container: 2
2025-02-06 21:50:28,738:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:28,738:INFO:create_model() successfully completed......................................
2025-02-06 21:50:28,821:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:28,821:INFO:Creating metrics dataframe
2025-02-06 21:50:28,826:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:50:28,829:INFO:Initializing create_model()
2025-02-06 21:50:28,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:28,829:INFO:Checking exceptions
2025-02-06 21:50:28,830:INFO:Importing libraries
2025-02-06 21:50:28,830:INFO:Copying training dataset
2025-02-06 21:50:28,836:INFO:Defining folds
2025-02-06 21:50:28,836:INFO:Declaring metric variables
2025-02-06 21:50:28,836:INFO:Importing untrained model
2025-02-06 21:50:28,836:INFO:Declaring custom model
2025-02-06 21:50:28,837:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:28,837:INFO:Cross validation set to False
2025-02-06 21:50:28,837:INFO:Fitting Model
2025-02-06 21:50:28,864:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:28,864:INFO:create_model() successfully completed......................................
2025-02-06 21:50:28,924:INFO:_master_model_container: 2
2025-02-06 21:50:28,924:INFO:_display_container: 2
2025-02-06 21:50:28,924:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:28,924:INFO:compare_models() successfully completed......................................
2025-02-06 21:50:28,924:INFO:Initializing create_model()
2025-02-06 21:50:28,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:28,924:INFO:Checking exceptions
2025-02-06 21:50:28,929:INFO:Importing libraries
2025-02-06 21:50:28,929:INFO:Copying training dataset
2025-02-06 21:50:28,936:INFO:Defining folds
2025-02-06 21:50:28,936:INFO:Declaring metric variables
2025-02-06 21:50:28,937:INFO:Importing untrained model
2025-02-06 21:50:28,939:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:28,942:INFO:Starting cross validation
2025-02-06 21:50:28,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:29,709:INFO:Calculating mean and std
2025-02-06 21:50:29,709:INFO:Creating metrics dataframe
2025-02-06 21:50:29,713:INFO:Finalizing model
2025-02-06 21:50:29,733:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:29,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
2025-02-06 21:50:29,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:29,734:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:29,734:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:29,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:29,736:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:29,840:INFO:Uploading results into container
2025-02-06 21:50:29,841:INFO:Uploading model into container now
2025-02-06 21:50:29,848:INFO:_master_model_container: 3
2025-02-06 21:50:29,848:INFO:_display_container: 3
2025-02-06 21:50:29,848:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:29,848:INFO:create_model() successfully completed......................................
2025-02-06 21:50:29,916:INFO:Initializing tune_model()
2025-02-06 21:50:29,916:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:50:29,917:INFO:Checking exceptions
2025-02-06 21:50:29,930:INFO:Copying training dataset
2025-02-06 21:50:29,934:INFO:Checking base model
2025-02-06 21:50:29,934:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 21:50:29,937:INFO:Declaring metric variables
2025-02-06 21:50:29,938:INFO:Defining Hyperparameters
2025-02-06 21:50:30,008:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 21:50:30,008:INFO:Tuning with n_jobs=-1
2025-02-06 21:50:30,008:INFO:Initializing RandomizedSearchCV
2025-02-06 21:50:33,287:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 21:50:33,288:INFO:Hyperparameter search completed
2025-02-06 21:50:33,288:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:33,288:INFO:Initializing create_model()
2025-02-06 21:50:33,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C5A254410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 21:50:33,288:INFO:Checking exceptions
2025-02-06 21:50:33,289:INFO:Importing libraries
2025-02-06 21:50:33,289:INFO:Copying training dataset
2025-02-06 21:50:33,298:INFO:Defining folds
2025-02-06 21:50:33,298:INFO:Declaring metric variables
2025-02-06 21:50:33,300:INFO:Importing untrained model
2025-02-06 21:50:33,300:INFO:Declaring custom model
2025-02-06 21:50:33,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:33,306:INFO:Starting cross validation
2025-02-06 21:50:33,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:33,617:INFO:Calculating mean and std
2025-02-06 21:50:33,618:INFO:Creating metrics dataframe
2025-02-06 21:50:33,622:INFO:Finalizing model
2025-02-06 21:50:33,643:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:33,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.
2025-02-06 21:50:33,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:33,644:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:33,644:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:33,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:33,644:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:33,709:INFO:Uploading results into container
2025-02-06 21:50:33,709:INFO:Uploading model into container now
2025-02-06 21:50:33,709:INFO:_master_model_container: 4
2025-02-06 21:50:33,709:INFO:_display_container: 4
2025-02-06 21:50:33,710:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:33,710:INFO:create_model() successfully completed......................................
2025-02-06 21:50:33,775:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:33,775:INFO:choose_better activated
2025-02-06 21:50:33,778:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:33,778:INFO:Initializing create_model()
2025-02-06 21:50:33,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:33,778:INFO:Checking exceptions
2025-02-06 21:50:33,779:INFO:Importing libraries
2025-02-06 21:50:33,779:INFO:Copying training dataset
2025-02-06 21:50:33,789:INFO:Defining folds
2025-02-06 21:50:33,789:INFO:Declaring metric variables
2025-02-06 21:50:33,789:INFO:Importing untrained model
2025-02-06 21:50:33,789:INFO:Declaring custom model
2025-02-06 21:50:33,789:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:33,790:INFO:Starting cross validation
2025-02-06 21:50:33,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:34,527:INFO:Calculating mean and std
2025-02-06 21:50:34,527:INFO:Creating metrics dataframe
2025-02-06 21:50:34,528:INFO:Finalizing model
2025-02-06 21:50:34,544:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:34,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
2025-02-06 21:50:34,546:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:34,546:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:34,546:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:34,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:34,547:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:34,655:INFO:Uploading results into container
2025-02-06 21:50:34,656:INFO:Uploading model into container now
2025-02-06 21:50:34,656:INFO:_master_model_container: 5
2025-02-06 21:50:34,656:INFO:_display_container: 5
2025-02-06 21:50:34,656:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:34,656:INFO:create_model() successfully completed......................................
2025-02-06 21:50:34,723:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:34,723:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 21:50:34,724:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 21:50:34,724:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 21:50:34,724:INFO:choose_better completed
2025-02-06 21:50:34,731:INFO:_master_model_container: 5
2025-02-06 21:50:34,732:INFO:_display_container: 4
2025-02-06 21:50:34,732:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:34,732:INFO:tune_model() successfully completed......................................
2025-02-06 21:50:34,802:INFO:Initializing create_model()
2025-02-06 21:50:34,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:34,802:INFO:Checking exceptions
2025-02-06 21:50:34,809:INFO:Importing libraries
2025-02-06 21:50:34,809:INFO:Copying training dataset
2025-02-06 21:50:34,816:INFO:Defining folds
2025-02-06 21:50:34,816:INFO:Declaring metric variables
2025-02-06 21:50:34,818:INFO:Importing untrained model
2025-02-06 21:50:34,819:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:34,823:INFO:Starting cross validation
2025-02-06 21:50:34,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:34,907:INFO:Calculating mean and std
2025-02-06 21:50:34,907:INFO:Creating metrics dataframe
2025-02-06 21:50:34,910:INFO:Finalizing model
2025-02-06 21:50:34,942:INFO:Uploading results into container
2025-02-06 21:50:34,942:INFO:Uploading model into container now
2025-02-06 21:50:34,947:INFO:_master_model_container: 6
2025-02-06 21:50:34,947:INFO:_display_container: 5
2025-02-06 21:50:34,947:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:34,947:INFO:create_model() successfully completed......................................
2025-02-06 21:50:35,005:INFO:Initializing tune_model()
2025-02-06 21:50:35,005:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 21:50:35,005:INFO:Checking exceptions
2025-02-06 21:50:35,014:INFO:Copying training dataset
2025-02-06 21:50:35,018:INFO:Checking base model
2025-02-06 21:50:35,018:INFO:Base model : Logistic Regression
2025-02-06 21:50:35,019:INFO:Declaring metric variables
2025-02-06 21:50:35,021:INFO:Defining Hyperparameters
2025-02-06 21:50:35,064:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 21:50:35,064:INFO:Tuning with n_jobs=-1
2025-02-06 21:50:35,064:INFO:Initializing RandomizedSearchCV
2025-02-06 21:50:35,491:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 21:50:35,491:INFO:Hyperparameter search completed
2025-02-06 21:50:35,491:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:35,492:INFO:Initializing create_model()
2025-02-06 21:50:35,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C1DD60D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 21:50:35,492:INFO:Checking exceptions
2025-02-06 21:50:35,492:INFO:Importing libraries
2025-02-06 21:50:35,492:INFO:Copying training dataset
2025-02-06 21:50:35,497:INFO:Defining folds
2025-02-06 21:50:35,497:INFO:Declaring metric variables
2025-02-06 21:50:35,500:INFO:Importing untrained model
2025-02-06 21:50:35,500:INFO:Declaring custom model
2025-02-06 21:50:35,502:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:35,505:INFO:Starting cross validation
2025-02-06 21:50:35,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:35,583:INFO:Calculating mean and std
2025-02-06 21:50:35,583:INFO:Creating metrics dataframe
2025-02-06 21:50:35,586:INFO:Finalizing model
2025-02-06 21:50:35,613:INFO:Uploading results into container
2025-02-06 21:50:35,614:INFO:Uploading model into container now
2025-02-06 21:50:35,614:INFO:_master_model_container: 7
2025-02-06 21:50:35,614:INFO:_display_container: 6
2025-02-06 21:50:35,614:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:35,614:INFO:create_model() successfully completed......................................
2025-02-06 21:50:35,670:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:35,671:INFO:choose_better activated
2025-02-06 21:50:35,673:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:35,673:INFO:Initializing create_model()
2025-02-06 21:50:35,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:35,673:INFO:Checking exceptions
2025-02-06 21:50:35,674:INFO:Importing libraries
2025-02-06 21:50:35,674:INFO:Copying training dataset
2025-02-06 21:50:35,680:INFO:Defining folds
2025-02-06 21:50:35,680:INFO:Declaring metric variables
2025-02-06 21:50:35,680:INFO:Importing untrained model
2025-02-06 21:50:35,680:INFO:Declaring custom model
2025-02-06 21:50:35,680:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:35,680:INFO:Starting cross validation
2025-02-06 21:50:35,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:35,737:INFO:Calculating mean and std
2025-02-06 21:50:35,737:INFO:Creating metrics dataframe
2025-02-06 21:50:35,738:INFO:Finalizing model
2025-02-06 21:50:35,766:INFO:Uploading results into container
2025-02-06 21:50:35,766:INFO:Uploading model into container now
2025-02-06 21:50:35,766:INFO:_master_model_container: 8
2025-02-06 21:50:35,766:INFO:_display_container: 7
2025-02-06 21:50:35,766:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:35,766:INFO:create_model() successfully completed......................................
2025-02-06 21:50:35,822:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:35,822:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 21:50:35,822:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 21:50:35,823:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 21:50:35,823:INFO:choose_better completed
2025-02-06 21:50:35,829:INFO:_master_model_container: 8
2025-02-06 21:50:35,829:INFO:_display_container: 6
2025-02-06 21:50:35,829:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:35,829:INFO:tune_model() successfully completed......................................
2025-02-06 21:50:35,873:INFO:Initializing compare_models()
2025-02-06 21:50:35,874:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 21:50:35,874:INFO:Checking exceptions
2025-02-06 21:50:35,876:INFO:Preparing display monitor
2025-02-06 21:50:35,887:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 21:50:35,887:INFO:Total runtime is 0.0 minutes
2025-02-06 21:50:35,889:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:35,889:INFO:Initializing create_model()
2025-02-06 21:50:35,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C1E378710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:35,889:INFO:Checking exceptions
2025-02-06 21:50:35,889:INFO:Importing libraries
2025-02-06 21:50:35,889:INFO:Copying training dataset
2025-02-06 21:50:35,894:INFO:Defining folds
2025-02-06 21:50:35,894:INFO:Declaring metric variables
2025-02-06 21:50:35,896:INFO:Importing untrained model
2025-02-06 21:50:35,896:INFO:Declaring custom model
2025-02-06 21:50:35,899:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:35,904:INFO:Starting cross validation
2025-02-06 21:50:35,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:36,201:INFO:Calculating mean and std
2025-02-06 21:50:36,201:INFO:Creating metrics dataframe
2025-02-06 21:50:36,203:INFO:Uploading results into container
2025-02-06 21:50:36,204:INFO:Uploading model into container now
2025-02-06 21:50:36,204:INFO:_master_model_container: 9
2025-02-06 21:50:36,204:INFO:_display_container: 7
2025-02-06 21:50:36,204:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:36,204:INFO:create_model() successfully completed......................................
2025-02-06 21:50:36,266:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:36,266:INFO:Creating metrics dataframe
2025-02-06 21:50:36,270:INFO:Initializing custom model Logistic Regression
2025-02-06 21:50:36,270:INFO:Total runtime is 0.006393015384674072 minutes
2025-02-06 21:50:36,272:INFO:SubProcess create_model() called ==================================
2025-02-06 21:50:36,273:INFO:Initializing create_model()
2025-02-06 21:50:36,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025C1E378710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:36,273:INFO:Checking exceptions
2025-02-06 21:50:36,273:INFO:Importing libraries
2025-02-06 21:50:36,273:INFO:Copying training dataset
2025-02-06 21:50:36,281:INFO:Defining folds
2025-02-06 21:50:36,281:INFO:Declaring metric variables
2025-02-06 21:50:36,284:INFO:Importing untrained model
2025-02-06 21:50:36,284:INFO:Declaring custom model
2025-02-06 21:50:36,286:INFO:Logistic Regression Imported successfully
2025-02-06 21:50:36,290:INFO:Starting cross validation
2025-02-06 21:50:36,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 21:50:36,369:INFO:Calculating mean and std
2025-02-06 21:50:36,369:INFO:Creating metrics dataframe
2025-02-06 21:50:36,370:INFO:Uploading results into container
2025-02-06 21:50:36,370:INFO:Uploading model into container now
2025-02-06 21:50:36,370:INFO:_master_model_container: 10
2025-02-06 21:50:36,370:INFO:_display_container: 7
2025-02-06 21:50:36,371:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 21:50:36,371:INFO:create_model() successfully completed......................................
2025-02-06 21:50:36,422:INFO:SubProcess create_model() end ==================================
2025-02-06 21:50:36,422:INFO:Creating metrics dataframe
2025-02-06 21:50:36,426:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 21:50:36,429:INFO:Initializing create_model()
2025-02-06 21:50:36,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 21:50:36,429:INFO:Checking exceptions
2025-02-06 21:50:36,430:INFO:Importing libraries
2025-02-06 21:50:36,430:INFO:Copying training dataset
2025-02-06 21:50:36,436:INFO:Defining folds
2025-02-06 21:50:36,436:INFO:Declaring metric variables
2025-02-06 21:50:36,436:INFO:Importing untrained model
2025-02-06 21:50:36,436:INFO:Declaring custom model
2025-02-06 21:50:36,437:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 21:50:36,437:INFO:Cross validation set to False
2025-02-06 21:50:36,437:INFO:Fitting Model
2025-02-06 21:50:36,450:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 21:50:36,451:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
2025-02-06 21:50:36,451:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 21:50:36,451:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 21:50:36,451:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 21:50:36,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 21:50:36,451:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 21:50:36,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 21:50:36,477:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:36,477:INFO:create_model() successfully completed......................................
2025-02-06 21:50:36,548:INFO:_master_model_container: 10
2025-02-06 21:50:36,548:INFO:_display_container: 7
2025-02-06 21:50:36,549:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 21:50:36,549:INFO:compare_models() successfully completed......................................
2025-02-06 21:50:36,549:INFO:Initializing predict_model()
2025-02-06 21:50:36,549:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025C1E4E0360>)
2025-02-06 21:50:36,550:INFO:Checking exceptions
2025-02-06 21:50:36,550:INFO:Preloading libraries
2025-02-06 21:50:36,551:INFO:Set up data.
2025-02-06 21:50:36,559:INFO:Set up index.
2025-02-06 21:50:36,671:INFO:Initializing predict_model()
2025-02-06 21:50:36,671:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025C1EACE840>)
2025-02-06 21:50:36,671:INFO:Checking exceptions
2025-02-06 21:50:36,671:INFO:Preloading libraries
2025-02-06 21:50:36,672:INFO:Set up data.
2025-02-06 21:50:36,678:INFO:Set up index.
2025-02-06 21:50:36,776:INFO:Initializing predict_model()
2025-02-06 21:50:36,777:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025C1EACE840>)
2025-02-06 21:50:36,777:INFO:Checking exceptions
2025-02-06 21:50:36,777:INFO:Preloading libraries
2025-02-06 21:50:36,778:INFO:Set up data.
2025-02-06 21:50:36,786:INFO:Set up index.
2025-02-06 21:50:36,877:INFO:Initializing predict_model()
2025-02-06 21:50:36,877:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025C1E19CED0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025C1E4B1940>)
2025-02-06 21:50:36,877:INFO:Checking exceptions
2025-02-06 21:50:36,877:INFO:Preloading libraries
2025-02-06 21:50:36,878:INFO:Set up data.
2025-02-06 21:50:36,882:INFO:Set up index.
2025-02-06 22:02:34,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:02:34,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:02:34,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:02:34,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:02:34,462:INFO:PyCaret ClassificationExperiment
2025-02-06 22:02:34,462:INFO:Logging name: clf-default-name
2025-02-06 22:02:34,462:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 22:02:34,462:INFO:version 3.3.2
2025-02-06 22:02:34,462:INFO:Initializing setup()
2025-02-06 22:02:34,462:INFO:self.USI: 07ce
2025-02-06 22:02:34,462:INFO:self._variable_keys: {'pipeline', 'X_train', 'fix_imbalance', 'seed', 'y_test', 'idx', 'logging_param', 'fold_groups_param', '_ml_usecase', 'y_train', 'gpu_n_jobs_param', 'gpu_param', 'y', 'X', '_available_plots', 'target_param', 'n_jobs_param', 'exp_name_log', 'X_test', 'fold_generator', 'memory', 'is_multiclass', 'USI', 'exp_id', 'log_plots_param', 'data', 'html_param', 'fold_shuffle_param'}
2025-02-06 22:02:34,462:INFO:Checking environment
2025-02-06 22:02:34,462:INFO:python_version: 3.11.9
2025-02-06 22:02:34,462:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 22:02:34,462:INFO:machine: AMD64
2025-02-06 22:02:34,462:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 22:02:34,467:INFO:Memory: svmem(total=67771465728, available=49668517888, percent=26.7, used=18102947840, free=49668517888)
2025-02-06 22:02:34,468:INFO:Physical Core: 8
2025-02-06 22:02:34,468:INFO:Logical Core: 16
2025-02-06 22:02:34,468:INFO:Checking libraries
2025-02-06 22:02:34,468:INFO:System:
2025-02-06 22:02:34,468:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 22:02:34,468:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 22:02:34,468:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 22:02:34,468:INFO:PyCaret required dependencies:
2025-02-06 22:02:34,484:INFO:                 pip: 25.0
2025-02-06 22:02:34,484:INFO:          setuptools: 65.5.0
2025-02-06 22:02:34,484:INFO:             pycaret: 3.3.2
2025-02-06 22:02:34,484:INFO:             IPython: 8.32.0
2025-02-06 22:02:34,484:INFO:          ipywidgets: 8.1.5
2025-02-06 22:02:34,484:INFO:                tqdm: 4.67.1
2025-02-06 22:02:34,484:INFO:               numpy: 1.26.4
2025-02-06 22:02:34,484:INFO:              pandas: 2.1.4
2025-02-06 22:02:34,484:INFO:              jinja2: 3.1.5
2025-02-06 22:02:34,484:INFO:               scipy: 1.11.4
2025-02-06 22:02:34,484:INFO:              joblib: 1.3.2
2025-02-06 22:02:34,484:INFO:             sklearn: 1.4.2
2025-02-06 22:02:34,484:INFO:                pyod: 2.0.3
2025-02-06 22:02:34,484:INFO:            imblearn: 0.13.0
2025-02-06 22:02:34,484:INFO:   category_encoders: 2.7.0
2025-02-06 22:02:34,484:INFO:            lightgbm: 4.5.0
2025-02-06 22:02:34,484:INFO:               numba: 0.61.0
2025-02-06 22:02:34,484:INFO:            requests: 2.32.3
2025-02-06 22:02:34,484:INFO:          matplotlib: 3.7.5
2025-02-06 22:02:34,484:INFO:          scikitplot: 0.3.7
2025-02-06 22:02:34,484:INFO:         yellowbrick: 1.5
2025-02-06 22:02:34,484:INFO:              plotly: 5.24.1
2025-02-06 22:02:34,484:INFO:    plotly-resampler: Not installed
2025-02-06 22:02:34,484:INFO:             kaleido: 0.2.1
2025-02-06 22:02:34,484:INFO:           schemdraw: 0.15
2025-02-06 22:02:34,484:INFO:         statsmodels: 0.14.4
2025-02-06 22:02:34,484:INFO:              sktime: 0.26.0
2025-02-06 22:02:34,484:INFO:               tbats: 1.1.3
2025-02-06 22:02:34,484:INFO:            pmdarima: 2.0.4
2025-02-06 22:02:34,484:INFO:              psutil: 6.1.1
2025-02-06 22:02:34,484:INFO:          markupsafe: 3.0.2
2025-02-06 22:02:34,484:INFO:             pickle5: Not installed
2025-02-06 22:02:34,484:INFO:         cloudpickle: 3.1.1
2025-02-06 22:02:34,484:INFO:         deprecation: 2.1.0
2025-02-06 22:02:34,484:INFO:              xxhash: 3.5.0
2025-02-06 22:02:34,484:INFO:           wurlitzer: Not installed
2025-02-06 22:02:34,484:INFO:PyCaret optional dependencies:
2025-02-06 22:02:34,491:INFO:                shap: Not installed
2025-02-06 22:02:34,491:INFO:           interpret: Not installed
2025-02-06 22:02:34,491:INFO:                umap: Not installed
2025-02-06 22:02:34,491:INFO:     ydata_profiling: Not installed
2025-02-06 22:02:34,491:INFO:  explainerdashboard: Not installed
2025-02-06 22:02:34,491:INFO:             autoviz: Not installed
2025-02-06 22:02:34,491:INFO:           fairlearn: Not installed
2025-02-06 22:02:34,491:INFO:          deepchecks: Not installed
2025-02-06 22:02:34,491:INFO:             xgboost: Not installed
2025-02-06 22:02:34,491:INFO:            catboost: Not installed
2025-02-06 22:02:34,491:INFO:              kmodes: Not installed
2025-02-06 22:02:34,491:INFO:             mlxtend: Not installed
2025-02-06 22:02:34,491:INFO:       statsforecast: Not installed
2025-02-06 22:02:34,491:INFO:        tune_sklearn: Not installed
2025-02-06 22:02:34,491:INFO:                 ray: Not installed
2025-02-06 22:02:34,491:INFO:            hyperopt: Not installed
2025-02-06 22:02:34,491:INFO:              optuna: Not installed
2025-02-06 22:02:34,491:INFO:               skopt: Not installed
2025-02-06 22:02:34,491:INFO:              mlflow: Not installed
2025-02-06 22:02:34,491:INFO:              gradio: Not installed
2025-02-06 22:02:34,491:INFO:             fastapi: Not installed
2025-02-06 22:02:34,491:INFO:             uvicorn: Not installed
2025-02-06 22:02:34,491:INFO:              m2cgen: Not installed
2025-02-06 22:02:34,491:INFO:           evidently: Not installed
2025-02-06 22:02:34,491:INFO:               fugue: Not installed
2025-02-06 22:02:34,491:INFO:           streamlit: Not installed
2025-02-06 22:02:34,491:INFO:             prophet: Not installed
2025-02-06 22:02:34,491:INFO:None
2025-02-06 22:02:34,491:INFO:Set up data.
2025-02-06 22:02:34,498:INFO:Set up folding strategy.
2025-02-06 22:02:34,498:INFO:Set up train/test split.
2025-02-06 22:02:34,503:INFO:Set up index.
2025-02-06 22:02:34,504:INFO:Assigning column types.
2025-02-06 22:02:34,509:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 22:02:34,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,596:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 22:02:34,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:02:34,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,673:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 22:02:34,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,753:INFO:Preparing preprocessing pipeline...
2025-02-06 22:02:34,754:INFO:Set up simple imputation.
2025-02-06 22:02:34,754:INFO:Set up feature normalization.
2025-02-06 22:02:34,777:INFO:Finished creating preprocessing pipeline.
2025-02-06 22:02:34,780:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 22:02:34,780:INFO:Creating final display dataframe.
2025-02-06 22:02:34,851:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              07ce
2025-02-06 22:02:34,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:02:34,929:INFO:setup() successfully completed in 0.47s...............
2025-02-06 22:02:34,929:INFO:Initializing compare_models()
2025-02-06 22:02:34,929:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:02:34,929:INFO:Checking exceptions
2025-02-06 22:02:34,933:INFO:Preparing display monitor
2025-02-06 22:02:34,945:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 22:02:34,945:INFO:Total runtime is 0.0 minutes
2025-02-06 22:02:34,946:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:34,946:INFO:Initializing create_model()
2025-02-06 22:02:34,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020527FD70D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:34,946:INFO:Checking exceptions
2025-02-06 22:02:34,946:INFO:Importing libraries
2025-02-06 22:02:34,946:INFO:Copying training dataset
2025-02-06 22:02:34,952:INFO:Defining folds
2025-02-06 22:02:34,952:INFO:Declaring metric variables
2025-02-06 22:02:34,953:INFO:Importing untrained model
2025-02-06 22:02:34,955:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:34,957:INFO:Starting cross validation
2025-02-06 22:02:34,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:38,062:INFO:Calculating mean and std
2025-02-06 22:02:38,063:INFO:Creating metrics dataframe
2025-02-06 22:02:38,065:INFO:Uploading results into container
2025-02-06 22:02:38,065:INFO:Uploading model into container now
2025-02-06 22:02:38,066:INFO:_master_model_container: 1
2025-02-06 22:02:38,066:INFO:_display_container: 2
2025-02-06 22:02:38,066:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:38,066:INFO:create_model() successfully completed......................................
2025-02-06 22:02:38,135:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:38,135:INFO:Creating metrics dataframe
2025-02-06 22:02:38,138:INFO:Initializing Logistic Regression
2025-02-06 22:02:38,138:INFO:Total runtime is 0.05322024822235107 minutes
2025-02-06 22:02:38,140:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:38,141:INFO:Initializing create_model()
2025-02-06 22:02:38,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020527FD70D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:38,141:INFO:Checking exceptions
2025-02-06 22:02:38,141:INFO:Importing libraries
2025-02-06 22:02:38,141:INFO:Copying training dataset
2025-02-06 22:02:38,149:INFO:Defining folds
2025-02-06 22:02:38,150:INFO:Declaring metric variables
2025-02-06 22:02:38,151:INFO:Importing untrained model
2025-02-06 22:02:38,153:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:38,157:INFO:Starting cross validation
2025-02-06 22:02:38,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:39,679:INFO:Calculating mean and std
2025-02-06 22:02:39,680:INFO:Creating metrics dataframe
2025-02-06 22:02:39,681:INFO:Uploading results into container
2025-02-06 22:02:39,681:INFO:Uploading model into container now
2025-02-06 22:02:39,681:INFO:_master_model_container: 2
2025-02-06 22:02:39,681:INFO:_display_container: 2
2025-02-06 22:02:39,682:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:39,682:INFO:create_model() successfully completed......................................
2025-02-06 22:02:39,754:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:39,754:INFO:Creating metrics dataframe
2025-02-06 22:02:39,759:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:02:39,762:INFO:Initializing create_model()
2025-02-06 22:02:39,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:39,762:INFO:Checking exceptions
2025-02-06 22:02:39,763:INFO:Importing libraries
2025-02-06 22:02:39,763:INFO:Copying training dataset
2025-02-06 22:02:39,770:INFO:Defining folds
2025-02-06 22:02:39,770:INFO:Declaring metric variables
2025-02-06 22:02:39,770:INFO:Importing untrained model
2025-02-06 22:02:39,770:INFO:Declaring custom model
2025-02-06 22:02:39,770:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:39,770:INFO:Cross validation set to False
2025-02-06 22:02:39,770:INFO:Fitting Model
2025-02-06 22:02:39,798:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:39,798:INFO:create_model() successfully completed......................................
2025-02-06 22:02:39,845:INFO:_master_model_container: 2
2025-02-06 22:02:39,845:INFO:_display_container: 2
2025-02-06 22:02:39,845:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:39,845:INFO:compare_models() successfully completed......................................
2025-02-06 22:02:39,845:INFO:Initializing create_model()
2025-02-06 22:02:39,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:39,845:INFO:Checking exceptions
2025-02-06 22:02:39,851:INFO:Importing libraries
2025-02-06 22:02:39,852:INFO:Copying training dataset
2025-02-06 22:02:39,859:INFO:Defining folds
2025-02-06 22:02:39,859:INFO:Declaring metric variables
2025-02-06 22:02:39,861:INFO:Importing untrained model
2025-02-06 22:02:39,863:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:39,866:INFO:Starting cross validation
2025-02-06 22:02:39,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:40,756:INFO:Calculating mean and std
2025-02-06 22:02:40,757:INFO:Creating metrics dataframe
2025-02-06 22:02:40,761:INFO:Finalizing model
2025-02-06 22:02:40,781:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:02:40,781:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
2025-02-06 22:02:40,781:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:02:40,782:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:02:40,782:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:02:40,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:02:40,783:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:02:40,901:INFO:Uploading results into container
2025-02-06 22:02:40,901:INFO:Uploading model into container now
2025-02-06 22:02:40,908:INFO:_master_model_container: 3
2025-02-06 22:02:40,908:INFO:_display_container: 3
2025-02-06 22:02:40,908:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:40,909:INFO:create_model() successfully completed......................................
2025-02-06 22:02:40,977:INFO:Initializing tune_model()
2025-02-06 22:02:40,977:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:02:40,977:INFO:Checking exceptions
2025-02-06 22:02:40,990:INFO:Copying training dataset
2025-02-06 22:02:40,996:INFO:Checking base model
2025-02-06 22:02:40,996:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 22:02:40,998:INFO:Declaring metric variables
2025-02-06 22:02:40,999:INFO:Defining Hyperparameters
2025-02-06 22:02:41,049:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 22:02:41,049:INFO:Tuning with n_jobs=-1
2025-02-06 22:02:41,049:INFO:Initializing RandomizedSearchCV
2025-02-06 22:02:44,721:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 22:02:44,722:INFO:Hyperparameter search completed
2025-02-06 22:02:44,722:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:44,723:INFO:Initializing create_model()
2025-02-06 22:02:44,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020526F13490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 22:02:44,723:INFO:Checking exceptions
2025-02-06 22:02:44,723:INFO:Importing libraries
2025-02-06 22:02:44,723:INFO:Copying training dataset
2025-02-06 22:02:44,733:INFO:Defining folds
2025-02-06 22:02:44,733:INFO:Declaring metric variables
2025-02-06 22:02:44,735:INFO:Importing untrained model
2025-02-06 22:02:44,735:INFO:Declaring custom model
2025-02-06 22:02:44,738:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:44,742:INFO:Starting cross validation
2025-02-06 22:02:44,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:45,066:INFO:Calculating mean and std
2025-02-06 22:02:45,066:INFO:Creating metrics dataframe
2025-02-06 22:02:45,070:INFO:Finalizing model
2025-02-06 22:02:45,087:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:02:45,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.
2025-02-06 22:02:45,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:02:45,088:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:02:45,088:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:02:45,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:02:45,088:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:02:45,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:45,143:INFO:Uploading results into container
2025-02-06 22:02:45,143:INFO:Uploading model into container now
2025-02-06 22:02:45,144:INFO:_master_model_container: 4
2025-02-06 22:02:45,144:INFO:_display_container: 4
2025-02-06 22:02:45,144:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:45,144:INFO:create_model() successfully completed......................................
2025-02-06 22:02:45,212:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:45,212:INFO:choose_better activated
2025-02-06 22:02:45,215:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:45,215:INFO:Initializing create_model()
2025-02-06 22:02:45,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:45,215:INFO:Checking exceptions
2025-02-06 22:02:45,216:INFO:Importing libraries
2025-02-06 22:02:45,216:INFO:Copying training dataset
2025-02-06 22:02:45,224:INFO:Defining folds
2025-02-06 22:02:45,224:INFO:Declaring metric variables
2025-02-06 22:02:45,224:INFO:Importing untrained model
2025-02-06 22:02:45,224:INFO:Declaring custom model
2025-02-06 22:02:45,225:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:45,225:INFO:Starting cross validation
2025-02-06 22:02:45,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:45,943:INFO:Calculating mean and std
2025-02-06 22:02:45,943:INFO:Creating metrics dataframe
2025-02-06 22:02:45,945:INFO:Finalizing model
2025-02-06 22:02:45,962:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:02:45,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.
2025-02-06 22:02:45,963:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:02:45,963:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:02:45,963:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:02:45,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:02:45,963:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:02:46,053:INFO:Uploading results into container
2025-02-06 22:02:46,054:INFO:Uploading model into container now
2025-02-06 22:02:46,054:INFO:_master_model_container: 5
2025-02-06 22:02:46,054:INFO:_display_container: 5
2025-02-06 22:02:46,055:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:46,055:INFO:create_model() successfully completed......................................
2025-02-06 22:02:46,109:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:46,109:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 22:02:46,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 22:02:46,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 22:02:46,110:INFO:choose_better completed
2025-02-06 22:02:46,115:INFO:_master_model_container: 5
2025-02-06 22:02:46,116:INFO:_display_container: 4
2025-02-06 22:02:46,116:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:46,116:INFO:tune_model() successfully completed......................................
2025-02-06 22:02:46,151:INFO:Initializing create_model()
2025-02-06 22:02:46,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:46,151:INFO:Checking exceptions
2025-02-06 22:02:46,159:INFO:Importing libraries
2025-02-06 22:02:46,160:INFO:Copying training dataset
2025-02-06 22:02:46,165:INFO:Defining folds
2025-02-06 22:02:46,165:INFO:Declaring metric variables
2025-02-06 22:02:46,168:INFO:Importing untrained model
2025-02-06 22:02:46,170:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:46,172:INFO:Starting cross validation
2025-02-06 22:02:46,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:46,240:INFO:Calculating mean and std
2025-02-06 22:02:46,240:INFO:Creating metrics dataframe
2025-02-06 22:02:46,243:INFO:Finalizing model
2025-02-06 22:02:46,271:INFO:Uploading results into container
2025-02-06 22:02:46,271:INFO:Uploading model into container now
2025-02-06 22:02:46,276:INFO:_master_model_container: 6
2025-02-06 22:02:46,276:INFO:_display_container: 5
2025-02-06 22:02:46,276:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:46,276:INFO:create_model() successfully completed......................................
2025-02-06 22:02:46,322:INFO:Initializing tune_model()
2025-02-06 22:02:46,322:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:02:46,322:INFO:Checking exceptions
2025-02-06 22:02:46,331:INFO:Copying training dataset
2025-02-06 22:02:46,334:INFO:Checking base model
2025-02-06 22:02:46,334:INFO:Base model : Logistic Regression
2025-02-06 22:02:46,335:INFO:Declaring metric variables
2025-02-06 22:02:46,338:INFO:Defining Hyperparameters
2025-02-06 22:02:46,379:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 22:02:46,379:INFO:Tuning with n_jobs=-1
2025-02-06 22:02:46,379:INFO:Initializing RandomizedSearchCV
2025-02-06 22:02:46,775:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 22:02:46,775:INFO:Hyperparameter search completed
2025-02-06 22:02:46,775:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:46,775:INFO:Initializing create_model()
2025-02-06 22:02:46,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020524F96210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 22:02:46,775:INFO:Checking exceptions
2025-02-06 22:02:46,775:INFO:Importing libraries
2025-02-06 22:02:46,775:INFO:Copying training dataset
2025-02-06 22:02:46,781:INFO:Defining folds
2025-02-06 22:02:46,781:INFO:Declaring metric variables
2025-02-06 22:02:46,782:INFO:Importing untrained model
2025-02-06 22:02:46,782:INFO:Declaring custom model
2025-02-06 22:02:46,785:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:46,787:INFO:Starting cross validation
2025-02-06 22:02:46,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:46,856:INFO:Calculating mean and std
2025-02-06 22:02:46,856:INFO:Creating metrics dataframe
2025-02-06 22:02:46,859:INFO:Finalizing model
2025-02-06 22:02:46,886:INFO:Uploading results into container
2025-02-06 22:02:46,887:INFO:Uploading model into container now
2025-02-06 22:02:46,887:INFO:_master_model_container: 7
2025-02-06 22:02:46,887:INFO:_display_container: 6
2025-02-06 22:02:46,887:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:46,887:INFO:create_model() successfully completed......................................
2025-02-06 22:02:46,931:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:46,931:INFO:choose_better activated
2025-02-06 22:02:46,933:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:46,933:INFO:Initializing create_model()
2025-02-06 22:02:46,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:46,933:INFO:Checking exceptions
2025-02-06 22:02:46,934:INFO:Importing libraries
2025-02-06 22:02:46,934:INFO:Copying training dataset
2025-02-06 22:02:46,941:INFO:Defining folds
2025-02-06 22:02:46,941:INFO:Declaring metric variables
2025-02-06 22:02:46,941:INFO:Importing untrained model
2025-02-06 22:02:46,941:INFO:Declaring custom model
2025-02-06 22:02:46,941:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:46,941:INFO:Starting cross validation
2025-02-06 22:02:46,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:46,997:INFO:Calculating mean and std
2025-02-06 22:02:46,997:INFO:Creating metrics dataframe
2025-02-06 22:02:46,998:INFO:Finalizing model
2025-02-06 22:02:47,022:INFO:Uploading results into container
2025-02-06 22:02:47,022:INFO:Uploading model into container now
2025-02-06 22:02:47,022:INFO:_master_model_container: 8
2025-02-06 22:02:47,022:INFO:_display_container: 7
2025-02-06 22:02:47,022:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:47,022:INFO:create_model() successfully completed......................................
2025-02-06 22:02:47,063:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:47,063:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 22:02:47,064:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 22:02:47,064:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 22:02:47,064:INFO:choose_better completed
2025-02-06 22:02:47,068:INFO:_master_model_container: 8
2025-02-06 22:02:47,068:INFO:_display_container: 6
2025-02-06 22:02:47,068:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:47,068:INFO:tune_model() successfully completed......................................
2025-02-06 22:02:47,094:INFO:Initializing compare_models()
2025-02-06 22:02:47,094:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:02:47,095:INFO:Checking exceptions
2025-02-06 22:02:47,097:INFO:Preparing display monitor
2025-02-06 22:02:47,106:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 22:02:47,107:INFO:Total runtime is 0.0 minutes
2025-02-06 22:02:47,108:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:47,108:INFO:Initializing create_model()
2025-02-06 22:02:47,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052797FE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:47,108:INFO:Checking exceptions
2025-02-06 22:02:47,108:INFO:Importing libraries
2025-02-06 22:02:47,108:INFO:Copying training dataset
2025-02-06 22:02:47,113:INFO:Defining folds
2025-02-06 22:02:47,113:INFO:Declaring metric variables
2025-02-06 22:02:47,116:INFO:Importing untrained model
2025-02-06 22:02:47,116:INFO:Declaring custom model
2025-02-06 22:02:47,117:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:47,120:INFO:Starting cross validation
2025-02-06 22:02:47,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:47,417:INFO:Calculating mean and std
2025-02-06 22:02:47,418:INFO:Creating metrics dataframe
2025-02-06 22:02:47,418:INFO:Uploading results into container
2025-02-06 22:02:47,419:INFO:Uploading model into container now
2025-02-06 22:02:47,420:INFO:_master_model_container: 9
2025-02-06 22:02:47,420:INFO:_display_container: 7
2025-02-06 22:02:47,420:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:47,420:INFO:create_model() successfully completed......................................
2025-02-06 22:02:47,477:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:47,477:INFO:Creating metrics dataframe
2025-02-06 22:02:47,481:INFO:Initializing custom model Logistic Regression
2025-02-06 22:02:47,481:INFO:Total runtime is 0.006252960364023844 minutes
2025-02-06 22:02:47,483:INFO:SubProcess create_model() called ==================================
2025-02-06 22:02:47,484:INFO:Initializing create_model()
2025-02-06 22:02:47,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052797FE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:47,484:INFO:Checking exceptions
2025-02-06 22:02:47,484:INFO:Importing libraries
2025-02-06 22:02:47,484:INFO:Copying training dataset
2025-02-06 22:02:47,492:INFO:Defining folds
2025-02-06 22:02:47,492:INFO:Declaring metric variables
2025-02-06 22:02:47,494:INFO:Importing untrained model
2025-02-06 22:02:47,494:INFO:Declaring custom model
2025-02-06 22:02:47,497:INFO:Logistic Regression Imported successfully
2025-02-06 22:02:47,500:INFO:Starting cross validation
2025-02-06 22:02:47,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:02:47,570:INFO:Calculating mean and std
2025-02-06 22:02:47,570:INFO:Creating metrics dataframe
2025-02-06 22:02:47,570:INFO:Uploading results into container
2025-02-06 22:02:47,571:INFO:Uploading model into container now
2025-02-06 22:02:47,571:INFO:_master_model_container: 10
2025-02-06 22:02:47,571:INFO:_display_container: 7
2025-02-06 22:02:47,571:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:02:47,571:INFO:create_model() successfully completed......................................
2025-02-06 22:02:47,613:INFO:SubProcess create_model() end ==================================
2025-02-06 22:02:47,614:INFO:Creating metrics dataframe
2025-02-06 22:02:47,617:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:02:47,621:INFO:Initializing create_model()
2025-02-06 22:02:47,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:02:47,621:INFO:Checking exceptions
2025-02-06 22:02:47,621:INFO:Importing libraries
2025-02-06 22:02:47,621:INFO:Copying training dataset
2025-02-06 22:02:47,627:INFO:Defining folds
2025-02-06 22:02:47,627:INFO:Declaring metric variables
2025-02-06 22:02:47,627:INFO:Importing untrained model
2025-02-06 22:02:47,628:INFO:Declaring custom model
2025-02-06 22:02:47,628:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:02:47,628:INFO:Cross validation set to False
2025-02-06 22:02:47,628:INFO:Fitting Model
2025-02-06 22:02:47,641:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:02:47,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
2025-02-06 22:02:47,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:02:47,642:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:02:47,642:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:02:47,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:02:47,643:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:02:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:02:47,668:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:47,668:INFO:create_model() successfully completed......................................
2025-02-06 22:02:47,721:INFO:_master_model_container: 10
2025-02-06 22:02:47,721:INFO:_display_container: 7
2025-02-06 22:02:47,722:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:02:47,722:INFO:compare_models() successfully completed......................................
2025-02-06 22:02:47,723:INFO:Initializing predict_model()
2025-02-06 22:02:47,723:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527FBFBA0>)
2025-02-06 22:02:47,724:INFO:Checking exceptions
2025-02-06 22:02:47,724:INFO:Preloading libraries
2025-02-06 22:02:47,725:INFO:Set up data.
2025-02-06 22:02:47,733:INFO:Set up index.
2025-02-06 22:02:47,824:INFO:Initializing predict_model()
2025-02-06 22:02:47,824:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527FBFBA0>)
2025-02-06 22:02:47,824:INFO:Checking exceptions
2025-02-06 22:02:47,824:INFO:Preloading libraries
2025-02-06 22:02:47,825:INFO:Set up data.
2025-02-06 22:02:47,830:INFO:Set up index.
2025-02-06 22:02:47,909:INFO:Initializing predict_model()
2025-02-06 22:02:47,909:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002052719FBA0>)
2025-02-06 22:02:47,909:INFO:Checking exceptions
2025-02-06 22:02:47,909:INFO:Preloading libraries
2025-02-06 22:02:47,909:INFO:Set up data.
2025-02-06 22:02:47,917:INFO:Set up index.
2025-02-06 22:02:47,998:INFO:Initializing predict_model()
2025-02-06 22:02:47,998:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527837050>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002052719FBA0>)
2025-02-06 22:02:47,998:INFO:Checking exceptions
2025-02-06 22:02:47,998:INFO:Preloading libraries
2025-02-06 22:02:47,999:INFO:Set up data.
2025-02-06 22:02:48,003:INFO:Set up index.
2025-02-06 22:03:43,864:INFO:PyCaret ClassificationExperiment
2025-02-06 22:03:43,865:INFO:Logging name: clf-default-name
2025-02-06 22:03:43,865:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 22:03:43,865:INFO:version 3.3.2
2025-02-06 22:03:43,865:INFO:Initializing setup()
2025-02-06 22:03:43,865:INFO:self.USI: d9ef
2025-02-06 22:03:43,865:INFO:self._variable_keys: {'pipeline', 'X_train', 'fix_imbalance', 'seed', 'y_test', 'idx', 'logging_param', 'fold_groups_param', '_ml_usecase', 'y_train', 'gpu_n_jobs_param', 'gpu_param', 'y', 'X', '_available_plots', 'target_param', 'n_jobs_param', 'exp_name_log', 'X_test', 'fold_generator', 'memory', 'is_multiclass', 'USI', 'exp_id', 'log_plots_param', 'data', 'html_param', 'fold_shuffle_param'}
2025-02-06 22:03:43,865:INFO:Checking environment
2025-02-06 22:03:43,865:INFO:python_version: 3.11.9
2025-02-06 22:03:43,865:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 22:03:43,865:INFO:machine: AMD64
2025-02-06 22:03:43,865:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 22:03:43,871:INFO:Memory: svmem(total=67771465728, available=47251394560, percent=30.3, used=20520071168, free=47251394560)
2025-02-06 22:03:43,871:INFO:Physical Core: 8
2025-02-06 22:03:43,871:INFO:Logical Core: 16
2025-02-06 22:03:43,871:INFO:Checking libraries
2025-02-06 22:03:43,871:INFO:System:
2025-02-06 22:03:43,872:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 22:03:43,872:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 22:03:43,872:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 22:03:43,872:INFO:PyCaret required dependencies:
2025-02-06 22:03:43,872:INFO:                 pip: 25.0
2025-02-06 22:03:43,872:INFO:          setuptools: 65.5.0
2025-02-06 22:03:43,872:INFO:             pycaret: 3.3.2
2025-02-06 22:03:43,872:INFO:             IPython: 8.32.0
2025-02-06 22:03:43,872:INFO:          ipywidgets: 8.1.5
2025-02-06 22:03:43,872:INFO:                tqdm: 4.67.1
2025-02-06 22:03:43,872:INFO:               numpy: 1.26.4
2025-02-06 22:03:43,872:INFO:              pandas: 2.1.4
2025-02-06 22:03:43,872:INFO:              jinja2: 3.1.5
2025-02-06 22:03:43,872:INFO:               scipy: 1.11.4
2025-02-06 22:03:43,872:INFO:              joblib: 1.3.2
2025-02-06 22:03:43,872:INFO:             sklearn: 1.4.2
2025-02-06 22:03:43,872:INFO:                pyod: 2.0.3
2025-02-06 22:03:43,872:INFO:            imblearn: 0.13.0
2025-02-06 22:03:43,872:INFO:   category_encoders: 2.7.0
2025-02-06 22:03:43,872:INFO:            lightgbm: 4.5.0
2025-02-06 22:03:43,872:INFO:               numba: 0.61.0
2025-02-06 22:03:43,872:INFO:            requests: 2.32.3
2025-02-06 22:03:43,872:INFO:          matplotlib: 3.7.5
2025-02-06 22:03:43,872:INFO:          scikitplot: 0.3.7
2025-02-06 22:03:43,872:INFO:         yellowbrick: 1.5
2025-02-06 22:03:43,872:INFO:              plotly: 5.24.1
2025-02-06 22:03:43,872:INFO:    plotly-resampler: Not installed
2025-02-06 22:03:43,872:INFO:             kaleido: 0.2.1
2025-02-06 22:03:43,872:INFO:           schemdraw: 0.15
2025-02-06 22:03:43,872:INFO:         statsmodels: 0.14.4
2025-02-06 22:03:43,872:INFO:              sktime: 0.26.0
2025-02-06 22:03:43,872:INFO:               tbats: 1.1.3
2025-02-06 22:03:43,872:INFO:            pmdarima: 2.0.4
2025-02-06 22:03:43,872:INFO:              psutil: 6.1.1
2025-02-06 22:03:43,872:INFO:          markupsafe: 3.0.2
2025-02-06 22:03:43,872:INFO:             pickle5: Not installed
2025-02-06 22:03:43,872:INFO:         cloudpickle: 3.1.1
2025-02-06 22:03:43,872:INFO:         deprecation: 2.1.0
2025-02-06 22:03:43,872:INFO:              xxhash: 3.5.0
2025-02-06 22:03:43,872:INFO:           wurlitzer: Not installed
2025-02-06 22:03:43,873:INFO:PyCaret optional dependencies:
2025-02-06 22:03:43,873:INFO:                shap: Not installed
2025-02-06 22:03:43,873:INFO:           interpret: Not installed
2025-02-06 22:03:43,873:INFO:                umap: Not installed
2025-02-06 22:03:43,873:INFO:     ydata_profiling: Not installed
2025-02-06 22:03:43,873:INFO:  explainerdashboard: Not installed
2025-02-06 22:03:43,873:INFO:             autoviz: Not installed
2025-02-06 22:03:43,873:INFO:           fairlearn: Not installed
2025-02-06 22:03:43,873:INFO:          deepchecks: Not installed
2025-02-06 22:03:43,873:INFO:             xgboost: Not installed
2025-02-06 22:03:43,873:INFO:            catboost: Not installed
2025-02-06 22:03:43,873:INFO:              kmodes: Not installed
2025-02-06 22:03:43,873:INFO:             mlxtend: Not installed
2025-02-06 22:03:43,873:INFO:       statsforecast: Not installed
2025-02-06 22:03:43,873:INFO:        tune_sklearn: Not installed
2025-02-06 22:03:43,873:INFO:                 ray: Not installed
2025-02-06 22:03:43,873:INFO:            hyperopt: Not installed
2025-02-06 22:03:43,873:INFO:              optuna: Not installed
2025-02-06 22:03:43,873:INFO:               skopt: Not installed
2025-02-06 22:03:43,873:INFO:              mlflow: Not installed
2025-02-06 22:03:43,873:INFO:              gradio: Not installed
2025-02-06 22:03:43,873:INFO:             fastapi: Not installed
2025-02-06 22:03:43,873:INFO:             uvicorn: Not installed
2025-02-06 22:03:43,873:INFO:              m2cgen: Not installed
2025-02-06 22:03:43,873:INFO:           evidently: Not installed
2025-02-06 22:03:43,873:INFO:               fugue: Not installed
2025-02-06 22:03:43,873:INFO:           streamlit: Not installed
2025-02-06 22:03:43,873:INFO:             prophet: Not installed
2025-02-06 22:03:43,873:INFO:None
2025-02-06 22:03:43,873:INFO:Set up data.
2025-02-06 22:03:43,882:INFO:Set up folding strategy.
2025-02-06 22:03:43,882:INFO:Set up train/test split.
2025-02-06 22:03:43,890:INFO:Set up index.
2025-02-06 22:03:43,890:INFO:Assigning column types.
2025-02-06 22:03:43,895:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 22:03:43,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:03:43,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:03:43,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:43,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:43,961:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:03:43,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:03:43,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:43,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:43,976:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 22:03:44,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:03:44,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,039:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:03:44,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,053:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 22:03:44,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,132:INFO:Preparing preprocessing pipeline...
2025-02-06 22:03:44,132:INFO:Set up simple imputation.
2025-02-06 22:03:44,133:INFO:Set up feature normalization.
2025-02-06 22:03:44,155:INFO:Finished creating preprocessing pipeline.
2025-02-06 22:03:44,157:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 22:03:44,157:INFO:Creating final display dataframe.
2025-02-06 22:03:44,226:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              d9ef
2025-02-06 22:03:44,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:03:44,304:INFO:setup() successfully completed in 0.44s...............
2025-02-06 22:03:44,304:INFO:Initializing compare_models()
2025-02-06 22:03:44,304:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:03:44,304:INFO:Checking exceptions
2025-02-06 22:03:44,308:INFO:Preparing display monitor
2025-02-06 22:03:44,318:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 22:03:44,318:INFO:Total runtime is 0.0 minutes
2025-02-06 22:03:44,320:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:44,320:INFO:Initializing create_model()
2025-02-06 22:03:44,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052564A410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:44,320:INFO:Checking exceptions
2025-02-06 22:03:44,320:INFO:Importing libraries
2025-02-06 22:03:44,320:INFO:Copying training dataset
2025-02-06 22:03:44,328:INFO:Defining folds
2025-02-06 22:03:44,328:INFO:Declaring metric variables
2025-02-06 22:03:44,329:INFO:Importing untrained model
2025-02-06 22:03:44,331:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:44,333:INFO:Starting cross validation
2025-02-06 22:03:44,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:45,106:INFO:Calculating mean and std
2025-02-06 22:03:45,106:INFO:Creating metrics dataframe
2025-02-06 22:03:45,108:INFO:Uploading results into container
2025-02-06 22:03:45,108:INFO:Uploading model into container now
2025-02-06 22:03:45,108:INFO:_master_model_container: 1
2025-02-06 22:03:45,108:INFO:_display_container: 2
2025-02-06 22:03:45,108:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:45,109:INFO:create_model() successfully completed......................................
2025-02-06 22:03:45,179:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:45,179:INFO:Creating metrics dataframe
2025-02-06 22:03:45,183:INFO:Initializing Logistic Regression
2025-02-06 22:03:45,183:INFO:Total runtime is 0.01441335678100586 minutes
2025-02-06 22:03:45,185:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:45,185:INFO:Initializing create_model()
2025-02-06 22:03:45,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052564A410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:45,185:INFO:Checking exceptions
2025-02-06 22:03:45,185:INFO:Importing libraries
2025-02-06 22:03:45,185:INFO:Copying training dataset
2025-02-06 22:03:45,194:INFO:Defining folds
2025-02-06 22:03:45,194:INFO:Declaring metric variables
2025-02-06 22:03:45,195:INFO:Importing untrained model
2025-02-06 22:03:45,198:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:45,201:INFO:Starting cross validation
2025-02-06 22:03:45,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:45,258:INFO:Calculating mean and std
2025-02-06 22:03:45,258:INFO:Creating metrics dataframe
2025-02-06 22:03:45,259:INFO:Uploading results into container
2025-02-06 22:03:45,259:INFO:Uploading model into container now
2025-02-06 22:03:45,260:INFO:_master_model_container: 2
2025-02-06 22:03:45,260:INFO:_display_container: 2
2025-02-06 22:03:45,260:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:45,260:INFO:create_model() successfully completed......................................
2025-02-06 22:03:45,306:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:45,307:INFO:Creating metrics dataframe
2025-02-06 22:03:45,310:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:03:45,313:INFO:Initializing create_model()
2025-02-06 22:03:45,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:45,314:INFO:Checking exceptions
2025-02-06 22:03:45,314:INFO:Importing libraries
2025-02-06 22:03:45,314:INFO:Copying training dataset
2025-02-06 22:03:45,319:INFO:Defining folds
2025-02-06 22:03:45,320:INFO:Declaring metric variables
2025-02-06 22:03:45,320:INFO:Importing untrained model
2025-02-06 22:03:45,320:INFO:Declaring custom model
2025-02-06 22:03:45,320:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:45,320:INFO:Cross validation set to False
2025-02-06 22:03:45,320:INFO:Fitting Model
2025-02-06 22:03:45,347:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:45,347:INFO:create_model() successfully completed......................................
2025-02-06 22:03:45,403:INFO:_master_model_container: 2
2025-02-06 22:03:45,403:INFO:_display_container: 2
2025-02-06 22:03:45,403:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:45,403:INFO:compare_models() successfully completed......................................
2025-02-06 22:03:45,403:INFO:Initializing create_model()
2025-02-06 22:03:45,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:45,403:INFO:Checking exceptions
2025-02-06 22:03:45,409:INFO:Importing libraries
2025-02-06 22:03:45,409:INFO:Copying training dataset
2025-02-06 22:03:45,415:INFO:Defining folds
2025-02-06 22:03:45,415:INFO:Declaring metric variables
2025-02-06 22:03:45,417:INFO:Importing untrained model
2025-02-06 22:03:45,418:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:45,421:INFO:Starting cross validation
2025-02-06 22:03:45,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:46,212:INFO:Calculating mean and std
2025-02-06 22:03:46,213:INFO:Creating metrics dataframe
2025-02-06 22:03:46,217:INFO:Finalizing model
2025-02-06 22:03:46,235:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:03:46,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000821 seconds.
2025-02-06 22:03:46,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:03:46,236:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:03:46,236:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:03:46,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:03:46,236:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:03:46,326:INFO:Uploading results into container
2025-02-06 22:03:46,326:INFO:Uploading model into container now
2025-02-06 22:03:46,333:INFO:_master_model_container: 3
2025-02-06 22:03:46,333:INFO:_display_container: 3
2025-02-06 22:03:46,333:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:46,333:INFO:create_model() successfully completed......................................
2025-02-06 22:03:46,403:INFO:Initializing tune_model()
2025-02-06 22:03:46,403:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:03:46,403:INFO:Checking exceptions
2025-02-06 22:03:46,414:INFO:Copying training dataset
2025-02-06 22:03:46,422:INFO:Checking base model
2025-02-06 22:03:46,422:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 22:03:46,424:INFO:Declaring metric variables
2025-02-06 22:03:46,426:INFO:Defining Hyperparameters
2025-02-06 22:03:46,483:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 22:03:46,483:INFO:Tuning with n_jobs=-1
2025-02-06 22:03:46,483:INFO:Initializing RandomizedSearchCV
2025-02-06 22:03:49,930:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 22:03:49,931:INFO:Hyperparameter search completed
2025-02-06 22:03:49,931:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:49,932:INFO:Initializing create_model()
2025-02-06 22:03:49,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020527838B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 22:03:49,932:INFO:Checking exceptions
2025-02-06 22:03:49,932:INFO:Importing libraries
2025-02-06 22:03:49,933:INFO:Copying training dataset
2025-02-06 22:03:49,941:INFO:Defining folds
2025-02-06 22:03:49,941:INFO:Declaring metric variables
2025-02-06 22:03:49,943:INFO:Importing untrained model
2025-02-06 22:03:49,943:INFO:Declaring custom model
2025-02-06 22:03:49,946:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:49,950:INFO:Starting cross validation
2025-02-06 22:03:49,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:50,372:INFO:Calculating mean and std
2025-02-06 22:03:50,372:INFO:Creating metrics dataframe
2025-02-06 22:03:50,379:INFO:Finalizing model
2025-02-06 22:03:50,400:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:03:50,400:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.
2025-02-06 22:03:50,400:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:03:50,401:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:03:50,401:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:03:50,402:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:03:50,402:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:03:50,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:50,464:INFO:Uploading results into container
2025-02-06 22:03:50,464:INFO:Uploading model into container now
2025-02-06 22:03:50,464:INFO:_master_model_container: 4
2025-02-06 22:03:50,465:INFO:_display_container: 4
2025-02-06 22:03:50,465:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:50,465:INFO:create_model() successfully completed......................................
2025-02-06 22:03:50,534:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:50,534:INFO:choose_better activated
2025-02-06 22:03:50,536:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:50,536:INFO:Initializing create_model()
2025-02-06 22:03:50,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:50,536:INFO:Checking exceptions
2025-02-06 22:03:50,538:INFO:Importing libraries
2025-02-06 22:03:50,538:INFO:Copying training dataset
2025-02-06 22:03:50,546:INFO:Defining folds
2025-02-06 22:03:50,546:INFO:Declaring metric variables
2025-02-06 22:03:50,548:INFO:Importing untrained model
2025-02-06 22:03:50,548:INFO:Declaring custom model
2025-02-06 22:03:50,548:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:50,548:INFO:Starting cross validation
2025-02-06 22:03:50,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:51,240:INFO:Calculating mean and std
2025-02-06 22:03:51,240:INFO:Creating metrics dataframe
2025-02-06 22:03:51,241:INFO:Finalizing model
2025-02-06 22:03:51,258:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:03:51,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.
2025-02-06 22:03:51,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:03:51,259:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:03:51,259:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:03:51,260:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:03:51,260:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:03:51,374:INFO:Uploading results into container
2025-02-06 22:03:51,374:INFO:Uploading model into container now
2025-02-06 22:03:51,374:INFO:_master_model_container: 5
2025-02-06 22:03:51,374:INFO:_display_container: 5
2025-02-06 22:03:51,375:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:51,375:INFO:create_model() successfully completed......................................
2025-02-06 22:03:51,438:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:51,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 22:03:51,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 22:03:51,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 22:03:51,438:INFO:choose_better completed
2025-02-06 22:03:51,444:INFO:_master_model_container: 5
2025-02-06 22:03:51,444:INFO:_display_container: 4
2025-02-06 22:03:51,445:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:51,445:INFO:tune_model() successfully completed......................................
2025-02-06 22:03:51,503:INFO:Initializing create_model()
2025-02-06 22:03:51,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:51,504:INFO:Checking exceptions
2025-02-06 22:03:51,513:INFO:Importing libraries
2025-02-06 22:03:51,513:INFO:Copying training dataset
2025-02-06 22:03:51,522:INFO:Defining folds
2025-02-06 22:03:51,522:INFO:Declaring metric variables
2025-02-06 22:03:51,524:INFO:Importing untrained model
2025-02-06 22:03:51,526:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:51,529:INFO:Starting cross validation
2025-02-06 22:03:51,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:51,598:INFO:Calculating mean and std
2025-02-06 22:03:51,598:INFO:Creating metrics dataframe
2025-02-06 22:03:51,601:INFO:Finalizing model
2025-02-06 22:03:51,630:INFO:Uploading results into container
2025-02-06 22:03:51,630:INFO:Uploading model into container now
2025-02-06 22:03:51,635:INFO:_master_model_container: 6
2025-02-06 22:03:51,635:INFO:_display_container: 5
2025-02-06 22:03:51,635:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:51,635:INFO:create_model() successfully completed......................................
2025-02-06 22:03:51,683:INFO:Initializing tune_model()
2025-02-06 22:03:51,683:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:03:51,683:INFO:Checking exceptions
2025-02-06 22:03:51,691:INFO:Copying training dataset
2025-02-06 22:03:51,695:INFO:Checking base model
2025-02-06 22:03:51,695:INFO:Base model : Logistic Regression
2025-02-06 22:03:51,696:INFO:Declaring metric variables
2025-02-06 22:03:51,698:INFO:Defining Hyperparameters
2025-02-06 22:03:51,744:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 22:03:51,744:INFO:Tuning with n_jobs=-1
2025-02-06 22:03:51,744:INFO:Initializing RandomizedSearchCV
2025-02-06 22:03:52,185:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 22:03:52,185:INFO:Hyperparameter search completed
2025-02-06 22:03:52,185:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:52,186:INFO:Initializing create_model()
2025-02-06 22:03:52,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205278685D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 22:03:52,186:INFO:Checking exceptions
2025-02-06 22:03:52,186:INFO:Importing libraries
2025-02-06 22:03:52,186:INFO:Copying training dataset
2025-02-06 22:03:52,194:INFO:Defining folds
2025-02-06 22:03:52,194:INFO:Declaring metric variables
2025-02-06 22:03:52,196:INFO:Importing untrained model
2025-02-06 22:03:52,196:INFO:Declaring custom model
2025-02-06 22:03:52,198:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:52,201:INFO:Starting cross validation
2025-02-06 22:03:52,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:52,290:INFO:Calculating mean and std
2025-02-06 22:03:52,290:INFO:Creating metrics dataframe
2025-02-06 22:03:52,292:INFO:Finalizing model
2025-02-06 22:03:52,321:INFO:Uploading results into container
2025-02-06 22:03:52,321:INFO:Uploading model into container now
2025-02-06 22:03:52,322:INFO:_master_model_container: 7
2025-02-06 22:03:52,322:INFO:_display_container: 6
2025-02-06 22:03:52,322:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:52,322:INFO:create_model() successfully completed......................................
2025-02-06 22:03:52,371:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:52,371:INFO:choose_better activated
2025-02-06 22:03:52,374:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:52,374:INFO:Initializing create_model()
2025-02-06 22:03:52,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:52,374:INFO:Checking exceptions
2025-02-06 22:03:52,375:INFO:Importing libraries
2025-02-06 22:03:52,375:INFO:Copying training dataset
2025-02-06 22:03:52,380:INFO:Defining folds
2025-02-06 22:03:52,380:INFO:Declaring metric variables
2025-02-06 22:03:52,380:INFO:Importing untrained model
2025-02-06 22:03:52,381:INFO:Declaring custom model
2025-02-06 22:03:52,381:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:52,381:INFO:Starting cross validation
2025-02-06 22:03:52,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:52,438:INFO:Calculating mean and std
2025-02-06 22:03:52,438:INFO:Creating metrics dataframe
2025-02-06 22:03:52,439:INFO:Finalizing model
2025-02-06 22:03:52,467:INFO:Uploading results into container
2025-02-06 22:03:52,467:INFO:Uploading model into container now
2025-02-06 22:03:52,468:INFO:_master_model_container: 8
2025-02-06 22:03:52,468:INFO:_display_container: 7
2025-02-06 22:03:52,468:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:52,468:INFO:create_model() successfully completed......................................
2025-02-06 22:03:52,518:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:52,518:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 22:03:52,518:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 22:03:52,518:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 22:03:52,518:INFO:choose_better completed
2025-02-06 22:03:52,522:INFO:_master_model_container: 8
2025-02-06 22:03:52,524:INFO:_display_container: 6
2025-02-06 22:03:52,524:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:52,524:INFO:tune_model() successfully completed......................................
2025-02-06 22:03:52,562:INFO:Initializing compare_models()
2025-02-06 22:03:52,562:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:03:52,562:INFO:Checking exceptions
2025-02-06 22:03:52,564:INFO:Preparing display monitor
2025-02-06 22:03:52,574:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 22:03:52,574:INFO:Total runtime is 0.0 minutes
2025-02-06 22:03:52,575:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:52,576:INFO:Initializing create_model()
2025-02-06 22:03:52,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052945C590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:52,576:INFO:Checking exceptions
2025-02-06 22:03:52,576:INFO:Importing libraries
2025-02-06 22:03:52,576:INFO:Copying training dataset
2025-02-06 22:03:52,582:INFO:Defining folds
2025-02-06 22:03:52,582:INFO:Declaring metric variables
2025-02-06 22:03:52,583:INFO:Importing untrained model
2025-02-06 22:03:52,584:INFO:Declaring custom model
2025-02-06 22:03:52,585:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:52,588:INFO:Starting cross validation
2025-02-06 22:03:52,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:52,871:INFO:Calculating mean and std
2025-02-06 22:03:52,872:INFO:Creating metrics dataframe
2025-02-06 22:03:52,873:INFO:Uploading results into container
2025-02-06 22:03:52,873:INFO:Uploading model into container now
2025-02-06 22:03:52,874:INFO:_master_model_container: 9
2025-02-06 22:03:52,874:INFO:_display_container: 7
2025-02-06 22:03:52,874:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:52,874:INFO:create_model() successfully completed......................................
2025-02-06 22:03:52,941:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:52,941:INFO:Creating metrics dataframe
2025-02-06 22:03:52,945:INFO:Initializing custom model Logistic Regression
2025-02-06 22:03:52,945:INFO:Total runtime is 0.0061804374059041345 minutes
2025-02-06 22:03:52,946:INFO:SubProcess create_model() called ==================================
2025-02-06 22:03:52,948:INFO:Initializing create_model()
2025-02-06 22:03:52,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002052945C590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:52,948:INFO:Checking exceptions
2025-02-06 22:03:52,948:INFO:Importing libraries
2025-02-06 22:03:52,948:INFO:Copying training dataset
2025-02-06 22:03:52,956:INFO:Defining folds
2025-02-06 22:03:52,956:INFO:Declaring metric variables
2025-02-06 22:03:52,958:INFO:Importing untrained model
2025-02-06 22:03:52,958:INFO:Declaring custom model
2025-02-06 22:03:52,960:INFO:Logistic Regression Imported successfully
2025-02-06 22:03:52,965:INFO:Starting cross validation
2025-02-06 22:03:52,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:03:53,044:INFO:Calculating mean and std
2025-02-06 22:03:53,044:INFO:Creating metrics dataframe
2025-02-06 22:03:53,045:INFO:Uploading results into container
2025-02-06 22:03:53,045:INFO:Uploading model into container now
2025-02-06 22:03:53,046:INFO:_master_model_container: 10
2025-02-06 22:03:53,046:INFO:_display_container: 7
2025-02-06 22:03:53,046:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:03:53,046:INFO:create_model() successfully completed......................................
2025-02-06 22:03:53,094:INFO:SubProcess create_model() end ==================================
2025-02-06 22:03:53,094:INFO:Creating metrics dataframe
2025-02-06 22:03:53,097:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:03:53,101:INFO:Initializing create_model()
2025-02-06 22:03:53,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:03:53,101:INFO:Checking exceptions
2025-02-06 22:03:53,102:INFO:Importing libraries
2025-02-06 22:03:53,102:INFO:Copying training dataset
2025-02-06 22:03:53,107:INFO:Defining folds
2025-02-06 22:03:53,108:INFO:Declaring metric variables
2025-02-06 22:03:53,108:INFO:Importing untrained model
2025-02-06 22:03:53,108:INFO:Declaring custom model
2025-02-06 22:03:53,108:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:03:53,108:INFO:Cross validation set to False
2025-02-06 22:03:53,108:INFO:Fitting Model
2025-02-06 22:03:53,121:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:03:53,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.
2025-02-06 22:03:53,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:03:53,122:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:03:53,122:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:03:53,122:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:03:53,122:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:03:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:03:53,147:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:53,147:INFO:create_model() successfully completed......................................
2025-02-06 22:03:53,242:INFO:_master_model_container: 10
2025-02-06 22:03:53,243:INFO:_display_container: 7
2025-02-06 22:03:53,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:03:53,243:INFO:compare_models() successfully completed......................................
2025-02-06 22:03:53,244:INFO:Initializing predict_model()
2025-02-06 22:03:53,244:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527F0B1A0>)
2025-02-06 22:03:53,244:INFO:Checking exceptions
2025-02-06 22:03:53,244:INFO:Preloading libraries
2025-02-06 22:03:53,245:INFO:Set up data.
2025-02-06 22:03:53,251:INFO:Set up index.
2025-02-06 22:03:53,357:INFO:Initializing predict_model()
2025-02-06 22:03:53,357:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527877420>)
2025-02-06 22:03:53,357:INFO:Checking exceptions
2025-02-06 22:03:53,357:INFO:Preloading libraries
2025-02-06 22:03:53,358:INFO:Set up data.
2025-02-06 22:03:53,365:INFO:Set up index.
2025-02-06 22:03:53,447:INFO:Initializing predict_model()
2025-02-06 22:03:53,447:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527877420>)
2025-02-06 22:03:53,447:INFO:Checking exceptions
2025-02-06 22:03:53,447:INFO:Preloading libraries
2025-02-06 22:03:53,448:INFO:Set up data.
2025-02-06 22:03:53,456:INFO:Set up index.
2025-02-06 22:03:53,551:INFO:Initializing predict_model()
2025-02-06 22:03:53,551:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020527BE3250>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020527877420>)
2025-02-06 22:03:53,551:INFO:Checking exceptions
2025-02-06 22:03:53,551:INFO:Preloading libraries
2025-02-06 22:03:53,552:INFO:Set up data.
2025-02-06 22:03:53,556:INFO:Set up index.
2025-02-06 22:15:28,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:15:28,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:15:28,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:15:28,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:15:29,392:INFO:PyCaret ClassificationExperiment
2025-02-06 22:15:29,392:INFO:Logging name: clf-default-name
2025-02-06 22:15:29,392:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 22:15:29,392:INFO:version 3.3.2
2025-02-06 22:15:29,393:INFO:Initializing setup()
2025-02-06 22:15:29,393:INFO:self.USI: e3fe
2025-02-06 22:15:29,393:INFO:self._variable_keys: {'logging_param', 'is_multiclass', 'y', 'target_param', 'y_test', 'fix_imbalance', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'n_jobs_param', 'USI', 'gpu_param', 'seed', 'X_test', 'X_train', 'exp_id', 'y_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', '_available_plots', '_ml_usecase', 'X', 'fold_generator', 'log_plots_param', 'memory', 'pipeline', 'html_param'}
2025-02-06 22:15:29,393:INFO:Checking environment
2025-02-06 22:15:29,393:INFO:python_version: 3.11.9
2025-02-06 22:15:29,393:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 22:15:29,393:INFO:machine: AMD64
2025-02-06 22:15:29,393:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 22:15:29,397:INFO:Memory: svmem(total=67771465728, available=49750245376, percent=26.6, used=18021220352, free=49750245376)
2025-02-06 22:15:29,397:INFO:Physical Core: 8
2025-02-06 22:15:29,397:INFO:Logical Core: 16
2025-02-06 22:15:29,397:INFO:Checking libraries
2025-02-06 22:15:29,397:INFO:System:
2025-02-06 22:15:29,398:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 22:15:29,398:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 22:15:29,398:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 22:15:29,398:INFO:PyCaret required dependencies:
2025-02-06 22:15:29,411:INFO:                 pip: 25.0
2025-02-06 22:15:29,411:INFO:          setuptools: 65.5.0
2025-02-06 22:15:29,411:INFO:             pycaret: 3.3.2
2025-02-06 22:15:29,411:INFO:             IPython: 8.32.0
2025-02-06 22:15:29,411:INFO:          ipywidgets: 8.1.5
2025-02-06 22:15:29,411:INFO:                tqdm: 4.67.1
2025-02-06 22:15:29,411:INFO:               numpy: 1.26.4
2025-02-06 22:15:29,411:INFO:              pandas: 2.1.4
2025-02-06 22:15:29,411:INFO:              jinja2: 3.1.5
2025-02-06 22:15:29,411:INFO:               scipy: 1.11.4
2025-02-06 22:15:29,411:INFO:              joblib: 1.3.2
2025-02-06 22:15:29,411:INFO:             sklearn: 1.4.2
2025-02-06 22:15:29,411:INFO:                pyod: 2.0.3
2025-02-06 22:15:29,411:INFO:            imblearn: 0.13.0
2025-02-06 22:15:29,411:INFO:   category_encoders: 2.7.0
2025-02-06 22:15:29,411:INFO:            lightgbm: 4.5.0
2025-02-06 22:15:29,411:INFO:               numba: 0.61.0
2025-02-06 22:15:29,411:INFO:            requests: 2.32.3
2025-02-06 22:15:29,411:INFO:          matplotlib: 3.7.5
2025-02-06 22:15:29,411:INFO:          scikitplot: 0.3.7
2025-02-06 22:15:29,411:INFO:         yellowbrick: 1.5
2025-02-06 22:15:29,411:INFO:              plotly: 5.24.1
2025-02-06 22:15:29,411:INFO:    plotly-resampler: Not installed
2025-02-06 22:15:29,411:INFO:             kaleido: 0.2.1
2025-02-06 22:15:29,411:INFO:           schemdraw: 0.15
2025-02-06 22:15:29,411:INFO:         statsmodels: 0.14.4
2025-02-06 22:15:29,411:INFO:              sktime: 0.26.0
2025-02-06 22:15:29,411:INFO:               tbats: 1.1.3
2025-02-06 22:15:29,411:INFO:            pmdarima: 2.0.4
2025-02-06 22:15:29,411:INFO:              psutil: 6.1.1
2025-02-06 22:15:29,411:INFO:          markupsafe: 3.0.2
2025-02-06 22:15:29,411:INFO:             pickle5: Not installed
2025-02-06 22:15:29,412:INFO:         cloudpickle: 3.1.1
2025-02-06 22:15:29,412:INFO:         deprecation: 2.1.0
2025-02-06 22:15:29,412:INFO:              xxhash: 3.5.0
2025-02-06 22:15:29,412:INFO:           wurlitzer: Not installed
2025-02-06 22:15:29,412:INFO:PyCaret optional dependencies:
2025-02-06 22:15:29,417:INFO:                shap: Not installed
2025-02-06 22:15:29,417:INFO:           interpret: Not installed
2025-02-06 22:15:29,417:INFO:                umap: Not installed
2025-02-06 22:15:29,417:INFO:     ydata_profiling: Not installed
2025-02-06 22:15:29,417:INFO:  explainerdashboard: Not installed
2025-02-06 22:15:29,417:INFO:             autoviz: Not installed
2025-02-06 22:15:29,417:INFO:           fairlearn: Not installed
2025-02-06 22:15:29,417:INFO:          deepchecks: Not installed
2025-02-06 22:15:29,417:INFO:             xgboost: Not installed
2025-02-06 22:15:29,417:INFO:            catboost: Not installed
2025-02-06 22:15:29,417:INFO:              kmodes: Not installed
2025-02-06 22:15:29,417:INFO:             mlxtend: Not installed
2025-02-06 22:15:29,417:INFO:       statsforecast: Not installed
2025-02-06 22:15:29,417:INFO:        tune_sklearn: Not installed
2025-02-06 22:15:29,417:INFO:                 ray: Not installed
2025-02-06 22:15:29,417:INFO:            hyperopt: Not installed
2025-02-06 22:15:29,417:INFO:              optuna: Not installed
2025-02-06 22:15:29,417:INFO:               skopt: Not installed
2025-02-06 22:15:29,417:INFO:              mlflow: Not installed
2025-02-06 22:15:29,417:INFO:              gradio: Not installed
2025-02-06 22:15:29,417:INFO:             fastapi: Not installed
2025-02-06 22:15:29,417:INFO:             uvicorn: Not installed
2025-02-06 22:15:29,417:INFO:              m2cgen: Not installed
2025-02-06 22:15:29,417:INFO:           evidently: Not installed
2025-02-06 22:15:29,417:INFO:               fugue: Not installed
2025-02-06 22:15:29,417:INFO:           streamlit: Not installed
2025-02-06 22:15:29,418:INFO:             prophet: Not installed
2025-02-06 22:15:29,418:INFO:None
2025-02-06 22:15:29,418:INFO:Set up data.
2025-02-06 22:15:29,427:INFO:Set up folding strategy.
2025-02-06 22:15:29,427:INFO:Set up train/test split.
2025-02-06 22:15:29,434:INFO:Set up index.
2025-02-06 22:15:29,435:INFO:Assigning column types.
2025-02-06 22:15:29,440:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 22:15:29,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,466:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,526:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 22:15:29,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:15:29,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,606:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 22:15:29,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,684:INFO:Preparing preprocessing pipeline...
2025-02-06 22:15:29,685:INFO:Set up simple imputation.
2025-02-06 22:15:29,685:INFO:Set up feature normalization.
2025-02-06 22:15:29,708:INFO:Finished creating preprocessing pipeline.
2025-02-06 22:15:29,711:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 22:15:29,711:INFO:Creating final display dataframe.
2025-02-06 22:15:29,781:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e3fe
2025-02-06 22:15:29,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:15:29,859:INFO:setup() successfully completed in 0.47s...............
2025-02-06 22:15:29,859:INFO:Initializing compare_models()
2025-02-06 22:15:29,859:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:15:29,859:INFO:Checking exceptions
2025-02-06 22:15:29,864:INFO:Preparing display monitor
2025-02-06 22:15:29,875:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 22:15:29,875:INFO:Total runtime is 0.0 minutes
2025-02-06 22:15:29,877:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:29,877:INFO:Initializing create_model()
2025-02-06 22:15:29,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E26699510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:29,877:INFO:Checking exceptions
2025-02-06 22:15:29,877:INFO:Importing libraries
2025-02-06 22:15:29,877:INFO:Copying training dataset
2025-02-06 22:15:29,882:INFO:Defining folds
2025-02-06 22:15:29,882:INFO:Declaring metric variables
2025-02-06 22:15:29,884:INFO:Importing untrained model
2025-02-06 22:15:29,885:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:29,888:INFO:Starting cross validation
2025-02-06 22:15:29,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:32,675:INFO:Calculating mean and std
2025-02-06 22:15:32,676:INFO:Creating metrics dataframe
2025-02-06 22:15:32,678:INFO:Uploading results into container
2025-02-06 22:15:32,678:INFO:Uploading model into container now
2025-02-06 22:15:32,679:INFO:_master_model_container: 1
2025-02-06 22:15:32,679:INFO:_display_container: 2
2025-02-06 22:15:32,679:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:32,679:INFO:create_model() successfully completed......................................
2025-02-06 22:15:32,756:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:32,756:INFO:Creating metrics dataframe
2025-02-06 22:15:32,759:INFO:Initializing Logistic Regression
2025-02-06 22:15:32,759:INFO:Total runtime is 0.048064319292704265 minutes
2025-02-06 22:15:32,761:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:32,761:INFO:Initializing create_model()
2025-02-06 22:15:32,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E26699510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:32,761:INFO:Checking exceptions
2025-02-06 22:15:32,761:INFO:Importing libraries
2025-02-06 22:15:32,761:INFO:Copying training dataset
2025-02-06 22:15:32,767:INFO:Defining folds
2025-02-06 22:15:32,767:INFO:Declaring metric variables
2025-02-06 22:15:32,768:INFO:Importing untrained model
2025-02-06 22:15:32,769:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:32,771:INFO:Starting cross validation
2025-02-06 22:15:32,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:34,169:INFO:Calculating mean and std
2025-02-06 22:15:34,169:INFO:Creating metrics dataframe
2025-02-06 22:15:34,171:INFO:Uploading results into container
2025-02-06 22:15:34,171:INFO:Uploading model into container now
2025-02-06 22:15:34,171:INFO:_master_model_container: 2
2025-02-06 22:15:34,173:INFO:_display_container: 2
2025-02-06 22:15:34,173:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:34,173:INFO:create_model() successfully completed......................................
2025-02-06 22:15:34,238:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:34,238:INFO:Creating metrics dataframe
2025-02-06 22:15:34,242:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:15:34,246:INFO:Initializing create_model()
2025-02-06 22:15:34,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:34,246:INFO:Checking exceptions
2025-02-06 22:15:34,247:INFO:Importing libraries
2025-02-06 22:15:34,247:INFO:Copying training dataset
2025-02-06 22:15:34,252:INFO:Defining folds
2025-02-06 22:15:34,252:INFO:Declaring metric variables
2025-02-06 22:15:34,252:INFO:Importing untrained model
2025-02-06 22:15:34,252:INFO:Declaring custom model
2025-02-06 22:15:34,253:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:34,253:INFO:Cross validation set to False
2025-02-06 22:15:34,253:INFO:Fitting Model
2025-02-06 22:15:34,281:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:34,281:INFO:create_model() successfully completed......................................
2025-02-06 22:15:34,324:INFO:_master_model_container: 2
2025-02-06 22:15:34,324:INFO:_display_container: 2
2025-02-06 22:15:34,324:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:34,324:INFO:compare_models() successfully completed......................................
2025-02-06 22:15:34,324:INFO:Initializing create_model()
2025-02-06 22:15:34,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:34,324:INFO:Checking exceptions
2025-02-06 22:15:34,331:INFO:Importing libraries
2025-02-06 22:15:34,331:INFO:Copying training dataset
2025-02-06 22:15:34,336:INFO:Defining folds
2025-02-06 22:15:34,336:INFO:Declaring metric variables
2025-02-06 22:15:34,337:INFO:Importing untrained model
2025-02-06 22:15:34,339:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:34,342:INFO:Starting cross validation
2025-02-06 22:15:34,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:35,068:INFO:Calculating mean and std
2025-02-06 22:15:35,068:INFO:Creating metrics dataframe
2025-02-06 22:15:35,072:INFO:Finalizing model
2025-02-06 22:15:35,091:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:15:35,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
2025-02-06 22:15:35,091:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:15:35,092:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:15:35,092:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:15:35,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:15:35,092:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:15:35,190:INFO:Uploading results into container
2025-02-06 22:15:35,191:INFO:Uploading model into container now
2025-02-06 22:15:35,197:INFO:_master_model_container: 3
2025-02-06 22:15:35,197:INFO:_display_container: 3
2025-02-06 22:15:35,198:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:35,198:INFO:create_model() successfully completed......................................
2025-02-06 22:15:35,252:INFO:Initializing tune_model()
2025-02-06 22:15:35,252:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:15:35,252:INFO:Checking exceptions
2025-02-06 22:15:35,263:INFO:Copying training dataset
2025-02-06 22:15:35,270:INFO:Checking base model
2025-02-06 22:15:35,270:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 22:15:35,272:INFO:Declaring metric variables
2025-02-06 22:15:35,276:INFO:Defining Hyperparameters
2025-02-06 22:15:35,342:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 22:15:35,342:INFO:Tuning with n_jobs=-1
2025-02-06 22:15:35,342:INFO:Initializing RandomizedSearchCV
2025-02-06 22:15:38,813:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 22:15:38,814:INFO:Hyperparameter search completed
2025-02-06 22:15:38,814:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:38,814:INFO:Initializing create_model()
2025-02-06 22:15:38,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E22E11290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 22:15:38,814:INFO:Checking exceptions
2025-02-06 22:15:38,814:INFO:Importing libraries
2025-02-06 22:15:38,814:INFO:Copying training dataset
2025-02-06 22:15:38,823:INFO:Defining folds
2025-02-06 22:15:38,823:INFO:Declaring metric variables
2025-02-06 22:15:38,825:INFO:Importing untrained model
2025-02-06 22:15:38,825:INFO:Declaring custom model
2025-02-06 22:15:38,827:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:38,831:INFO:Starting cross validation
2025-02-06 22:15:38,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:39,138:INFO:Calculating mean and std
2025-02-06 22:15:39,138:INFO:Creating metrics dataframe
2025-02-06 22:15:39,142:INFO:Finalizing model
2025-02-06 22:15:39,164:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:15:39,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
2025-02-06 22:15:39,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:15:39,165:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:15:39,165:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:15:39,165:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:15:39,165:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:15:39,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:39,230:INFO:Uploading results into container
2025-02-06 22:15:39,230:INFO:Uploading model into container now
2025-02-06 22:15:39,230:INFO:_master_model_container: 4
2025-02-06 22:15:39,231:INFO:_display_container: 4
2025-02-06 22:15:39,231:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:39,231:INFO:create_model() successfully completed......................................
2025-02-06 22:15:39,292:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:39,292:INFO:choose_better activated
2025-02-06 22:15:39,294:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:39,295:INFO:Initializing create_model()
2025-02-06 22:15:39,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:39,295:INFO:Checking exceptions
2025-02-06 22:15:39,296:INFO:Importing libraries
2025-02-06 22:15:39,296:INFO:Copying training dataset
2025-02-06 22:15:39,304:INFO:Defining folds
2025-02-06 22:15:39,304:INFO:Declaring metric variables
2025-02-06 22:15:39,304:INFO:Importing untrained model
2025-02-06 22:15:39,304:INFO:Declaring custom model
2025-02-06 22:15:39,305:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:39,305:INFO:Starting cross validation
2025-02-06 22:15:39,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:40,097:INFO:Calculating mean and std
2025-02-06 22:15:40,097:INFO:Creating metrics dataframe
2025-02-06 22:15:40,098:INFO:Finalizing model
2025-02-06 22:15:40,114:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:15:40,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.
2025-02-06 22:15:40,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:15:40,115:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:15:40,115:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:15:40,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:15:40,116:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:15:40,229:INFO:Uploading results into container
2025-02-06 22:15:40,229:INFO:Uploading model into container now
2025-02-06 22:15:40,229:INFO:_master_model_container: 5
2025-02-06 22:15:40,229:INFO:_display_container: 5
2025-02-06 22:15:40,230:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:40,230:INFO:create_model() successfully completed......................................
2025-02-06 22:15:40,282:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:40,282:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 22:15:40,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 22:15:40,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 22:15:40,284:INFO:choose_better completed
2025-02-06 22:15:40,290:INFO:_master_model_container: 5
2025-02-06 22:15:40,290:INFO:_display_container: 4
2025-02-06 22:15:40,290:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:40,290:INFO:tune_model() successfully completed......................................
2025-02-06 22:15:40,330:INFO:Initializing create_model()
2025-02-06 22:15:40,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:40,330:INFO:Checking exceptions
2025-02-06 22:15:40,338:INFO:Importing libraries
2025-02-06 22:15:40,338:INFO:Copying training dataset
2025-02-06 22:15:40,345:INFO:Defining folds
2025-02-06 22:15:40,345:INFO:Declaring metric variables
2025-02-06 22:15:40,346:INFO:Importing untrained model
2025-02-06 22:15:40,348:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:40,351:INFO:Starting cross validation
2025-02-06 22:15:40,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:40,420:INFO:Calculating mean and std
2025-02-06 22:15:40,420:INFO:Creating metrics dataframe
2025-02-06 22:15:40,424:INFO:Finalizing model
2025-02-06 22:15:40,453:INFO:Uploading results into container
2025-02-06 22:15:40,454:INFO:Uploading model into container now
2025-02-06 22:15:40,459:INFO:_master_model_container: 6
2025-02-06 22:15:40,459:INFO:_display_container: 5
2025-02-06 22:15:40,460:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:40,460:INFO:create_model() successfully completed......................................
2025-02-06 22:15:40,518:INFO:Initializing tune_model()
2025-02-06 22:15:40,519:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:15:40,519:INFO:Checking exceptions
2025-02-06 22:15:40,527:INFO:Copying training dataset
2025-02-06 22:15:40,531:INFO:Checking base model
2025-02-06 22:15:40,531:INFO:Base model : Logistic Regression
2025-02-06 22:15:40,532:INFO:Declaring metric variables
2025-02-06 22:15:40,534:INFO:Defining Hyperparameters
2025-02-06 22:15:40,573:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 22:15:40,573:INFO:Tuning with n_jobs=-1
2025-02-06 22:15:40,573:INFO:Initializing RandomizedSearchCV
2025-02-06 22:15:41,009:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 22:15:41,009:INFO:Hyperparameter search completed
2025-02-06 22:15:41,009:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:41,010:INFO:Initializing create_model()
2025-02-06 22:15:41,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E2487ED90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 22:15:41,010:INFO:Checking exceptions
2025-02-06 22:15:41,010:INFO:Importing libraries
2025-02-06 22:15:41,010:INFO:Copying training dataset
2025-02-06 22:15:41,015:INFO:Defining folds
2025-02-06 22:15:41,015:INFO:Declaring metric variables
2025-02-06 22:15:41,017:INFO:Importing untrained model
2025-02-06 22:15:41,017:INFO:Declaring custom model
2025-02-06 22:15:41,018:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:41,022:INFO:Starting cross validation
2025-02-06 22:15:41,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:41,102:INFO:Calculating mean and std
2025-02-06 22:15:41,102:INFO:Creating metrics dataframe
2025-02-06 22:15:41,105:INFO:Finalizing model
2025-02-06 22:15:41,131:INFO:Uploading results into container
2025-02-06 22:15:41,131:INFO:Uploading model into container now
2025-02-06 22:15:41,132:INFO:_master_model_container: 7
2025-02-06 22:15:41,132:INFO:_display_container: 6
2025-02-06 22:15:41,132:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:41,132:INFO:create_model() successfully completed......................................
2025-02-06 22:15:41,176:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:41,177:INFO:choose_better activated
2025-02-06 22:15:41,178:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:41,178:INFO:Initializing create_model()
2025-02-06 22:15:41,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:41,178:INFO:Checking exceptions
2025-02-06 22:15:41,180:INFO:Importing libraries
2025-02-06 22:15:41,180:INFO:Copying training dataset
2025-02-06 22:15:41,185:INFO:Defining folds
2025-02-06 22:15:41,185:INFO:Declaring metric variables
2025-02-06 22:15:41,185:INFO:Importing untrained model
2025-02-06 22:15:41,185:INFO:Declaring custom model
2025-02-06 22:15:41,186:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:41,186:INFO:Starting cross validation
2025-02-06 22:15:41,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:41,243:INFO:Calculating mean and std
2025-02-06 22:15:41,243:INFO:Creating metrics dataframe
2025-02-06 22:15:41,244:INFO:Finalizing model
2025-02-06 22:15:41,271:INFO:Uploading results into container
2025-02-06 22:15:41,271:INFO:Uploading model into container now
2025-02-06 22:15:41,271:INFO:_master_model_container: 8
2025-02-06 22:15:41,271:INFO:_display_container: 7
2025-02-06 22:15:41,272:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:41,272:INFO:create_model() successfully completed......................................
2025-02-06 22:15:41,314:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:41,314:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 22:15:41,314:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 22:15:41,314:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 22:15:41,315:INFO:choose_better completed
2025-02-06 22:15:41,320:INFO:_master_model_container: 8
2025-02-06 22:15:41,320:INFO:_display_container: 6
2025-02-06 22:15:41,320:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:41,320:INFO:tune_model() successfully completed......................................
2025-02-06 22:15:41,350:INFO:Initializing compare_models()
2025-02-06 22:15:41,350:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:15:41,350:INFO:Checking exceptions
2025-02-06 22:15:41,353:INFO:Preparing display monitor
2025-02-06 22:15:41,365:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 22:15:41,365:INFO:Total runtime is 0.0 minutes
2025-02-06 22:15:41,366:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:41,366:INFO:Initializing create_model()
2025-02-06 22:15:41,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E26689490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:41,368:INFO:Checking exceptions
2025-02-06 22:15:41,368:INFO:Importing libraries
2025-02-06 22:15:41,368:INFO:Copying training dataset
2025-02-06 22:15:41,374:INFO:Defining folds
2025-02-06 22:15:41,374:INFO:Declaring metric variables
2025-02-06 22:15:41,377:INFO:Importing untrained model
2025-02-06 22:15:41,377:INFO:Declaring custom model
2025-02-06 22:15:41,378:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:41,381:INFO:Starting cross validation
2025-02-06 22:15:41,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:41,753:INFO:Calculating mean and std
2025-02-06 22:15:41,754:INFO:Creating metrics dataframe
2025-02-06 22:15:41,755:INFO:Uploading results into container
2025-02-06 22:15:41,756:INFO:Uploading model into container now
2025-02-06 22:15:41,756:INFO:_master_model_container: 9
2025-02-06 22:15:41,756:INFO:_display_container: 7
2025-02-06 22:15:41,756:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:41,756:INFO:create_model() successfully completed......................................
2025-02-06 22:15:41,823:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:41,823:INFO:Creating metrics dataframe
2025-02-06 22:15:41,827:INFO:Initializing custom model Logistic Regression
2025-02-06 22:15:41,827:INFO:Total runtime is 0.007692372798919678 minutes
2025-02-06 22:15:41,829:INFO:SubProcess create_model() called ==================================
2025-02-06 22:15:41,830:INFO:Initializing create_model()
2025-02-06 22:15:41,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021E26689490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:41,830:INFO:Checking exceptions
2025-02-06 22:15:41,830:INFO:Importing libraries
2025-02-06 22:15:41,830:INFO:Copying training dataset
2025-02-06 22:15:41,839:INFO:Defining folds
2025-02-06 22:15:41,839:INFO:Declaring metric variables
2025-02-06 22:15:41,840:INFO:Importing untrained model
2025-02-06 22:15:41,840:INFO:Declaring custom model
2025-02-06 22:15:41,842:INFO:Logistic Regression Imported successfully
2025-02-06 22:15:41,846:INFO:Starting cross validation
2025-02-06 22:15:41,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:15:41,934:INFO:Calculating mean and std
2025-02-06 22:15:41,934:INFO:Creating metrics dataframe
2025-02-06 22:15:41,934:INFO:Uploading results into container
2025-02-06 22:15:41,935:INFO:Uploading model into container now
2025-02-06 22:15:41,935:INFO:_master_model_container: 10
2025-02-06 22:15:41,935:INFO:_display_container: 7
2025-02-06 22:15:41,935:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:15:41,935:INFO:create_model() successfully completed......................................
2025-02-06 22:15:41,981:INFO:SubProcess create_model() end ==================================
2025-02-06 22:15:41,981:INFO:Creating metrics dataframe
2025-02-06 22:15:41,985:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:15:41,988:INFO:Initializing create_model()
2025-02-06 22:15:41,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:15:41,988:INFO:Checking exceptions
2025-02-06 22:15:41,989:INFO:Importing libraries
2025-02-06 22:15:41,989:INFO:Copying training dataset
2025-02-06 22:15:41,995:INFO:Defining folds
2025-02-06 22:15:41,995:INFO:Declaring metric variables
2025-02-06 22:15:41,995:INFO:Importing untrained model
2025-02-06 22:15:41,995:INFO:Declaring custom model
2025-02-06 22:15:41,995:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:15:41,995:INFO:Cross validation set to False
2025-02-06 22:15:41,995:INFO:Fitting Model
2025-02-06 22:15:42,009:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:15:42,010:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
2025-02-06 22:15:42,010:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:15:42,010:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:15:42,010:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:15:42,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:15:42,010:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:15:42,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:15:42,041:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:42,041:INFO:create_model() successfully completed......................................
2025-02-06 22:15:42,108:INFO:_master_model_container: 10
2025-02-06 22:15:42,108:INFO:_display_container: 7
2025-02-06 22:15:42,108:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:15:42,108:INFO:compare_models() successfully completed......................................
2025-02-06 22:15:42,109:INFO:Initializing predict_model()
2025-02-06 22:15:42,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.6, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021E5F426F20>)
2025-02-06 22:15:42,110:INFO:Checking exceptions
2025-02-06 22:15:42,110:INFO:Preloading libraries
2025-02-06 22:15:42,111:INFO:Set up data.
2025-02-06 22:15:42,121:INFO:Set up index.
2025-02-06 22:15:42,222:INFO:Initializing predict_model()
2025-02-06 22:15:42,222:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021E5F426F20>)
2025-02-06 22:15:42,222:INFO:Checking exceptions
2025-02-06 22:15:42,222:INFO:Preloading libraries
2025-02-06 22:15:42,223:INFO:Set up data.
2025-02-06 22:15:42,228:INFO:Set up index.
2025-02-06 22:15:42,304:INFO:Initializing predict_model()
2025-02-06 22:15:42,304:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021E5F426F20>)
2025-02-06 22:15:42,304:INFO:Checking exceptions
2025-02-06 22:15:42,305:INFO:Preloading libraries
2025-02-06 22:15:42,306:INFO:Set up data.
2025-02-06 22:15:42,312:INFO:Set up index.
2025-02-06 22:15:42,397:INFO:Initializing predict_model()
2025-02-06 22:15:42,397:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021E24FC6FD0>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021E5F426F20>)
2025-02-06 22:15:42,397:INFO:Checking exceptions
2025-02-06 22:15:42,397:INFO:Preloading libraries
2025-02-06 22:15:42,398:INFO:Set up data.
2025-02-06 22:15:42,402:INFO:Set up index.
2025-02-06 22:16:22,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:16:22,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:16:22,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:16:22,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:16:23,193:INFO:PyCaret ClassificationExperiment
2025-02-06 22:16:23,193:INFO:Logging name: clf-default-name
2025-02-06 22:16:23,193:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 22:16:23,193:INFO:version 3.3.2
2025-02-06 22:16:23,193:INFO:Initializing setup()
2025-02-06 22:16:23,193:INFO:self.USI: d99e
2025-02-06 22:16:23,193:INFO:self._variable_keys: {'y_test', 'gpu_n_jobs_param', 'fold_generator', '_ml_usecase', 'data', 'html_param', 'logging_param', 'log_plots_param', 'gpu_param', 'memory', 'seed', 'y', 'pipeline', '_available_plots', 'X_train', 'is_multiclass', 'y_train', 'USI', 'fold_groups_param', 'X', 'idx', 'exp_name_log', 'X_test', 'fix_imbalance', 'target_param', 'fold_shuffle_param', 'n_jobs_param', 'exp_id'}
2025-02-06 22:16:23,193:INFO:Checking environment
2025-02-06 22:16:23,193:INFO:python_version: 3.11.9
2025-02-06 22:16:23,193:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 22:16:23,193:INFO:machine: AMD64
2025-02-06 22:16:23,194:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 22:16:23,198:INFO:Memory: svmem(total=67771465728, available=49683427328, percent=26.7, used=18088038400, free=49683427328)
2025-02-06 22:16:23,198:INFO:Physical Core: 8
2025-02-06 22:16:23,198:INFO:Logical Core: 16
2025-02-06 22:16:23,198:INFO:Checking libraries
2025-02-06 22:16:23,198:INFO:System:
2025-02-06 22:16:23,199:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 22:16:23,199:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 22:16:23,199:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 22:16:23,199:INFO:PyCaret required dependencies:
2025-02-06 22:16:23,211:INFO:                 pip: 25.0
2025-02-06 22:16:23,211:INFO:          setuptools: 65.5.0
2025-02-06 22:16:23,211:INFO:             pycaret: 3.3.2
2025-02-06 22:16:23,211:INFO:             IPython: 8.32.0
2025-02-06 22:16:23,211:INFO:          ipywidgets: 8.1.5
2025-02-06 22:16:23,211:INFO:                tqdm: 4.67.1
2025-02-06 22:16:23,211:INFO:               numpy: 1.26.4
2025-02-06 22:16:23,211:INFO:              pandas: 2.1.4
2025-02-06 22:16:23,211:INFO:              jinja2: 3.1.5
2025-02-06 22:16:23,211:INFO:               scipy: 1.11.4
2025-02-06 22:16:23,211:INFO:              joblib: 1.3.2
2025-02-06 22:16:23,211:INFO:             sklearn: 1.4.2
2025-02-06 22:16:23,211:INFO:                pyod: 2.0.3
2025-02-06 22:16:23,211:INFO:            imblearn: 0.13.0
2025-02-06 22:16:23,211:INFO:   category_encoders: 2.7.0
2025-02-06 22:16:23,211:INFO:            lightgbm: 4.5.0
2025-02-06 22:16:23,211:INFO:               numba: 0.61.0
2025-02-06 22:16:23,211:INFO:            requests: 2.32.3
2025-02-06 22:16:23,211:INFO:          matplotlib: 3.7.5
2025-02-06 22:16:23,211:INFO:          scikitplot: 0.3.7
2025-02-06 22:16:23,211:INFO:         yellowbrick: 1.5
2025-02-06 22:16:23,212:INFO:              plotly: 5.24.1
2025-02-06 22:16:23,212:INFO:    plotly-resampler: Not installed
2025-02-06 22:16:23,212:INFO:             kaleido: 0.2.1
2025-02-06 22:16:23,212:INFO:           schemdraw: 0.15
2025-02-06 22:16:23,212:INFO:         statsmodels: 0.14.4
2025-02-06 22:16:23,212:INFO:              sktime: 0.26.0
2025-02-06 22:16:23,212:INFO:               tbats: 1.1.3
2025-02-06 22:16:23,212:INFO:            pmdarima: 2.0.4
2025-02-06 22:16:23,212:INFO:              psutil: 6.1.1
2025-02-06 22:16:23,212:INFO:          markupsafe: 3.0.2
2025-02-06 22:16:23,212:INFO:             pickle5: Not installed
2025-02-06 22:16:23,212:INFO:         cloudpickle: 3.1.1
2025-02-06 22:16:23,212:INFO:         deprecation: 2.1.0
2025-02-06 22:16:23,212:INFO:              xxhash: 3.5.0
2025-02-06 22:16:23,212:INFO:           wurlitzer: Not installed
2025-02-06 22:16:23,212:INFO:PyCaret optional dependencies:
2025-02-06 22:16:23,217:INFO:                shap: Not installed
2025-02-06 22:16:23,217:INFO:           interpret: Not installed
2025-02-06 22:16:23,217:INFO:                umap: Not installed
2025-02-06 22:16:23,217:INFO:     ydata_profiling: Not installed
2025-02-06 22:16:23,217:INFO:  explainerdashboard: Not installed
2025-02-06 22:16:23,217:INFO:             autoviz: Not installed
2025-02-06 22:16:23,217:INFO:           fairlearn: Not installed
2025-02-06 22:16:23,217:INFO:          deepchecks: Not installed
2025-02-06 22:16:23,217:INFO:             xgboost: Not installed
2025-02-06 22:16:23,217:INFO:            catboost: Not installed
2025-02-06 22:16:23,217:INFO:              kmodes: Not installed
2025-02-06 22:16:23,217:INFO:             mlxtend: Not installed
2025-02-06 22:16:23,217:INFO:       statsforecast: Not installed
2025-02-06 22:16:23,217:INFO:        tune_sklearn: Not installed
2025-02-06 22:16:23,217:INFO:                 ray: Not installed
2025-02-06 22:16:23,217:INFO:            hyperopt: Not installed
2025-02-06 22:16:23,217:INFO:              optuna: Not installed
2025-02-06 22:16:23,217:INFO:               skopt: Not installed
2025-02-06 22:16:23,217:INFO:              mlflow: Not installed
2025-02-06 22:16:23,217:INFO:              gradio: Not installed
2025-02-06 22:16:23,217:INFO:             fastapi: Not installed
2025-02-06 22:16:23,218:INFO:             uvicorn: Not installed
2025-02-06 22:16:23,218:INFO:              m2cgen: Not installed
2025-02-06 22:16:23,218:INFO:           evidently: Not installed
2025-02-06 22:16:23,218:INFO:               fugue: Not installed
2025-02-06 22:16:23,218:INFO:           streamlit: Not installed
2025-02-06 22:16:23,218:INFO:             prophet: Not installed
2025-02-06 22:16:23,218:INFO:None
2025-02-06 22:16:23,218:INFO:Set up data.
2025-02-06 22:16:23,224:INFO:Set up folding strategy.
2025-02-06 22:16:23,224:INFO:Set up train/test split.
2025-02-06 22:16:23,230:INFO:Set up index.
2025-02-06 22:16:23,230:INFO:Assigning column types.
2025-02-06 22:16:23,235:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 22:16:23,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,260:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,319:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 22:16:23,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:16:23,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,398:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 22:16:23,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,477:INFO:Preparing preprocessing pipeline...
2025-02-06 22:16:23,478:INFO:Set up simple imputation.
2025-02-06 22:16:23,478:INFO:Set up feature normalization.
2025-02-06 22:16:23,503:INFO:Finished creating preprocessing pipeline.
2025-02-06 22:16:23,506:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 22:16:23,506:INFO:Creating final display dataframe.
2025-02-06 22:16:23,576:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              d99e
2025-02-06 22:16:23,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:16:23,654:INFO:setup() successfully completed in 0.46s...............
2025-02-06 22:16:23,654:INFO:Initializing compare_models()
2025-02-06 22:16:23,654:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:16:23,654:INFO:Checking exceptions
2025-02-06 22:16:23,658:INFO:Preparing display monitor
2025-02-06 22:16:23,669:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 22:16:23,669:INFO:Total runtime is 0.0 minutes
2025-02-06 22:16:23,670:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:23,671:INFO:Initializing create_model()
2025-02-06 22:16:23,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBC2D8550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:23,671:INFO:Checking exceptions
2025-02-06 22:16:23,671:INFO:Importing libraries
2025-02-06 22:16:23,671:INFO:Copying training dataset
2025-02-06 22:16:23,678:INFO:Defining folds
2025-02-06 22:16:23,678:INFO:Declaring metric variables
2025-02-06 22:16:23,680:INFO:Importing untrained model
2025-02-06 22:16:23,682:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:23,686:INFO:Starting cross validation
2025-02-06 22:16:23,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:26,720:INFO:Calculating mean and std
2025-02-06 22:16:26,721:INFO:Creating metrics dataframe
2025-02-06 22:16:26,722:INFO:Uploading results into container
2025-02-06 22:16:26,722:INFO:Uploading model into container now
2025-02-06 22:16:26,723:INFO:_master_model_container: 1
2025-02-06 22:16:26,723:INFO:_display_container: 2
2025-02-06 22:16:26,723:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:26,723:INFO:create_model() successfully completed......................................
2025-02-06 22:16:26,820:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:26,820:INFO:Creating metrics dataframe
2025-02-06 22:16:26,823:INFO:Initializing Logistic Regression
2025-02-06 22:16:26,823:INFO:Total runtime is 0.05258062283198039 minutes
2025-02-06 22:16:26,826:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:26,826:INFO:Initializing create_model()
2025-02-06 22:16:26,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBC2D8550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:26,826:INFO:Checking exceptions
2025-02-06 22:16:26,826:INFO:Importing libraries
2025-02-06 22:16:26,826:INFO:Copying training dataset
2025-02-06 22:16:26,832:INFO:Defining folds
2025-02-06 22:16:26,832:INFO:Declaring metric variables
2025-02-06 22:16:26,834:INFO:Importing untrained model
2025-02-06 22:16:26,835:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:26,838:INFO:Starting cross validation
2025-02-06 22:16:26,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:28,272:INFO:Calculating mean and std
2025-02-06 22:16:28,273:INFO:Creating metrics dataframe
2025-02-06 22:16:28,275:INFO:Uploading results into container
2025-02-06 22:16:28,275:INFO:Uploading model into container now
2025-02-06 22:16:28,275:INFO:_master_model_container: 2
2025-02-06 22:16:28,276:INFO:_display_container: 2
2025-02-06 22:16:28,276:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:28,276:INFO:create_model() successfully completed......................................
2025-02-06 22:16:28,347:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:28,347:INFO:Creating metrics dataframe
2025-02-06 22:16:28,351:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:16:28,355:INFO:Initializing create_model()
2025-02-06 22:16:28,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:28,355:INFO:Checking exceptions
2025-02-06 22:16:28,356:INFO:Importing libraries
2025-02-06 22:16:28,356:INFO:Copying training dataset
2025-02-06 22:16:28,362:INFO:Defining folds
2025-02-06 22:16:28,362:INFO:Declaring metric variables
2025-02-06 22:16:28,362:INFO:Importing untrained model
2025-02-06 22:16:28,362:INFO:Declaring custom model
2025-02-06 22:16:28,363:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:28,363:INFO:Cross validation set to False
2025-02-06 22:16:28,363:INFO:Fitting Model
2025-02-06 22:16:28,391:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:28,391:INFO:create_model() successfully completed......................................
2025-02-06 22:16:28,438:INFO:_master_model_container: 2
2025-02-06 22:16:28,438:INFO:_display_container: 2
2025-02-06 22:16:28,438:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:28,438:INFO:compare_models() successfully completed......................................
2025-02-06 22:16:28,438:INFO:Initializing create_model()
2025-02-06 22:16:28,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:28,438:INFO:Checking exceptions
2025-02-06 22:16:28,446:INFO:Importing libraries
2025-02-06 22:16:28,446:INFO:Copying training dataset
2025-02-06 22:16:28,454:INFO:Defining folds
2025-02-06 22:16:28,454:INFO:Declaring metric variables
2025-02-06 22:16:28,457:INFO:Importing untrained model
2025-02-06 22:16:28,459:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:28,463:INFO:Starting cross validation
2025-02-06 22:16:28,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:29,421:INFO:Calculating mean and std
2025-02-06 22:16:29,421:INFO:Creating metrics dataframe
2025-02-06 22:16:29,426:INFO:Finalizing model
2025-02-06 22:16:29,447:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:16:29,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
2025-02-06 22:16:29,448:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:16:29,448:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:16:29,448:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:16:29,448:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:16:29,448:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:16:29,568:INFO:Uploading results into container
2025-02-06 22:16:29,569:INFO:Uploading model into container now
2025-02-06 22:16:29,576:INFO:_master_model_container: 3
2025-02-06 22:16:29,576:INFO:_display_container: 3
2025-02-06 22:16:29,576:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:29,577:INFO:create_model() successfully completed......................................
2025-02-06 22:16:29,640:INFO:Initializing tune_model()
2025-02-06 22:16:29,640:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:16:29,641:INFO:Checking exceptions
2025-02-06 22:16:29,651:INFO:Copying training dataset
2025-02-06 22:16:29,658:INFO:Checking base model
2025-02-06 22:16:29,658:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 22:16:29,661:INFO:Declaring metric variables
2025-02-06 22:16:29,662:INFO:Defining Hyperparameters
2025-02-06 22:16:29,705:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 22:16:29,705:INFO:Tuning with n_jobs=-1
2025-02-06 22:16:29,705:INFO:Initializing RandomizedSearchCV
2025-02-06 22:16:33,254:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 22:16:33,255:INFO:Hyperparameter search completed
2025-02-06 22:16:33,255:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:33,255:INFO:Initializing create_model()
2025-02-06 22:16:33,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBB029DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 22:16:33,256:INFO:Checking exceptions
2025-02-06 22:16:33,256:INFO:Importing libraries
2025-02-06 22:16:33,256:INFO:Copying training dataset
2025-02-06 22:16:33,265:INFO:Defining folds
2025-02-06 22:16:33,265:INFO:Declaring metric variables
2025-02-06 22:16:33,267:INFO:Importing untrained model
2025-02-06 22:16:33,267:INFO:Declaring custom model
2025-02-06 22:16:33,269:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:33,273:INFO:Starting cross validation
2025-02-06 22:16:33,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:33,635:INFO:Calculating mean and std
2025-02-06 22:16:33,636:INFO:Creating metrics dataframe
2025-02-06 22:16:33,639:INFO:Finalizing model
2025-02-06 22:16:33,658:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:16:33,660:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.
2025-02-06 22:16:33,660:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:16:33,660:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:16:33,660:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:16:33,661:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:16:33,661:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:16:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:33,729:INFO:Uploading results into container
2025-02-06 22:16:33,730:INFO:Uploading model into container now
2025-02-06 22:16:33,730:INFO:_master_model_container: 4
2025-02-06 22:16:33,730:INFO:_display_container: 4
2025-02-06 22:16:33,731:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:33,731:INFO:create_model() successfully completed......................................
2025-02-06 22:16:33,788:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:33,789:INFO:choose_better activated
2025-02-06 22:16:33,791:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:33,791:INFO:Initializing create_model()
2025-02-06 22:16:33,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:33,791:INFO:Checking exceptions
2025-02-06 22:16:33,792:INFO:Importing libraries
2025-02-06 22:16:33,792:INFO:Copying training dataset
2025-02-06 22:16:33,802:INFO:Defining folds
2025-02-06 22:16:33,802:INFO:Declaring metric variables
2025-02-06 22:16:33,802:INFO:Importing untrained model
2025-02-06 22:16:33,802:INFO:Declaring custom model
2025-02-06 22:16:33,802:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:33,802:INFO:Starting cross validation
2025-02-06 22:16:33,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:34,523:INFO:Calculating mean and std
2025-02-06 22:16:34,523:INFO:Creating metrics dataframe
2025-02-06 22:16:34,524:INFO:Finalizing model
2025-02-06 22:16:34,541:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:16:34,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
2025-02-06 22:16:34,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:16:34,542:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:16:34,542:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:16:34,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:16:34,542:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:16:34,651:INFO:Uploading results into container
2025-02-06 22:16:34,652:INFO:Uploading model into container now
2025-02-06 22:16:34,652:INFO:_master_model_container: 5
2025-02-06 22:16:34,652:INFO:_display_container: 5
2025-02-06 22:16:34,652:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:34,652:INFO:create_model() successfully completed......................................
2025-02-06 22:16:34,721:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:34,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 22:16:34,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 22:16:34,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 22:16:34,721:INFO:choose_better completed
2025-02-06 22:16:34,729:INFO:_master_model_container: 5
2025-02-06 22:16:34,729:INFO:_display_container: 4
2025-02-06 22:16:34,729:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:34,729:INFO:tune_model() successfully completed......................................
2025-02-06 22:16:34,804:INFO:Initializing create_model()
2025-02-06 22:16:34,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:34,804:INFO:Checking exceptions
2025-02-06 22:16:34,812:INFO:Importing libraries
2025-02-06 22:16:34,812:INFO:Copying training dataset
2025-02-06 22:16:34,817:INFO:Defining folds
2025-02-06 22:16:34,817:INFO:Declaring metric variables
2025-02-06 22:16:34,820:INFO:Importing untrained model
2025-02-06 22:16:34,821:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:34,824:INFO:Starting cross validation
2025-02-06 22:16:34,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:34,892:INFO:Calculating mean and std
2025-02-06 22:16:34,892:INFO:Creating metrics dataframe
2025-02-06 22:16:34,895:INFO:Finalizing model
2025-02-06 22:16:34,929:INFO:Uploading results into container
2025-02-06 22:16:34,929:INFO:Uploading model into container now
2025-02-06 22:16:34,934:INFO:_master_model_container: 6
2025-02-06 22:16:34,934:INFO:_display_container: 5
2025-02-06 22:16:34,934:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:34,934:INFO:create_model() successfully completed......................................
2025-02-06 22:16:34,989:INFO:Initializing tune_model()
2025-02-06 22:16:34,989:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:16:34,989:INFO:Checking exceptions
2025-02-06 22:16:34,998:INFO:Copying training dataset
2025-02-06 22:16:35,001:INFO:Checking base model
2025-02-06 22:16:35,001:INFO:Base model : Logistic Regression
2025-02-06 22:16:35,003:INFO:Declaring metric variables
2025-02-06 22:16:35,004:INFO:Defining Hyperparameters
2025-02-06 22:16:35,045:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 22:16:35,045:INFO:Tuning with n_jobs=-1
2025-02-06 22:16:35,045:INFO:Initializing RandomizedSearchCV
2025-02-06 22:16:35,533:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 22:16:35,533:INFO:Hyperparameter search completed
2025-02-06 22:16:35,533:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:35,534:INFO:Initializing create_model()
2025-02-06 22:16:35,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBB48F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 22:16:35,534:INFO:Checking exceptions
2025-02-06 22:16:35,534:INFO:Importing libraries
2025-02-06 22:16:35,534:INFO:Copying training dataset
2025-02-06 22:16:35,539:INFO:Defining folds
2025-02-06 22:16:35,539:INFO:Declaring metric variables
2025-02-06 22:16:35,542:INFO:Importing untrained model
2025-02-06 22:16:35,542:INFO:Declaring custom model
2025-02-06 22:16:35,543:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:35,546:INFO:Starting cross validation
2025-02-06 22:16:35,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:35,644:INFO:Calculating mean and std
2025-02-06 22:16:35,644:INFO:Creating metrics dataframe
2025-02-06 22:16:35,646:INFO:Finalizing model
2025-02-06 22:16:35,677:INFO:Uploading results into container
2025-02-06 22:16:35,677:INFO:Uploading model into container now
2025-02-06 22:16:35,677:INFO:_master_model_container: 7
2025-02-06 22:16:35,677:INFO:_display_container: 6
2025-02-06 22:16:35,677:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:35,678:INFO:create_model() successfully completed......................................
2025-02-06 22:16:35,751:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:35,751:INFO:choose_better activated
2025-02-06 22:16:35,753:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:35,753:INFO:Initializing create_model()
2025-02-06 22:16:35,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:35,753:INFO:Checking exceptions
2025-02-06 22:16:35,754:INFO:Importing libraries
2025-02-06 22:16:35,754:INFO:Copying training dataset
2025-02-06 22:16:35,760:INFO:Defining folds
2025-02-06 22:16:35,760:INFO:Declaring metric variables
2025-02-06 22:16:35,760:INFO:Importing untrained model
2025-02-06 22:16:35,760:INFO:Declaring custom model
2025-02-06 22:16:35,761:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:35,761:INFO:Starting cross validation
2025-02-06 22:16:35,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:35,818:INFO:Calculating mean and std
2025-02-06 22:16:35,818:INFO:Creating metrics dataframe
2025-02-06 22:16:35,819:INFO:Finalizing model
2025-02-06 22:16:35,844:INFO:Uploading results into container
2025-02-06 22:16:35,844:INFO:Uploading model into container now
2025-02-06 22:16:35,844:INFO:_master_model_container: 8
2025-02-06 22:16:35,844:INFO:_display_container: 7
2025-02-06 22:16:35,844:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:35,844:INFO:create_model() successfully completed......................................
2025-02-06 22:16:35,892:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:35,892:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 22:16:35,892:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 22:16:35,892:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 22:16:35,892:INFO:choose_better completed
2025-02-06 22:16:35,896:INFO:_master_model_container: 8
2025-02-06 22:16:35,896:INFO:_display_container: 6
2025-02-06 22:16:35,896:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:35,896:INFO:tune_model() successfully completed......................................
2025-02-06 22:16:35,931:INFO:Initializing compare_models()
2025-02-06 22:16:35,931:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:16:35,931:INFO:Checking exceptions
2025-02-06 22:16:35,933:INFO:Preparing display monitor
2025-02-06 22:16:35,943:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 22:16:35,943:INFO:Total runtime is 0.0 minutes
2025-02-06 22:16:35,945:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:35,945:INFO:Initializing create_model()
2025-02-06 22:16:35,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBBDC6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:35,945:INFO:Checking exceptions
2025-02-06 22:16:35,945:INFO:Importing libraries
2025-02-06 22:16:35,945:INFO:Copying training dataset
2025-02-06 22:16:35,952:INFO:Defining folds
2025-02-06 22:16:35,952:INFO:Declaring metric variables
2025-02-06 22:16:35,954:INFO:Importing untrained model
2025-02-06 22:16:35,954:INFO:Declaring custom model
2025-02-06 22:16:35,955:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:35,958:INFO:Starting cross validation
2025-02-06 22:16:35,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:36,229:INFO:Calculating mean and std
2025-02-06 22:16:36,229:INFO:Creating metrics dataframe
2025-02-06 22:16:36,229:INFO:Uploading results into container
2025-02-06 22:16:36,231:INFO:Uploading model into container now
2025-02-06 22:16:36,231:INFO:_master_model_container: 9
2025-02-06 22:16:36,231:INFO:_display_container: 7
2025-02-06 22:16:36,231:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:36,231:INFO:create_model() successfully completed......................................
2025-02-06 22:16:36,289:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:36,289:INFO:Creating metrics dataframe
2025-02-06 22:16:36,292:INFO:Initializing custom model Logistic Regression
2025-02-06 22:16:36,292:INFO:Total runtime is 0.005824593702952067 minutes
2025-02-06 22:16:36,295:INFO:SubProcess create_model() called ==================================
2025-02-06 22:16:36,295:INFO:Initializing create_model()
2025-02-06 22:16:36,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEBBDC6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:36,295:INFO:Checking exceptions
2025-02-06 22:16:36,295:INFO:Importing libraries
2025-02-06 22:16:36,296:INFO:Copying training dataset
2025-02-06 22:16:36,303:INFO:Defining folds
2025-02-06 22:16:36,303:INFO:Declaring metric variables
2025-02-06 22:16:36,306:INFO:Importing untrained model
2025-02-06 22:16:36,306:INFO:Declaring custom model
2025-02-06 22:16:36,308:INFO:Logistic Regression Imported successfully
2025-02-06 22:16:36,311:INFO:Starting cross validation
2025-02-06 22:16:36,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:16:36,414:INFO:Calculating mean and std
2025-02-06 22:16:36,414:INFO:Creating metrics dataframe
2025-02-06 22:16:36,415:INFO:Uploading results into container
2025-02-06 22:16:36,415:INFO:Uploading model into container now
2025-02-06 22:16:36,415:INFO:_master_model_container: 10
2025-02-06 22:16:36,415:INFO:_display_container: 7
2025-02-06 22:16:36,416:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:16:36,416:INFO:create_model() successfully completed......................................
2025-02-06 22:16:36,475:INFO:SubProcess create_model() end ==================================
2025-02-06 22:16:36,476:INFO:Creating metrics dataframe
2025-02-06 22:16:36,479:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:16:36,484:INFO:Initializing create_model()
2025-02-06 22:16:36,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:16:36,484:INFO:Checking exceptions
2025-02-06 22:16:36,484:INFO:Importing libraries
2025-02-06 22:16:36,484:INFO:Copying training dataset
2025-02-06 22:16:36,489:INFO:Defining folds
2025-02-06 22:16:36,489:INFO:Declaring metric variables
2025-02-06 22:16:36,489:INFO:Importing untrained model
2025-02-06 22:16:36,489:INFO:Declaring custom model
2025-02-06 22:16:36,491:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:16:36,491:INFO:Cross validation set to False
2025-02-06 22:16:36,491:INFO:Fitting Model
2025-02-06 22:16:36,504:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:16:36,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
2025-02-06 22:16:36,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:16:36,505:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:16:36,506:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:16:36,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:16:36,506:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:16:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:16:36,536:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:36,536:INFO:create_model() successfully completed......................................
2025-02-06 22:16:36,606:INFO:_master_model_container: 10
2025-02-06 22:16:36,606:INFO:_display_container: 7
2025-02-06 22:16:36,607:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:16:36,607:INFO:compare_models() successfully completed......................................
2025-02-06 22:16:36,608:INFO:Initializing predict_model()
2025-02-06 22:16:36,608:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.6, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FEBBDBA340>)
2025-02-06 22:16:36,608:INFO:Checking exceptions
2025-02-06 22:16:36,608:INFO:Preloading libraries
2025-02-06 22:16:36,609:INFO:Set up data.
2025-02-06 22:16:36,619:INFO:Set up index.
2025-02-06 22:16:36,723:INFO:Initializing predict_model()
2025-02-06 22:16:36,723:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FEBBCE7C40>)
2025-02-06 22:16:36,723:INFO:Checking exceptions
2025-02-06 22:16:36,723:INFO:Preloading libraries
2025-02-06 22:16:36,724:INFO:Set up data.
2025-02-06 22:16:36,730:INFO:Set up index.
2025-02-06 22:16:36,835:INFO:Initializing predict_model()
2025-02-06 22:16:36,835:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FEBBCE7C40>)
2025-02-06 22:16:36,835:INFO:Checking exceptions
2025-02-06 22:16:36,835:INFO:Preloading libraries
2025-02-06 22:16:36,836:INFO:Set up data.
2025-02-06 22:16:36,846:INFO:Set up index.
2025-02-06 22:16:36,940:INFO:Initializing predict_model()
2025-02-06 22:16:36,940:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEF7B8F390>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FEBBCE7C40>)
2025-02-06 22:16:36,941:INFO:Checking exceptions
2025-02-06 22:16:36,941:INFO:Preloading libraries
2025-02-06 22:16:36,941:INFO:Set up data.
2025-02-06 22:16:36,945:INFO:Set up index.
2025-02-06 22:18:08,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:18:08,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:18:08,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:18:08,440:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-06 22:18:08,897:INFO:PyCaret ClassificationExperiment
2025-02-06 22:18:08,897:INFO:Logging name: clf-default-name
2025-02-06 22:18:08,897:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-06 22:18:08,897:INFO:version 3.3.2
2025-02-06 22:18:08,897:INFO:Initializing setup()
2025-02-06 22:18:08,897:INFO:self.USI: f284
2025-02-06 22:18:08,897:INFO:self._variable_keys: {'USI', 'fold_generator', 'pipeline', 'seed', 'X', 'y_train', 'fold_shuffle_param', 'gpu_n_jobs_param', 'data', '_ml_usecase', 'log_plots_param', '_available_plots', 'target_param', 'html_param', 'X_test', 'gpu_param', 'y', 'idx', 'y_test', 'X_train', 'exp_id', 'is_multiclass', 'fix_imbalance', 'memory', 'exp_name_log', 'fold_groups_param', 'n_jobs_param', 'logging_param'}
2025-02-06 22:18:08,898:INFO:Checking environment
2025-02-06 22:18:08,898:INFO:python_version: 3.11.9
2025-02-06 22:18:08,898:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-06 22:18:08,898:INFO:machine: AMD64
2025-02-06 22:18:08,898:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-06 22:18:08,904:INFO:Memory: svmem(total=67771465728, available=49658404864, percent=26.7, used=18113060864, free=49658404864)
2025-02-06 22:18:08,904:INFO:Physical Core: 8
2025-02-06 22:18:08,904:INFO:Logical Core: 16
2025-02-06 22:18:08,904:INFO:Checking libraries
2025-02-06 22:18:08,904:INFO:System:
2025-02-06 22:18:08,904:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-06 22:18:08,904:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-06 22:18:08,904:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-06 22:18:08,904:INFO:PyCaret required dependencies:
2025-02-06 22:18:08,919:INFO:                 pip: 25.0
2025-02-06 22:18:08,919:INFO:          setuptools: 65.5.0
2025-02-06 22:18:08,919:INFO:             pycaret: 3.3.2
2025-02-06 22:18:08,919:INFO:             IPython: 8.32.0
2025-02-06 22:18:08,919:INFO:          ipywidgets: 8.1.5
2025-02-06 22:18:08,919:INFO:                tqdm: 4.67.1
2025-02-06 22:18:08,919:INFO:               numpy: 1.26.4
2025-02-06 22:18:08,919:INFO:              pandas: 2.1.4
2025-02-06 22:18:08,919:INFO:              jinja2: 3.1.5
2025-02-06 22:18:08,919:INFO:               scipy: 1.11.4
2025-02-06 22:18:08,919:INFO:              joblib: 1.3.2
2025-02-06 22:18:08,919:INFO:             sklearn: 1.4.2
2025-02-06 22:18:08,919:INFO:                pyod: 2.0.3
2025-02-06 22:18:08,919:INFO:            imblearn: 0.13.0
2025-02-06 22:18:08,919:INFO:   category_encoders: 2.7.0
2025-02-06 22:18:08,919:INFO:            lightgbm: 4.5.0
2025-02-06 22:18:08,919:INFO:               numba: 0.61.0
2025-02-06 22:18:08,919:INFO:            requests: 2.32.3
2025-02-06 22:18:08,919:INFO:          matplotlib: 3.7.5
2025-02-06 22:18:08,919:INFO:          scikitplot: 0.3.7
2025-02-06 22:18:08,919:INFO:         yellowbrick: 1.5
2025-02-06 22:18:08,919:INFO:              plotly: 5.24.1
2025-02-06 22:18:08,919:INFO:    plotly-resampler: Not installed
2025-02-06 22:18:08,919:INFO:             kaleido: 0.2.1
2025-02-06 22:18:08,919:INFO:           schemdraw: 0.15
2025-02-06 22:18:08,919:INFO:         statsmodels: 0.14.4
2025-02-06 22:18:08,919:INFO:              sktime: 0.26.0
2025-02-06 22:18:08,919:INFO:               tbats: 1.1.3
2025-02-06 22:18:08,919:INFO:            pmdarima: 2.0.4
2025-02-06 22:18:08,919:INFO:              psutil: 6.1.1
2025-02-06 22:18:08,919:INFO:          markupsafe: 3.0.2
2025-02-06 22:18:08,919:INFO:             pickle5: Not installed
2025-02-06 22:18:08,920:INFO:         cloudpickle: 3.1.1
2025-02-06 22:18:08,920:INFO:         deprecation: 2.1.0
2025-02-06 22:18:08,920:INFO:              xxhash: 3.5.0
2025-02-06 22:18:08,920:INFO:           wurlitzer: Not installed
2025-02-06 22:18:08,920:INFO:PyCaret optional dependencies:
2025-02-06 22:18:08,926:INFO:                shap: Not installed
2025-02-06 22:18:08,926:INFO:           interpret: Not installed
2025-02-06 22:18:08,926:INFO:                umap: Not installed
2025-02-06 22:18:08,926:INFO:     ydata_profiling: Not installed
2025-02-06 22:18:08,926:INFO:  explainerdashboard: Not installed
2025-02-06 22:18:08,926:INFO:             autoviz: Not installed
2025-02-06 22:18:08,926:INFO:           fairlearn: Not installed
2025-02-06 22:18:08,926:INFO:          deepchecks: Not installed
2025-02-06 22:18:08,926:INFO:             xgboost: Not installed
2025-02-06 22:18:08,926:INFO:            catboost: Not installed
2025-02-06 22:18:08,926:INFO:              kmodes: Not installed
2025-02-06 22:18:08,926:INFO:             mlxtend: Not installed
2025-02-06 22:18:08,926:INFO:       statsforecast: Not installed
2025-02-06 22:18:08,926:INFO:        tune_sklearn: Not installed
2025-02-06 22:18:08,926:INFO:                 ray: Not installed
2025-02-06 22:18:08,926:INFO:            hyperopt: Not installed
2025-02-06 22:18:08,926:INFO:              optuna: Not installed
2025-02-06 22:18:08,926:INFO:               skopt: Not installed
2025-02-06 22:18:08,926:INFO:              mlflow: Not installed
2025-02-06 22:18:08,926:INFO:              gradio: Not installed
2025-02-06 22:18:08,926:INFO:             fastapi: Not installed
2025-02-06 22:18:08,926:INFO:             uvicorn: Not installed
2025-02-06 22:18:08,926:INFO:              m2cgen: Not installed
2025-02-06 22:18:08,927:INFO:           evidently: Not installed
2025-02-06 22:18:08,927:INFO:               fugue: Not installed
2025-02-06 22:18:08,927:INFO:           streamlit: Not installed
2025-02-06 22:18:08,927:INFO:             prophet: Not installed
2025-02-06 22:18:08,927:INFO:None
2025-02-06 22:18:08,927:INFO:Set up data.
2025-02-06 22:18:08,935:INFO:Set up folding strategy.
2025-02-06 22:18:08,935:INFO:Set up train/test split.
2025-02-06 22:18:08,941:INFO:Set up index.
2025-02-06 22:18:08,941:INFO:Assigning column types.
2025-02-06 22:18:08,946:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-06 22:18:08,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:18:08,971:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:18:08,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:08,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-06 22:18:09,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:18:09,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,031:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-06 22:18:09,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:18:09,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-06 22:18:09,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,109:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-06 22:18:09,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,187:INFO:Preparing preprocessing pipeline...
2025-02-06 22:18:09,188:INFO:Set up simple imputation.
2025-02-06 22:18:09,188:INFO:Set up feature normalization.
2025-02-06 22:18:09,210:INFO:Finished creating preprocessing pipeline.
2025-02-06 22:18:09,213:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['VAR_1', 'VAR_72', 'VAR_53',
                                             'VAR_65', 'VAR_6', 'VAR_17',
                                             'VAR_30', 'VAR_57', 'VAR_9',
                                             'VAR_54', 'VAR_59', 'VAR_76',
                                             'VAR_7', 'VAR_11', 'VAR_5',
                                             'VAR_34', 'VAR_38', 'VAR_15',
                                             'VAR_35', 'VAR_8', 'VAR_13',
                                             'VAR_52', 'VAR_24'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-02-06 22:18:09,213:INFO:Creating final display dataframe.
2025-02-06 22:18:09,283:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (6568, 35)
4        Transformed data shape        (6568, 35)
5   Transformed train set shape        (5254, 35)
6    Transformed test set shape        (1314, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              f284
2025-02-06 22:18:09,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-06 22:18:09,361:INFO:setup() successfully completed in 0.46s...............
2025-02-06 22:18:09,361:INFO:Initializing compare_models()
2025-02-06 22:18:09,362:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, include=['lightgbm', 'lr'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, 'include': ['lightgbm', 'lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:18:09,362:INFO:Checking exceptions
2025-02-06 22:18:09,365:INFO:Preparing display monitor
2025-02-06 22:18:09,378:INFO:Initializing Light Gradient Boosting Machine
2025-02-06 22:18:09,378:INFO:Total runtime is 0.0 minutes
2025-02-06 22:18:09,380:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:09,380:INFO:Initializing create_model()
2025-02-06 22:18:09,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661E16F950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:09,381:INFO:Checking exceptions
2025-02-06 22:18:09,381:INFO:Importing libraries
2025-02-06 22:18:09,381:INFO:Copying training dataset
2025-02-06 22:18:09,386:INFO:Defining folds
2025-02-06 22:18:09,386:INFO:Declaring metric variables
2025-02-06 22:18:09,387:INFO:Importing untrained model
2025-02-06 22:18:09,390:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:09,393:INFO:Starting cross validation
2025-02-06 22:18:09,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:12,089:INFO:Calculating mean and std
2025-02-06 22:18:12,090:INFO:Creating metrics dataframe
2025-02-06 22:18:12,091:INFO:Uploading results into container
2025-02-06 22:18:12,092:INFO:Uploading model into container now
2025-02-06 22:18:12,092:INFO:_master_model_container: 1
2025-02-06 22:18:12,092:INFO:_display_container: 2
2025-02-06 22:18:12,093:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:12,093:INFO:create_model() successfully completed......................................
2025-02-06 22:18:12,160:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:12,160:INFO:Creating metrics dataframe
2025-02-06 22:18:12,163:INFO:Initializing Logistic Regression
2025-02-06 22:18:12,164:INFO:Total runtime is 0.04643533229827881 minutes
2025-02-06 22:18:12,165:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:12,165:INFO:Initializing create_model()
2025-02-06 22:18:12,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661E16F950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:12,167:INFO:Checking exceptions
2025-02-06 22:18:12,167:INFO:Importing libraries
2025-02-06 22:18:12,167:INFO:Copying training dataset
2025-02-06 22:18:12,174:INFO:Defining folds
2025-02-06 22:18:12,174:INFO:Declaring metric variables
2025-02-06 22:18:12,177:INFO:Importing untrained model
2025-02-06 22:18:12,179:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:12,182:INFO:Starting cross validation
2025-02-06 22:18:12,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:13,585:INFO:Calculating mean and std
2025-02-06 22:18:13,586:INFO:Creating metrics dataframe
2025-02-06 22:18:13,587:INFO:Uploading results into container
2025-02-06 22:18:13,587:INFO:Uploading model into container now
2025-02-06 22:18:13,587:INFO:_master_model_container: 2
2025-02-06 22:18:13,587:INFO:_display_container: 2
2025-02-06 22:18:13,588:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:13,588:INFO:create_model() successfully completed......................................
2025-02-06 22:18:13,654:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:13,654:INFO:Creating metrics dataframe
2025-02-06 22:18:13,660:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:18:13,664:INFO:Initializing create_model()
2025-02-06 22:18:13,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:13,665:INFO:Checking exceptions
2025-02-06 22:18:13,665:INFO:Importing libraries
2025-02-06 22:18:13,665:INFO:Copying training dataset
2025-02-06 22:18:13,671:INFO:Defining folds
2025-02-06 22:18:13,671:INFO:Declaring metric variables
2025-02-06 22:18:13,671:INFO:Importing untrained model
2025-02-06 22:18:13,671:INFO:Declaring custom model
2025-02-06 22:18:13,671:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:13,672:INFO:Cross validation set to False
2025-02-06 22:18:13,672:INFO:Fitting Model
2025-02-06 22:18:13,705:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:13,705:INFO:create_model() successfully completed......................................
2025-02-06 22:18:13,760:INFO:_master_model_container: 2
2025-02-06 22:18:13,760:INFO:_display_container: 2
2025-02-06 22:18:13,760:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:13,760:INFO:compare_models() successfully completed......................................
2025-02-06 22:18:13,760:INFO:Initializing create_model()
2025-02-06 22:18:13,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:13,761:INFO:Checking exceptions
2025-02-06 22:18:13,767:INFO:Importing libraries
2025-02-06 22:18:13,767:INFO:Copying training dataset
2025-02-06 22:18:13,774:INFO:Defining folds
2025-02-06 22:18:13,774:INFO:Declaring metric variables
2025-02-06 22:18:13,775:INFO:Importing untrained model
2025-02-06 22:18:13,776:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:13,779:INFO:Starting cross validation
2025-02-06 22:18:13,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:14,575:INFO:Calculating mean and std
2025-02-06 22:18:14,575:INFO:Creating metrics dataframe
2025-02-06 22:18:14,579:INFO:Finalizing model
2025-02-06 22:18:14,599:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:18:14,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.
2025-02-06 22:18:14,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:18:14,600:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:18:14,600:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:18:14,601:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:18:14,601:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:18:14,710:INFO:Uploading results into container
2025-02-06 22:18:14,710:INFO:Uploading model into container now
2025-02-06 22:18:14,716:INFO:_master_model_container: 3
2025-02-06 22:18:14,717:INFO:_display_container: 3
2025-02-06 22:18:14,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:14,717:INFO:create_model() successfully completed......................................
2025-02-06 22:18:14,773:INFO:Initializing tune_model()
2025-02-06 22:18:14,774:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid={'num_leaves': [2, 5, 10], 'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [100, 200, 300], 'max_depth': [3], 'subsample': [0.6, 0.8], 'colsample_bytree': [0.6, 0.8], 'reg_alpha': [0.1, 0.5, 1], 'reg_lambda': [0.1, 0.5, 1]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:18:14,774:INFO:Checking exceptions
2025-02-06 22:18:14,784:INFO:Copying training dataset
2025-02-06 22:18:14,790:INFO:Checking base model
2025-02-06 22:18:14,791:INFO:Base model : Light Gradient Boosting Machine
2025-02-06 22:18:14,793:INFO:Declaring metric variables
2025-02-06 22:18:14,795:INFO:Defining Hyperparameters
2025-02-06 22:18:14,853:INFO:custom_grid: {'actual_estimator__num_leaves': [2, 5, 10], 'actual_estimator__learning_rate': [0.005, 0.01, 0.05], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3], 'actual_estimator__subsample': [0.6, 0.8], 'actual_estimator__colsample_bytree': [0.6, 0.8], 'actual_estimator__reg_alpha': [0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0.1, 0.5, 1]}
2025-02-06 22:18:14,853:INFO:Tuning with n_jobs=-1
2025-02-06 22:18:14,853:INFO:Initializing RandomizedSearchCV
2025-02-06 22:18:18,149:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.8}
2025-02-06 22:18:18,150:INFO:Hyperparameter search completed
2025-02-06 22:18:18,150:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:18,150:INFO:Initializing create_model()
2025-02-06 22:18:18,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661D351D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 1, 'num_leaves': 10, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8})
2025-02-06 22:18:18,150:INFO:Checking exceptions
2025-02-06 22:18:18,151:INFO:Importing libraries
2025-02-06 22:18:18,151:INFO:Copying training dataset
2025-02-06 22:18:18,161:INFO:Defining folds
2025-02-06 22:18:18,161:INFO:Declaring metric variables
2025-02-06 22:18:18,162:INFO:Importing untrained model
2025-02-06 22:18:18,163:INFO:Declaring custom model
2025-02-06 22:18:18,165:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:18,169:INFO:Starting cross validation
2025-02-06 22:18:18,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:18,481:INFO:Calculating mean and std
2025-02-06 22:18:18,482:INFO:Creating metrics dataframe
2025-02-06 22:18:18,485:INFO:Finalizing model
2025-02-06 22:18:18,503:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:18:18,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.
2025-02-06 22:18:18,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:18:18,504:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:18:18,504:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:18:18,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:18:18,505:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:18:18,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:18,570:INFO:Uploading results into container
2025-02-06 22:18:18,571:INFO:Uploading model into container now
2025-02-06 22:18:18,571:INFO:_master_model_container: 4
2025-02-06 22:18:18,571:INFO:_display_container: 4
2025-02-06 22:18:18,571:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:18,571:INFO:create_model() successfully completed......................................
2025-02-06 22:18:18,628:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:18,628:INFO:choose_better activated
2025-02-06 22:18:18,630:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:18,631:INFO:Initializing create_model()
2025-02-06 22:18:18,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:18,631:INFO:Checking exceptions
2025-02-06 22:18:18,631:INFO:Importing libraries
2025-02-06 22:18:18,633:INFO:Copying training dataset
2025-02-06 22:18:18,640:INFO:Defining folds
2025-02-06 22:18:18,640:INFO:Declaring metric variables
2025-02-06 22:18:18,640:INFO:Importing untrained model
2025-02-06 22:18:18,640:INFO:Declaring custom model
2025-02-06 22:18:18,640:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:18,641:INFO:Starting cross validation
2025-02-06 22:18:18,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:19,367:INFO:Calculating mean and std
2025-02-06 22:18:19,367:INFO:Creating metrics dataframe
2025-02-06 22:18:19,369:INFO:Finalizing model
2025-02-06 22:18:19,386:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:18:19,386:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.
2025-02-06 22:18:19,386:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:18:19,386:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:18:19,387:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:18:19,387:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:18:19,387:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:18:19,496:INFO:Uploading results into container
2025-02-06 22:18:19,496:INFO:Uploading model into container now
2025-02-06 22:18:19,496:INFO:_master_model_container: 5
2025-02-06 22:18:19,496:INFO:_display_container: 5
2025-02-06 22:18:19,496:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:19,498:INFO:create_model() successfully completed......................................
2025-02-06 22:18:19,552:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:19,552:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7806
2025-02-06 22:18:19,553:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7928
2025-02-06 22:18:19,553:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-02-06 22:18:19,553:INFO:choose_better completed
2025-02-06 22:18:19,559:INFO:_master_model_container: 5
2025-02-06 22:18:19,559:INFO:_display_container: 4
2025-02-06 22:18:19,560:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:19,560:INFO:tune_model() successfully completed......................................
2025-02-06 22:18:19,601:INFO:Initializing create_model()
2025-02-06 22:18:19,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:19,601:INFO:Checking exceptions
2025-02-06 22:18:19,608:INFO:Importing libraries
2025-02-06 22:18:19,608:INFO:Copying training dataset
2025-02-06 22:18:19,616:INFO:Defining folds
2025-02-06 22:18:19,616:INFO:Declaring metric variables
2025-02-06 22:18:19,618:INFO:Importing untrained model
2025-02-06 22:18:19,620:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:19,623:INFO:Starting cross validation
2025-02-06 22:18:19,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:19,692:INFO:Calculating mean and std
2025-02-06 22:18:19,693:INFO:Creating metrics dataframe
2025-02-06 22:18:19,696:INFO:Finalizing model
2025-02-06 22:18:19,730:INFO:Uploading results into container
2025-02-06 22:18:19,731:INFO:Uploading model into container now
2025-02-06 22:18:19,736:INFO:_master_model_container: 6
2025-02-06 22:18:19,736:INFO:_display_container: 5
2025-02-06 22:18:19,736:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:19,736:INFO:create_model() successfully completed......................................
2025-02-06 22:18:19,794:INFO:Initializing tune_model()
2025-02-06 22:18:19,794:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 500], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-02-06 22:18:19,794:INFO:Checking exceptions
2025-02-06 22:18:19,803:INFO:Copying training dataset
2025-02-06 22:18:19,807:INFO:Checking base model
2025-02-06 22:18:19,807:INFO:Base model : Logistic Regression
2025-02-06 22:18:19,809:INFO:Declaring metric variables
2025-02-06 22:18:19,810:INFO:Defining Hyperparameters
2025-02-06 22:18:19,852:INFO:custom_grid: {'actual_estimator__C': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [100, 200, 500], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-02-06 22:18:19,853:INFO:Tuning with n_jobs=-1
2025-02-06 22:18:19,853:INFO:Initializing RandomizedSearchCV
2025-02-06 22:18:20,309:INFO:best_params: {'actual_estimator__solver': 'liblinear', 'actual_estimator__max_iter': 100, 'actual_estimator__C': 0.1}
2025-02-06 22:18:20,309:INFO:Hyperparameter search completed
2025-02-06 22:18:20,310:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:20,310:INFO:Initializing create_model()
2025-02-06 22:18:20,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661BA6E390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'liblinear', 'max_iter': 100, 'C': 0.1})
2025-02-06 22:18:20,310:INFO:Checking exceptions
2025-02-06 22:18:20,310:INFO:Importing libraries
2025-02-06 22:18:20,310:INFO:Copying training dataset
2025-02-06 22:18:20,315:INFO:Defining folds
2025-02-06 22:18:20,315:INFO:Declaring metric variables
2025-02-06 22:18:20,318:INFO:Importing untrained model
2025-02-06 22:18:20,318:INFO:Declaring custom model
2025-02-06 22:18:20,319:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:20,322:INFO:Starting cross validation
2025-02-06 22:18:20,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:20,410:INFO:Calculating mean and std
2025-02-06 22:18:20,410:INFO:Creating metrics dataframe
2025-02-06 22:18:20,412:INFO:Finalizing model
2025-02-06 22:18:20,444:INFO:Uploading results into container
2025-02-06 22:18:20,444:INFO:Uploading model into container now
2025-02-06 22:18:20,444:INFO:_master_model_container: 7
2025-02-06 22:18:20,444:INFO:_display_container: 6
2025-02-06 22:18:20,445:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:20,445:INFO:create_model() successfully completed......................................
2025-02-06 22:18:20,491:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:20,491:INFO:choose_better activated
2025-02-06 22:18:20,492:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:20,493:INFO:Initializing create_model()
2025-02-06 22:18:20,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:20,493:INFO:Checking exceptions
2025-02-06 22:18:20,493:INFO:Importing libraries
2025-02-06 22:18:20,493:INFO:Copying training dataset
2025-02-06 22:18:20,499:INFO:Defining folds
2025-02-06 22:18:20,499:INFO:Declaring metric variables
2025-02-06 22:18:20,499:INFO:Importing untrained model
2025-02-06 22:18:20,499:INFO:Declaring custom model
2025-02-06 22:18:20,499:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:20,499:INFO:Starting cross validation
2025-02-06 22:18:20,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:20,557:INFO:Calculating mean and std
2025-02-06 22:18:20,557:INFO:Creating metrics dataframe
2025-02-06 22:18:20,558:INFO:Finalizing model
2025-02-06 22:18:20,583:INFO:Uploading results into container
2025-02-06 22:18:20,583:INFO:Uploading model into container now
2025-02-06 22:18:20,584:INFO:_master_model_container: 8
2025-02-06 22:18:20,584:INFO:_display_container: 7
2025-02-06 22:18:20,584:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:20,584:INFO:create_model() successfully completed......................................
2025-02-06 22:18:20,631:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:20,631:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7856
2025-02-06 22:18:20,631:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.7857
2025-02-06 22:18:20,632:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-02-06 22:18:20,632:INFO:choose_better completed
2025-02-06 22:18:20,635:INFO:_master_model_container: 8
2025-02-06 22:18:20,635:INFO:_display_container: 6
2025-02-06 22:18:20,636:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:20,636:INFO:tune_model() successfully completed......................................
2025-02-06 22:18:20,670:INFO:Initializing compare_models()
2025-02-06 22:18:20,670:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, include=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, 'include': [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-06 22:18:20,670:INFO:Checking exceptions
2025-02-06 22:18:20,673:INFO:Preparing display monitor
2025-02-06 22:18:20,682:INFO:Initializing custom model Light Gradient Boosting Machine
2025-02-06 22:18:20,682:INFO:Total runtime is 0.0 minutes
2025-02-06 22:18:20,683:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:20,684:INFO:Initializing create_model()
2025-02-06 22:18:20,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661DA1D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:20,684:INFO:Checking exceptions
2025-02-06 22:18:20,684:INFO:Importing libraries
2025-02-06 22:18:20,684:INFO:Copying training dataset
2025-02-06 22:18:20,690:INFO:Defining folds
2025-02-06 22:18:20,690:INFO:Declaring metric variables
2025-02-06 22:18:20,692:INFO:Importing untrained model
2025-02-06 22:18:20,692:INFO:Declaring custom model
2025-02-06 22:18:20,693:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:20,696:INFO:Starting cross validation
2025-02-06 22:18:20,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:21,002:INFO:Calculating mean and std
2025-02-06 22:18:21,002:INFO:Creating metrics dataframe
2025-02-06 22:18:21,003:INFO:Uploading results into container
2025-02-06 22:18:21,003:INFO:Uploading model into container now
2025-02-06 22:18:21,003:INFO:_master_model_container: 9
2025-02-06 22:18:21,004:INFO:_display_container: 7
2025-02-06 22:18:21,004:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:21,004:INFO:create_model() successfully completed......................................
2025-02-06 22:18:21,064:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:21,064:INFO:Creating metrics dataframe
2025-02-06 22:18:21,069:INFO:Initializing custom model Logistic Regression
2025-02-06 22:18:21,069:INFO:Total runtime is 0.006440814336140951 minutes
2025-02-06 22:18:21,071:INFO:SubProcess create_model() called ==================================
2025-02-06 22:18:21,071:INFO:Initializing create_model()
2025-02-06 22:18:21,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001661DA1D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:21,071:INFO:Checking exceptions
2025-02-06 22:18:21,071:INFO:Importing libraries
2025-02-06 22:18:21,072:INFO:Copying training dataset
2025-02-06 22:18:21,081:INFO:Defining folds
2025-02-06 22:18:21,081:INFO:Declaring metric variables
2025-02-06 22:18:21,083:INFO:Importing untrained model
2025-02-06 22:18:21,083:INFO:Declaring custom model
2025-02-06 22:18:21,085:INFO:Logistic Regression Imported successfully
2025-02-06 22:18:21,089:INFO:Starting cross validation
2025-02-06 22:18:21,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-06 22:18:21,167:INFO:Calculating mean and std
2025-02-06 22:18:21,167:INFO:Creating metrics dataframe
2025-02-06 22:18:21,168:INFO:Uploading results into container
2025-02-06 22:18:21,168:INFO:Uploading model into container now
2025-02-06 22:18:21,168:INFO:_master_model_container: 10
2025-02-06 22:18:21,168:INFO:_display_container: 7
2025-02-06 22:18:21,168:INFO:LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-06 22:18:21,169:INFO:create_model() successfully completed......................................
2025-02-06 22:18:21,214:INFO:SubProcess create_model() end ==================================
2025-02-06 22:18:21,214:INFO:Creating metrics dataframe
2025-02-06 22:18:21,218:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-02-06 22:18:21,221:INFO:Initializing create_model()
2025-02-06 22:18:21,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-06 22:18:21,222:INFO:Checking exceptions
2025-02-06 22:18:21,222:INFO:Importing libraries
2025-02-06 22:18:21,222:INFO:Copying training dataset
2025-02-06 22:18:21,228:INFO:Defining folds
2025-02-06 22:18:21,228:INFO:Declaring metric variables
2025-02-06 22:18:21,228:INFO:Importing untrained model
2025-02-06 22:18:21,228:INFO:Declaring custom model
2025-02-06 22:18:21,229:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-06 22:18:21,229:INFO:Cross validation set to False
2025-02-06 22:18:21,229:INFO:Fitting Model
2025-02-06 22:18:21,242:INFO:[LightGBM] [Info] Number of positive: 1482, number of negative: 3772
2025-02-06 22:18:21,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-02-06 22:18:21,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-02-06 22:18:21,244:INFO:[LightGBM] [Info] Total Bins 6546
2025-02-06 22:18:21,244:INFO:[LightGBM] [Info] Number of data points in the train set: 5254, number of used features: 34
2025-02-06 22:18:21,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282071 -> initscore=-0.934213
2025-02-06 22:18:21,244:INFO:[LightGBM] [Info] Start training from score -0.934213
2025-02-06 22:18:21,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-02-06 22:18:21,274:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:21,274:INFO:create_model() successfully completed......................................
2025-02-06 22:18:21,342:INFO:_master_model_container: 10
2025-02-06 22:18:21,342:INFO:_display_container: 7
2025-02-06 22:18:21,343:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-06 22:18:21,343:INFO:compare_models() successfully completed......................................
2025-02-06 22:18:21,343:INFO:Initializing predict_model()
2025-02-06 22:18:21,344:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001661E15A2A0>)
2025-02-06 22:18:21,344:INFO:Checking exceptions
2025-02-06 22:18:21,344:INFO:Preloading libraries
2025-02-06 22:18:21,345:INFO:Set up data.
2025-02-06 22:18:21,354:INFO:Set up index.
2025-02-06 22:18:21,451:INFO:Initializing predict_model()
2025-02-06 22:18:21,451:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,
               importance_type='split', learning_rate=0.05, max_depth=3,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=10, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.5, subsample=0.6,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001661E15A2A0>)
2025-02-06 22:18:21,451:INFO:Checking exceptions
2025-02-06 22:18:21,451:INFO:Preloading libraries
2025-02-06 22:18:21,452:INFO:Set up data.
2025-02-06 22:18:21,459:INFO:Set up index.
2025-02-06 22:18:21,548:INFO:Initializing predict_model()
2025-02-06 22:18:21,548:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=0.5, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001661D33FBA0>)
2025-02-06 22:18:21,548:INFO:Checking exceptions
2025-02-06 22:18:21,548:INFO:Preloading libraries
2025-02-06 22:18:21,549:INFO:Set up data.
2025-02-06 22:18:21,557:INFO:Set up index.
2025-02-06 22:18:21,643:INFO:Initializing predict_model()
2025-02-06 22:18:21,643:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016659AB4490>, estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=0.5, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001661D33FBA0>)
2025-02-06 22:18:21,643:INFO:Checking exceptions
2025-02-06 22:18:21,643:INFO:Preloading libraries
2025-02-06 22:18:21,644:INFO:Set up data.
2025-02-06 22:18:21,648:INFO:Set up index.
2025-02-07 08:19:00,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-07 08:19:00,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-07 08:19:00,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-07 08:19:00,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-07 08:24:38,538:INFO:PyCaret ClassificationExperiment
2025-02-07 08:24:38,538:INFO:Logging name: clf-default-name
2025-02-07 08:24:38,538:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-07 08:24:38,538:INFO:version 3.3.2
2025-02-07 08:24:38,538:INFO:Initializing setup()
2025-02-07 08:24:38,538:INFO:self.USI: e6c7
2025-02-07 08:24:38,539:INFO:self._variable_keys: {'X', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'exp_name_log', '_ml_usecase', 'html_param', 'log_plots_param', 'data', 'idx', 'y_test', 'X_test', 'pipeline', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'USI', '_available_plots', 'target_param', 'X_train', 'seed', 'fix_imbalance', 'logging_param', 'n_jobs_param'}
2025-02-07 08:24:38,539:INFO:Checking environment
2025-02-07 08:24:38,539:INFO:python_version: 3.11.9
2025-02-07 08:24:38,539:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-07 08:24:38,539:INFO:machine: AMD64
2025-02-07 08:24:38,539:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-07 08:24:38,543:INFO:Memory: svmem(total=67771465728, available=48369864704, percent=28.6, used=19401601024, free=48369864704)
2025-02-07 08:24:38,543:INFO:Physical Core: 8
2025-02-07 08:24:38,543:INFO:Logical Core: 16
2025-02-07 08:24:38,543:INFO:Checking libraries
2025-02-07 08:24:38,543:INFO:System:
2025-02-07 08:24:38,543:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-07 08:24:38,543:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-07 08:24:38,543:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-07 08:24:38,543:INFO:PyCaret required dependencies:
2025-02-07 08:24:38,588:INFO:                 pip: 25.0
2025-02-07 08:24:38,588:INFO:          setuptools: 65.5.0
2025-02-07 08:24:38,588:INFO:             pycaret: 3.3.2
2025-02-07 08:24:38,588:INFO:             IPython: 8.32.0
2025-02-07 08:24:38,588:INFO:          ipywidgets: 8.1.5
2025-02-07 08:24:38,588:INFO:                tqdm: 4.67.1
2025-02-07 08:24:38,588:INFO:               numpy: 1.26.4
2025-02-07 08:24:38,588:INFO:              pandas: 2.1.4
2025-02-07 08:24:38,588:INFO:              jinja2: 3.1.5
2025-02-07 08:24:38,588:INFO:               scipy: 1.11.4
2025-02-07 08:24:38,588:INFO:              joblib: 1.3.2
2025-02-07 08:24:38,588:INFO:             sklearn: 1.4.2
2025-02-07 08:24:38,588:INFO:                pyod: 2.0.3
2025-02-07 08:24:38,588:INFO:            imblearn: 0.13.0
2025-02-07 08:24:38,588:INFO:   category_encoders: 2.7.0
2025-02-07 08:24:38,588:INFO:            lightgbm: 4.5.0
2025-02-07 08:24:38,588:INFO:               numba: 0.61.0
2025-02-07 08:24:38,588:INFO:            requests: 2.32.3
2025-02-07 08:24:38,588:INFO:          matplotlib: 3.7.5
2025-02-07 08:24:38,588:INFO:          scikitplot: 0.3.7
2025-02-07 08:24:38,588:INFO:         yellowbrick: 1.5
2025-02-07 08:24:38,588:INFO:              plotly: 5.24.1
2025-02-07 08:24:38,588:INFO:    plotly-resampler: Not installed
2025-02-07 08:24:38,589:INFO:             kaleido: 0.2.1
2025-02-07 08:24:38,589:INFO:           schemdraw: 0.15
2025-02-07 08:24:38,589:INFO:         statsmodels: 0.14.4
2025-02-07 08:24:38,589:INFO:              sktime: 0.26.0
2025-02-07 08:24:38,589:INFO:               tbats: 1.1.3
2025-02-07 08:24:38,589:INFO:            pmdarima: 2.0.4
2025-02-07 08:24:38,589:INFO:              psutil: 6.1.1
2025-02-07 08:24:38,589:INFO:          markupsafe: 3.0.2
2025-02-07 08:24:38,589:INFO:             pickle5: Not installed
2025-02-07 08:24:38,589:INFO:         cloudpickle: 3.1.1
2025-02-07 08:24:38,589:INFO:         deprecation: 2.1.0
2025-02-07 08:24:38,589:INFO:              xxhash: 3.5.0
2025-02-07 08:24:38,589:INFO:           wurlitzer: Not installed
2025-02-07 08:24:38,589:INFO:PyCaret optional dependencies:
2025-02-07 08:24:38,597:INFO:                shap: Not installed
2025-02-07 08:24:38,597:INFO:           interpret: Not installed
2025-02-07 08:24:38,597:INFO:                umap: Not installed
2025-02-07 08:24:38,597:INFO:     ydata_profiling: Not installed
2025-02-07 08:24:38,597:INFO:  explainerdashboard: Not installed
2025-02-07 08:24:38,597:INFO:             autoviz: Not installed
2025-02-07 08:24:38,597:INFO:           fairlearn: Not installed
2025-02-07 08:24:38,597:INFO:          deepchecks: Not installed
2025-02-07 08:24:38,597:INFO:             xgboost: Not installed
2025-02-07 08:24:38,597:INFO:            catboost: Not installed
2025-02-07 08:24:38,598:INFO:              kmodes: Not installed
2025-02-07 08:24:38,598:INFO:             mlxtend: Not installed
2025-02-07 08:24:38,598:INFO:       statsforecast: Not installed
2025-02-07 08:24:38,598:INFO:        tune_sklearn: Not installed
2025-02-07 08:24:38,598:INFO:                 ray: Not installed
2025-02-07 08:24:38,598:INFO:            hyperopt: Not installed
2025-02-07 08:24:38,598:INFO:              optuna: Not installed
2025-02-07 08:24:38,598:INFO:               skopt: Not installed
2025-02-07 08:24:38,598:INFO:              mlflow: Not installed
2025-02-07 08:24:38,598:INFO:              gradio: Not installed
2025-02-07 08:24:38,598:INFO:             fastapi: Not installed
2025-02-07 08:24:38,598:INFO:             uvicorn: Not installed
2025-02-07 08:24:38,598:INFO:              m2cgen: Not installed
2025-02-07 08:24:38,598:INFO:           evidently: Not installed
2025-02-07 08:24:38,598:INFO:               fugue: Not installed
2025-02-07 08:24:38,598:INFO:           streamlit: Not installed
2025-02-07 08:24:38,598:INFO:             prophet: Not installed
2025-02-07 08:24:38,598:INFO:None
2025-02-07 08:24:38,598:INFO:Set up data.
2025-02-07 08:24:48,072:INFO:PyCaret ClassificationExperiment
2025-02-07 08:24:48,072:INFO:Logging name: clf-default-name
2025-02-07 08:24:48,072:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-07 08:24:48,072:INFO:version 3.3.2
2025-02-07 08:24:48,072:INFO:Initializing setup()
2025-02-07 08:24:48,072:INFO:self.USI: 39b8
2025-02-07 08:24:48,072:INFO:self._variable_keys: {'X', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'exp_name_log', '_ml_usecase', 'html_param', 'log_plots_param', 'data', 'idx', 'y_test', 'X_test', 'pipeline', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'USI', '_available_plots', 'target_param', 'X_train', 'seed', 'fix_imbalance', 'logging_param', 'n_jobs_param'}
2025-02-07 08:24:48,072:INFO:Checking environment
2025-02-07 08:24:48,072:INFO:python_version: 3.11.9
2025-02-07 08:24:48,072:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-07 08:24:48,072:INFO:machine: AMD64
2025-02-07 08:24:48,072:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-07 08:24:48,076:INFO:Memory: svmem(total=67771465728, available=48379555840, percent=28.6, used=19391909888, free=48379555840)
2025-02-07 08:24:48,076:INFO:Physical Core: 8
2025-02-07 08:24:48,076:INFO:Logical Core: 16
2025-02-07 08:24:48,077:INFO:Checking libraries
2025-02-07 08:24:48,077:INFO:System:
2025-02-07 08:24:48,077:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-07 08:24:48,077:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-07 08:24:48,077:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-07 08:24:48,077:INFO:PyCaret required dependencies:
2025-02-07 08:24:48,077:INFO:                 pip: 25.0
2025-02-07 08:24:48,077:INFO:          setuptools: 65.5.0
2025-02-07 08:24:48,077:INFO:             pycaret: 3.3.2
2025-02-07 08:24:48,077:INFO:             IPython: 8.32.0
2025-02-07 08:24:48,077:INFO:          ipywidgets: 8.1.5
2025-02-07 08:24:48,077:INFO:                tqdm: 4.67.1
2025-02-07 08:24:48,077:INFO:               numpy: 1.26.4
2025-02-07 08:24:48,077:INFO:              pandas: 2.1.4
2025-02-07 08:24:48,077:INFO:              jinja2: 3.1.5
2025-02-07 08:24:48,077:INFO:               scipy: 1.11.4
2025-02-07 08:24:48,077:INFO:              joblib: 1.3.2
2025-02-07 08:24:48,077:INFO:             sklearn: 1.4.2
2025-02-07 08:24:48,077:INFO:                pyod: 2.0.3
2025-02-07 08:24:48,077:INFO:            imblearn: 0.13.0
2025-02-07 08:24:48,077:INFO:   category_encoders: 2.7.0
2025-02-07 08:24:48,077:INFO:            lightgbm: 4.5.0
2025-02-07 08:24:48,077:INFO:               numba: 0.61.0
2025-02-07 08:24:48,077:INFO:            requests: 2.32.3
2025-02-07 08:24:48,077:INFO:          matplotlib: 3.7.5
2025-02-07 08:24:48,077:INFO:          scikitplot: 0.3.7
2025-02-07 08:24:48,077:INFO:         yellowbrick: 1.5
2025-02-07 08:24:48,077:INFO:              plotly: 5.24.1
2025-02-07 08:24:48,077:INFO:    plotly-resampler: Not installed
2025-02-07 08:24:48,077:INFO:             kaleido: 0.2.1
2025-02-07 08:24:48,077:INFO:           schemdraw: 0.15
2025-02-07 08:24:48,077:INFO:         statsmodels: 0.14.4
2025-02-07 08:24:48,077:INFO:              sktime: 0.26.0
2025-02-07 08:24:48,077:INFO:               tbats: 1.1.3
2025-02-07 08:24:48,077:INFO:            pmdarima: 2.0.4
2025-02-07 08:24:48,077:INFO:              psutil: 6.1.1
2025-02-07 08:24:48,077:INFO:          markupsafe: 3.0.2
2025-02-07 08:24:48,077:INFO:             pickle5: Not installed
2025-02-07 08:24:48,077:INFO:         cloudpickle: 3.1.1
2025-02-07 08:24:48,077:INFO:         deprecation: 2.1.0
2025-02-07 08:24:48,077:INFO:              xxhash: 3.5.0
2025-02-07 08:24:48,077:INFO:           wurlitzer: Not installed
2025-02-07 08:24:48,077:INFO:PyCaret optional dependencies:
2025-02-07 08:24:48,077:INFO:                shap: Not installed
2025-02-07 08:24:48,077:INFO:           interpret: Not installed
2025-02-07 08:24:48,077:INFO:                umap: Not installed
2025-02-07 08:24:48,077:INFO:     ydata_profiling: Not installed
2025-02-07 08:24:48,077:INFO:  explainerdashboard: Not installed
2025-02-07 08:24:48,077:INFO:             autoviz: Not installed
2025-02-07 08:24:48,077:INFO:           fairlearn: Not installed
2025-02-07 08:24:48,077:INFO:          deepchecks: Not installed
2025-02-07 08:24:48,077:INFO:             xgboost: Not installed
2025-02-07 08:24:48,077:INFO:            catboost: Not installed
2025-02-07 08:24:48,077:INFO:              kmodes: Not installed
2025-02-07 08:24:48,077:INFO:             mlxtend: Not installed
2025-02-07 08:24:48,077:INFO:       statsforecast: Not installed
2025-02-07 08:24:48,077:INFO:        tune_sklearn: Not installed
2025-02-07 08:24:48,078:INFO:                 ray: Not installed
2025-02-07 08:24:48,078:INFO:            hyperopt: Not installed
2025-02-07 08:24:48,078:INFO:              optuna: Not installed
2025-02-07 08:24:48,078:INFO:               skopt: Not installed
2025-02-07 08:24:48,078:INFO:              mlflow: Not installed
2025-02-07 08:24:48,078:INFO:              gradio: Not installed
2025-02-07 08:24:48,078:INFO:             fastapi: Not installed
2025-02-07 08:24:48,078:INFO:             uvicorn: Not installed
2025-02-07 08:24:48,078:INFO:              m2cgen: Not installed
2025-02-07 08:24:48,078:INFO:           evidently: Not installed
2025-02-07 08:24:48,078:INFO:               fugue: Not installed
2025-02-07 08:24:48,078:INFO:           streamlit: Not installed
2025-02-07 08:24:48,078:INFO:             prophet: Not installed
2025-02-07 08:24:48,078:INFO:None
2025-02-07 08:24:48,078:INFO:Set up data.
2025-02-07 08:24:48,087:INFO:Set up folding strategy.
2025-02-07 08:24:48,087:INFO:Set up train/test split.
2025-02-07 08:24:48,096:INFO:Set up index.
2025-02-07 08:24:48,097:INFO:Assigning column types.
2025-02-07 08:24:48,102:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-07 08:24:48,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,188:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-07 08:24:48,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,251:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:24:48,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,335:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-07 08:24:48,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,414:INFO:Preparing preprocessing pipeline...
2025-02-07 08:24:48,415:INFO:Set up simple imputation.
2025-02-07 08:24:48,416:INFO:Set up feature selection.
2025-02-07 08:24:48,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,640:INFO:Finished creating preprocessing pipeline.
2025-02-07 08:24:48,647:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'safra', 'VAR_1', 'VAR_2',
                                             'VAR_3', 'VAR_4', 'VAR_5', 'VAR_6',
                                             'VAR_7', 'VAR_8', 'VAR_9',
                                             'VAR_11', 'VAR_13', 'VAR_15',
                                             'VAR_17', 'VAR_19', 'VAR_20',
                                             'VAR_22', 'VAR_24', 'VAR_25',
                                             'VAR_28', 'VAR_30', 'VAR_32',
                                             'VAR_33...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=8,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-02-07 08:24:48,647:INFO:Creating final display dataframe.
2025-02-07 08:24:48,794:INFO:Setup _display_container:                     Description             Value
0                    Session id              3548
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape         (8211, 9)
5   Transformed train set shape         (5747, 9)
6    Transformed test set shape         (2464, 9)
7              Numeric features                42
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12            Feature selection              True
13     Feature selection method           classic
14  Feature selection estimator          lightgbm
15  Number of features selected               0.2
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              39b8
2025-02-07 08:24:48,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:24:48,896:INFO:setup() successfully completed in 0.82s...............
2025-02-07 08:26:01,028:INFO:PyCaret ClassificationExperiment
2025-02-07 08:26:01,028:INFO:Logging name: clf-default-name
2025-02-07 08:26:01,028:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-07 08:26:01,028:INFO:version 3.3.2
2025-02-07 08:26:01,028:INFO:Initializing setup()
2025-02-07 08:26:01,028:INFO:self.USI: d30c
2025-02-07 08:26:01,029:INFO:self._variable_keys: {'X', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'exp_name_log', '_ml_usecase', 'html_param', 'log_plots_param', 'data', 'idx', 'y_test', 'X_test', 'pipeline', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'USI', '_available_plots', 'target_param', 'X_train', 'seed', 'fix_imbalance', 'logging_param', 'n_jobs_param'}
2025-02-07 08:26:01,029:INFO:Checking environment
2025-02-07 08:26:01,029:INFO:python_version: 3.11.9
2025-02-07 08:26:01,029:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-07 08:26:01,029:INFO:machine: AMD64
2025-02-07 08:26:01,029:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-07 08:26:01,033:INFO:Memory: svmem(total=67771465728, available=48263872512, percent=28.8, used=19507593216, free=48263872512)
2025-02-07 08:26:01,033:INFO:Physical Core: 8
2025-02-07 08:26:01,033:INFO:Logical Core: 16
2025-02-07 08:26:01,033:INFO:Checking libraries
2025-02-07 08:26:01,033:INFO:System:
2025-02-07 08:26:01,033:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-07 08:26:01,033:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-07 08:26:01,033:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-07 08:26:01,033:INFO:PyCaret required dependencies:
2025-02-07 08:26:01,034:INFO:                 pip: 25.0
2025-02-07 08:26:01,034:INFO:          setuptools: 65.5.0
2025-02-07 08:26:01,034:INFO:             pycaret: 3.3.2
2025-02-07 08:26:01,034:INFO:             IPython: 8.32.0
2025-02-07 08:26:01,034:INFO:          ipywidgets: 8.1.5
2025-02-07 08:26:01,034:INFO:                tqdm: 4.67.1
2025-02-07 08:26:01,034:INFO:               numpy: 1.26.4
2025-02-07 08:26:01,034:INFO:              pandas: 2.1.4
2025-02-07 08:26:01,034:INFO:              jinja2: 3.1.5
2025-02-07 08:26:01,034:INFO:               scipy: 1.11.4
2025-02-07 08:26:01,034:INFO:              joblib: 1.3.2
2025-02-07 08:26:01,034:INFO:             sklearn: 1.4.2
2025-02-07 08:26:01,034:INFO:                pyod: 2.0.3
2025-02-07 08:26:01,034:INFO:            imblearn: 0.13.0
2025-02-07 08:26:01,034:INFO:   category_encoders: 2.7.0
2025-02-07 08:26:01,034:INFO:            lightgbm: 4.5.0
2025-02-07 08:26:01,034:INFO:               numba: 0.61.0
2025-02-07 08:26:01,034:INFO:            requests: 2.32.3
2025-02-07 08:26:01,034:INFO:          matplotlib: 3.7.5
2025-02-07 08:26:01,034:INFO:          scikitplot: 0.3.7
2025-02-07 08:26:01,034:INFO:         yellowbrick: 1.5
2025-02-07 08:26:01,034:INFO:              plotly: 5.24.1
2025-02-07 08:26:01,034:INFO:    plotly-resampler: Not installed
2025-02-07 08:26:01,034:INFO:             kaleido: 0.2.1
2025-02-07 08:26:01,034:INFO:           schemdraw: 0.15
2025-02-07 08:26:01,034:INFO:         statsmodels: 0.14.4
2025-02-07 08:26:01,034:INFO:              sktime: 0.26.0
2025-02-07 08:26:01,034:INFO:               tbats: 1.1.3
2025-02-07 08:26:01,034:INFO:            pmdarima: 2.0.4
2025-02-07 08:26:01,034:INFO:              psutil: 6.1.1
2025-02-07 08:26:01,034:INFO:          markupsafe: 3.0.2
2025-02-07 08:26:01,034:INFO:             pickle5: Not installed
2025-02-07 08:26:01,034:INFO:         cloudpickle: 3.1.1
2025-02-07 08:26:01,034:INFO:         deprecation: 2.1.0
2025-02-07 08:26:01,034:INFO:              xxhash: 3.5.0
2025-02-07 08:26:01,034:INFO:           wurlitzer: Not installed
2025-02-07 08:26:01,034:INFO:PyCaret optional dependencies:
2025-02-07 08:26:01,034:INFO:                shap: Not installed
2025-02-07 08:26:01,034:INFO:           interpret: Not installed
2025-02-07 08:26:01,034:INFO:                umap: Not installed
2025-02-07 08:26:01,034:INFO:     ydata_profiling: Not installed
2025-02-07 08:26:01,034:INFO:  explainerdashboard: Not installed
2025-02-07 08:26:01,034:INFO:             autoviz: Not installed
2025-02-07 08:26:01,034:INFO:           fairlearn: Not installed
2025-02-07 08:26:01,034:INFO:          deepchecks: Not installed
2025-02-07 08:26:01,034:INFO:             xgboost: Not installed
2025-02-07 08:26:01,034:INFO:            catboost: Not installed
2025-02-07 08:26:01,034:INFO:              kmodes: Not installed
2025-02-07 08:26:01,034:INFO:             mlxtend: Not installed
2025-02-07 08:26:01,034:INFO:       statsforecast: Not installed
2025-02-07 08:26:01,034:INFO:        tune_sklearn: Not installed
2025-02-07 08:26:01,034:INFO:                 ray: Not installed
2025-02-07 08:26:01,034:INFO:            hyperopt: Not installed
2025-02-07 08:26:01,034:INFO:              optuna: Not installed
2025-02-07 08:26:01,034:INFO:               skopt: Not installed
2025-02-07 08:26:01,034:INFO:              mlflow: Not installed
2025-02-07 08:26:01,034:INFO:              gradio: Not installed
2025-02-07 08:26:01,034:INFO:             fastapi: Not installed
2025-02-07 08:26:01,034:INFO:             uvicorn: Not installed
2025-02-07 08:26:01,034:INFO:              m2cgen: Not installed
2025-02-07 08:26:01,034:INFO:           evidently: Not installed
2025-02-07 08:26:01,034:INFO:               fugue: Not installed
2025-02-07 08:26:01,034:INFO:           streamlit: Not installed
2025-02-07 08:26:01,034:INFO:             prophet: Not installed
2025-02-07 08:26:01,034:INFO:None
2025-02-07 08:26:01,034:INFO:Set up data.
2025-02-07 08:26:01,044:INFO:Set up folding strategy.
2025-02-07 08:26:01,044:INFO:Set up train/test split.
2025-02-07 08:26:01,051:INFO:Set up index.
2025-02-07 08:26:01,051:INFO:Assigning column types.
2025-02-07 08:26:01,058:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-07 08:26:01,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,082:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,120:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,135:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-07 08:26:01,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,213:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-07 08:26:01,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,291:INFO:Preparing preprocessing pipeline...
2025-02-07 08:26:01,293:INFO:Set up simple imputation.
2025-02-07 08:26:01,293:INFO:Set up feature selection.
2025-02-07 08:26:01,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,430:INFO:Finished creating preprocessing pipeline.
2025-02-07 08:26:01,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'safra', 'VAR_1', 'VAR_2',
                                             'VAR_3', 'VAR_4', 'VAR_5', 'VAR_6',
                                             'VAR_7', 'VAR_8', 'VAR_9',
                                             'VAR_11', 'VAR_13', 'VAR_15',
                                             'VAR_17', 'VAR_19', 'VAR_20',
                                             'VAR_22', 'VAR_24', 'VAR_25',
                                             'VAR_28', 'VAR_30', 'VAR_32',
                                             'VAR_33...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=8,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-02-07 08:26:01,436:INFO:Creating final display dataframe.
2025-02-07 08:26:01,568:INFO:Setup _display_container:                     Description             Value
0                    Session id               502
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape         (8211, 9)
5   Transformed train set shape         (5747, 9)
6    Transformed test set shape         (2464, 9)
7              Numeric features                42
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12            Feature selection              True
13     Feature selection method           classic
14  Feature selection estimator          lightgbm
15  Number of features selected               0.2
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d30c
2025-02-07 08:26:01,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,675:INFO:setup() successfully completed in 0.65s...............
2025-02-07 08:26:01,675:INFO:Initializing get_config()
2025-02-07 08:26:01,675:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013E23969790>, variable=X_train)
2025-02-07 08:26:01,675:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-02-07 08:26:01,675:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-02-07 08:26:01,683:INFO:Variable:  returned as          id   safra  VAR_1  VAR_2  VAR_3  VAR_4       VAR_5   VAR_6  \
535     669  201401   25.0    0.0    0.0    0.0   71.769997  1757.0   
3758   4881  201409   17.0    0.0    0.0    0.0   69.410004   245.0   
1798   2314  201408    0.0    0.0    0.0    0.0   57.849998   734.0   
31       40  201408    4.0    0.0    0.0    0.0  118.370003   878.0   
3706   4814  201402  174.0    3.0    1.0    2.0   69.410004  1912.0   
...     ...     ...    ...    ...    ...    ...         ...     ...   
7344   9614  201402   18.0    0.0    0.0    0.0   69.410004   890.0   
6880   8985  201405   26.0    0.0    0.0    0.0   80.849998   453.0   
6900   9011  201401   26.0    0.0    0.0    0.0   21.500000  1757.0   
7988  10448  201404   44.0    0.0    0.0    2.0   63.919998  1917.0   
5183   6737  201405    0.0    0.0    0.0    0.0   69.410004   228.0   

          VAR_7       VAR_8  ...       VAR_53       VAR_54  VAR_57  VAR_58  \
535   53.389999   40.490002  ...  1058.979980    58.980000      55   246.0   
3758  39.990002  112.220001  ...  1600.000000  1000.000000      57   262.0   
1798   8.860000   57.660000  ...   500.000000   500.000000      50   209.0   
31     8.960000  172.970001  ...  2608.040039  1552.010010      46   649.0   
3706  58.639999   42.200001  ...  1600.000000  1230.000000      23   262.0   
...         ...         ...  ...          ...          ...     ...     ...   
7344  53.645000   55.230000  ...  4200.000000  1700.000000      51   262.0   
6880  43.180000   50.189999  ...  2224.100098  1258.000000      61   304.0   
6900  46.970001   88.800003  ...  2021.290039   840.429993      52   105.0   
7988  46.720001   85.300003  ...  3515.560059  5728.890137      47   251.0   
5183   7.400000   55.230000  ...   651.400024   651.400024      55   262.0   

          VAR_59    VAR_60  VAR_64       VAR_65  VAR_72      VAR_76  
535   107.290001  0.219380       0  4184.720215    -2.0  128.729996  
3758  250.699997  0.319425       1   552.340027   -48.0  314.250000  
1798  123.849998  0.156301       1   753.020020   -57.0  123.760002  
31    519.859985 -0.016209       1   411.489990   -48.0  292.450012  
3706  220.000000 -0.411787       0   613.059998   -22.0  926.940002  
...          ...       ...     ...          ...     ...         ...  
7344  250.699997  0.156301       0   757.989990   890.0  314.250000  
6880  250.699997  0.357324       1  1150.599976     4.0  314.250000  
6900  391.200012  0.156301       0  1407.530029    20.0  646.130005  
7988   11.700000  0.079926       1   805.859985     8.0    0.000000  
5183  250.699997  0.219380       1  1539.150024   218.0  314.250000  

[5747 rows x 42 columns]
2025-02-07 08:26:01,683:INFO:get_config() successfully completed......................................
2025-02-07 08:26:01,685:INFO:PyCaret ClassificationExperiment
2025-02-07 08:26:01,685:INFO:Logging name: clf-default-name
2025-02-07 08:26:01,685:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-07 08:26:01,685:INFO:version 3.3.2
2025-02-07 08:26:01,685:INFO:Initializing setup()
2025-02-07 08:26:01,685:INFO:self.USI: 6b82
2025-02-07 08:26:01,685:INFO:self._variable_keys: {'X', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'exp_name_log', '_ml_usecase', 'html_param', 'log_plots_param', 'data', 'idx', 'y_test', 'X_test', 'pipeline', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'USI', '_available_plots', 'target_param', 'X_train', 'seed', 'fix_imbalance', 'logging_param', 'n_jobs_param'}
2025-02-07 08:26:01,685:INFO:Checking environment
2025-02-07 08:26:01,685:INFO:python_version: 3.11.9
2025-02-07 08:26:01,685:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-07 08:26:01,685:INFO:machine: AMD64
2025-02-07 08:26:01,685:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-07 08:26:01,689:INFO:Memory: svmem(total=67771465728, available=48265834496, percent=28.8, used=19505631232, free=48265834496)
2025-02-07 08:26:01,689:INFO:Physical Core: 8
2025-02-07 08:26:01,689:INFO:Logical Core: 16
2025-02-07 08:26:01,689:INFO:Checking libraries
2025-02-07 08:26:01,689:INFO:System:
2025-02-07 08:26:01,689:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-07 08:26:01,689:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-07 08:26:01,689:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-07 08:26:01,689:INFO:PyCaret required dependencies:
2025-02-07 08:26:01,689:INFO:                 pip: 25.0
2025-02-07 08:26:01,689:INFO:          setuptools: 65.5.0
2025-02-07 08:26:01,689:INFO:             pycaret: 3.3.2
2025-02-07 08:26:01,689:INFO:             IPython: 8.32.0
2025-02-07 08:26:01,689:INFO:          ipywidgets: 8.1.5
2025-02-07 08:26:01,689:INFO:                tqdm: 4.67.1
2025-02-07 08:26:01,689:INFO:               numpy: 1.26.4
2025-02-07 08:26:01,689:INFO:              pandas: 2.1.4
2025-02-07 08:26:01,689:INFO:              jinja2: 3.1.5
2025-02-07 08:26:01,689:INFO:               scipy: 1.11.4
2025-02-07 08:26:01,689:INFO:              joblib: 1.3.2
2025-02-07 08:26:01,689:INFO:             sklearn: 1.4.2
2025-02-07 08:26:01,689:INFO:                pyod: 2.0.3
2025-02-07 08:26:01,689:INFO:            imblearn: 0.13.0
2025-02-07 08:26:01,689:INFO:   category_encoders: 2.7.0
2025-02-07 08:26:01,689:INFO:            lightgbm: 4.5.0
2025-02-07 08:26:01,689:INFO:               numba: 0.61.0
2025-02-07 08:26:01,689:INFO:            requests: 2.32.3
2025-02-07 08:26:01,689:INFO:          matplotlib: 3.7.5
2025-02-07 08:26:01,689:INFO:          scikitplot: 0.3.7
2025-02-07 08:26:01,689:INFO:         yellowbrick: 1.5
2025-02-07 08:26:01,689:INFO:              plotly: 5.24.1
2025-02-07 08:26:01,689:INFO:    plotly-resampler: Not installed
2025-02-07 08:26:01,689:INFO:             kaleido: 0.2.1
2025-02-07 08:26:01,689:INFO:           schemdraw: 0.15
2025-02-07 08:26:01,689:INFO:         statsmodels: 0.14.4
2025-02-07 08:26:01,689:INFO:              sktime: 0.26.0
2025-02-07 08:26:01,691:INFO:               tbats: 1.1.3
2025-02-07 08:26:01,691:INFO:            pmdarima: 2.0.4
2025-02-07 08:26:01,691:INFO:              psutil: 6.1.1
2025-02-07 08:26:01,691:INFO:          markupsafe: 3.0.2
2025-02-07 08:26:01,691:INFO:             pickle5: Not installed
2025-02-07 08:26:01,691:INFO:         cloudpickle: 3.1.1
2025-02-07 08:26:01,691:INFO:         deprecation: 2.1.0
2025-02-07 08:26:01,691:INFO:              xxhash: 3.5.0
2025-02-07 08:26:01,691:INFO:           wurlitzer: Not installed
2025-02-07 08:26:01,691:INFO:PyCaret optional dependencies:
2025-02-07 08:26:01,691:INFO:                shap: Not installed
2025-02-07 08:26:01,691:INFO:           interpret: Not installed
2025-02-07 08:26:01,691:INFO:                umap: Not installed
2025-02-07 08:26:01,691:INFO:     ydata_profiling: Not installed
2025-02-07 08:26:01,691:INFO:  explainerdashboard: Not installed
2025-02-07 08:26:01,691:INFO:             autoviz: Not installed
2025-02-07 08:26:01,691:INFO:           fairlearn: Not installed
2025-02-07 08:26:01,691:INFO:          deepchecks: Not installed
2025-02-07 08:26:01,691:INFO:             xgboost: Not installed
2025-02-07 08:26:01,691:INFO:            catboost: Not installed
2025-02-07 08:26:01,691:INFO:              kmodes: Not installed
2025-02-07 08:26:01,691:INFO:             mlxtend: Not installed
2025-02-07 08:26:01,691:INFO:       statsforecast: Not installed
2025-02-07 08:26:01,691:INFO:        tune_sklearn: Not installed
2025-02-07 08:26:01,691:INFO:                 ray: Not installed
2025-02-07 08:26:01,691:INFO:            hyperopt: Not installed
2025-02-07 08:26:01,691:INFO:              optuna: Not installed
2025-02-07 08:26:01,691:INFO:               skopt: Not installed
2025-02-07 08:26:01,691:INFO:              mlflow: Not installed
2025-02-07 08:26:01,691:INFO:              gradio: Not installed
2025-02-07 08:26:01,691:INFO:             fastapi: Not installed
2025-02-07 08:26:01,691:INFO:             uvicorn: Not installed
2025-02-07 08:26:01,691:INFO:              m2cgen: Not installed
2025-02-07 08:26:01,691:INFO:           evidently: Not installed
2025-02-07 08:26:01,691:INFO:               fugue: Not installed
2025-02-07 08:26:01,691:INFO:           streamlit: Not installed
2025-02-07 08:26:01,691:INFO:             prophet: Not installed
2025-02-07 08:26:01,691:INFO:None
2025-02-07 08:26:01,691:INFO:Set up data.
2025-02-07 08:26:01,698:INFO:Set up folding strategy.
2025-02-07 08:26:01,698:INFO:Set up train/test split.
2025-02-07 08:26:01,705:INFO:Set up index.
2025-02-07 08:26:01,705:INFO:Assigning column types.
2025-02-07 08:26:01,711:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-07 08:26:01,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,790:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-07 08:26:01,814:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,853:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:01,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,867:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-07 08:26:01,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,946:INFO:Preparing preprocessing pipeline...
2025-02-07 08:26:01,947:INFO:Set up simple imputation.
2025-02-07 08:26:01,947:INFO:Set up feature selection.
2025-02-07 08:26:01,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:01,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,013:INFO:Finished creating preprocessing pipeline.
2025-02-07 08:26:02,014:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\MILA_D~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'safra', 'VAR_1', 'VAR_2',
                                             'VAR_3', 'VAR_4', 'VAR_5', 'VAR_6',
                                             'VAR_7', 'VAR_8', 'VAR_9',
                                             'VAR_11', 'VAR_13', 'VAR_15',
                                             'VAR_17', 'VAR_19', 'VAR_20',
                                             'VAR_22', 'VAR_24', 'VAR_25',
                                             'VAR_28', 'VAR_30', 'VAR_32',
                                             'VAR_33...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('feature_selection',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=SelectKBest(k=8,
                                                            score_func=<function f_classif at 0x0000013E22617060>)))],
         verbose=False)
2025-02-07 08:26:02,014:INFO:Creating final display dataframe.
2025-02-07 08:26:02,096:INFO:Setup _display_container:                     Description             Value
0                    Session id              4270
1                        Target                 y
2                   Target type            Binary
3           Original data shape        (8211, 43)
4        Transformed data shape         (8211, 9)
5   Transformed train set shape         (5747, 9)
6    Transformed test set shape         (2464, 9)
7              Numeric features                42
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12            Feature selection              True
13     Feature selection method        univariate
14  Feature selection estimator          lightgbm
15  Number of features selected               0.2
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              6b82
2025-02-07 08:26:02,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,175:INFO:setup() successfully completed in 0.49s...............
2025-02-07 08:26:02,175:INFO:Initializing get_config()
2025-02-07 08:26:02,175:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013E2432A2D0>, variable=X_train)
2025-02-07 08:26:02,175:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-02-07 08:26:02,175:WARNING:c:\MachineLearning\chalenge_pic_pay_env\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-02-07 08:26:02,182:INFO:Variable:  returned as          id   safra  VAR_1  VAR_2  VAR_3  VAR_4       VAR_5   VAR_6  \
871    1117  201404   16.0    0.0    0.0    0.0   41.919998  2475.0   
4258   5540  201407   54.0    0.0    0.0    1.0   51.590000   582.0   
7617   9974  201409   16.0    0.0    0.0    0.0   49.970001  2191.0   
7729  10103  201404   18.0    0.0    0.0    0.0   69.410004  2923.0   
277     340  201409   16.0    0.0    0.0    0.0  103.480003   522.0   
...     ...     ...    ...    ...    ...    ...         ...     ...   
2038   2640  201403    0.0    0.0    0.0    0.0   38.730000   452.0   
6069   7906  201405   24.0    0.0    0.0    0.0   69.410004  3067.0   
4146   5398  201401  171.0    5.0    0.0    2.0   69.410004  1046.0   
5667   7370  201402   14.0    0.0    0.0    0.0   15.990000  4419.0   
6579   8596  201405   20.0    0.0    0.0    0.0  290.660004  1381.0   

           VAR_7       VAR_8  ...       VAR_53       VAR_54  VAR_57  VAR_58  \
871    53.645000   19.090000  ...   150.000000   150.000000      35   165.0   
4258   53.645000   55.230000  ...  6759.700195  2000.000000      32   257.0   
7617    7.490000   25.719999  ...  1600.000000   500.000000      56   223.0   
7729   53.645000   55.230000  ...  2296.820068  1296.819946      34   262.0   
277    66.150002   87.980003  ...   500.000000  2100.000000      66   478.0   
...          ...         ...  ...          ...          ...     ...     ...   
2038   25.000000   47.990002  ...   500.000000   500.000000      45   190.0   
6069   53.645000   49.980000  ...   700.000000   700.000000      63   262.0   
4146   53.645000   16.600000  ...  1757.790039  1230.000000      43   262.0   
5667   53.645000   47.180000  ...  7100.000000  1230.000000      65    15.0   
6579  117.070000  401.690002  ...  5800.540039  2000.000000      23   922.0   

          VAR_59    VAR_60  VAR_64       VAR_65  VAR_72       VAR_76  
871   250.699997 -0.308453       1   551.809998    52.0   314.250000  
4258   30.080000 -0.354108       1   250.000000   167.0   102.599998  
7617  430.640015  0.242880       0   868.309998    50.0   479.670013  
7729  250.699997 -0.308453       1   757.989990  2230.0   314.250000  
277   250.699997  0.534878       1  1046.069946    32.0   314.250000  
...          ...       ...     ...          ...     ...          ...  
2038  250.699997 -0.030478       1   974.070007    81.0   314.250000  
6069  157.149994  0.412256       1    50.139999    47.0   211.369995  
4146  176.619995 -0.059299       0   757.989990   -73.0  1190.199951  
5667  377.049988  0.534878       0  3078.729980    83.0   393.369995  
6579  743.789978 -0.411787       0   412.820007   -68.0   276.989990  

[5747 rows x 42 columns]
2025-02-07 08:26:02,182:INFO:get_config() successfully completed......................................
2025-02-07 08:26:02,183:INFO:PyCaret ClassificationExperiment
2025-02-07 08:26:02,183:INFO:Logging name: clf-default-name
2025-02-07 08:26:02,183:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-07 08:26:02,183:INFO:version 3.3.2
2025-02-07 08:26:02,183:INFO:Initializing setup()
2025-02-07 08:26:02,183:INFO:self.USI: ff7e
2025-02-07 08:26:02,183:INFO:self._variable_keys: {'X', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'exp_name_log', '_ml_usecase', 'html_param', 'log_plots_param', 'data', 'idx', 'y_test', 'X_test', 'pipeline', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'USI', '_available_plots', 'target_param', 'X_train', 'seed', 'fix_imbalance', 'logging_param', 'n_jobs_param'}
2025-02-07 08:26:02,183:INFO:Checking environment
2025-02-07 08:26:02,183:INFO:python_version: 3.11.9
2025-02-07 08:26:02,183:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-02-07 08:26:02,183:INFO:machine: AMD64
2025-02-07 08:26:02,183:INFO:platform: Windows-10-10.0.26100-SP0
2025-02-07 08:26:02,189:INFO:Memory: svmem(total=67771465728, available=48263417856, percent=28.8, used=19508047872, free=48263417856)
2025-02-07 08:26:02,189:INFO:Physical Core: 8
2025-02-07 08:26:02,189:INFO:Logical Core: 16
2025-02-07 08:26:02,189:INFO:Checking libraries
2025-02-07 08:26:02,189:INFO:System:
2025-02-07 08:26:02,189:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-02-07 08:26:02,189:INFO:executable: c:\MachineLearning\chalenge_pic_pay_env\Scripts\python.exe
2025-02-07 08:26:02,189:INFO:   machine: Windows-10-10.0.26100-SP0
2025-02-07 08:26:02,189:INFO:PyCaret required dependencies:
2025-02-07 08:26:02,189:INFO:                 pip: 25.0
2025-02-07 08:26:02,189:INFO:          setuptools: 65.5.0
2025-02-07 08:26:02,189:INFO:             pycaret: 3.3.2
2025-02-07 08:26:02,189:INFO:             IPython: 8.32.0
2025-02-07 08:26:02,189:INFO:          ipywidgets: 8.1.5
2025-02-07 08:26:02,189:INFO:                tqdm: 4.67.1
2025-02-07 08:26:02,189:INFO:               numpy: 1.26.4
2025-02-07 08:26:02,189:INFO:              pandas: 2.1.4
2025-02-07 08:26:02,189:INFO:              jinja2: 3.1.5
2025-02-07 08:26:02,189:INFO:               scipy: 1.11.4
2025-02-07 08:26:02,189:INFO:              joblib: 1.3.2
2025-02-07 08:26:02,189:INFO:             sklearn: 1.4.2
2025-02-07 08:26:02,189:INFO:                pyod: 2.0.3
2025-02-07 08:26:02,189:INFO:            imblearn: 0.13.0
2025-02-07 08:26:02,189:INFO:   category_encoders: 2.7.0
2025-02-07 08:26:02,189:INFO:            lightgbm: 4.5.0
2025-02-07 08:26:02,189:INFO:               numba: 0.61.0
2025-02-07 08:26:02,189:INFO:            requests: 2.32.3
2025-02-07 08:26:02,189:INFO:          matplotlib: 3.7.5
2025-02-07 08:26:02,189:INFO:          scikitplot: 0.3.7
2025-02-07 08:26:02,189:INFO:         yellowbrick: 1.5
2025-02-07 08:26:02,189:INFO:              plotly: 5.24.1
2025-02-07 08:26:02,189:INFO:    plotly-resampler: Not installed
2025-02-07 08:26:02,189:INFO:             kaleido: 0.2.1
2025-02-07 08:26:02,189:INFO:           schemdraw: 0.15
2025-02-07 08:26:02,189:INFO:         statsmodels: 0.14.4
2025-02-07 08:26:02,189:INFO:              sktime: 0.26.0
2025-02-07 08:26:02,189:INFO:               tbats: 1.1.3
2025-02-07 08:26:02,189:INFO:            pmdarima: 2.0.4
2025-02-07 08:26:02,189:INFO:              psutil: 6.1.1
2025-02-07 08:26:02,189:INFO:          markupsafe: 3.0.2
2025-02-07 08:26:02,189:INFO:             pickle5: Not installed
2025-02-07 08:26:02,190:INFO:         cloudpickle: 3.1.1
2025-02-07 08:26:02,190:INFO:         deprecation: 2.1.0
2025-02-07 08:26:02,190:INFO:              xxhash: 3.5.0
2025-02-07 08:26:02,190:INFO:           wurlitzer: Not installed
2025-02-07 08:26:02,190:INFO:PyCaret optional dependencies:
2025-02-07 08:26:02,190:INFO:                shap: Not installed
2025-02-07 08:26:02,190:INFO:           interpret: Not installed
2025-02-07 08:26:02,190:INFO:                umap: Not installed
2025-02-07 08:26:02,190:INFO:     ydata_profiling: Not installed
2025-02-07 08:26:02,190:INFO:  explainerdashboard: Not installed
2025-02-07 08:26:02,190:INFO:             autoviz: Not installed
2025-02-07 08:26:02,190:INFO:           fairlearn: Not installed
2025-02-07 08:26:02,190:INFO:          deepchecks: Not installed
2025-02-07 08:26:02,190:INFO:             xgboost: Not installed
2025-02-07 08:26:02,190:INFO:            catboost: Not installed
2025-02-07 08:26:02,190:INFO:              kmodes: Not installed
2025-02-07 08:26:02,190:INFO:             mlxtend: Not installed
2025-02-07 08:26:02,190:INFO:       statsforecast: Not installed
2025-02-07 08:26:02,190:INFO:        tune_sklearn: Not installed
2025-02-07 08:26:02,190:INFO:                 ray: Not installed
2025-02-07 08:26:02,190:INFO:            hyperopt: Not installed
2025-02-07 08:26:02,190:INFO:              optuna: Not installed
2025-02-07 08:26:02,190:INFO:               skopt: Not installed
2025-02-07 08:26:02,190:INFO:              mlflow: Not installed
2025-02-07 08:26:02,190:INFO:              gradio: Not installed
2025-02-07 08:26:02,190:INFO:             fastapi: Not installed
2025-02-07 08:26:02,190:INFO:             uvicorn: Not installed
2025-02-07 08:26:02,190:INFO:              m2cgen: Not installed
2025-02-07 08:26:02,190:INFO:           evidently: Not installed
2025-02-07 08:26:02,190:INFO:               fugue: Not installed
2025-02-07 08:26:02,190:INFO:           streamlit: Not installed
2025-02-07 08:26:02,190:INFO:             prophet: Not installed
2025-02-07 08:26:02,190:INFO:None
2025-02-07 08:26:02,190:INFO:Set up data.
2025-02-07 08:26:02,197:INFO:Set up folding strategy.
2025-02-07 08:26:02,197:INFO:Set up train/test split.
2025-02-07 08:26:02,204:INFO:Set up index.
2025-02-07 08:26:02,204:INFO:Assigning column types.
2025-02-07 08:26:02,210:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-07 08:26:02,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,288:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-07 08:26:02,312:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-07 08:26:02,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,366:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-07 08:26:02,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,445:INFO:Preparing preprocessing pipeline...
2025-02-07 08:26:02,446:INFO:Set up simple imputation.
2025-02-07 08:26:02,446:INFO:Set up feature selection.
2025-02-07 08:26:02,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-07 08:26:02,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
